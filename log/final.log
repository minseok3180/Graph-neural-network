nohup: ignoring input
running on cuda:0
â–¶ Experiment Parameters
     batch_size: 32768
       fold_num: 5
     hidden_dim: 300
      num_layer: 3
          epoch: 100
       patience: 50
             lr: 0.001
   weight_decay: 1e-05
     label_type: multi_class
      condition: s1
           mode: concat
      data_path: ./data
        kg_name: FOODRKG
       ddi_name: DrugBank
            set: all
train setting...
HetDDI(
  (kg): HGNN(
    (dropout): Dropout(p=0.2, inplace=False)
    (node_embedding): Embedding(98744, 300)
    (gat_layers): ModuleList(
      (0): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (1): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (2): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
    )
  )
  (kg_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (mol): Mol(
    (readout): AvgPooling()
    (gnn): HGNN(
      (dropout): Dropout(p=0.2, inplace=False)
      (node_embedding): Embedding(47601, 300)
      (gat_layers): ModuleList(
        (0): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (1): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (2): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
      )
    )
  )
  (mol_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (decoder): Mlp(
    (fc_layer): Sequential(
      (0): Linear(in_features=1200, out_features=1200, bias=True)
      (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=1200, out_features=1200, bias=True)
      (5): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=1200, out_features=1200, bias=True)
      (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): ReLU()
      (11): Dropout(p=0.5, inplace=False)
    )
    (output_layer): Sequential(
      (0): Linear(in_features=1200, out_features=86, bias=False)
    )
  )
)
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:0 train loss:4.547227, train acc:1.819, train f1:0.891, train precision:1.156, train recall:1.209, train kappa:0.091
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:1 train loss:4.248011, train acc:11.139, train f1:1.315, train precision:1.753, train recall:1.948, train kappa:2.685
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:2 train loss:4.023457, train acc:14.078, train f1:1.712, train precision:2.039, train recall:2.463, train kappa:4.645
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:3 train loss:3.910114, train acc:15.683, train f1:2.051, train precision:3.632, train recall:2.933, train kappa:5.987
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:4 train loss:3.856539, train acc:16.931, train f1:2.980, train precision:5.184, train recall:3.617, train kappa:6.867
