nohup: ignoring input
running on cuda:0
â–¶ Experiment Parameters
     batch_size: 32768
       fold_num: 5
     hidden_dim: 300
      num_layer: 3
          epoch: 100
       patience: 50
             lr: 0.001
   weight_decay: 1e-05
     label_type: multi_class
      condition: s1
           mode: concat
      data_path: ./data
        kg_name: FOODRKG
       ddi_name: DrugBank
            set: all
train setting...
HetDDI(
  (kg): HGNN(
    (dropout): Dropout(p=0.2, inplace=False)
    (node_embedding): Embedding(98744, 300)
    (gat_layers): ModuleList(
      (0): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (1): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (2): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
    )
  )
  (kg_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (mol): Mol(
    (readout): AvgPooling()
    (gnn): HGNN(
      (dropout): Dropout(p=0.2, inplace=False)
      (node_embedding): Embedding(47601, 300)
      (gat_layers): ModuleList(
        (0): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (1): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (2): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
      )
    )
  )
  (mol_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (decoder): Mlp(
    (fc_layer): Sequential(
      (0): Linear(in_features=1200, out_features=1200, bias=True)
      (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=1200, out_features=1200, bias=True)
      (5): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=1200, out_features=1200, bias=True)
      (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): ReLU()
      (11): Dropout(p=0.5, inplace=False)
    )
    (output_layer): Sequential(
      (0): Linear(in_features=1200, out_features=86, bias=False)
    )
  )
)
fold:0 epoch:0 step:0 train loss:4.547227, train acc:1.819, train f1:0.891, train precision:1.156, train recall:1.209, train kappa:0.091
fold:0 epoch:0 step:1 train loss:4.247993, train acc:11.154, train f1:1.320, train precision:1.749, train recall:1.956, train kappa:2.707
fold:0 epoch:0 step:2 train loss:4.023541, train acc:14.053, train f1:1.697, train precision:1.998, train recall:2.451, train kappa:4.610
fold:0 epoch:0 step:3 train loss:3.910423, train acc:15.744, train f1:2.078, train precision:3.713, train recall:2.952, train kappa:6.051
fold:0 epoch:0 step:4 train loss:3.857174, train acc:16.861, train f1:2.996, train precision:5.313, train recall:3.614, train kappa:6.786
fold:0 epoch:0 step:5 train loss:3.819041, train acc:16.528, train f1:3.485, train precision:5.252, train recall:3.949, train kappa:7.448
fold:0 epoch:0 step:6 train loss:3.730113, train acc:18.045, train f1:4.339, train precision:7.087, train recall:4.756, train kappa:8.770
fold:0 epoch:0 step:7 train loss:3.687857, train acc:18.954, train f1:4.752, train precision:7.745, train recall:5.136, train kappa:9.938
fold:0 epoch:0 step:8 train loss:3.613863, train acc:20.096, train f1:5.131, train precision:10.612, train recall:5.532, train kappa:11.477
fold:0 epoch:0 step:9 train loss:3.552647, train acc:20.779, train f1:5.856, train precision:9.889, train recall:6.043, train kappa:12.496
fold:0 epoch:0 step:10 train loss:3.493685, train acc:21.570, train f1:6.542, train precision:10.735, train recall:6.908, train kappa:13.286
fold:0 epoch:0 step:11 train loss:3.435974, train acc:22.044, train f1:7.579, train precision:14.165, train recall:7.829, train kappa:14.268
fold:0 epoch:0        valid loss:3.358056, valid acc:26.544, valid f1:2.228, valid precision:3.000, valid recall:2.993, valid kappa:11.093
None
====================================================================================================
fold:0 epoch:1 step:0 train loss:3.333674, train acc:24.268, train f1:8.831, train precision:14.530, train recall:9.087, train kappa:16.733
fold:0 epoch:1 step:1 train loss:3.276130, train acc:24.854, train f1:9.601, train precision:15.933, train recall:9.951, train kappa:17.484
fold:0 epoch:1 step:2 train loss:3.194829, train acc:26.782, train f1:11.501, train precision:15.916, train recall:11.775, train kappa:19.689
fold:0 epoch:1 step:3 train loss:3.136656, train acc:27.579, train f1:11.539, train precision:16.746, train recall:12.298, train kappa:20.534
fold:0 epoch:1 step:4 train loss:3.112192, train acc:27.328, train f1:11.490, train precision:19.909, train recall:12.806, train kappa:20.466
fold:0 epoch:1 step:5 train loss:3.019331, train acc:28.595, train f1:13.234, train precision:20.872, train recall:13.933, train kappa:21.862
fold:0 epoch:1 step:6 train loss:2.961287, train acc:28.906, train f1:13.883, train precision:20.531, train recall:14.652, train kappa:22.457
fold:0 epoch:1 step:7 train loss:2.913662, train acc:29.767, train f1:15.440, train precision:22.196, train recall:15.596, train kappa:23.542
fold:0 epoch:1 step:8 train loss:2.844012, train acc:30.515, train f1:16.610, train precision:25.887, train recall:16.376, train kappa:24.452
fold:0 epoch:1 step:9 train loss:2.793560, train acc:32.019, train f1:18.355, train precision:27.632, train recall:17.801, train kappa:26.260
fold:0 epoch:1 step:10 train loss:2.740152, train acc:32.394, train f1:19.585, train precision:28.688, train recall:18.879, train kappa:26.931
fold:0 epoch:1 step:11 train loss:2.705470, train acc:33.018, train f1:20.872, train precision:32.839, train recall:20.660, train kappa:27.766
fold:0 epoch:1        valid loss:3.943045, valid acc:17.584, valid f1:2.169, valid precision:3.810, valid recall:3.206, valid kappa:5.949
None
====================================================================================================
fold:0 epoch:2 step:0 train loss:2.630648, train acc:34.329, train f1:22.214, train precision:31.564, train recall:21.374, train kappa:29.222
fold:0 epoch:2 step:1 train loss:2.608310, train acc:34.717, train f1:23.773, train precision:30.758, train recall:23.070, train kappa:30.032
fold:0 epoch:2 step:2 train loss:2.513761, train acc:36.902, train f1:26.381, train precision:37.856, train recall:25.942, train kappa:32.540
fold:0 epoch:2 step:3 train loss:2.467199, train acc:38.205, train f1:27.833, train precision:34.511, train recall:27.342, train kappa:34.019
fold:0 epoch:2 step:4 train loss:2.411918, train acc:39.160, train f1:29.560, train precision:36.040, train recall:29.041, train kappa:35.207
fold:0 epoch:2 step:5 train loss:2.408385, train acc:38.879, train f1:29.607, train precision:37.324, train recall:29.048, train kappa:35.051
fold:0 epoch:2 step:6 train loss:2.376692, train acc:39.694, train f1:31.006, train precision:38.336, train recall:30.222, train kappa:35.980
fold:0 epoch:2 step:7 train loss:2.310216, train acc:40.652, train f1:32.248, train precision:39.458, train recall:31.283, train kappa:37.109
fold:0 epoch:2 step:8 train loss:2.277542, train acc:41.681, train f1:33.999, train precision:40.766, train recall:33.246, train kappa:38.304
fold:0 epoch:2 step:9 train loss:2.243799, train acc:42.560, train f1:35.049, train precision:40.739, train recall:34.439, train kappa:39.280
fold:0 epoch:2 step:10 train loss:2.184605, train acc:43.530, train f1:36.446, train precision:44.512, train recall:35.893, train kappa:40.311
fold:0 epoch:2 step:11 train loss:2.137538, train acc:44.600, train f1:37.193, train precision:43.008, train recall:36.682, train kappa:41.557
fold:0 epoch:2        valid loss:3.603670, valid acc:14.489, valid f1:6.264, valid precision:10.006, valid recall:10.460, valid kappa:5.641
None
====================================================================================================
fold:0 epoch:3 step:0 train loss:2.107084, train acc:45.508, train f1:38.744, train precision:44.793, train recall:38.177, train kappa:42.540
fold:0 epoch:3 step:1 train loss:2.076048, train acc:45.996, train f1:39.850, train precision:44.996, train recall:39.409, train kappa:43.130
fold:0 epoch:3 step:2 train loss:2.039592, train acc:46.939, train f1:40.802, train precision:48.728, train recall:39.779, train kappa:44.069
fold:0 epoch:3 step:3 train loss:2.003614, train acc:47.888, train f1:42.666, train precision:48.942, train recall:41.714, train kappa:45.137
fold:0 epoch:3 step:4 train loss:1.960451, train acc:49.051, train f1:43.478, train precision:50.391, train recall:42.657, train kappa:46.358
fold:0 epoch:3 step:5 train loss:1.933650, train acc:49.896, train f1:44.441, train precision:51.007, train recall:43.474, train kappa:47.257
fold:0 epoch:3 step:6 train loss:1.913568, train acc:50.305, train f1:45.091, train precision:52.335, train recall:43.699, train kappa:47.705
fold:0 epoch:3 step:7 train loss:1.885843, train acc:50.595, train f1:45.933, train precision:52.640, train recall:44.929, train kappa:48.061
fold:0 epoch:3 step:8 train loss:1.850503, train acc:51.456, train f1:46.681, train precision:53.345, train recall:45.436, train kappa:48.978
fold:0 epoch:3 step:9 train loss:1.817613, train acc:52.631, train f1:48.329, train precision:53.919, train recall:47.307, train kappa:50.238
fold:0 epoch:3 step:10 train loss:1.780928, train acc:53.513, train f1:50.357, train precision:55.088, train recall:49.395, train kappa:51.281
fold:0 epoch:3 step:11 train loss:1.745514, train acc:54.570, train f1:50.461, train precision:55.164, train recall:49.363, train kappa:52.384
fold:0 epoch:3        valid loss:3.025460, valid acc:22.571, valid f1:17.437, valid precision:26.083, valid recall:26.721, valid kappa:17.059
None
====================================================================================================
fold:0 epoch:4 step:0 train loss:1.749051, train acc:54.590, train f1:51.015, train precision:56.715, train recall:50.229, train kappa:52.422
fold:0 epoch:4 step:1 train loss:1.716454, train acc:54.871, train f1:51.178, train precision:56.316, train recall:50.069, train kappa:52.649
fold:0 epoch:4 step:2 train loss:1.681521, train acc:55.890, train f1:52.007, train precision:57.395, train recall:50.810, train kappa:53.732
fold:0 epoch:4 step:3 train loss:1.679318, train acc:56.207, train f1:52.553, train precision:57.243, train recall:51.603, train kappa:54.061
fold:0 epoch:4 step:4 train loss:1.646137, train acc:56.876, train f1:53.736, train precision:59.640, train recall:52.443, train kappa:54.801
fold:0 epoch:4 step:5 train loss:1.636317, train acc:57.346, train f1:53.984, train precision:59.057, train recall:52.621, train kappa:55.330
fold:0 epoch:4 step:6 train loss:1.606714, train acc:57.605, train f1:55.081, train precision:61.373, train recall:53.839, train kappa:55.636
fold:0 epoch:4 step:7 train loss:1.601637, train acc:58.023, train f1:55.418, train precision:60.056, train recall:54.318, train kappa:56.079
fold:0 epoch:4 step:8 train loss:1.581182, train acc:58.649, train f1:55.907, train precision:60.606, train recall:54.675, train kappa:56.754
fold:0 epoch:4 step:9 train loss:1.556648, train acc:59.595, train f1:56.964, train precision:61.287, train recall:55.931, train kappa:57.788
fold:0 epoch:4 step:10 train loss:1.539777, train acc:59.668, train f1:57.045, train precision:60.878, train recall:56.115, train kappa:57.823
fold:0 epoch:4 step:11 train loss:1.559204, train acc:59.521, train f1:57.565, train precision:62.344, train recall:56.513, train kappa:57.678
fold:0 epoch:4        valid loss:2.233287, valid acc:37.825, valid f1:27.255, valid precision:32.864, valid recall:42.818, valid kappa:32.529
None
====================================================================================================
fold:0 epoch:5 step:0 train loss:1.515174, train acc:60.590, train f1:57.503, train precision:62.262, train recall:56.400, train kappa:58.769
fold:0 epoch:5 step:1 train loss:1.492141, train acc:60.855, train f1:58.009, train precision:62.911, train recall:56.466, train kappa:59.041
fold:0 epoch:5 step:2 train loss:1.482815, train acc:61.523, train f1:58.964, train precision:63.501, train recall:57.466, train kappa:59.809
fold:0 epoch:5 step:3 train loss:1.471224, train acc:61.673, train f1:59.015, train precision:63.177, train recall:58.110, train kappa:59.943
fold:0 epoch:5 step:4 train loss:1.442969, train acc:62.521, train f1:59.383, train precision:62.834, train recall:59.089, train kappa:60.861
fold:0 epoch:5 step:5 train loss:1.425726, train acc:62.650, train f1:60.174, train precision:63.422, train recall:59.557, train kappa:61.037
fold:0 epoch:5 step:6 train loss:1.416241, train acc:62.823, train f1:60.063, train precision:64.319, train recall:58.696, train kappa:61.136
fold:0 epoch:5 step:7 train loss:1.400591, train acc:63.489, train f1:60.811, train precision:64.899, train recall:59.332, train kappa:61.845
fold:0 epoch:5 step:8 train loss:1.418232, train acc:62.885, train f1:60.674, train precision:66.648, train recall:59.116, train kappa:61.183
fold:0 epoch:5 step:9 train loss:1.360544, train acc:64.139, train f1:61.569, train precision:67.065, train recall:60.101, train kappa:62.530
fold:0 epoch:5 step:10 train loss:1.378685, train acc:64.041, train f1:61.679, train precision:65.307, train recall:60.752, train kappa:62.462
fold:0 epoch:5 step:11 train loss:1.360184, train acc:64.830, train f1:62.421, train precision:65.581, train recall:61.951, train kappa:63.282
fold:0 epoch:5        valid loss:1.662280, valid acc:52.874, valid f1:35.985, valid precision:36.489, valid recall:55.278, valid kappa:48.020
None
====================================================================================================
fold:0 epoch:6 step:0 train loss:1.345915, train acc:64.728, train f1:62.636, train precision:66.984, train recall:61.873, train kappa:63.201
fold:0 epoch:6 step:1 train loss:1.323975, train acc:65.482, train f1:63.287, train precision:68.466, train recall:62.254, train kappa:63.971
fold:0 epoch:6 step:2 train loss:1.333381, train acc:65.103, train f1:62.735, train precision:68.042, train recall:61.685, train kappa:63.601
fold:0 epoch:6 step:3 train loss:1.310704, train acc:65.817, train f1:63.258, train precision:68.555, train recall:62.227, train kappa:64.324
fold:0 epoch:6 step:4 train loss:1.295793, train acc:66.013, train f1:63.337, train precision:67.398, train recall:61.990, train kappa:64.520
fold:0 epoch:6 step:5 train loss:1.276718, train acc:66.220, train f1:64.062, train precision:68.996, train recall:62.737, train kappa:64.738
fold:0 epoch:6 step:6 train loss:1.299803, train acc:66.052, train f1:63.470, train precision:68.326, train recall:62.333, train kappa:64.565
fold:0 epoch:6 step:7 train loss:1.277438, train acc:66.513, train f1:64.257, train precision:69.182, train recall:63.091, train kappa:65.040
fold:0 epoch:6 step:8 train loss:1.268909, train acc:66.916, train f1:64.667, train precision:68.388, train recall:63.721, train kappa:65.485
fold:0 epoch:6 step:9 train loss:1.259154, train acc:66.641, train f1:64.249, train precision:68.277, train recall:63.347, train kappa:65.184
fold:0 epoch:6 step:10 train loss:1.244904, train acc:67.389, train f1:64.909, train precision:69.473, train recall:64.269, train kappa:66.001
fold:0 epoch:6 step:11 train loss:1.254490, train acc:67.069, train f1:64.686, train precision:67.908, train recall:64.498, train kappa:65.687
fold:0 epoch:6        valid loss:1.125668, valid acc:69.272, valid f1:46.268, valid precision:44.103, valid recall:63.936, valid kappa:65.629
None
====================================================================================================
fold:0 epoch:7 step:0 train loss:1.227221, train acc:67.529, train f1:65.141, train precision:69.089, train recall:64.606, train kappa:66.151
fold:0 epoch:7 step:1 train loss:1.233638, train acc:67.419, train f1:65.193, train precision:69.655, train recall:64.376, train kappa:66.008
fold:0 epoch:7 step:2 train loss:1.222310, train acc:67.749, train f1:65.492, train precision:70.965, train recall:64.239, train kappa:66.324
fold:0 epoch:7 step:3 train loss:1.205945, train acc:68.222, train f1:66.042, train precision:70.062, train recall:65.115, train kappa:66.849
fold:0 epoch:7 step:4 train loss:1.199415, train acc:68.237, train f1:66.091, train precision:69.776, train recall:65.378, train kappa:66.903
fold:0 epoch:7 step:5 train loss:1.187313, train acc:68.567, train f1:65.837, train precision:69.481, train recall:65.296, train kappa:67.239
fold:0 epoch:7 step:6 train loss:1.186468, train acc:68.195, train f1:65.856, train precision:70.456, train recall:65.191, train kappa:66.858
fold:0 epoch:7 step:7 train loss:1.183529, train acc:68.814, train f1:66.261, train precision:69.879, train recall:65.524, train kappa:67.499
fold:0 epoch:7 step:8 train loss:1.177644, train acc:68.530, train f1:66.061, train precision:69.341, train recall:65.393, train kappa:67.189
fold:0 epoch:7 step:9 train loss:1.169224, train acc:68.808, train f1:66.477, train precision:71.303, train recall:65.627, train kappa:67.478
fold:0 epoch:7 step:10 train loss:1.167418, train acc:69.177, train f1:67.015, train precision:71.226, train recall:65.965, train kappa:67.838
fold:0 epoch:7 step:11 train loss:1.135434, train acc:70.032, train f1:67.405, train precision:71.803, train recall:66.484, train kappa:68.724
fold:0 epoch:7        valid loss:0.996986, valid acc:72.812, valid f1:49.803, valid precision:47.263, valid recall:66.090, valid kappa:69.544
None
====================================================================================================
fold:0 epoch:8 step:0 train loss:1.123971, train acc:70.340, train f1:68.213, train precision:73.344, train recall:67.125, train kappa:69.092
fold:0 epoch:8 step:1 train loss:1.127193, train acc:70.013, train f1:67.894, train precision:71.732, train recall:67.139, train kappa:68.733
fold:0 epoch:8 step:2 train loss:1.122875, train acc:70.248, train f1:68.024, train precision:71.548, train recall:67.593, train kappa:69.010
fold:0 epoch:8 step:3 train loss:1.115590, train acc:70.505, train f1:67.754, train precision:72.664, train recall:67.369, train kappa:69.272
fold:0 epoch:8 step:4 train loss:1.118148, train acc:70.056, train f1:67.723, train precision:70.786, train recall:67.432, train kappa:68.778
fold:0 epoch:8 step:5 train loss:1.113381, train acc:70.276, train f1:67.709, train precision:70.766, train recall:67.180, train kappa:69.033
fold:0 epoch:8 step:6 train loss:1.106622, train acc:70.590, train f1:68.255, train precision:71.778, train recall:67.580, train kappa:69.320
fold:0 epoch:8 step:7 train loss:1.106726, train acc:70.331, train f1:68.218, train precision:72.804, train recall:67.259, train kappa:69.029
fold:0 epoch:8 step:8 train loss:1.107605, train acc:70.410, train f1:68.271, train precision:72.805, train recall:66.953, train kappa:69.155
fold:0 epoch:8 step:9 train loss:1.096681, train acc:70.862, train f1:68.530, train precision:72.797, train recall:67.536, train kappa:69.626
fold:0 epoch:8 step:10 train loss:1.098612, train acc:70.792, train f1:68.721, train precision:73.551, train recall:67.930, train kappa:69.592
fold:0 epoch:8 step:11 train loss:1.116136, train acc:69.984, train f1:68.700, train precision:71.921, train recall:67.926, train kappa:68.738
fold:0 epoch:8        valid loss:0.965116, valid acc:73.910, valid f1:50.105, valid precision:47.273, valid recall:67.328, valid kappa:70.832
None
====================================================================================================
fold:0 epoch:9 step:0 train loss:1.083809, train acc:71.375, train f1:69.579, train precision:73.181, train recall:68.663, train kappa:70.181
fold:0 epoch:9 step:1 train loss:1.063930, train acc:71.628, train f1:69.398, train precision:72.490, train recall:69.090, train kappa:70.451
fold:0 epoch:9 step:2 train loss:1.067739, train acc:71.735, train f1:69.572, train precision:72.622, train recall:69.424, train kappa:70.562
fold:0 epoch:9 step:3 train loss:1.056576, train acc:72.104, train f1:69.780, train precision:73.391, train recall:69.131, train kappa:70.929
fold:0 epoch:9 step:4 train loss:1.047159, train acc:71.918, train f1:69.778, train precision:73.827, train recall:69.301, train kappa:70.765
fold:0 epoch:9 step:5 train loss:1.043549, train acc:71.912, train f1:69.665, train precision:74.480, train recall:68.997, train kappa:70.701
fold:0 epoch:9 step:6 train loss:1.045625, train acc:72.089, train f1:70.131, train precision:74.062, train recall:69.195, train kappa:70.918
fold:0 epoch:9 step:7 train loss:1.045017, train acc:71.753, train f1:69.661, train precision:73.704, train recall:68.387, train kappa:70.549
fold:0 epoch:9 step:8 train loss:1.044675, train acc:72.107, train f1:69.737, train precision:73.592, train recall:69.116, train kappa:70.946
fold:0 epoch:9 step:9 train loss:1.022411, train acc:72.482, train f1:70.286, train precision:74.006, train recall:69.852, train kappa:71.343
fold:0 epoch:9 step:10 train loss:1.034238, train acc:72.086, train f1:70.132, train precision:73.612, train recall:69.624, train kappa:70.927
fold:0 epoch:9 step:11 train loss:0.991072, train acc:73.062, train f1:70.633, train precision:73.869, train recall:70.235, train kappa:71.932
fold:0 epoch:9        valid loss:0.900593, valid acc:75.423, valid f1:51.776, valid precision:50.792, valid recall:67.584, valid kappa:72.452
None
====================================================================================================
fold:0 epoch:10 step:0 train loss:1.004941, train acc:73.047, train f1:71.154, train precision:74.826, train recall:70.529, train kappa:71.917
fold:0 epoch:10 step:1 train loss:1.010203, train acc:72.815, train f1:70.739, train precision:75.029, train recall:69.977, train kappa:71.688
fold:0 epoch:10 step:2 train loss:1.008231, train acc:72.855, train f1:70.843, train precision:74.328, train recall:70.256, train kappa:71.726
fold:0 epoch:10 step:3 train loss:0.989041, train acc:73.041, train f1:70.707, train precision:73.672, train recall:69.875, train kappa:71.907
fold:0 epoch:10 step:4 train loss:0.996702, train acc:73.239, train f1:71.101, train precision:75.451, train recall:70.331, train kappa:72.115
fold:0 epoch:10 step:5 train loss:1.002354, train acc:72.830, train f1:70.586, train precision:74.586, train recall:70.128, train kappa:71.715
fold:0 epoch:10 step:6 train loss:0.993547, train acc:73.264, train f1:71.181, train precision:75.000, train recall:70.573, train kappa:72.140
fold:0 epoch:10 step:7 train loss:0.977805, train acc:73.419, train f1:71.115, train precision:75.099, train recall:70.753, train kappa:72.317
fold:0 epoch:10 step:8 train loss:0.993750, train acc:73.007, train f1:71.325, train precision:74.890, train recall:71.021, train kappa:71.911
fold:0 epoch:10 step:9 train loss:0.971166, train acc:73.639, train f1:71.525, train precision:74.267, train recall:71.088, train kappa:72.555
fold:0 epoch:10 step:10 train loss:0.978131, train acc:73.764, train f1:71.766, train precision:74.170, train recall:71.313, train kappa:72.698
fold:0 epoch:10 step:11 train loss:0.991046, train acc:73.342, train f1:71.884, train precision:75.477, train recall:71.317, train kappa:72.255
fold:0 epoch:10        valid loss:0.873481, valid acc:76.034, valid f1:52.419, valid precision:50.137, valid recall:68.438, valid kappa:73.155
None
====================================================================================================
fold:0 epoch:11 step:0 train loss:0.963073, train acc:73.514, train f1:71.827, train precision:75.947, train recall:71.037, train kappa:72.438
fold:0 epoch:11 step:1 train loss:0.964916, train acc:74.039, train f1:72.178, train precision:75.571, train recall:71.520, train kappa:72.979
fold:0 epoch:11 step:2 train loss:0.947050, train acc:74.438, train f1:72.450, train precision:75.384, train recall:72.005, train kappa:73.395
fold:0 epoch:11 step:3 train loss:0.970338, train acc:73.590, train f1:71.607, train precision:75.792, train recall:71.310, train kappa:72.495
fold:0 epoch:11 step:4 train loss:0.943548, train acc:74.756, train f1:72.665, train precision:76.391, train recall:72.014, train kappa:73.709
fold:0 epoch:11 step:5 train loss:0.951142, train acc:74.081, train f1:71.895, train precision:75.670, train recall:71.198, train kappa:72.994
fold:0 epoch:11 step:6 train loss:0.939058, train acc:74.490, train f1:72.519, train precision:76.268, train recall:71.838, train kappa:73.421
fold:0 epoch:11 step:7 train loss:0.936971, train acc:74.667, train f1:72.394, train precision:75.327, train recall:72.087, train kappa:73.631
fold:0 epoch:11 step:8 train loss:0.943182, train acc:74.374, train f1:72.472, train precision:76.776, train recall:71.882, train kappa:73.312
fold:0 epoch:11 step:9 train loss:0.949019, train acc:74.222, train f1:72.236, train precision:76.017, train recall:71.902, train kappa:73.197
fold:0 epoch:11 step:10 train loss:0.925549, train acc:74.963, train f1:72.994, train precision:75.825, train recall:72.549, train kappa:73.917
fold:0 epoch:11 step:11 train loss:0.940107, train acc:74.172, train f1:72.548, train precision:75.615, train recall:71.873, train kappa:73.112
fold:0 epoch:11        valid loss:0.841181, valid acc:76.960, valid f1:52.857, valid precision:50.874, valid recall:69.084, valid kappa:74.130
None
====================================================================================================
fold:0 epoch:12 step:0 train loss:0.942399, train acc:74.445, train f1:72.760, train precision:76.598, train recall:72.504, train kappa:73.401
fold:0 epoch:12 step:1 train loss:0.912944, train acc:75.122, train f1:73.018, train precision:76.581, train recall:72.590, train kappa:74.091
fold:0 epoch:12 step:2 train loss:0.912374, train acc:75.159, train f1:73.141, train precision:76.743, train recall:72.660, train kappa:74.138
fold:0 epoch:12 step:3 train loss:0.914251, train acc:74.927, train f1:72.861, train precision:76.200, train recall:72.382, train kappa:73.898
fold:0 epoch:12 step:4 train loss:0.912276, train acc:75.027, train f1:73.024, train precision:76.081, train recall:72.387, train kappa:73.986
fold:0 epoch:12 step:5 train loss:0.931094, train acc:74.380, train f1:72.507, train precision:76.822, train recall:71.778, train kappa:73.293
fold:0 epoch:12 step:6 train loss:0.908052, train acc:75.201, train f1:73.304, train precision:76.921, train recall:72.830, train kappa:74.204
fold:0 epoch:12 step:7 train loss:0.905707, train acc:75.461, train f1:73.566, train precision:76.690, train recall:73.216, train kappa:74.470
fold:0 epoch:12 step:8 train loss:0.897210, train acc:75.577, train f1:73.437, train precision:77.518, train recall:73.057, train kappa:74.576
fold:0 epoch:12 step:9 train loss:0.891748, train acc:75.659, train f1:73.798, train precision:77.617, train recall:73.425, train kappa:74.657
fold:0 epoch:12 step:10 train loss:0.888506, train acc:75.577, train f1:73.503, train precision:77.607, train recall:73.119, train kappa:74.587
fold:0 epoch:12 step:11 train loss:0.895507, train acc:75.485, train f1:73.693, train precision:76.008, train recall:73.573, train kappa:74.512
fold:0 epoch:12        valid loss:0.822177, valid acc:77.617, valid f1:53.765, valid precision:51.515, valid recall:68.981, valid kappa:74.906
None
====================================================================================================
fold:0 epoch:13 step:0 train loss:0.890616, train acc:75.598, train f1:73.899, train precision:77.947, train recall:73.378, train kappa:74.629
fold:0 epoch:13 step:1 train loss:0.882119, train acc:75.433, train f1:73.770, train precision:77.522, train recall:73.066, train kappa:74.423
fold:0 epoch:13 step:2 train loss:0.877023, train acc:75.995, train f1:74.023, train precision:77.490, train recall:73.387, train kappa:75.016
fold:0 epoch:13 step:3 train loss:0.877252, train acc:76.093, train f1:74.258, train precision:77.902, train recall:73.779, train kappa:75.119
fold:0 epoch:13 step:4 train loss:0.872574, train acc:76.236, train f1:74.228, train precision:77.179, train recall:73.845, train kappa:75.262
fold:0 epoch:13 step:5 train loss:0.866432, train acc:76.138, train f1:74.335, train precision:77.432, train recall:73.999, train kappa:75.153
fold:0 epoch:13 step:6 train loss:0.875134, train acc:76.035, train f1:74.178, train precision:78.060, train recall:73.801, train kappa:75.077
fold:0 epoch:13 step:7 train loss:0.861308, train acc:76.733, train f1:74.748, train precision:78.524, train recall:74.384, train kappa:75.782
fold:0 epoch:13 step:8 train loss:0.860691, train acc:76.337, train f1:74.475, train precision:77.445, train recall:74.143, train kappa:75.373
fold:0 epoch:13 step:9 train loss:0.863889, train acc:76.627, train f1:74.627, train precision:77.901, train recall:74.278, train kappa:75.667
fold:0 epoch:13 step:10 train loss:0.867287, train acc:76.196, train f1:74.510, train precision:78.087, train recall:73.747, train kappa:75.216
fold:0 epoch:13 step:11 train loss:0.867881, train acc:76.180, train f1:73.918, train precision:77.444, train recall:73.440, train kappa:75.180
fold:0 epoch:13        valid loss:0.803012, valid acc:78.263, valid f1:54.226, valid precision:51.831, valid recall:69.630, valid kappa:75.580
None
====================================================================================================
fold:0 epoch:14 step:0 train loss:0.842816, train acc:76.743, train f1:74.978, train precision:78.213, train recall:74.421, train kappa:75.802
fold:0 epoch:14 step:1 train loss:0.852924, train acc:76.743, train f1:75.027, train precision:78.259, train recall:74.708, train kappa:75.799
fold:0 epoch:14 step:2 train loss:0.853685, train acc:76.437, train f1:74.510, train precision:77.538, train recall:74.330, train kappa:75.492
fold:0 epoch:14 step:3 train loss:0.846333, train acc:76.526, train f1:74.958, train precision:78.777, train recall:74.836, train kappa:75.587
fold:0 epoch:14 step:4 train loss:0.840449, train acc:76.929, train f1:75.063, train precision:78.109, train recall:74.965, train kappa:76.011
fold:0 epoch:14 step:5 train loss:0.836546, train acc:76.935, train f1:74.957, train precision:77.667, train recall:74.754, train kappa:76.013
fold:0 epoch:14 step:6 train loss:0.843216, train acc:76.813, train f1:74.867, train precision:77.776, train recall:74.515, train kappa:75.865
fold:0 epoch:14 step:7 train loss:0.838369, train acc:76.804, train f1:75.219, train precision:78.139, train recall:74.983, train kappa:75.847
fold:0 epoch:14 step:8 train loss:0.841361, train acc:76.831, train f1:75.189, train precision:77.969, train recall:74.758, train kappa:75.907
fold:0 epoch:14 step:9 train loss:0.832781, train acc:77.133, train f1:75.463, train precision:79.007, train recall:74.898, train kappa:76.187
fold:0 epoch:14 step:10 train loss:0.810038, train acc:77.652, train f1:75.842, train precision:78.856, train recall:75.326, train kappa:76.734
fold:0 epoch:14 step:11 train loss:0.835602, train acc:76.556, train f1:74.908, train precision:78.401, train recall:74.669, train kappa:75.626
fold:0 epoch:14        valid loss:0.787839, valid acc:78.657, valid f1:54.779, valid precision:52.480, valid recall:69.597, valid kappa:75.988
None
====================================================================================================
fold:0 epoch:15 step:0 train loss:0.830015, train acc:76.926, train f1:75.275, train precision:78.190, train recall:74.879, train kappa:75.990
fold:0 epoch:15 step:1 train loss:0.814504, train acc:77.570, train f1:75.915, train precision:78.731, train recall:75.833, train kappa:76.674
fold:0 epoch:15 step:2 train loss:0.817004, train acc:77.582, train f1:75.723, train precision:78.290, train recall:75.731, train kappa:76.681
fold:0 epoch:15 step:3 train loss:0.803815, train acc:77.676, train f1:75.889, train precision:78.300, train recall:75.867, train kappa:76.778
fold:0 epoch:15 step:4 train loss:0.805545, train acc:77.786, train f1:75.846, train precision:78.474, train recall:75.632, train kappa:76.897
fold:0 epoch:15 step:5 train loss:0.814231, train acc:77.277, train f1:75.581, train precision:78.831, train recall:75.170, train kappa:76.373
fold:0 epoch:15 step:6 train loss:0.814847, train acc:77.521, train f1:75.793, train precision:78.820, train recall:75.204, train kappa:76.595
fold:0 epoch:15 step:7 train loss:0.813578, train acc:77.521, train f1:75.823, train precision:78.530, train recall:75.254, train kappa:76.616
fold:0 epoch:15 step:8 train loss:0.813703, train acc:77.460, train f1:76.021, train precision:78.584, train recall:75.805, train kappa:76.538
fold:0 epoch:15 step:9 train loss:0.811880, train acc:77.271, train f1:75.459, train precision:78.277, train recall:75.098, train kappa:76.364
fold:0 epoch:15 step:10 train loss:0.813644, train acc:77.301, train f1:75.775, train precision:78.094, train recall:75.681, train kappa:76.364
fold:0 epoch:15 step:11 train loss:0.786675, train acc:78.805, train f1:76.902, train precision:79.595, train recall:76.501, train kappa:77.976
fold:0 epoch:15        valid loss:0.770624, valid acc:79.183, valid f1:54.317, valid precision:52.165, valid recall:69.056, valid kappa:76.595
None
====================================================================================================
fold:0 epoch:16 step:0 train loss:0.781518, train acc:78.293, train f1:76.514, train precision:79.188, train recall:76.374, train kappa:77.415
fold:0 epoch:16 step:1 train loss:0.778338, train acc:78.482, train f1:76.613, train precision:80.037, train recall:76.403, train kappa:77.642
fold:0 epoch:16 step:2 train loss:0.796734, train acc:77.737, train f1:76.035, train precision:79.374, train recall:75.809, train kappa:76.830
fold:0 epoch:16 step:3 train loss:0.793312, train acc:77.942, train f1:76.203, train precision:80.391, train recall:76.002, train kappa:77.071
fold:0 epoch:16 step:4 train loss:0.794001, train acc:77.753, train f1:76.214, train precision:79.453, train recall:75.942, train kappa:76.869
fold:0 epoch:16 step:5 train loss:0.783588, train acc:78.146, train f1:76.382, train precision:78.632, train recall:76.346, train kappa:77.267
fold:0 epoch:16 step:6 train loss:0.793789, train acc:78.271, train f1:76.541, train precision:80.236, train recall:76.344, train kappa:77.409
fold:0 epoch:16 step:7 train loss:0.785437, train acc:78.223, train f1:76.556, train precision:79.204, train recall:76.372, train kappa:77.346
fold:0 epoch:16 step:8 train loss:0.783594, train acc:78.165, train f1:76.525, train precision:79.616, train recall:76.061, train kappa:77.275
fold:0 epoch:16 step:9 train loss:0.784223, train acc:78.290, train f1:76.637, train precision:79.448, train recall:76.215, train kappa:77.407
fold:0 epoch:16 step:10 train loss:0.768363, train acc:78.528, train f1:76.794, train precision:79.869, train recall:76.325, train kappa:77.648
fold:0 epoch:16 step:11 train loss:0.786118, train acc:77.908, train f1:75.542, train precision:77.461, train recall:75.663, train kappa:77.006
fold:0 epoch:16        valid loss:0.764495, valid acc:79.224, valid f1:55.004, valid precision:52.390, valid recall:69.920, valid kappa:76.664
None
====================================================================================================
fold:0 epoch:17 step:0 train loss:0.765130, train acc:78.568, train f1:77.156, train precision:80.530, train recall:76.828, train kappa:77.715
fold:0 epoch:17 step:1 train loss:0.759306, train acc:78.650, train f1:76.965, train precision:80.291, train recall:76.824, train kappa:77.784
fold:0 epoch:17 step:2 train loss:0.774110, train acc:78.473, train f1:76.740, train precision:79.590, train recall:76.482, train kappa:77.601
fold:0 epoch:17 step:3 train loss:0.753729, train acc:78.964, train f1:77.475, train precision:79.776, train recall:77.292, train kappa:78.104
fold:0 epoch:17 step:4 train loss:0.777279, train acc:78.244, train f1:76.976, train precision:80.557, train recall:76.617, train kappa:77.366
fold:0 epoch:17 step:5 train loss:0.752864, train acc:78.897, train f1:77.165, train precision:79.853, train recall:76.971, train kappa:78.041
fold:0 epoch:17 step:6 train loss:0.768167, train acc:78.436, train f1:77.059, train precision:79.718, train recall:76.828, train kappa:77.575
fold:0 epoch:17 step:7 train loss:0.748399, train acc:78.925, train f1:77.183, train precision:79.575, train recall:76.896, train kappa:78.074
fold:0 epoch:17 step:8 train loss:0.766461, train acc:78.531, train f1:77.022, train precision:79.381, train recall:76.726, train kappa:77.700
fold:0 epoch:17 step:9 train loss:0.764989, train acc:78.537, train f1:77.020, train precision:79.602, train recall:76.944, train kappa:77.703
fold:0 epoch:17 step:10 train loss:0.744982, train acc:79.135, train f1:77.361, train precision:79.776, train recall:77.238, train kappa:78.298
fold:0 epoch:17 step:11 train loss:0.732107, train acc:79.143, train f1:77.346, train precision:79.396, train recall:77.564, train kappa:78.325
fold:0 epoch:17        valid loss:0.759199, valid acc:79.635, valid f1:55.052, valid precision:52.182, valid recall:69.707, valid kappa:77.106
None
====================================================================================================
fold:0 epoch:18 step:0 train loss:0.743886, train acc:78.946, train f1:77.520, train precision:80.493, train recall:77.210, train kappa:78.118
fold:0 epoch:18 step:1 train loss:0.748816, train acc:78.864, train f1:77.280, train precision:79.845, train recall:77.033, train kappa:78.016
fold:0 epoch:18 step:2 train loss:0.757536, train acc:78.564, train f1:76.995, train precision:79.904, train recall:76.839, train kappa:77.709
fold:0 epoch:18 step:3 train loss:0.739819, train acc:79.346, train f1:77.922, train precision:81.287, train recall:77.589, train kappa:78.523
fold:0 epoch:18 step:4 train loss:0.737993, train acc:79.370, train f1:77.825, train precision:80.127, train recall:77.681, train kappa:78.527
fold:0 epoch:18 step:5 train loss:0.740500, train acc:79.108, train f1:77.634, train precision:79.656, train recall:77.685, train kappa:78.277
fold:0 epoch:18 step:6 train loss:0.739254, train acc:79.160, train f1:77.604, train precision:79.908, train recall:77.411, train kappa:78.325
fold:0 epoch:18 step:7 train loss:0.751190, train acc:78.723, train f1:77.189, train precision:79.981, train recall:76.844, train kappa:77.886
fold:0 epoch:18 step:8 train loss:0.741860, train acc:78.998, train f1:77.423, train precision:79.664, train recall:77.249, train kappa:78.152
fold:0 epoch:18 step:9 train loss:0.738787, train acc:79.303, train f1:77.676, train precision:79.792, train recall:77.834, train kappa:78.485
fold:0 epoch:18 step:10 train loss:0.727820, train acc:79.575, train f1:77.926, train precision:80.393, train recall:77.756, train kappa:78.761
fold:0 epoch:18 step:11 train loss:0.754424, train acc:78.535, train f1:77.178, train precision:81.008, train recall:76.689, train kappa:77.654
fold:0 epoch:18        valid loss:0.748546, valid acc:79.878, valid f1:55.534, valid precision:52.846, valid recall:69.901, valid kappa:77.375
None
====================================================================================================
fold:0 epoch:19 step:0 train loss:0.729205, train acc:79.752, train f1:77.959, train precision:80.467, train recall:78.023, train kappa:78.945
fold:0 epoch:19 step:1 train loss:0.724705, train acc:79.337, train f1:77.795, train precision:80.218, train recall:77.755, train kappa:78.517
fold:0 epoch:19 step:2 train loss:0.722633, train acc:79.639, train f1:78.016, train precision:80.569, train recall:77.833, train kappa:78.807
fold:0 epoch:19 step:3 train loss:0.716669, train acc:79.666, train f1:78.474, train precision:81.547, train recall:78.247, train kappa:78.860
fold:0 epoch:19 step:4 train loss:0.719026, train acc:79.764, train f1:78.182, train precision:80.528, train recall:78.149, train kappa:78.963
fold:0 epoch:19 step:5 train loss:0.735563, train acc:79.196, train f1:77.808, train precision:80.124, train recall:77.406, train kappa:78.373
fold:0 epoch:19 step:6 train loss:0.712950, train acc:79.559, train f1:78.294, train precision:81.633, train recall:77.925, train kappa:78.734
fold:0 epoch:19 step:7 train loss:0.722828, train acc:79.694, train f1:78.250, train precision:80.712, train recall:78.079, train kappa:78.882
fold:0 epoch:19 step:8 train loss:0.714755, train acc:79.898, train f1:78.359, train precision:80.728, train recall:78.265, train kappa:79.103
fold:0 epoch:19 step:9 train loss:0.725138, train acc:79.309, train f1:77.728, train precision:80.092, train recall:77.725, train kappa:78.487
fold:0 epoch:19 step:10 train loss:0.720975, train acc:79.672, train f1:78.225, train precision:80.605, train recall:78.222, train kappa:78.861
fold:0 epoch:19 step:11 train loss:0.722641, train acc:79.404, train f1:78.185, train precision:80.564, train recall:78.326, train kappa:78.609
fold:0 epoch:19        valid loss:0.731200, valid acc:80.365, valid f1:56.397, valid precision:53.810, valid recall:70.232, valid kappa:77.905
None
====================================================================================================
fold:0 epoch:20 step:0 train loss:0.700025, train acc:80.258, train f1:78.643, train precision:81.026, train recall:78.601, train kappa:79.462
fold:0 epoch:20 step:1 train loss:0.697959, train acc:80.353, train f1:78.868, train precision:81.665, train recall:78.697, train kappa:79.583
fold:0 epoch:20 step:2 train loss:0.712626, train acc:79.727, train f1:78.295, train precision:81.135, train recall:78.025, train kappa:78.926
fold:0 epoch:20 step:3 train loss:0.710125, train acc:79.678, train f1:78.283, train precision:81.177, train recall:77.990, train kappa:78.843
fold:0 epoch:20 step:4 train loss:0.690049, train acc:80.380, train f1:78.726, train precision:80.911, train recall:78.613, train kappa:79.606
fold:0 epoch:20 step:5 train loss:0.707474, train acc:80.072, train f1:78.524, train precision:80.710, train recall:78.473, train kappa:79.266
fold:0 epoch:20 step:6 train loss:0.705447, train acc:79.962, train f1:78.429, train precision:81.544, train recall:78.118, train kappa:79.167
fold:0 epoch:20 step:7 train loss:0.708154, train acc:79.877, train f1:78.370, train precision:80.296, train recall:78.609, train kappa:79.076
fold:0 epoch:20 step:8 train loss:0.705716, train acc:79.926, train f1:78.477, train precision:80.787, train recall:78.678, train kappa:79.125
fold:0 epoch:20 step:9 train loss:0.702947, train acc:80.054, train f1:78.553, train precision:80.948, train recall:78.608, train kappa:79.285
fold:0 epoch:20 step:10 train loss:0.707820, train acc:79.742, train f1:78.221, train precision:80.088, train recall:78.445, train kappa:78.951
fold:0 epoch:20 step:11 train loss:0.689047, train acc:80.398, train f1:79.187, train precision:81.786, train recall:78.841, train kappa:79.626
fold:0 epoch:20        valid loss:0.726417, valid acc:80.418, valid f1:56.562, valid precision:53.546, valid recall:69.849, valid kappa:77.966
None
====================================================================================================
fold:0 epoch:21 step:0 train loss:0.696070, train acc:80.081, train f1:78.640, train precision:81.000, train recall:78.352, train kappa:79.292
fold:0 epoch:21 step:1 train loss:0.690190, train acc:80.347, train f1:79.236, train precision:81.772, train recall:78.902, train kappa:79.573
fold:0 epoch:21 step:2 train loss:0.687998, train acc:80.313, train f1:78.844, train precision:81.138, train recall:78.620, train kappa:79.515
fold:0 epoch:21 step:3 train loss:0.694616, train acc:80.127, train f1:78.617, train precision:80.974, train recall:78.374, train kappa:79.331
fold:0 epoch:21 step:4 train loss:0.695067, train acc:80.136, train f1:78.795, train precision:81.538, train recall:78.676, train kappa:79.338
fold:0 epoch:21 step:5 train loss:0.685153, train acc:80.585, train f1:78.924, train precision:81.142, train recall:78.993, train kappa:79.809
fold:0 epoch:21 step:6 train loss:0.699990, train acc:80.145, train f1:78.593, train precision:81.128, train recall:78.874, train kappa:79.366
fold:0 epoch:21 step:7 train loss:0.687472, train acc:80.597, train f1:79.051, train precision:81.010, train recall:79.071, train kappa:79.841
fold:0 epoch:21 step:8 train loss:0.681714, train acc:80.569, train f1:79.246, train precision:81.880, train recall:79.025, train kappa:79.791
fold:0 epoch:21 step:9 train loss:0.666244, train acc:81.079, train f1:79.495, train precision:82.175, train recall:79.335, train kappa:80.333
fold:0 epoch:21 step:10 train loss:0.691063, train acc:80.399, train f1:79.011, train precision:81.469, train recall:78.893, train kappa:79.622
fold:0 epoch:21 step:11 train loss:0.664829, train acc:81.170, train f1:79.736, train precision:82.386, train recall:79.691, train kappa:80.437
fold:0 epoch:21        valid loss:0.722297, valid acc:80.516, valid f1:56.880, valid precision:53.941, valid recall:70.382, valid kappa:78.075
None
====================================================================================================
fold:0 epoch:22 step:0 train loss:0.678767, train acc:80.682, train f1:79.391, train precision:81.577, train recall:79.369, train kappa:79.910
fold:0 epoch:22 step:1 train loss:0.674196, train acc:80.869, train f1:79.224, train precision:82.316, train recall:79.112, train kappa:80.106
fold:0 epoch:22 step:2 train loss:0.676904, train acc:80.817, train f1:79.596, train precision:82.191, train recall:79.363, train kappa:80.075
fold:0 epoch:22 step:3 train loss:0.673610, train acc:80.667, train f1:79.395, train precision:82.154, train recall:79.335, train kappa:79.913
fold:0 epoch:22 step:4 train loss:0.673606, train acc:81.015, train f1:79.543, train precision:82.432, train recall:79.392, train kappa:80.255
fold:0 epoch:22 step:5 train loss:0.658085, train acc:80.942, train f1:79.604, train precision:82.089, train recall:79.446, train kappa:80.196
fold:0 epoch:22 step:6 train loss:0.671245, train acc:80.762, train f1:79.312, train precision:82.150, train recall:79.214, train kappa:79.994
fold:0 epoch:22 step:7 train loss:0.664775, train acc:81.195, train f1:79.523, train precision:82.055, train recall:79.631, train kappa:80.446
fold:0 epoch:22 step:8 train loss:0.668467, train acc:80.713, train f1:79.354, train precision:81.655, train recall:79.645, train kappa:79.944
fold:0 epoch:22 step:9 train loss:0.665058, train acc:81.165, train f1:79.612, train precision:81.856, train recall:79.669, train kappa:80.420
fold:0 epoch:22 step:10 train loss:0.674821, train acc:80.835, train f1:79.503, train precision:81.968, train recall:79.421, train kappa:80.085
fold:0 epoch:22 step:11 train loss:0.648539, train acc:81.488, train f1:80.009, train precision:83.184, train recall:79.671, train kappa:80.749
fold:0 epoch:22        valid loss:0.713649, valid acc:80.798, valid f1:56.621, valid precision:53.664, valid recall:70.017, valid kappa:78.400
None
====================================================================================================
fold:0 epoch:23 step:0 train loss:0.659145, train acc:81.009, train f1:79.804, train precision:81.894, train recall:79.641, train kappa:80.256
fold:0 epoch:23 step:1 train loss:0.648326, train acc:81.274, train f1:80.069, train precision:83.539, train recall:79.842, train kappa:80.528
fold:0 epoch:23 step:2 train loss:0.668941, train acc:80.725, train f1:79.645, train precision:82.113, train recall:79.293, train kappa:79.955
fold:0 epoch:23 step:3 train loss:0.646223, train acc:81.400, train f1:80.069, train precision:82.064, train recall:79.843, train kappa:80.671
fold:0 epoch:23 step:4 train loss:0.678558, train acc:80.377, train f1:79.244, train precision:80.981, train recall:79.451, train kappa:79.593
fold:0 epoch:23 step:5 train loss:0.660146, train acc:81.201, train f1:79.860, train precision:82.132, train recall:79.961, train kappa:80.450
fold:0 epoch:23 step:6 train loss:0.657854, train acc:81.110, train f1:79.565, train precision:81.203, train recall:79.800, train kappa:80.370
fold:0 epoch:23 step:7 train loss:0.657352, train acc:81.262, train f1:79.614, train precision:82.032, train recall:79.782, train kappa:80.523
fold:0 epoch:23 step:8 train loss:0.644496, train acc:81.470, train f1:79.992, train precision:82.547, train recall:79.942, train kappa:80.748
fold:0 epoch:23 step:9 train loss:0.649346, train acc:81.497, train f1:79.938, train precision:82.513, train recall:79.774, train kappa:80.770
fold:0 epoch:23 step:10 train loss:0.655284, train acc:81.174, train f1:79.739, train precision:82.222, train recall:79.568, train kappa:80.437
fold:0 epoch:23 step:11 train loss:0.663414, train acc:81.247, train f1:79.811, train precision:81.661, train recall:79.705, train kappa:80.503
fold:0 epoch:23        valid loss:0.715168, valid acc:80.739, valid f1:56.694, valid precision:53.755, valid recall:70.379, valid kappa:78.341
None
====================================================================================================
fold:0 epoch:24 step:0 train loss:0.633690, train acc:81.735, train f1:80.425, train precision:83.189, train recall:80.524, train kappa:81.007
fold:0 epoch:24 step:1 train loss:0.661049, train acc:80.927, train f1:79.630, train precision:81.430, train recall:79.769, train kappa:80.178
fold:0 epoch:24 step:2 train loss:0.641044, train acc:81.555, train f1:80.076, train precision:82.449, train recall:80.339, train kappa:80.814
fold:0 epoch:24 step:3 train loss:0.659201, train acc:80.835, train f1:79.520, train precision:81.721, train recall:79.431, train kappa:80.077
fold:0 epoch:24 step:4 train loss:0.647602, train acc:81.442, train f1:79.982, train precision:82.623, train recall:79.761, train kappa:80.709
fold:0 epoch:24 step:5 train loss:0.662299, train acc:81.009, train f1:79.760, train precision:82.158, train recall:79.362, train kappa:80.255
fold:0 epoch:24 step:6 train loss:0.637844, train acc:81.827, train f1:80.436, train precision:82.630, train recall:80.314, train kappa:81.109
fold:0 epoch:24 step:7 train loss:0.630940, train acc:81.882, train f1:80.385, train precision:82.513, train recall:80.302, train kappa:81.182
fold:0 epoch:24 step:8 train loss:0.636033, train acc:81.586, train f1:80.129, train precision:82.496, train recall:80.361, train kappa:80.865
fold:0 epoch:24 step:9 train loss:0.633217, train acc:81.955, train f1:80.689, train precision:82.751, train recall:80.893, train kappa:81.254
fold:0 epoch:24 step:10 train loss:0.632726, train acc:81.729, train f1:80.146, train precision:82.391, train recall:80.321, train kappa:81.009
fold:0 epoch:24 step:11 train loss:0.635948, train acc:81.739, train f1:80.125, train precision:81.991, train recall:80.106, train kappa:81.021
fold:0 epoch:24        valid loss:0.715279, valid acc:80.772, valid f1:57.141, valid precision:54.119, valid recall:70.689, valid kappa:78.373
None
====================================================================================================
fold:0 epoch:25 step:0 train loss:0.641177, train acc:81.415, train f1:80.170, train precision:82.886, train recall:80.237, train kappa:80.675
fold:0 epoch:25 step:1 train loss:0.624068, train acc:81.961, train f1:80.590, train precision:83.398, train recall:80.488, train kappa:81.259
fold:0 epoch:25 step:2 train loss:0.630109, train acc:81.891, train f1:80.554, train precision:82.795, train recall:80.551, train kappa:81.183
fold:0 epoch:25 step:3 train loss:0.632404, train acc:81.708, train f1:80.246, train precision:82.850, train recall:80.022, train kappa:80.975
fold:0 epoch:25 step:4 train loss:0.640392, train acc:81.516, train f1:80.368, train precision:82.764, train recall:80.268, train kappa:80.785
fold:0 epoch:25 step:5 train loss:0.620142, train acc:82.004, train f1:80.567, train precision:82.843, train recall:80.645, train kappa:81.303
fold:0 epoch:25 step:6 train loss:0.623637, train acc:81.836, train f1:80.539, train precision:82.715, train recall:80.523, train kappa:81.131
fold:0 epoch:25 step:7 train loss:0.623299, train acc:82.074, train f1:80.686, train precision:82.793, train recall:80.922, train kappa:81.370
fold:0 epoch:25 step:8 train loss:0.632905, train acc:81.833, train f1:80.546, train precision:82.559, train recall:80.509, train kappa:81.112
fold:0 epoch:25 step:9 train loss:0.623321, train acc:81.949, train f1:80.817, train precision:83.146, train recall:80.562, train kappa:81.233
fold:0 epoch:25 step:10 train loss:0.630935, train acc:81.885, train f1:80.328, train precision:82.465, train recall:80.249, train kappa:81.155
fold:0 epoch:25 step:11 train loss:0.617728, train acc:82.318, train f1:81.249, train precision:84.032, train recall:81.126, train kappa:81.647
fold:0 epoch:25        valid loss:0.705576, valid acc:81.009, valid f1:57.253, valid precision:54.747, valid recall:70.098, valid kappa:78.632
None
====================================================================================================
fold:0 epoch:26 step:0 train loss:0.621079, train acc:82.007, train f1:80.852, train precision:82.514, train recall:80.877, train kappa:81.298
fold:0 epoch:26 step:1 train loss:0.613590, train acc:82.120, train f1:80.700, train precision:82.289, train recall:81.224, train kappa:81.420
fold:0 epoch:26 step:2 train loss:0.629906, train acc:81.900, train f1:80.520, train precision:82.092, train recall:80.965, train kappa:81.198
fold:0 epoch:26 step:3 train loss:0.621974, train acc:81.894, train f1:80.537, train precision:81.813, train recall:80.745, train kappa:81.181
fold:0 epoch:26 step:4 train loss:0.616938, train acc:82.141, train f1:80.891, train precision:83.347, train recall:80.679, train kappa:81.451
fold:0 epoch:26 step:5 train loss:0.616391, train acc:82.065, train f1:80.493, train precision:83.239, train recall:80.236, train kappa:81.343
fold:0 epoch:26 step:6 train loss:0.616193, train acc:82.217, train f1:80.876, train precision:83.077, train recall:80.561, train kappa:81.506
fold:0 epoch:26 step:7 train loss:0.622401, train acc:81.970, train f1:80.830, train precision:83.546, train recall:80.718, train kappa:81.254
fold:0 epoch:26 step:8 train loss:0.610255, train acc:82.071, train f1:80.759, train precision:83.009, train recall:80.645, train kappa:81.378
fold:0 epoch:26 step:9 train loss:0.613783, train acc:82.095, train f1:80.738, train precision:83.091, train recall:80.847, train kappa:81.399
fold:0 epoch:26 step:10 train loss:0.626417, train acc:82.114, train f1:81.025, train precision:82.713, train recall:81.366, train kappa:81.423
fold:0 epoch:26 step:11 train loss:0.580482, train acc:83.081, train f1:81.706, train precision:82.874, train recall:82.293, train kappa:82.414
fold:0 epoch:26        valid loss:0.705018, valid acc:81.215, valid f1:57.153, valid precision:54.700, valid recall:70.393, valid kappa:78.860
None
====================================================================================================
fold:0 epoch:27 step:0 train loss:0.618176, train acc:82.065, train f1:80.750, train precision:83.073, train recall:80.800, train kappa:81.364
fold:0 epoch:27 step:1 train loss:0.618812, train acc:82.019, train f1:80.770, train precision:82.908, train recall:80.844, train kappa:81.312
fold:0 epoch:27 step:2 train loss:0.599416, train acc:82.394, train f1:81.268, train precision:84.067, train recall:81.064, train kappa:81.704
fold:0 epoch:27 step:3 train loss:0.606343, train acc:82.599, train f1:81.265, train precision:83.892, train recall:80.882, train kappa:81.903
fold:0 epoch:27 step:4 train loss:0.607712, train acc:82.349, train f1:81.074, train precision:83.828, train recall:80.745, train kappa:81.645
fold:0 epoch:27 step:5 train loss:0.613081, train acc:82.379, train f1:80.968, train precision:83.342, train recall:80.840, train kappa:81.688
fold:0 epoch:27 step:6 train loss:0.603360, train acc:82.388, train f1:81.189, train precision:83.185, train recall:81.112, train kappa:81.689
fold:0 epoch:27 step:7 train loss:0.605364, train acc:82.599, train f1:81.360, train precision:83.158, train recall:81.697, train kappa:81.921
fold:0 epoch:27 step:8 train loss:0.606525, train acc:82.532, train f1:81.043, train precision:82.289, train recall:81.418, train kappa:81.858
fold:0 epoch:27 step:9 train loss:0.595560, train acc:82.709, train f1:81.388, train precision:83.475, train recall:81.702, train kappa:82.036
fold:0 epoch:27 step:10 train loss:0.615352, train acc:82.108, train f1:80.823, train precision:83.121, train recall:80.763, train kappa:81.399
fold:0 epoch:27 step:11 train loss:0.594388, train acc:82.473, train f1:81.043, train precision:83.161, train recall:81.102, train kappa:81.780
fold:0 epoch:27        valid loss:0.692876, valid acc:81.661, valid f1:57.727, valid precision:55.123, valid recall:70.247, valid kappa:79.346
None
====================================================================================================
fold:0 epoch:28 step:0 train loss:0.598784, train acc:82.608, train f1:81.162, train precision:83.402, train recall:81.237, train kappa:81.920
fold:0 epoch:28 step:1 train loss:0.594598, train acc:82.581, train f1:81.425, train precision:83.641, train recall:81.376, train kappa:81.891
fold:0 epoch:28 step:2 train loss:0.594780, train acc:82.645, train f1:81.478, train precision:83.889, train recall:81.517, train kappa:81.952
fold:0 epoch:28 step:3 train loss:0.594836, train acc:82.587, train f1:81.595, train precision:84.403, train recall:81.384, train kappa:81.901
fold:0 epoch:28 step:4 train loss:0.599058, train acc:82.492, train f1:81.327, train precision:83.499, train recall:81.321, train kappa:81.820
fold:0 epoch:28 step:5 train loss:0.591174, train acc:83.054, train f1:81.443, train precision:83.051, train recall:81.710, train kappa:82.386
fold:0 epoch:28 step:6 train loss:0.590663, train acc:82.822, train f1:81.509, train precision:83.166, train recall:81.717, train kappa:82.151
fold:0 epoch:28 step:7 train loss:0.591353, train acc:82.800, train f1:81.994, train precision:84.090, train recall:81.959, train kappa:82.141
fold:0 epoch:28 step:8 train loss:0.589844, train acc:82.709, train f1:81.523, train precision:83.382, train recall:81.573, train kappa:82.052
fold:0 epoch:28 step:9 train loss:0.595731, train acc:82.660, train f1:81.306, train precision:83.009, train recall:81.604, train kappa:81.973
fold:0 epoch:28 step:10 train loss:0.606095, train acc:82.312, train f1:81.019, train precision:83.246, train recall:81.117, train kappa:81.614
fold:0 epoch:28 step:11 train loss:0.614897, train acc:81.990, train f1:81.041, train precision:83.078, train recall:81.038, train kappa:81.273
fold:0 epoch:28        valid loss:0.687671, valid acc:81.896, valid f1:58.174, valid precision:55.351, valid recall:69.988, valid kappa:79.608
None
====================================================================================================
fold:0 epoch:29 step:0 train loss:0.593421, train acc:82.571, train f1:81.547, train precision:83.876, train recall:81.337, train kappa:81.892
fold:0 epoch:29 step:1 train loss:0.576969, train acc:82.837, train f1:81.493, train precision:83.536, train recall:81.343, train kappa:82.160
fold:0 epoch:29 step:2 train loss:0.588889, train acc:82.700, train f1:81.430, train precision:83.322, train recall:81.379, train kappa:82.025
fold:0 epoch:29 step:3 train loss:0.587630, train acc:83.054, train f1:81.921, train precision:83.770, train recall:82.246, train kappa:82.394
fold:0 epoch:29 step:4 train loss:0.588053, train acc:82.886, train f1:81.633, train precision:83.621, train recall:81.620, train kappa:82.217
fold:0 epoch:29 step:5 train loss:0.590836, train acc:82.840, train f1:81.794, train precision:83.499, train recall:82.037, train kappa:82.175
fold:0 epoch:29 step:6 train loss:0.587120, train acc:83.047, train f1:81.876, train precision:84.003, train recall:81.840, train kappa:82.390
fold:0 epoch:29 step:7 train loss:0.586041, train acc:82.693, train f1:81.430, train precision:83.246, train recall:81.716, train kappa:82.014
fold:0 epoch:29 step:8 train loss:0.587491, train acc:82.596, train f1:81.434, train precision:83.323, train recall:81.514, train kappa:81.919
fold:0 epoch:29 step:9 train loss:0.583876, train acc:83.069, train f1:81.888, train precision:84.134, train recall:81.960, train kappa:82.386
fold:0 epoch:29 step:10 train loss:0.577511, train acc:82.980, train f1:81.853, train precision:83.945, train recall:81.844, train kappa:82.308
fold:0 epoch:29 step:11 train loss:0.578798, train acc:83.110, train f1:81.962, train precision:84.489, train recall:81.851, train kappa:82.465
fold:0 epoch:29        valid loss:0.690361, valid acc:81.671, valid f1:57.808, valid precision:54.940, valid recall:70.313, valid kappa:79.366
None
====================================================================================================
fold:0 epoch:30 step:0 train loss:0.565886, train acc:83.273, train f1:82.087, train precision:83.635, train recall:82.236, train kappa:82.612
fold:0 epoch:30 step:1 train loss:0.589681, train acc:82.755, train f1:81.843, train precision:83.493, train recall:81.916, train kappa:82.092
fold:0 epoch:30 step:2 train loss:0.576189, train acc:83.264, train f1:81.766, train precision:83.433, train recall:81.902, train kappa:82.625
fold:0 epoch:30 step:3 train loss:0.574381, train acc:83.194, train f1:82.208, train precision:83.851, train recall:82.455, train kappa:82.525
fold:0 epoch:30 step:4 train loss:0.574809, train acc:83.234, train f1:82.331, train precision:84.356, train recall:82.229, train kappa:82.585
fold:0 epoch:30 step:5 train loss:0.567986, train acc:83.240, train f1:82.210, train precision:84.511, train recall:82.040, train kappa:82.568
fold:0 epoch:30 step:6 train loss:0.586859, train acc:82.693, train f1:81.546, train precision:83.824, train recall:81.413, train kappa:82.004
fold:0 epoch:30 step:7 train loss:0.579945, train acc:82.892, train f1:81.754, train precision:83.619, train recall:81.954, train kappa:82.226
fold:0 epoch:30 step:8 train loss:0.567748, train acc:83.420, train f1:82.176, train precision:84.105, train recall:82.268, train kappa:82.784
fold:0 epoch:30 step:9 train loss:0.579078, train acc:83.130, train f1:82.002, train precision:83.667, train recall:82.258, train kappa:82.486
fold:0 epoch:30 step:10 train loss:0.571594, train acc:83.530, train f1:82.051, train precision:83.769, train recall:82.327, train kappa:82.890
fold:0 epoch:30 step:11 train loss:0.566146, train acc:83.235, train f1:81.434, train precision:83.023, train recall:81.685, train kappa:82.545
fold:0 epoch:30        valid loss:0.689178, valid acc:81.794, valid f1:58.062, valid precision:55.174, valid recall:70.411, valid kappa:79.502
None
====================================================================================================
fold:0 epoch:31 step:0 train loss:0.569036, train acc:83.261, train f1:82.051, train precision:83.762, train recall:82.186, train kappa:82.612
fold:0 epoch:31 step:1 train loss:0.577764, train acc:83.014, train f1:81.911, train precision:83.990, train recall:81.946, train kappa:82.341
fold:0 epoch:31 step:2 train loss:0.574682, train acc:83.160, train f1:82.020, train precision:83.968, train recall:82.198, train kappa:82.504
fold:0 epoch:31 step:3 train loss:0.565037, train acc:83.481, train f1:82.487, train precision:84.494, train recall:82.499, train kappa:82.835
fold:0 epoch:31 step:4 train loss:0.565546, train acc:83.563, train f1:82.406, train precision:84.309, train recall:82.348, train kappa:82.930
fold:0 epoch:31 step:5 train loss:0.557949, train acc:83.612, train f1:82.446, train precision:84.075, train recall:82.624, train kappa:82.973
fold:0 epoch:31 step:6 train loss:0.571106, train acc:83.148, train f1:82.141, train precision:83.922, train recall:82.218, train kappa:82.491
fold:0 epoch:31 step:7 train loss:0.566478, train acc:83.295, train f1:82.161, train precision:84.046, train recall:82.130, train kappa:82.640
fold:0 epoch:31 step:8 train loss:0.550669, train acc:83.853, train f1:82.742, train precision:84.540, train recall:82.847, train kappa:83.210
fold:0 epoch:31 step:9 train loss:0.572427, train acc:83.154, train f1:82.072, train precision:83.880, train recall:82.220, train kappa:82.503
fold:0 epoch:31 step:10 train loss:0.562305, train acc:83.411, train f1:82.246, train precision:84.281, train recall:82.256, train kappa:82.773
fold:0 epoch:31 step:11 train loss:0.560365, train acc:83.670, train f1:82.273, train precision:84.851, train recall:82.288, train kappa:83.016
fold:0 epoch:31        valid loss:0.685129, valid acc:82.046, valid f1:58.049, valid precision:55.062, valid recall:70.146, valid kappa:79.780
[82.04551495695912, 58.04926299850295, 55.062278401100286, 70.1463079475537, 79.78025759894587]
====================================================================================================
fold:0 epoch:32 step:0 train loss:0.559709, train acc:83.395, train f1:82.416, train precision:84.699, train recall:82.475, train kappa:82.737
fold:0 epoch:32 step:1 train loss:0.546193, train acc:83.841, train f1:82.742, train precision:84.986, train recall:82.742, train kappa:83.210
fold:0 epoch:32 step:2 train loss:0.564480, train acc:83.380, train f1:82.329, train precision:84.080, train recall:82.297, train kappa:82.740
fold:0 epoch:32 step:3 train loss:0.568196, train acc:83.334, train f1:82.301, train precision:83.838, train recall:82.341, train kappa:82.696
fold:0 epoch:32 step:4 train loss:0.555243, train acc:83.615, train f1:82.551, train precision:84.300, train recall:82.661, train kappa:82.981
fold:0 epoch:32 step:5 train loss:0.564094, train acc:83.286, train f1:82.230, train precision:84.295, train recall:82.275, train kappa:82.620
fold:0 epoch:32 step:6 train loss:0.559527, train acc:83.633, train f1:82.492, train precision:84.662, train recall:82.348, train kappa:82.987
fold:0 epoch:32 step:7 train loss:0.555986, train acc:83.536, train f1:82.318, train precision:84.464, train recall:82.270, train kappa:82.892
fold:0 epoch:32 step:8 train loss:0.560086, train acc:83.588, train f1:82.357, train precision:84.244, train recall:82.668, train kappa:82.956
fold:0 epoch:32 step:9 train loss:0.565777, train acc:83.228, train f1:82.034, train precision:83.684, train recall:82.223, train kappa:82.579
fold:0 epoch:32 step:10 train loss:0.550919, train acc:83.890, train f1:82.633, train precision:84.184, train recall:82.969, train kappa:83.261
fold:0 epoch:32 step:11 train loss:0.547185, train acc:83.959, train f1:82.467, train precision:84.231, train recall:82.778, train kappa:83.323
fold:0 epoch:32        valid loss:0.689105, valid acc:81.890, valid f1:58.011, valid precision:54.916, valid recall:70.539, valid kappa:79.611
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.04551495695912, 58.04926299850295, 55.062278401100286, 70.1463079475537, 79.78025759894587]
====================================================================================================
fold:0 epoch:33 step:0 train loss:0.554835, train acc:83.533, train f1:82.348, train precision:83.988, train recall:82.583, train kappa:82.892
fold:0 epoch:33 step:1 train loss:0.554850, train acc:83.505, train f1:82.562, train precision:84.622, train recall:82.703, train kappa:82.865
fold:0 epoch:33 step:2 train loss:0.542110, train acc:84.204, train f1:83.029, train precision:85.341, train recall:82.826, train kappa:83.574
fold:0 epoch:33 step:3 train loss:0.552773, train acc:83.627, train f1:82.509, train precision:84.709, train recall:82.414, train kappa:82.983
fold:0 epoch:33 step:4 train loss:0.544795, train acc:83.972, train f1:82.803, train precision:84.694, train recall:82.723, train kappa:83.356
fold:0 epoch:33 step:5 train loss:0.538631, train acc:84.079, train f1:83.110, train precision:84.846, train recall:83.173, train kappa:83.463
fold:0 epoch:33 step:6 train loss:0.563585, train acc:83.429, train f1:82.595, train precision:84.867, train recall:82.643, train kappa:82.780
fold:0 epoch:33 step:7 train loss:0.547025, train acc:83.841, train f1:82.773, train precision:84.412, train recall:82.972, train kappa:83.214
fold:0 epoch:33 step:8 train loss:0.557582, train acc:83.450, train f1:82.246, train precision:84.326, train recall:82.397, train kappa:82.803
fold:0 epoch:33 step:9 train loss:0.548995, train acc:83.713, train f1:82.650, train precision:84.532, train recall:82.869, train kappa:83.077
fold:0 epoch:33 step:10 train loss:0.549540, train acc:83.994, train f1:82.925, train precision:84.890, train recall:83.207, train kappa:83.375
fold:0 epoch:33 step:11 train loss:0.556370, train acc:83.612, train f1:82.359, train precision:84.300, train recall:82.718, train kappa:82.995
fold:0 epoch:33        valid loss:0.677554, valid acc:82.252, valid f1:58.153, valid precision:55.653, valid recall:70.134, valid kappa:80.014
[1;31mTest score increased (82.045515 --> 82.252029).[0m
[82.25202936185005, 58.15262782909102, 55.65264607925825, 70.13425483534861, 80.01396422128701]
====================================================================================================
fold:0 epoch:34 step:0 train loss:0.542466, train acc:83.911, train f1:82.643, train precision:84.565, train recall:82.776, train kappa:83.276
fold:0 epoch:34 step:1 train loss:0.547423, train acc:83.704, train f1:82.622, train precision:84.743, train recall:82.654, train kappa:83.060
fold:0 epoch:34 step:2 train loss:0.544517, train acc:84.149, train f1:83.168, train precision:85.533, train recall:83.116, train kappa:83.531
fold:0 epoch:34 step:3 train loss:0.540524, train acc:84.030, train f1:82.928, train precision:84.556, train recall:82.878, train kappa:83.407
fold:0 epoch:34 step:4 train loss:0.544073, train acc:83.878, train f1:82.562, train precision:83.964, train recall:82.951, train kappa:83.254
fold:0 epoch:34 step:5 train loss:0.543443, train acc:84.048, train f1:83.044, train precision:84.535, train recall:83.195, train kappa:83.426
fold:0 epoch:34 step:6 train loss:0.543489, train acc:83.878, train f1:82.944, train precision:84.576, train recall:82.994, train kappa:83.265
fold:0 epoch:34 step:7 train loss:0.533230, train acc:84.293, train f1:83.245, train precision:84.634, train recall:83.437, train kappa:83.683
fold:0 epoch:34 step:8 train loss:0.545396, train acc:83.792, train f1:82.593, train precision:84.464, train recall:82.581, train kappa:83.153
fold:0 epoch:34 step:9 train loss:0.538653, train acc:83.972, train f1:82.786, train precision:84.744, train recall:82.772, train kappa:83.352
fold:0 epoch:34 step:10 train loss:0.548838, train acc:83.899, train f1:82.736, train precision:84.740, train recall:82.730, train kappa:83.280
fold:0 epoch:34 step:11 train loss:0.525760, train acc:84.364, train f1:83.139, train precision:85.152, train recall:83.005, train kappa:83.753
fold:0 epoch:34        valid loss:0.687036, valid acc:81.753, valid f1:58.503, valid precision:55.356, valid recall:70.592, valid kappa:79.475
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.25202936185005, 58.15262782909102, 55.65264607925825, 70.13425483534861, 80.01396422128701]
====================================================================================================
fold:0 epoch:35 step:0 train loss:0.532112, train acc:84.348, train f1:83.139, train precision:84.613, train recall:83.447, train kappa:83.731
fold:0 epoch:35 step:1 train loss:0.553666, train acc:83.664, train f1:82.852, train precision:84.098, train recall:83.288, train kappa:83.048
fold:0 epoch:35 step:2 train loss:0.533580, train acc:84.167, train f1:82.979, train precision:84.234, train recall:83.387, train kappa:83.549
fold:0 epoch:35 step:3 train loss:0.535814, train acc:84.116, train f1:83.071, train precision:84.900, train recall:83.134, train kappa:83.492
fold:0 epoch:35 step:4 train loss:0.543537, train acc:83.987, train f1:82.942, train precision:84.951, train recall:82.700, train kappa:83.356
fold:0 epoch:35 step:5 train loss:0.536740, train acc:84.174, train f1:83.042, train precision:85.060, train recall:82.987, train kappa:83.554
fold:0 epoch:35 step:6 train loss:0.543723, train acc:84.006, train f1:82.891, train precision:85.155, train recall:82.863, train kappa:83.378
fold:0 epoch:35 step:7 train loss:0.532777, train acc:84.271, train f1:82.950, train precision:85.155, train recall:82.886, train kappa:83.657
fold:0 epoch:35 step:8 train loss:0.534090, train acc:84.097, train f1:83.104, train precision:84.584, train recall:83.355, train kappa:83.489
fold:0 epoch:35 step:9 train loss:0.521354, train acc:84.711, train f1:83.704, train precision:84.932, train recall:84.142, train kappa:84.135
fold:0 epoch:35 step:10 train loss:0.528878, train acc:84.360, train f1:83.033, train precision:84.423, train recall:83.451, train kappa:83.761
fold:0 epoch:35 step:11 train loss:0.549401, train acc:83.650, train f1:82.440, train precision:83.964, train recall:82.785, train kappa:82.997
fold:0 epoch:35        valid loss:0.672931, valid acc:82.504, valid f1:58.951, valid precision:56.292, valid recall:70.246, valid kappa:80.293
[1;31mTest score increased (82.252029 --> 82.503527).[0m
[82.50352710245977, 58.951005067035325, 56.292436391524326, 70.24612358144178, 80.2929566951377]
====================================================================================================
fold:0 epoch:36 step:0 train loss:0.526177, train acc:84.427, train f1:83.309, train precision:85.329, train recall:83.415, train kappa:83.822
fold:0 epoch:36 step:1 train loss:0.523892, train acc:84.473, train f1:83.491, train precision:85.463, train recall:83.417, train kappa:83.867
fold:0 epoch:36 step:2 train loss:0.526883, train acc:84.149, train f1:83.005, train precision:85.241, train recall:82.656, train kappa:83.511
fold:0 epoch:36 step:3 train loss:0.530203, train acc:84.384, train f1:83.095, train precision:84.955, train recall:82.901, train kappa:83.766
fold:0 epoch:36 step:4 train loss:0.529576, train acc:84.326, train f1:83.462, train precision:84.831, train recall:83.612, train kappa:83.721
fold:0 epoch:36 step:5 train loss:0.528848, train acc:84.219, train f1:83.104, train precision:83.865, train recall:83.671, train kappa:83.610
fold:0 epoch:36 step:6 train loss:0.535066, train acc:84.381, train f1:83.473, train precision:84.815, train recall:83.820, train kappa:83.785
fold:0 epoch:36 step:7 train loss:0.522415, train acc:84.512, train f1:83.459, train precision:85.211, train recall:83.735, train kappa:83.913
fold:0 epoch:36 step:8 train loss:0.524171, train acc:84.409, train f1:83.182, train precision:84.954, train recall:83.609, train kappa:83.815
fold:0 epoch:36 step:9 train loss:0.526985, train acc:84.308, train f1:83.343, train precision:85.667, train recall:83.359, train kappa:83.710
fold:0 epoch:36 step:10 train loss:0.526402, train acc:84.424, train f1:83.396, train precision:85.901, train recall:83.275, train kappa:83.822
fold:0 epoch:36 step:11 train loss:0.532881, train acc:84.307, train f1:83.209, train precision:85.403, train recall:83.254, train kappa:83.686
fold:0 epoch:36        valid loss:0.668220, valid acc:82.561, valid f1:58.923, valid precision:55.705, valid recall:70.365, valid kappa:80.355
[1;31mTest score increased (82.503527 --> 82.560779).[0m
[82.56077862064734, 58.92283152547419, 55.70548574938816, 70.36510376814748, 80.35508295690718]
====================================================================================================
fold:0 epoch:37 step:0 train loss:0.526309, train acc:84.314, train f1:83.463, train precision:85.234, train recall:83.430, train kappa:83.711
fold:0 epoch:37 step:1 train loss:0.515442, train acc:84.644, train f1:83.536, train precision:84.749, train recall:83.664, train kappa:84.051
fold:0 epoch:37 step:2 train loss:0.523204, train acc:84.497, train f1:83.471, train precision:84.415, train recall:83.748, train kappa:83.911
fold:0 epoch:37 step:3 train loss:0.517232, train acc:84.616, train f1:83.492, train precision:84.531, train recall:83.798, train kappa:84.022
fold:0 epoch:37 step:4 train loss:0.534642, train acc:84.177, train f1:83.135, train precision:84.325, train recall:83.485, train kappa:83.585
fold:0 epoch:37 step:5 train loss:0.526518, train acc:84.402, train f1:83.290, train precision:84.910, train recall:83.270, train kappa:83.793
fold:0 epoch:37 step:6 train loss:0.520219, train acc:84.497, train f1:83.579, train precision:86.013, train recall:83.572, train kappa:83.889
fold:0 epoch:37 step:7 train loss:0.517517, train acc:84.634, train f1:83.496, train precision:85.616, train recall:83.504, train kappa:84.019
fold:0 epoch:37 step:8 train loss:0.511632, train acc:84.714, train f1:83.475, train precision:85.220, train recall:83.717, train kappa:84.117
fold:0 epoch:37 step:9 train loss:0.526272, train acc:84.335, train f1:83.170, train precision:84.973, train recall:83.405, train kappa:83.725
fold:0 epoch:37 step:10 train loss:0.513223, train acc:84.875, train f1:83.845, train precision:85.187, train recall:84.085, train kappa:84.288
fold:0 epoch:37 step:11 train loss:0.544490, train acc:83.805, train f1:82.882, train precision:83.695, train recall:83.372, train kappa:83.187
fold:0 epoch:37        valid loss:0.675392, valid acc:82.174, valid f1:58.803, valid precision:55.632, valid recall:70.471, valid kappa:79.927
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.56077862064734, 58.92283152547419, 55.70548574938816, 70.36510376814748, 80.35508295690718]
====================================================================================================
fold:0 epoch:38 step:0 train loss:0.513197, train acc:84.619, train f1:83.694, train precision:85.400, train recall:83.701, train kappa:84.041
fold:0 epoch:38 step:1 train loss:0.516637, train acc:84.641, train f1:83.724, train precision:85.201, train recall:83.848, train kappa:84.048
fold:0 epoch:38 step:2 train loss:0.507031, train acc:84.805, train f1:83.641, train precision:85.190, train recall:83.735, train kappa:84.217
fold:0 epoch:38 step:3 train loss:0.511214, train acc:84.753, train f1:83.366, train precision:85.078, train recall:83.329, train kappa:84.168
fold:0 epoch:38 step:4 train loss:0.514560, train acc:84.479, train f1:83.543, train precision:85.813, train recall:83.716, train kappa:83.869
fold:0 epoch:38 step:5 train loss:0.510058, train acc:84.961, train f1:83.799, train precision:85.739, train recall:83.900, train kappa:84.375
fold:0 epoch:38 step:6 train loss:0.517970, train acc:84.467, train f1:83.427, train precision:85.307, train recall:83.697, train kappa:83.865
fold:0 epoch:38 step:7 train loss:0.515576, train acc:84.677, train f1:83.792, train precision:85.345, train recall:84.105, train kappa:84.088
fold:0 epoch:38 step:8 train loss:0.521584, train acc:84.686, train f1:83.713, train precision:85.218, train recall:83.982, train kappa:84.090
fold:0 epoch:38 step:9 train loss:0.524532, train acc:84.424, train f1:83.530, train precision:84.970, train recall:83.851, train kappa:83.822
fold:0 epoch:38 step:10 train loss:0.517010, train acc:84.613, train f1:83.689, train precision:85.227, train recall:83.923, train kappa:84.002
fold:0 epoch:38 step:11 train loss:0.515837, train acc:84.364, train f1:83.742, train precision:85.508, train recall:83.720, train kappa:83.749
fold:0 epoch:38        valid loss:0.669745, valid acc:82.630, valid f1:59.209, valid precision:56.348, valid recall:70.380, valid kappa:80.429
[1;31mTest score increased (82.560779 --> 82.630298).[0m
[82.6302983213037, 59.20891971073624, 56.34786812235018, 70.37952334326555, 80.42911906692024]
====================================================================================================
fold:0 epoch:39 step:0 train loss:0.514212, train acc:84.570, train f1:83.711, train precision:85.600, train recall:83.634, train kappa:83.973
fold:0 epoch:39 step:1 train loss:0.507940, train acc:84.570, train f1:83.813, train precision:85.904, train recall:83.687, train kappa:83.952
fold:0 epoch:39 step:2 train loss:0.519865, train acc:84.467, train f1:83.597, train precision:85.373, train recall:83.508, train kappa:83.873
fold:0 epoch:39 step:3 train loss:0.503440, train acc:85.022, train f1:84.204, train precision:85.610, train recall:84.408, train kappa:84.426
fold:0 epoch:39 step:4 train loss:0.505067, train acc:84.988, train f1:83.829, train precision:84.770, train recall:84.313, train kappa:84.415
fold:0 epoch:39 step:5 train loss:0.506805, train acc:84.988, train f1:83.978, train precision:85.362, train recall:84.124, train kappa:84.414
fold:0 epoch:39 step:6 train loss:0.522343, train acc:84.396, train f1:83.374, train precision:84.996, train recall:83.604, train kappa:83.789
fold:0 epoch:39 step:7 train loss:0.503958, train acc:84.952, train f1:83.951, train precision:85.865, train recall:84.098, train kappa:84.364
fold:0 epoch:39 step:8 train loss:0.508338, train acc:85.010, train f1:83.936, train precision:86.207, train recall:83.847, train kappa:84.433
fold:0 epoch:39 step:9 train loss:0.517201, train acc:84.625, train f1:83.480, train precision:85.461, train recall:83.476, train kappa:84.040
fold:0 epoch:39 step:10 train loss:0.500525, train acc:84.979, train f1:83.858, train precision:85.315, train recall:84.080, train kappa:84.407
fold:0 epoch:39 step:11 train loss:0.504764, train acc:84.702, train f1:83.794, train precision:84.939, train recall:84.197, train kappa:84.105
fold:0 epoch:39        valid loss:0.672377, valid acc:82.442, valid f1:58.858, valid precision:55.616, valid recall:70.240, valid kappa:80.233
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.6302983213037, 59.20891971073624, 56.34786812235018, 70.37952334326555, 80.42911906692024]
====================================================================================================
fold:0 epoch:40 step:0 train loss:0.490838, train acc:85.226, train f1:84.230, train precision:85.376, train recall:84.566, train kappa:84.662
fold:0 epoch:40 step:1 train loss:0.509854, train acc:84.659, train f1:83.901, train precision:85.501, train recall:84.007, train kappa:84.078
fold:0 epoch:40 step:2 train loss:0.504848, train acc:85.043, train f1:83.934, train precision:85.495, train recall:84.166, train kappa:84.462
fold:0 epoch:40 step:3 train loss:0.504757, train acc:84.930, train f1:83.809, train precision:85.409, train recall:84.041, train kappa:84.334
fold:0 epoch:40 step:4 train loss:0.502631, train acc:85.025, train f1:84.034, train precision:85.991, train recall:84.085, train kappa:84.444
fold:0 epoch:40 step:5 train loss:0.509486, train acc:84.644, train f1:83.626, train precision:85.326, train recall:83.922, train kappa:84.056
fold:0 epoch:40 step:6 train loss:0.498761, train acc:85.129, train f1:83.940, train precision:85.735, train recall:84.069, train kappa:84.565
fold:0 epoch:40 step:7 train loss:0.500933, train acc:84.833, train f1:83.860, train precision:85.362, train recall:83.912, train kappa:84.243
fold:0 epoch:40 step:8 train loss:0.497078, train acc:85.074, train f1:84.195, train precision:85.534, train recall:84.432, train kappa:84.507
fold:0 epoch:40 step:9 train loss:0.517670, train acc:84.537, train f1:83.477, train precision:84.803, train recall:83.860, train kappa:83.930
fold:0 epoch:40 step:10 train loss:0.501984, train acc:85.083, train f1:83.948, train precision:85.213, train recall:84.131, train kappa:84.503
fold:0 epoch:40 step:11 train loss:0.490954, train acc:85.175, train f1:84.297, train precision:85.844, train recall:84.389, train kappa:84.597
fold:0 epoch:40        valid loss:0.665142, valid acc:82.708, valid f1:59.587, valid precision:56.713, valid recall:70.367, valid kappa:80.518
[1;31mTest score increased (82.630298 --> 82.707997).[0m
[82.70799681027256, 59.587094540691666, 56.712745631031744, 70.36682303846673, 80.5176129730732]
====================================================================================================
fold:0 epoch:41 step:0 train loss:0.488559, train acc:85.092, train f1:84.254, train precision:86.079, train recall:84.424, train kappa:84.521
fold:0 epoch:41 step:1 train loss:0.491765, train acc:85.016, train f1:83.928, train precision:85.619, train recall:83.856, train kappa:84.433
fold:0 epoch:41 step:2 train loss:0.497806, train acc:85.245, train f1:84.083, train precision:85.617, train recall:84.207, train kappa:84.661
fold:0 epoch:41 step:3 train loss:0.500626, train acc:84.995, train f1:84.147, train precision:85.539, train recall:84.487, train kappa:84.420
fold:0 epoch:41 step:4 train loss:0.490269, train acc:85.251, train f1:83.967, train precision:85.702, train recall:84.119, train kappa:84.680
fold:0 epoch:41 step:5 train loss:0.502703, train acc:84.842, train f1:83.906, train precision:85.640, train recall:84.021, train kappa:84.272
fold:0 epoch:41 step:6 train loss:0.513174, train acc:84.662, train f1:83.767, train precision:85.631, train recall:83.733, train kappa:84.068
fold:0 epoch:41 step:7 train loss:0.502341, train acc:84.991, train f1:84.119, train precision:85.977, train recall:84.206, train kappa:84.424
fold:0 epoch:41 step:8 train loss:0.501608, train acc:84.787, train f1:83.965, train precision:85.208, train recall:84.303, train kappa:84.184
fold:0 epoch:41 step:9 train loss:0.491345, train acc:85.193, train f1:84.219, train precision:85.443, train recall:84.389, train kappa:84.623
fold:0 epoch:41 step:10 train loss:0.500573, train acc:84.958, train f1:84.045, train precision:85.415, train recall:84.272, train kappa:84.370
fold:0 epoch:41 step:11 train loss:0.490066, train acc:85.339, train f1:84.051, train precision:85.561, train recall:84.287, train kappa:84.772
fold:0 epoch:41        valid loss:0.666795, valid acc:82.880, valid f1:59.782, valid precision:56.870, valid recall:70.767, valid kappa:80.718
[1;31mTest score increased (82.707997 --> 82.879751).[0m
[82.8797513648353, 59.78248706493646, 56.86977399676252, 70.76699323690138, 80.71760834843514]
====================================================================================================
fold:0 epoch:42 step:0 train loss:0.485254, train acc:85.449, train f1:84.494, train precision:85.790, train recall:84.978, train kappa:84.897
fold:0 epoch:42 step:1 train loss:0.490912, train acc:85.199, train f1:84.212, train precision:85.790, train recall:84.450, train kappa:84.629
fold:0 epoch:42 step:2 train loss:0.493902, train acc:85.016, train f1:83.930, train precision:85.867, train recall:83.982, train kappa:84.430
fold:0 epoch:42 step:3 train loss:0.497488, train acc:84.958, train f1:84.077, train precision:86.513, train recall:83.874, train kappa:84.377
fold:0 epoch:42 step:4 train loss:0.487833, train acc:85.269, train f1:84.320, train precision:86.295, train recall:84.289, train kappa:84.695
fold:0 epoch:42 step:5 train loss:0.496443, train acc:85.474, train f1:84.419, train precision:85.699, train recall:84.706, train kappa:84.917
fold:0 epoch:42 step:6 train loss:0.501161, train acc:84.940, train f1:84.044, train precision:85.220, train recall:84.464, train kappa:84.365
fold:0 epoch:42 step:7 train loss:0.486964, train acc:85.526, train f1:84.571, train precision:85.905, train recall:84.842, train kappa:84.971
fold:0 epoch:42 step:8 train loss:0.497229, train acc:84.982, train f1:84.135, train precision:85.446, train recall:84.201, train kappa:84.405
fold:0 epoch:42 step:9 train loss:0.493323, train acc:85.339, train f1:84.381, train precision:85.818, train recall:84.611, train kappa:84.769
fold:0 epoch:42 step:10 train loss:0.488405, train acc:85.263, train f1:84.396, train precision:86.288, train recall:84.230, train kappa:84.687
fold:0 epoch:42 step:11 train loss:0.487608, train acc:85.301, train f1:84.032, train precision:85.709, train recall:84.183, train kappa:84.719
fold:0 epoch:42        valid loss:0.669116, valid acc:82.800, valid f1:59.446, valid precision:56.299, valid recall:70.521, valid kappa:80.627
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.8797513648353, 59.78248706493646, 56.86977399676252, 70.76699323690138, 80.71760834843514]
====================================================================================================
fold:0 epoch:43 step:0 train loss:0.476565, train acc:85.794, train f1:84.520, train precision:86.306, train recall:84.518, train kappa:85.252
fold:0 epoch:43 step:1 train loss:0.487675, train acc:85.260, train f1:84.314, train precision:86.228, train recall:84.337, train kappa:84.691
fold:0 epoch:43 step:2 train loss:0.492507, train acc:85.202, train f1:84.328, train precision:86.079, train recall:84.423, train kappa:84.622
fold:0 epoch:43 step:3 train loss:0.475329, train acc:85.571, train f1:84.715, train precision:86.055, train recall:84.991, train kappa:85.011
fold:0 epoch:43 step:4 train loss:0.493792, train acc:85.397, train f1:84.335, train precision:85.534, train recall:84.526, train kappa:84.836
fold:0 epoch:43 step:5 train loss:0.487149, train acc:85.385, train f1:84.453, train precision:85.860, train recall:84.633, train kappa:84.822
fold:0 epoch:43 step:6 train loss:0.490797, train acc:85.062, train f1:84.138, train precision:85.678, train recall:84.298, train kappa:84.482
fold:0 epoch:43 step:7 train loss:0.486807, train acc:85.223, train f1:84.481, train precision:86.176, train recall:84.533, train kappa:84.655
fold:0 epoch:43 step:8 train loss:0.495189, train acc:85.022, train f1:84.003, train precision:85.522, train recall:84.246, train kappa:84.449
fold:0 epoch:43 step:9 train loss:0.485917, train acc:85.336, train f1:84.381, train precision:85.645, train recall:84.608, train kappa:84.775
fold:0 epoch:43 step:10 train loss:0.481683, train acc:85.315, train f1:84.258, train precision:85.466, train recall:84.444, train kappa:84.745
fold:0 epoch:43 step:11 train loss:0.490394, train acc:85.156, train f1:84.712, train precision:86.283, train recall:84.824, train kappa:84.590
fold:0 epoch:43        valid loss:0.664202, valid acc:82.917, valid f1:59.695, valid precision:56.703, valid recall:70.356, valid kappa:80.761
[1;31mTest score increased (82.879751 --> 82.916556).[0m
[82.91655591224159, 59.69481086917479, 56.70264300277796, 70.3561615361251, 80.76116133743578]
====================================================================================================
fold:0 epoch:44 step:0 train loss:0.472869, train acc:85.870, train f1:84.887, train precision:86.535, train recall:84.908, train kappa:85.321
fold:0 epoch:44 step:1 train loss:0.486293, train acc:85.294, train f1:84.107, train precision:85.804, train recall:84.153, train kappa:84.712
fold:0 epoch:44 step:2 train loss:0.483943, train acc:85.181, train f1:84.285, train precision:85.438, train recall:84.577, train kappa:84.616
fold:0 epoch:44 step:3 train loss:0.482018, train acc:85.321, train f1:84.314, train precision:85.584, train recall:84.610, train kappa:84.762
fold:0 epoch:44 step:4 train loss:0.473658, train acc:85.733, train f1:84.749, train precision:85.935, train recall:85.019, train kappa:85.174
fold:0 epoch:44 step:5 train loss:0.484549, train acc:85.291, train f1:84.389, train precision:85.663, train recall:84.577, train kappa:84.725
fold:0 epoch:44 step:6 train loss:0.480260, train acc:85.434, train f1:84.563, train precision:85.898, train recall:84.673, train kappa:84.882
fold:0 epoch:44 step:7 train loss:0.480635, train acc:85.632, train f1:84.934, train precision:86.602, train recall:84.869, train kappa:85.071
fold:0 epoch:44 step:8 train loss:0.473198, train acc:85.541, train f1:84.719, train precision:86.424, train recall:84.790, train kappa:84.985
fold:0 epoch:44 step:9 train loss:0.483298, train acc:85.638, train f1:84.639, train precision:86.264, train recall:84.685, train kappa:85.082
fold:0 epoch:44 step:10 train loss:0.477873, train acc:85.568, train f1:84.630, train precision:86.005, train recall:84.757, train kappa:85.016
fold:0 epoch:44 step:11 train loss:0.486533, train acc:85.658, train f1:84.724, train precision:86.223, train recall:84.896, train kappa:85.109
fold:0 epoch:44        valid loss:0.664012, valid acc:83.123, valid f1:60.000, valid precision:56.987, valid recall:70.504, valid kappa:80.979
[1;31mTest score increased (82.916556 --> 83.123070).[0m
[83.12307031713252, 60.000183792590455, 56.98740246021926, 70.50374623711797, 80.97862869148217]
====================================================================================================
fold:0 epoch:45 step:0 train loss:0.482595, train acc:85.684, train f1:84.789, train precision:86.343, train recall:84.979, train kappa:85.129
fold:0 epoch:45 step:1 train loss:0.475279, train acc:85.477, train f1:84.657, train precision:86.098, train recall:84.821, train kappa:84.916
fold:0 epoch:45 step:2 train loss:0.477183, train acc:85.538, train f1:84.588, train precision:86.011, train recall:84.876, train kappa:84.986
fold:0 epoch:45 step:3 train loss:0.472028, train acc:85.788, train f1:84.786, train precision:86.172, train recall:85.137, train kappa:85.243
fold:0 epoch:45 step:4 train loss:0.477230, train acc:85.519, train f1:84.702, train precision:86.518, train recall:84.745, train kappa:84.968
fold:0 epoch:45 step:5 train loss:0.478042, train acc:85.464, train f1:84.670, train precision:86.550, train recall:84.827, train kappa:84.895
fold:0 epoch:45 step:6 train loss:0.474927, train acc:85.477, train f1:84.664, train precision:86.101, train recall:84.899, train kappa:84.915
fold:0 epoch:45 step:7 train loss:0.478559, train acc:85.678, train f1:84.560, train precision:86.060, train recall:84.675, train kappa:85.125
fold:0 epoch:45 step:8 train loss:0.481289, train acc:85.663, train f1:84.614, train precision:86.102, train recall:84.950, train kappa:85.108
fold:0 epoch:45 step:9 train loss:0.474933, train acc:85.645, train f1:84.562, train precision:86.076, train recall:84.626, train kappa:85.097
fold:0 epoch:45 step:10 train loss:0.483538, train acc:85.519, train f1:84.553, train precision:86.313, train recall:84.557, train kappa:84.964
fold:0 epoch:45 step:11 train loss:0.478894, train acc:85.301, train f1:84.449, train precision:86.293, train recall:84.548, train kappa:84.728
fold:0 epoch:45        valid loss:0.664151, valid acc:83.090, valid f1:59.967, valid precision:57.087, valid recall:70.230, valid kappa:80.946
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.12307031713252, 60.000183792590455, 56.98740246021926, 70.50374623711797, 80.97862869148217]
====================================================================================================
fold:0 epoch:46 step:0 train loss:0.473979, train acc:85.608, train f1:84.717, train precision:86.385, train recall:84.721, train kappa:85.051
fold:0 epoch:46 step:1 train loss:0.474956, train acc:85.669, train f1:84.621, train precision:86.062, train recall:84.929, train kappa:85.121
fold:0 epoch:46 step:2 train loss:0.460633, train acc:86.118, train f1:84.978, train precision:86.383, train recall:85.386, train kappa:85.582
fold:0 epoch:46 step:3 train loss:0.474213, train acc:85.571, train f1:84.721, train precision:86.073, train recall:85.138, train kappa:85.013
fold:0 epoch:46 step:4 train loss:0.482431, train acc:85.468, train f1:84.516, train precision:86.040, train recall:84.802, train kappa:84.913
fold:0 epoch:46 step:5 train loss:0.462491, train acc:86.090, train f1:85.044, train precision:86.611, train recall:85.117, train kappa:85.562
fold:0 epoch:46 step:6 train loss:0.477751, train acc:85.782, train f1:84.721, train precision:86.458, train recall:84.738, train kappa:85.237
fold:0 epoch:46 step:7 train loss:0.471983, train acc:85.855, train f1:84.974, train precision:86.565, train recall:84.840, train kappa:85.310
fold:0 epoch:46 step:8 train loss:0.469554, train acc:85.626, train f1:84.742, train precision:86.142, train recall:84.808, train kappa:85.075
fold:0 epoch:46 step:9 train loss:0.469841, train acc:85.519, train f1:84.846, train precision:85.796, train recall:85.171, train kappa:84.963
fold:0 epoch:46 step:10 train loss:0.472184, train acc:85.599, train f1:84.720, train precision:86.060, train recall:84.987, train kappa:85.035
fold:0 epoch:46 step:11 train loss:0.456628, train acc:85.947, train f1:84.817, train precision:86.041, train recall:85.076, train kappa:85.400
fold:0 epoch:46        valid loss:0.670121, valid acc:82.939, valid f1:59.517, valid precision:56.261, valid recall:70.357, valid kappa:80.783
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.12307031713252, 60.000183792590455, 56.98740246021926, 70.50374623711797, 80.97862869148217]
====================================================================================================
fold:0 epoch:47 step:0 train loss:0.469978, train acc:85.742, train f1:84.520, train precision:85.765, train recall:84.807, train kappa:85.196
fold:0 epoch:47 step:1 train loss:0.458951, train acc:85.938, train f1:85.242, train precision:86.713, train recall:85.317, train kappa:85.396
fold:0 epoch:47 step:2 train loss:0.467716, train acc:85.788, train f1:84.761, train precision:86.325, train recall:84.928, train kappa:85.248
fold:0 epoch:47 step:3 train loss:0.465037, train acc:85.886, train f1:84.769, train precision:86.440, train recall:84.883, train kappa:85.338
fold:0 epoch:47 step:4 train loss:0.466809, train acc:85.861, train f1:84.815, train precision:86.329, train recall:84.986, train kappa:85.323
fold:0 epoch:47 step:5 train loss:0.462223, train acc:86.002, train f1:85.156, train precision:86.624, train recall:85.366, train kappa:85.468
fold:0 epoch:47 step:6 train loss:0.471925, train acc:85.776, train f1:85.019, train precision:86.685, train recall:85.058, train kappa:85.224
fold:0 epoch:47 step:7 train loss:0.460839, train acc:85.980, train f1:85.003, train precision:86.341, train recall:85.191, train kappa:85.432
fold:0 epoch:47 step:8 train loss:0.462923, train acc:85.870, train f1:84.790, train precision:85.874, train recall:85.054, train kappa:85.313
fold:0 epoch:47 step:9 train loss:0.467956, train acc:85.767, train f1:84.786, train precision:86.084, train recall:84.971, train kappa:85.221
fold:0 epoch:47 step:10 train loss:0.466323, train acc:85.721, train f1:84.939, train precision:86.154, train recall:85.097, train kappa:85.183
fold:0 epoch:47 step:11 train loss:0.487659, train acc:85.185, train f1:84.441, train precision:85.945, train recall:84.695, train kappa:84.614
fold:0 epoch:47        valid loss:0.660018, valid acc:83.103, valid f1:59.733, valid precision:56.833, valid recall:70.350, valid kappa:80.964
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.12307031713252, 60.000183792590455, 56.98740246021926, 70.50374623711797, 80.97862869148217]
====================================================================================================
fold:0 epoch:48 step:0 train loss:0.455294, train acc:86.041, train f1:85.076, train precision:86.593, train recall:85.224, train kappa:85.506
fold:0 epoch:48 step:1 train loss:0.453854, train acc:86.246, train f1:85.210, train precision:86.988, train recall:85.240, train kappa:85.717
fold:0 epoch:48 step:2 train loss:0.460289, train acc:86.008, train f1:85.183, train precision:86.888, train recall:85.283, train kappa:85.469
fold:0 epoch:48 step:3 train loss:0.459721, train acc:86.063, train f1:85.283, train precision:86.657, train recall:85.506, train kappa:85.520
fold:0 epoch:48 step:4 train loss:0.462408, train acc:85.876, train f1:84.991, train precision:86.353, train recall:85.076, train kappa:85.338
fold:0 epoch:48 step:5 train loss:0.456631, train acc:85.983, train f1:84.959, train precision:86.007, train recall:85.195, train kappa:85.453
fold:0 epoch:48 step:6 train loss:0.467197, train acc:85.748, train f1:84.761, train precision:85.919, train recall:84.975, train kappa:85.194
fold:0 epoch:48 step:7 train loss:0.469782, train acc:85.950, train f1:84.987, train precision:86.303, train recall:85.148, train kappa:85.411
fold:0 epoch:48 step:8 train loss:0.456218, train acc:86.310, train f1:85.343, train precision:86.654, train recall:85.448, train kappa:85.782
fold:0 epoch:48 step:9 train loss:0.465311, train acc:86.029, train f1:85.450, train precision:87.323, train recall:85.295, train kappa:85.491
fold:0 epoch:48 step:10 train loss:0.466593, train acc:85.950, train f1:85.223, train precision:86.701, train recall:85.341, train kappa:85.405
fold:0 epoch:48 step:11 train loss:0.458045, train acc:86.025, train f1:85.071, train precision:86.741, train recall:85.086, train kappa:85.486
fold:0 epoch:48        valid loss:0.663897, valid acc:83.176, valid f1:59.860, valid precision:56.815, valid recall:70.254, valid kappa:81.046
[1;31mTest score increased (83.123070 --> 83.176232).[0m
[83.17623244116385, 59.859778777995245, 56.814555311801975, 70.25430219344578, 81.04609432128646]
====================================================================================================
fold:0 epoch:49 step:0 train loss:0.453575, train acc:86.115, train f1:85.290, train precision:86.689, train recall:85.533, train kappa:85.584
fold:0 epoch:49 step:1 train loss:0.448183, train acc:86.407, train f1:85.379, train precision:86.612, train recall:85.659, train kappa:85.898
fold:0 epoch:49 step:2 train loss:0.458366, train acc:86.053, train f1:85.045, train precision:86.203, train recall:85.409, train kappa:85.517
fold:0 epoch:49 step:3 train loss:0.455921, train acc:86.151, train f1:85.276, train precision:86.377, train recall:85.582, train kappa:85.627
fold:0 epoch:49 step:4 train loss:0.455006, train acc:86.090, train f1:85.026, train precision:86.504, train recall:85.155, train kappa:85.549
fold:0 epoch:49 step:5 train loss:0.460100, train acc:85.941, train f1:85.203, train precision:86.235, train recall:85.484, train kappa:85.406
fold:0 epoch:49 step:6 train loss:0.451332, train acc:86.127, train f1:85.111, train precision:86.484, train recall:85.137, train kappa:85.579
fold:0 epoch:49 step:7 train loss:0.463730, train acc:85.876, train f1:85.163, train precision:86.965, train recall:85.136, train kappa:85.334
fold:0 epoch:49 step:8 train loss:0.451723, train acc:86.371, train f1:85.324, train precision:87.138, train recall:85.433, train kappa:85.840
fold:0 epoch:49 step:9 train loss:0.461329, train acc:85.989, train f1:85.244, train precision:86.745, train recall:85.395, train kappa:85.458
fold:0 epoch:49 step:10 train loss:0.465412, train acc:85.898, train f1:84.953, train precision:86.067, train recall:85.210, train kappa:85.357
fold:0 epoch:49 step:11 train loss:0.475836, train acc:85.619, train f1:84.785, train precision:85.773, train recall:85.229, train kappa:85.058
fold:0 epoch:49        valid loss:0.671296, valid acc:82.957, valid f1:59.977, valid precision:56.963, valid recall:70.523, valid kappa:80.805
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.17623244116385, 59.859778777995245, 56.814555311801975, 70.25430219344578, 81.04609432128646]
====================================================================================================
fold:0 epoch:50 step:0 train loss:0.442257, train acc:86.487, train f1:85.453, train precision:86.779, train recall:85.827, train kappa:85.966
fold:0 epoch:50 step:1 train loss:0.454556, train acc:86.249, train f1:85.380, train precision:86.619, train recall:85.504, train kappa:85.722
fold:0 epoch:50 step:2 train loss:0.459383, train acc:85.870, train f1:85.129, train precision:86.663, train recall:85.179, train kappa:85.327
fold:0 epoch:50 step:3 train loss:0.444836, train acc:86.450, train f1:85.418, train precision:86.899, train recall:85.590, train kappa:85.925
fold:0 epoch:50 step:4 train loss:0.458448, train acc:85.925, train f1:85.166, train precision:86.733, train recall:85.298, train kappa:85.397
fold:0 epoch:50 step:5 train loss:0.457082, train acc:85.931, train f1:84.987, train precision:85.976, train recall:85.361, train kappa:85.404
fold:0 epoch:50 step:6 train loss:0.448595, train acc:86.459, train f1:85.509, train precision:86.935, train recall:85.672, train kappa:85.930
fold:0 epoch:50 step:7 train loss:0.455408, train acc:86.267, train f1:85.273, train precision:86.505, train recall:85.508, train kappa:85.736
fold:0 epoch:50 step:8 train loss:0.445957, train acc:86.273, train f1:85.296, train precision:86.812, train recall:85.395, train kappa:85.756
fold:0 epoch:50 step:9 train loss:0.462867, train acc:85.959, train f1:84.956, train precision:86.213, train recall:85.257, train kappa:85.419
fold:0 epoch:50 step:10 train loss:0.465076, train acc:85.739, train f1:84.840, train precision:86.083, train recall:85.183, train kappa:85.185
fold:0 epoch:50 step:11 train loss:0.459374, train acc:85.774, train f1:84.764, train precision:86.434, train recall:85.194, train kappa:85.227
fold:0 epoch:50        valid loss:0.662127, valid acc:83.375, valid f1:60.264, valid precision:57.360, valid recall:70.441, valid kappa:81.266
[1;31mTest score increased (83.176232 --> 83.374568).[0m
[83.37456805774225, 60.26433587342397, 57.36047572195119, 70.4405234870999, 81.26613022413184]
====================================================================================================
fold:0 epoch:51 step:0 train loss:0.449061, train acc:86.185, train f1:85.267, train precision:86.687, train recall:85.481, train kappa:85.648
fold:0 epoch:51 step:1 train loss:0.447887, train acc:86.411, train f1:85.617, train precision:86.884, train recall:85.766, train kappa:85.888
fold:0 epoch:51 step:2 train loss:0.443005, train acc:86.539, train f1:85.562, train precision:86.892, train recall:85.678, train kappa:86.019
fold:0 epoch:51 step:3 train loss:0.448368, train acc:86.188, train f1:85.370, train precision:86.605, train recall:85.534, train kappa:85.670
fold:0 epoch:51 step:4 train loss:0.450671, train acc:86.313, train f1:85.485, train precision:87.049, train recall:85.439, train kappa:85.792
fold:0 epoch:51 step:5 train loss:0.439699, train acc:86.493, train f1:85.757, train precision:87.150, train recall:85.843, train kappa:85.982
fold:0 epoch:51 step:6 train loss:0.441021, train acc:86.548, train f1:85.805, train precision:86.936, train recall:85.963, train kappa:86.023
fold:0 epoch:51 step:7 train loss:0.449187, train acc:86.166, train f1:85.300, train precision:86.462, train recall:85.438, train kappa:85.634
fold:0 epoch:51 step:8 train loss:0.447268, train acc:86.166, train f1:85.226, train precision:86.773, train recall:85.393, train kappa:85.620
fold:0 epoch:51 step:9 train loss:0.458461, train acc:85.962, train f1:85.404, train precision:86.724, train recall:85.706, train kappa:85.434
fold:0 epoch:51 step:10 train loss:0.462761, train acc:85.980, train f1:84.995, train precision:86.399, train recall:85.275, train kappa:85.438
fold:0 epoch:51 step:11 train loss:0.452610, train acc:86.285, train f1:85.357, train precision:87.185, train recall:85.499, train kappa:85.765
fold:0 epoch:51        valid loss:0.664308, valid acc:83.283, valid f1:59.820, valid precision:56.962, valid recall:70.264, valid kappa:81.163
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.37456805774225, 60.26433587342397, 57.36047572195119, 70.4405234870999, 81.26613022413184]
====================================================================================================
fold:0 epoch:52 step:0 train loss:0.441522, train acc:86.514, train f1:85.527, train precision:87.111, train recall:85.960, train kappa:86.001
fold:0 epoch:52 step:1 train loss:0.437897, train acc:86.636, train f1:85.784, train precision:87.362, train recall:86.051, train kappa:86.125
fold:0 epoch:52 step:2 train loss:0.443554, train acc:86.389, train f1:85.452, train precision:86.702, train recall:85.603, train kappa:85.872
fold:0 epoch:52 step:3 train loss:0.450996, train acc:86.200, train f1:85.336, train precision:86.409, train recall:85.458, train kappa:85.667
fold:0 epoch:52 step:4 train loss:0.452173, train acc:86.252, train f1:85.241, train precision:86.299, train recall:85.408, train kappa:85.720
fold:0 epoch:52 step:5 train loss:0.448200, train acc:86.209, train f1:85.267, train precision:86.593, train recall:85.263, train kappa:85.678
fold:0 epoch:52 step:6 train loss:0.441760, train acc:86.429, train f1:85.634, train precision:87.495, train recall:85.393, train kappa:85.910
fold:0 epoch:52 step:7 train loss:0.445523, train acc:86.331, train f1:85.525, train precision:87.068, train recall:85.554, train kappa:85.797
fold:0 epoch:52 step:8 train loss:0.447557, train acc:86.374, train f1:85.568, train precision:87.031, train recall:85.926, train kappa:85.854
fold:0 epoch:52 step:9 train loss:0.450173, train acc:86.020, train f1:84.984, train precision:85.904, train recall:85.596, train kappa:85.493
fold:0 epoch:52 step:10 train loss:0.450944, train acc:86.221, train f1:85.396, train precision:86.728, train recall:85.782, train kappa:85.691
fold:0 epoch:52 step:11 train loss:0.448552, train acc:86.304, train f1:85.201, train precision:86.534, train recall:85.525, train kappa:85.779
fold:0 epoch:52        valid loss:0.657591, valid acc:83.442, valid f1:60.411, valid precision:57.491, valid recall:70.478, valid kappa:81.344
[1;31mTest score increased (83.374568 --> 83.442043).[0m
[83.44204306132048, 60.410617479731386, 57.49103573691021, 70.47799263811335, 81.34398421279366]
====================================================================================================
fold:0 epoch:53 step:0 train loss:0.437188, train acc:86.441, train f1:85.651, train precision:86.984, train recall:85.838, train kappa:85.918
fold:0 epoch:53 step:1 train loss:0.441061, train acc:86.499, train f1:85.736, train precision:87.397, train recall:85.772, train kappa:85.980
fold:0 epoch:53 step:2 train loss:0.436003, train acc:86.530, train f1:85.435, train precision:86.975, train recall:85.482, train kappa:86.013
fold:0 epoch:53 step:3 train loss:0.444828, train acc:86.487, train f1:85.696, train precision:86.864, train recall:85.811, train kappa:85.962
fold:0 epoch:53 step:4 train loss:0.449828, train acc:86.264, train f1:85.459, train precision:86.602, train recall:85.583, train kappa:85.749
fold:0 epoch:53 step:5 train loss:0.444928, train acc:86.502, train f1:85.705, train precision:86.727, train recall:85.831, train kappa:85.979
fold:0 epoch:53 step:6 train loss:0.440245, train acc:86.661, train f1:85.896, train precision:87.078, train recall:86.076, train kappa:86.155
fold:0 epoch:53 step:7 train loss:0.437548, train acc:86.490, train f1:85.503, train precision:86.582, train recall:85.702, train kappa:85.972
fold:0 epoch:53 step:8 train loss:0.452257, train acc:86.255, train f1:85.603, train precision:87.095, train recall:85.781, train kappa:85.723
fold:0 epoch:53 step:9 train loss:0.441234, train acc:86.526, train f1:85.687, train precision:87.011, train recall:85.831, train kappa:86.012
fold:0 epoch:53 step:10 train loss:0.442806, train acc:86.456, train f1:85.479, train precision:86.657, train recall:85.861, train kappa:85.939
fold:0 epoch:53 step:11 train loss:0.439784, train acc:86.401, train f1:85.757, train precision:87.399, train recall:85.830, train kappa:85.872
fold:0 epoch:53        valid loss:0.659421, valid acc:83.495, valid f1:60.311, valid precision:57.257, valid recall:70.436, valid kappa:81.401
[1;31mTest score increased (83.442043 --> 83.495205).[0m
[83.4952051853518, 60.31126677868085, 57.257433098640654, 70.43642173815357, 81.4009532829871]
====================================================================================================
fold:0 epoch:54 step:0 train loss:0.441498, train acc:86.502, train f1:85.744, train precision:86.908, train recall:85.983, train kappa:85.986
fold:0 epoch:54 step:1 train loss:0.439445, train acc:86.633, train f1:85.803, train precision:86.987, train recall:85.971, train kappa:86.133
fold:0 epoch:54 step:2 train loss:0.443942, train acc:86.383, train f1:85.753, train precision:86.976, train recall:86.034, train kappa:85.866
fold:0 epoch:54 step:3 train loss:0.426962, train acc:86.630, train f1:85.827, train precision:86.957, train recall:85.910, train kappa:86.110
fold:0 epoch:54 step:4 train loss:0.436690, train acc:86.600, train f1:85.816, train precision:87.027, train recall:85.794, train kappa:86.092
fold:0 epoch:54 step:5 train loss:0.440939, train acc:86.453, train f1:85.557, train precision:86.574, train recall:85.851, train kappa:85.925
fold:0 epoch:54 step:6 train loss:0.442170, train acc:86.478, train f1:85.632, train precision:86.877, train recall:85.758, train kappa:85.946
fold:0 epoch:54 step:7 train loss:0.432745, train acc:86.621, train f1:85.873, train precision:87.249, train recall:85.915, train kappa:86.105
fold:0 epoch:54 step:8 train loss:0.443136, train acc:86.487, train f1:85.761, train precision:87.302, train recall:85.904, train kappa:85.969
fold:0 epoch:54 step:9 train loss:0.437444, train acc:86.609, train f1:85.635, train precision:86.898, train recall:85.975, train kappa:86.093
fold:0 epoch:54 step:10 train loss:0.440892, train acc:86.414, train f1:85.612, train precision:86.877, train recall:85.771, train kappa:85.902
fold:0 epoch:54 step:11 train loss:0.449478, train acc:86.111, train f1:85.031, train precision:85.795, train recall:85.387, train kappa:85.611
fold:0 epoch:54        valid loss:0.658981, valid acc:83.667, valid f1:60.422, valid precision:57.166, valid recall:70.298, valid kappa:81.595
[1;31mTest score increased (83.495205 --> 83.666960).[0m
[83.66695973991453, 60.42228224848378, 57.16605671394455, 70.29808662245183, 81.59463862458716]
====================================================================================================
fold:0 epoch:55 step:0 train loss:0.429787, train acc:86.896, train f1:86.134, train precision:87.210, train recall:86.397, train kappa:86.395
fold:0 epoch:55 step:1 train loss:0.436473, train acc:86.539, train f1:85.685, train precision:87.133, train recall:85.769, train kappa:86.015
fold:0 epoch:55 step:2 train loss:0.441437, train acc:86.435, train f1:85.456, train precision:87.174, train recall:85.354, train kappa:85.923
fold:0 epoch:55 step:3 train loss:0.428235, train acc:86.993, train f1:85.859, train precision:87.122, train recall:86.092, train kappa:86.495
fold:0 epoch:55 step:4 train loss:0.437973, train acc:86.462, train f1:85.737, train precision:86.786, train recall:86.011, train kappa:85.941
fold:0 epoch:55 step:5 train loss:0.446110, train acc:86.234, train f1:85.610, train precision:86.453, train recall:86.002, train kappa:85.710
fold:0 epoch:55 step:6 train loss:0.429008, train acc:86.951, train f1:85.855, train precision:86.819, train recall:86.157, train kappa:86.453
fold:0 epoch:55 step:7 train loss:0.428974, train acc:86.661, train f1:85.812, train precision:87.032, train recall:85.920, train kappa:86.143
fold:0 epoch:55 step:8 train loss:0.432826, train acc:86.716, train f1:85.876, train precision:87.229, train recall:85.900, train kappa:86.210
fold:0 epoch:55 step:9 train loss:0.431619, train acc:86.618, train f1:85.594, train precision:86.939, train recall:85.617, train kappa:86.101
fold:0 epoch:55 step:10 train loss:0.440579, train acc:86.426, train f1:85.842, train precision:87.119, train recall:86.006, train kappa:85.909
fold:0 epoch:55 step:11 train loss:0.436046, train acc:86.517, train f1:85.681, train precision:86.984, train recall:85.839, train kappa:86.010
fold:0 epoch:55        valid loss:0.663511, valid acc:83.422, valid f1:60.451, valid precision:57.311, valid recall:70.386, valid kappa:81.327
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.66695973991453, 60.42228224848378, 57.16605671394455, 70.29808662245183, 81.59463862458716]
====================================================================================================
fold:0 epoch:56 step:0 train loss:0.421857, train acc:87.018, train f1:86.068, train precision:87.178, train recall:86.434, train kappa:86.522
fold:0 epoch:56 step:1 train loss:0.427081, train acc:86.844, train f1:86.122, train precision:87.469, train recall:86.262, train kappa:86.350
fold:0 epoch:56 step:2 train loss:0.424393, train acc:87.018, train f1:86.087, train precision:87.137, train recall:86.423, train kappa:86.519
fold:0 epoch:56 step:3 train loss:0.431842, train acc:86.877, train f1:86.015, train precision:87.264, train recall:86.184, train kappa:86.366
fold:0 epoch:56 step:4 train loss:0.419303, train acc:87.177, train f1:86.376, train precision:87.648, train recall:86.426, train kappa:86.697
fold:0 epoch:56 step:5 train loss:0.437302, train acc:86.661, train f1:85.762, train precision:87.079, train recall:85.806, train kappa:86.143
fold:0 epoch:56 step:6 train loss:0.440433, train acc:86.478, train f1:85.894, train precision:87.252, train recall:85.993, train kappa:85.966
fold:0 epoch:56 step:7 train loss:0.435167, train acc:86.612, train f1:85.702, train precision:87.031, train recall:85.992, train kappa:86.100
fold:0 epoch:56 step:8 train loss:0.430309, train acc:86.520, train f1:85.608, train precision:86.812, train recall:85.810, train kappa:85.995
fold:0 epoch:56 step:9 train loss:0.432905, train acc:86.673, train f1:85.941, train precision:87.127, train recall:86.174, train kappa:86.170
fold:0 epoch:56 step:10 train loss:0.419872, train acc:86.981, train f1:86.177, train precision:87.346, train recall:86.386, train kappa:86.480
fold:0 epoch:56 step:11 train loss:0.441365, train acc:86.314, train f1:85.513, train precision:86.451, train recall:85.846, train kappa:85.794
fold:0 epoch:56        valid loss:0.657028, valid acc:83.647, valid f1:60.871, valid precision:57.837, valid recall:70.512, valid kappa:81.573
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.66695973991453, 60.42228224848378, 57.16605671394455, 70.29808662245183, 81.59463862458716]
====================================================================================================
fold:0 epoch:57 step:0 train loss:0.424022, train acc:86.981, train f1:85.896, train precision:87.070, train recall:85.995, train kappa:86.478
fold:0 epoch:57 step:1 train loss:0.433460, train acc:86.597, train f1:85.886, train precision:87.026, train recall:86.018, train kappa:86.082
fold:0 epoch:57 step:2 train loss:0.430511, train acc:86.578, train f1:85.855, train precision:86.825, train recall:86.014, train kappa:86.064
fold:0 epoch:57 step:3 train loss:0.421781, train acc:86.926, train f1:86.174, train precision:87.671, train recall:86.062, train kappa:86.423
fold:0 epoch:57 step:4 train loss:0.430326, train acc:86.908, train f1:85.846, train precision:87.157, train recall:85.937, train kappa:86.403
fold:0 epoch:57 step:5 train loss:0.427146, train acc:86.737, train f1:85.910, train precision:87.051, train recall:86.018, train kappa:86.227
fold:0 epoch:57 step:6 train loss:0.435108, train acc:86.661, train f1:85.698, train precision:86.896, train recall:85.929, train kappa:86.168
fold:0 epoch:57 step:7 train loss:0.423366, train acc:86.908, train f1:85.963, train precision:87.117, train recall:86.225, train kappa:86.410
fold:0 epoch:57 step:8 train loss:0.436231, train acc:86.774, train f1:86.043, train precision:87.002, train recall:86.495, train kappa:86.275
fold:0 epoch:57 step:9 train loss:0.421170, train acc:86.984, train f1:86.224, train precision:87.165, train recall:86.522, train kappa:86.486
fold:0 epoch:57 step:10 train loss:0.436226, train acc:86.673, train f1:85.994, train precision:87.111, train recall:86.090, train kappa:86.156
fold:0 epoch:57 step:11 train loss:0.426387, train acc:86.758, train f1:85.734, train precision:86.806, train recall:85.893, train kappa:86.259
fold:0 epoch:57        valid loss:0.655587, valid acc:83.824, valid f1:60.842, valid precision:57.681, valid recall:70.433, valid kappa:81.764
[1;31mTest score increased (83.666960 --> 83.824401).[0m
[83.82440141493038, 60.84222114371918, 57.68128965410676, 70.4334486258521, 81.76427372039939]
====================================================================================================
fold:0 epoch:58 step:0 train loss:0.428446, train acc:86.780, train f1:85.990, train precision:87.496, train recall:85.925, train kappa:86.258
fold:0 epoch:58 step:1 train loss:0.422377, train acc:86.951, train f1:86.172, train precision:87.301, train recall:86.259, train kappa:86.457
fold:0 epoch:58 step:2 train loss:0.431087, train acc:86.578, train f1:85.781, train precision:87.080, train recall:85.886, train kappa:86.069
fold:0 epoch:58 step:3 train loss:0.431738, train acc:86.853, train f1:86.152, train precision:87.490, train recall:86.288, train kappa:86.348
fold:0 epoch:58 step:4 train loss:0.423373, train acc:86.832, train f1:86.096, train precision:87.179, train recall:86.252, train kappa:86.320
fold:0 epoch:58 step:5 train loss:0.428708, train acc:86.761, train f1:85.829, train precision:86.777, train recall:86.128, train kappa:86.263
fold:0 epoch:58 step:6 train loss:0.415442, train acc:87.305, train f1:86.396, train precision:87.646, train recall:86.456, train kappa:86.822
fold:0 epoch:58 step:7 train loss:0.419590, train acc:87.091, train f1:86.062, train precision:87.303, train recall:86.373, train kappa:86.603
fold:0 epoch:58 step:8 train loss:0.423152, train acc:86.929, train f1:86.089, train precision:87.196, train recall:86.263, train kappa:86.432
fold:0 epoch:58 step:9 train loss:0.426372, train acc:87.027, train f1:86.160, train precision:87.458, train recall:86.265, train kappa:86.541
fold:0 epoch:58 step:10 train loss:0.431048, train acc:86.658, train f1:85.950, train precision:87.052, train recall:86.051, train kappa:86.138
fold:0 epoch:58 step:11 train loss:0.431586, train acc:86.652, train f1:85.894, train precision:86.997, train recall:86.106, train kappa:86.126
fold:0 epoch:58        valid loss:0.666543, valid acc:83.350, valid f1:60.258, valid precision:56.900, valid recall:70.379, valid kappa:81.252
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.82440141493038, 60.84222114371918, 57.68128965410676, 70.4334486258521, 81.76427372039939]
====================================================================================================
fold:0 epoch:59 step:0 train loss:0.424085, train acc:86.908, train f1:86.170, train precision:86.862, train recall:86.614, train kappa:86.396
fold:0 epoch:59 step:1 train loss:0.417572, train acc:87.018, train f1:86.138, train precision:87.165, train recall:86.277, train kappa:86.518
fold:0 epoch:59 step:2 train loss:0.419698, train acc:87.158, train f1:86.337, train precision:87.536, train recall:86.568, train kappa:86.663
fold:0 epoch:59 step:3 train loss:0.418125, train acc:86.929, train f1:85.861, train precision:87.111, train recall:86.018, train kappa:86.430
fold:0 epoch:59 step:4 train loss:0.415434, train acc:87.363, train f1:86.560, train precision:87.948, train recall:86.610, train kappa:86.879
fold:0 epoch:59 step:5 train loss:0.426446, train acc:86.938, train f1:86.086, train precision:87.409, train recall:86.185, train kappa:86.434
fold:0 epoch:59 step:6 train loss:0.428660, train acc:86.575, train f1:85.999, train precision:87.334, train recall:85.939, train kappa:86.067
fold:0 epoch:59 step:7 train loss:0.419960, train acc:86.832, train f1:85.978, train precision:87.163, train recall:86.231, train kappa:86.331
fold:0 epoch:59 step:8 train loss:0.417406, train acc:87.109, train f1:86.026, train precision:87.282, train recall:86.128, train kappa:86.626
fold:0 epoch:59 step:9 train loss:0.418496, train acc:87.173, train f1:86.254, train precision:87.183, train recall:86.763, train kappa:86.690
fold:0 epoch:59 step:10 train loss:0.416820, train acc:87.054, train f1:86.266, train precision:87.176, train recall:86.671, train kappa:86.562
fold:0 epoch:59 step:11 train loss:0.428538, train acc:86.623, train f1:86.165, train precision:87.906, train recall:86.109, train kappa:86.127
fold:0 epoch:59        valid loss:0.661224, valid acc:83.565, valid f1:60.640, valid precision:57.357, valid recall:70.651, valid kappa:81.487
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.82440141493038, 60.84222114371918, 57.68128965410676, 70.4334486258521, 81.76427372039939]
====================================================================================================
fold:0 epoch:60 step:0 train loss:0.404183, train acc:87.488, train f1:86.602, train precision:87.492, train recall:86.901, train kappa:87.015
fold:0 epoch:60 step:1 train loss:0.416339, train acc:87.012, train f1:86.175, train precision:87.220, train recall:86.375, train kappa:86.513
fold:0 epoch:60 step:2 train loss:0.418708, train acc:87.146, train f1:86.320, train precision:87.117, train recall:86.594, train kappa:86.648
fold:0 epoch:60 step:3 train loss:0.418921, train acc:87.311, train f1:86.492, train precision:87.418, train recall:86.663, train kappa:86.824
fold:0 epoch:60 step:4 train loss:0.420369, train acc:86.920, train f1:86.023, train precision:87.307, train recall:86.123, train kappa:86.428
fold:0 epoch:60 step:5 train loss:0.414668, train acc:87.115, train f1:86.377, train precision:88.075, train recall:86.282, train kappa:86.613
fold:0 epoch:60 step:6 train loss:0.418895, train acc:86.951, train f1:86.313, train precision:87.788, train recall:86.342, train kappa:86.451
fold:0 epoch:60 step:7 train loss:0.414440, train acc:87.094, train f1:86.146, train precision:87.525, train recall:86.155, train kappa:86.608
fold:0 epoch:60 step:8 train loss:0.413115, train acc:87.219, train f1:86.340, train precision:87.922, train recall:86.531, train kappa:86.725
fold:0 epoch:60 step:9 train loss:0.422992, train acc:86.972, train f1:86.115, train precision:86.976, train recall:86.487, train kappa:86.480
fold:0 epoch:60 step:10 train loss:0.421873, train acc:87.106, train f1:86.259, train precision:87.114, train recall:86.643, train kappa:86.610
fold:0 epoch:60 step:11 train loss:0.421502, train acc:87.279, train f1:86.558, train precision:87.462, train recall:86.865, train kappa:86.814
fold:0 epoch:60        valid loss:0.660350, valid acc:83.724, valid f1:60.831, valid precision:57.690, valid recall:70.519, valid kappa:81.661
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.82440141493038, 60.84222114371918, 57.68128965410676, 70.4334486258521, 81.76427372039939]
====================================================================================================
fold:0 epoch:61 step:0 train loss:0.411084, train acc:87.106, train f1:86.247, train precision:87.472, train recall:86.449, train kappa:86.611
fold:0 epoch:61 step:1 train loss:0.418288, train acc:86.990, train f1:86.112, train precision:87.533, train recall:86.134, train kappa:86.486
fold:0 epoch:61 step:2 train loss:0.404248, train acc:87.286, train f1:86.421, train precision:87.839, train recall:86.338, train kappa:86.787
fold:0 epoch:61 step:3 train loss:0.410407, train acc:87.262, train f1:86.458, train precision:87.728, train recall:86.394, train kappa:86.779
fold:0 epoch:61 step:4 train loss:0.416872, train acc:87.128, train f1:86.512, train precision:87.455, train recall:86.853, train kappa:86.651
fold:0 epoch:61 step:5 train loss:0.407194, train acc:87.476, train f1:86.695, train precision:87.590, train recall:87.054, train kappa:86.992
fold:0 epoch:61 step:6 train loss:0.418784, train acc:86.938, train f1:86.072, train precision:87.211, train recall:86.338, train kappa:86.456
fold:0 epoch:61 step:7 train loss:0.423879, train acc:86.838, train f1:86.108, train precision:87.506, train recall:86.121, train kappa:86.334
fold:0 epoch:61 step:8 train loss:0.424473, train acc:86.908, train f1:86.138, train precision:87.225, train recall:86.355, train kappa:86.407
fold:0 epoch:61 step:9 train loss:0.424902, train acc:86.975, train f1:86.234, train precision:87.330, train recall:86.377, train kappa:86.474
fold:0 epoch:61 step:10 train loss:0.418845, train acc:87.048, train f1:86.137, train precision:87.345, train recall:86.399, train kappa:86.558
fold:0 epoch:61 step:11 train loss:0.416591, train acc:87.337, train f1:86.583, train precision:88.100, train recall:86.759, train kappa:86.836
fold:0 epoch:61        valid loss:0.656574, valid acc:83.747, valid f1:60.577, valid precision:57.384, valid recall:70.336, valid kappa:81.688
[1;31mEarlyStopping counter: 4 out of 50[0m
[83.82440141493038, 60.84222114371918, 57.68128965410676, 70.4334486258521, 81.76427372039939]
====================================================================================================
fold:0 epoch:62 step:0 train loss:0.402871, train acc:87.439, train f1:86.440, train precision:87.362, train recall:86.784, train kappa:86.969
fold:0 epoch:62 step:1 train loss:0.417734, train acc:87.006, train f1:86.181, train precision:87.344, train recall:86.477, train kappa:86.509
fold:0 epoch:62 step:2 train loss:0.415188, train acc:87.283, train f1:86.434, train precision:87.485, train recall:86.733, train kappa:86.797
fold:0 epoch:62 step:3 train loss:0.411571, train acc:87.296, train f1:86.466, train precision:88.066, train recall:86.426, train kappa:86.805
fold:0 epoch:62 step:4 train loss:0.418149, train acc:86.853, train f1:86.286, train precision:87.652, train recall:86.233, train kappa:86.345
fold:0 epoch:62 step:5 train loss:0.402861, train acc:87.332, train f1:86.599, train precision:87.880, train recall:86.581, train kappa:86.845
fold:0 epoch:62 step:6 train loss:0.413237, train acc:87.180, train f1:86.320, train precision:87.807, train recall:86.214, train kappa:86.689
fold:0 epoch:62 step:7 train loss:0.413657, train acc:87.207, train f1:86.304, train precision:87.570, train recall:86.433, train kappa:86.721
fold:0 epoch:62 step:8 train loss:0.414199, train acc:87.097, train f1:86.444, train precision:87.350, train recall:86.577, train kappa:86.613
fold:0 epoch:62 step:9 train loss:0.407599, train acc:87.378, train f1:86.478, train precision:87.212, train recall:86.911, train kappa:86.892
fold:0 epoch:62 step:10 train loss:0.415552, train acc:87.003, train f1:86.159, train precision:87.017, train recall:86.529, train kappa:86.505
fold:0 epoch:62 step:11 train loss:0.421048, train acc:87.154, train f1:86.756, train precision:87.848, train recall:87.093, train kappa:86.662
fold:0 epoch:62        valid loss:0.653517, valid acc:83.826, valid f1:60.786, valid precision:57.822, valid recall:70.223, valid kappa:81.769
[1;31mTest score increased (83.824401 --> 83.826446).[0m
[83.8264461120085, 60.78597439909598, 57.82212535680799, 70.22265100059019, 81.76867189388275]
====================================================================================================
fold:0 epoch:63 step:0 train loss:0.404686, train acc:87.585, train f1:86.842, train precision:88.164, train recall:86.903, train kappa:87.120
fold:0 epoch:63 step:1 train loss:0.403819, train acc:87.485, train f1:86.556, train precision:87.992, train recall:86.652, train kappa:87.002
fold:0 epoch:63 step:2 train loss:0.419403, train acc:87.170, train f1:86.267, train precision:87.389, train recall:86.489, train kappa:86.680
fold:0 epoch:63 step:3 train loss:0.401610, train acc:87.549, train f1:86.678, train precision:87.860, train recall:86.751, train kappa:87.069
fold:0 epoch:63 step:4 train loss:0.401176, train acc:87.570, train f1:86.677, train precision:87.829, train recall:86.801, train kappa:87.087
fold:0 epoch:63 step:5 train loss:0.402580, train acc:87.546, train f1:86.790, train precision:87.637, train recall:87.092, train kappa:87.060
fold:0 epoch:63 step:6 train loss:0.416533, train acc:87.161, train f1:86.387, train precision:87.539, train recall:86.533, train kappa:86.669
fold:0 epoch:63 step:7 train loss:0.418325, train acc:87.027, train f1:86.456, train precision:87.659, train recall:86.636, train kappa:86.530
fold:0 epoch:63 step:8 train loss:0.418861, train acc:86.948, train f1:86.285, train precision:87.477, train recall:86.401, train kappa:86.463
fold:0 epoch:63 step:9 train loss:0.403931, train acc:87.552, train f1:86.570, train precision:87.535, train recall:86.800, train kappa:87.084
fold:0 epoch:63 step:10 train loss:0.416690, train acc:86.954, train f1:86.253, train precision:87.394, train recall:86.406, train kappa:86.460
fold:0 epoch:63 step:11 train loss:0.414775, train acc:86.941, train f1:86.193, train precision:87.643, train recall:86.176, train kappa:86.445
fold:0 epoch:63        valid loss:0.662190, valid acc:83.728, valid f1:60.541, valid precision:57.400, valid recall:70.136, valid kappa:81.663
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.8264461120085, 60.78597439909598, 57.82212535680799, 70.22265100059019, 81.76867189388275]
====================================================================================================
fold:0 epoch:64 step:0 train loss:0.402641, train acc:87.329, train f1:86.398, train precision:87.747, train recall:86.464, train kappa:86.854
fold:0 epoch:64 step:1 train loss:0.412363, train acc:87.146, train f1:86.387, train precision:87.322, train recall:86.687, train kappa:86.653
fold:0 epoch:64 step:2 train loss:0.420954, train acc:86.942, train f1:86.178, train precision:87.061, train recall:86.472, train kappa:86.435
fold:0 epoch:64 step:3 train loss:0.405706, train acc:87.469, train f1:86.702, train precision:87.536, train recall:86.976, train kappa:86.999
fold:0 epoch:64 step:4 train loss:0.398022, train acc:87.704, train f1:86.657, train precision:87.573, train recall:86.946, train kappa:87.246
fold:0 epoch:64 step:5 train loss:0.398858, train acc:87.619, train f1:86.726, train precision:87.799, train recall:86.944, train kappa:87.147
fold:0 epoch:64 step:6 train loss:0.404310, train acc:87.433, train f1:86.451, train precision:87.557, train recall:86.729, train kappa:86.951
fold:0 epoch:64 step:7 train loss:0.406715, train acc:87.308, train f1:86.452, train precision:87.938, train recall:86.423, train kappa:86.805
fold:0 epoch:64 step:8 train loss:0.396019, train acc:87.708, train f1:86.970, train precision:88.288, train recall:86.926, train kappa:87.237
fold:0 epoch:64 step:9 train loss:0.408923, train acc:87.387, train f1:86.662, train precision:87.841, train recall:86.774, train kappa:86.910
fold:0 epoch:64 step:10 train loss:0.407896, train acc:87.152, train f1:86.600, train precision:87.741, train recall:86.561, train kappa:86.661
fold:0 epoch:64 step:11 train loss:0.422251, train acc:86.855, train f1:86.384, train precision:87.047, train recall:86.758, train kappa:86.353
fold:0 epoch:64        valid loss:0.665825, valid acc:83.608, valid f1:60.735, valid precision:57.563, valid recall:70.311, valid kappa:81.536
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.8264461120085, 60.78597439909598, 57.82212535680799, 70.22265100059019, 81.76867189388275]
====================================================================================================
fold:0 epoch:65 step:0 train loss:0.412508, train acc:87.112, train f1:86.162, train precision:87.038, train recall:86.589, train kappa:86.613
fold:0 epoch:65 step:1 train loss:0.398477, train acc:87.552, train f1:87.001, train precision:87.792, train recall:87.211, train kappa:87.080
fold:0 epoch:65 step:2 train loss:0.409842, train acc:87.097, train f1:86.309, train precision:87.649, train recall:86.276, train kappa:86.605
fold:0 epoch:65 step:3 train loss:0.407439, train acc:87.189, train f1:86.213, train precision:87.492, train recall:86.432, train kappa:86.696
fold:0 epoch:65 step:4 train loss:0.396438, train acc:87.622, train f1:86.767, train precision:88.186, train recall:86.693, train kappa:87.148
fold:0 epoch:65 step:5 train loss:0.406396, train acc:87.421, train f1:86.669, train precision:87.786, train recall:86.832, train kappa:86.955
fold:0 epoch:65 step:6 train loss:0.398083, train acc:87.515, train f1:86.749, train precision:87.637, train recall:87.000, train kappa:87.033
fold:0 epoch:65 step:7 train loss:0.399226, train acc:87.531, train f1:86.912, train precision:87.624, train recall:87.331, train kappa:87.064
fold:0 epoch:65 step:8 train loss:0.407696, train acc:87.317, train f1:86.687, train precision:87.585, train recall:87.179, train kappa:86.836
fold:0 epoch:65 step:9 train loss:0.407663, train acc:87.509, train f1:86.533, train precision:87.509, train recall:86.890, train kappa:87.039
fold:0 epoch:65 step:10 train loss:0.401199, train acc:87.442, train f1:86.610, train precision:87.585, train recall:86.805, train kappa:86.961
fold:0 epoch:65 step:11 train loss:0.414068, train acc:87.048, train f1:86.307, train precision:87.952, train recall:86.230, train kappa:86.550
fold:0 epoch:65        valid loss:0.660103, valid acc:83.896, valid f1:61.026, valid precision:58.106, valid recall:70.154, valid kappa:81.843
[1;31mTest score increased (83.826446 --> 83.895966).[0m
[83.89596581266485, 61.02649556485215, 58.105959440575596, 70.15415968970149, 81.84262782988884]
====================================================================================================
fold:0 epoch:66 step:0 train loss:0.412478, train acc:87.128, train f1:86.340, train precision:87.912, train recall:86.432, train kappa:86.624
fold:0 epoch:66 step:1 train loss:0.400485, train acc:87.573, train f1:86.691, train precision:88.310, train recall:86.673, train kappa:87.093
fold:0 epoch:66 step:2 train loss:0.403030, train acc:87.399, train f1:86.760, train precision:87.831, train recall:86.842, train kappa:86.929
fold:0 epoch:66 step:3 train loss:0.391790, train acc:87.900, train f1:87.045, train precision:87.982, train recall:87.158, train kappa:87.440
fold:0 epoch:66 step:4 train loss:0.405790, train acc:87.466, train f1:86.872, train precision:87.383, train recall:87.185, train kappa:86.994
fold:0 epoch:66 step:5 train loss:0.396511, train acc:87.543, train f1:86.845, train precision:87.419, train recall:87.241, train kappa:87.069
fold:0 epoch:66 step:6 train loss:0.403411, train acc:87.399, train f1:86.691, train precision:87.478, train recall:87.111, train kappa:86.920
fold:0 epoch:66 step:7 train loss:0.400025, train acc:87.488, train f1:86.676, train precision:87.964, train recall:86.723, train kappa:87.014
fold:0 epoch:66 step:8 train loss:0.393686, train acc:87.720, train f1:86.846, train precision:88.366, train recall:86.827, train kappa:87.247
fold:0 epoch:66 step:9 train loss:0.401609, train acc:87.610, train f1:86.805, train precision:88.457, train recall:86.693, train kappa:87.129
fold:0 epoch:66 step:10 train loss:0.409008, train acc:87.378, train f1:86.477, train precision:87.612, train recall:86.549, train kappa:86.897
fold:0 epoch:66 step:11 train loss:0.422433, train acc:86.758, train f1:86.242, train precision:86.964, train recall:86.617, train kappa:86.259
fold:0 epoch:66        valid loss:0.664501, valid acc:83.708, valid f1:60.685, valid precision:57.291, valid recall:70.389, valid kappa:81.650
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.89596581266485, 61.02649556485215, 58.105959440575596, 70.15415968970149, 81.84262782988884]
====================================================================================================
fold:0 epoch:67 step:0 train loss:0.394234, train acc:87.656, train f1:87.137, train precision:87.934, train recall:87.339, train kappa:87.183
fold:0 epoch:67 step:1 train loss:0.396788, train acc:87.604, train f1:86.967, train precision:87.616, train recall:87.352, train kappa:87.139
fold:0 epoch:67 step:2 train loss:0.392435, train acc:87.753, train f1:86.682, train precision:87.563, train recall:87.098, train kappa:87.281
fold:0 epoch:67 step:3 train loss:0.389573, train acc:87.961, train f1:87.226, train precision:88.402, train recall:87.309, train kappa:87.510
fold:0 epoch:67 step:4 train loss:0.404876, train acc:87.299, train f1:86.634, train precision:88.222, train recall:86.530, train kappa:86.807
fold:0 epoch:67 step:5 train loss:0.397973, train acc:87.595, train f1:86.797, train precision:88.194, train recall:86.692, train kappa:87.113
fold:0 epoch:67 step:6 train loss:0.394435, train acc:87.573, train f1:86.832, train precision:88.436, train recall:86.552, train kappa:87.101
fold:0 epoch:67 step:7 train loss:0.402650, train acc:87.451, train f1:86.784, train precision:87.765, train recall:86.993, train kappa:86.966
fold:0 epoch:67 step:8 train loss:0.398274, train acc:87.494, train f1:86.543, train precision:87.326, train recall:86.784, train kappa:87.014
fold:0 epoch:67 step:9 train loss:0.403461, train acc:87.357, train f1:86.563, train precision:87.500, train recall:86.848, train kappa:86.881
fold:0 epoch:67 step:10 train loss:0.397220, train acc:87.631, train f1:86.914, train precision:87.978, train recall:87.121, train kappa:87.166
fold:0 epoch:67 step:11 train loss:0.414325, train acc:86.864, train f1:86.079, train precision:86.909, train recall:86.369, train kappa:86.381
fold:0 epoch:67        valid loss:0.660781, valid acc:83.955, valid f1:61.067, valid precision:57.728, valid recall:70.188, valid kappa:81.914
[1;31mTest score increased (83.895966 --> 83.955262).[0m
[83.95526202793057, 61.06669347897934, 57.727784791425975, 70.1878705821761, 81.91402055965382]
====================================================================================================
fold:0 epoch:68 step:0 train loss:0.385826, train acc:87.881, train f1:86.900, train precision:88.110, train recall:87.135, train kappa:87.426
fold:0 epoch:68 step:1 train loss:0.390312, train acc:87.915, train f1:87.128, train precision:88.376, train recall:87.342, train kappa:87.459
fold:0 epoch:68 step:2 train loss:0.388525, train acc:87.759, train f1:87.155, train precision:88.371, train recall:87.391, train kappa:87.286
fold:0 epoch:68 step:3 train loss:0.399702, train acc:87.625, train f1:86.905, train precision:88.005, train recall:87.075, train kappa:87.156
fold:0 epoch:68 step:4 train loss:0.386157, train acc:87.854, train f1:87.122, train precision:88.191, train recall:87.153, train kappa:87.391
fold:0 epoch:68 step:5 train loss:0.396434, train acc:87.613, train f1:86.991, train precision:87.846, train recall:87.109, train kappa:87.146
fold:0 epoch:68 step:6 train loss:0.403126, train acc:87.460, train f1:86.793, train precision:87.480, train recall:87.097, train kappa:86.985
fold:0 epoch:68 step:7 train loss:0.404591, train acc:87.430, train f1:86.774, train precision:87.891, train recall:86.894, train kappa:86.947
fold:0 epoch:68 step:8 train loss:0.400554, train acc:87.494, train f1:86.601, train precision:87.722, train recall:86.599, train kappa:87.014
fold:0 epoch:68 step:9 train loss:0.399335, train acc:87.543, train f1:86.735, train precision:87.885, train recall:86.747, train kappa:87.065
fold:0 epoch:68 step:10 train loss:0.400741, train acc:87.619, train f1:86.817, train precision:87.734, train recall:87.114, train kappa:87.148
fold:0 epoch:68 step:11 train loss:0.403427, train acc:87.501, train f1:86.679, train precision:87.591, train recall:86.972, train kappa:87.029
fold:0 epoch:68        valid loss:0.666136, valid acc:83.906, valid f1:61.060, valid precision:57.874, valid recall:70.432, valid kappa:81.863
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.95526202793057, 61.06669347897934, 57.727784791425975, 70.1878705821761, 81.91402055965382]
====================================================================================================
fold:0 epoch:69 step:0 train loss:0.387235, train acc:87.894, train f1:87.156, train precision:88.424, train recall:87.239, train kappa:87.427
fold:0 epoch:69 step:1 train loss:0.384859, train acc:88.031, train f1:87.086, train precision:88.045, train recall:87.313, train kappa:87.578
fold:0 epoch:69 step:2 train loss:0.396375, train acc:87.653, train f1:86.926, train precision:88.072, train recall:87.111, train kappa:87.174
fold:0 epoch:69 step:3 train loss:0.398244, train acc:87.491, train f1:86.663, train precision:87.637, train recall:87.117, train kappa:87.016
fold:0 epoch:69 step:4 train loss:0.383626, train acc:88.226, train f1:87.444, train precision:88.601, train recall:87.552, train kappa:87.783
fold:0 epoch:69 step:5 train loss:0.396557, train acc:87.454, train f1:86.730, train precision:87.899, train recall:86.901, train kappa:86.968
fold:0 epoch:69 step:6 train loss:0.396301, train acc:87.695, train f1:86.881, train precision:88.131, train recall:87.002, train kappa:87.217
fold:0 epoch:69 step:7 train loss:0.398995, train acc:87.503, train f1:86.876, train precision:87.959, train recall:86.947, train kappa:87.032
fold:0 epoch:69 step:8 train loss:0.391609, train acc:87.592, train f1:86.793, train precision:88.034, train recall:86.640, train kappa:87.124
fold:0 epoch:69 step:9 train loss:0.405737, train acc:87.521, train f1:86.865, train precision:87.869, train recall:87.031, train kappa:87.047
fold:0 epoch:69 step:10 train loss:0.393210, train acc:87.531, train f1:86.788, train precision:87.968, train recall:86.879, train kappa:87.064
fold:0 epoch:69 step:11 train loss:0.402298, train acc:87.134, train f1:86.390, train precision:87.550, train recall:86.530, train kappa:86.634
fold:0 epoch:69        valid loss:0.660959, valid acc:83.898, valid f1:61.149, valid precision:57.959, valid recall:70.455, valid kappa:81.859
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.95526202793057, 61.06669347897934, 57.727784791425975, 70.1878705821761, 81.91402055965382]
====================================================================================================
fold:0 epoch:70 step:0 train loss:0.389422, train acc:87.875, train f1:87.073, train precision:87.705, train recall:87.549, train kappa:87.426
fold:0 epoch:70 step:1 train loss:0.392199, train acc:87.634, train f1:86.746, train precision:87.440, train recall:87.158, train kappa:87.167
fold:0 epoch:70 step:2 train loss:0.391287, train acc:87.701, train f1:86.875, train precision:88.051, train recall:87.138, train kappa:87.229
fold:0 epoch:70 step:3 train loss:0.396806, train acc:87.509, train f1:86.760, train precision:88.010, train recall:86.835, train kappa:87.041
fold:0 epoch:70 step:4 train loss:0.393994, train acc:87.738, train f1:87.177, train precision:88.475, train recall:87.141, train kappa:87.274
fold:0 epoch:70 step:5 train loss:0.381946, train acc:87.936, train f1:86.954, train precision:88.101, train recall:87.005, train kappa:87.470
fold:0 epoch:70 step:6 train loss:0.399753, train acc:87.506, train f1:86.946, train precision:87.611, train recall:87.257, train kappa:87.013
fold:0 epoch:70 step:7 train loss:0.396493, train acc:87.656, train f1:86.870, train precision:87.599, train recall:87.207, train kappa:87.199
fold:0 epoch:70 step:8 train loss:0.389834, train acc:87.784, train f1:86.944, train precision:87.739, train recall:87.178, train kappa:87.328
fold:0 epoch:70 step:9 train loss:0.390039, train acc:87.701, train f1:86.812, train precision:87.737, train recall:86.936, train kappa:87.236
fold:0 epoch:70 step:10 train loss:0.393809, train acc:87.665, train f1:86.759, train precision:87.821, train recall:86.844, train kappa:87.191
fold:0 epoch:70 step:11 train loss:0.385513, train acc:88.032, train f1:87.301, train precision:88.258, train recall:87.439, train kappa:87.561
fold:0 epoch:70        valid loss:0.663273, valid acc:83.976, valid f1:61.274, valid precision:58.195, valid recall:70.403, valid kappa:81.938
[1;31mTest score increased (83.955262 --> 83.975709).[0m
[83.97570899871184, 61.27412281842221, 58.19531479414973, 70.40294035639512, 81.93822374724368]
====================================================================================================
fold:0 epoch:71 step:0 train loss:0.394385, train acc:87.637, train f1:86.788, train precision:88.049, train recall:86.912, train kappa:87.164
fold:0 epoch:71 step:1 train loss:0.384586, train acc:87.949, train f1:87.059, train precision:88.018, train recall:87.258, train kappa:87.493
fold:0 epoch:71 step:2 train loss:0.398059, train acc:87.531, train f1:86.890, train precision:87.883, train recall:87.141, train kappa:87.057
fold:0 epoch:71 step:3 train loss:0.390206, train acc:87.558, train f1:86.849, train precision:87.801, train recall:87.134, train kappa:87.089
fold:0 epoch:71 step:4 train loss:0.392878, train acc:87.695, train f1:87.005, train precision:87.898, train recall:87.368, train kappa:87.224
fold:0 epoch:71 step:5 train loss:0.385528, train acc:88.028, train f1:87.259, train precision:88.059, train recall:87.493, train kappa:87.570
fold:0 epoch:71 step:6 train loss:0.399260, train acc:87.552, train f1:86.924, train precision:87.768, train recall:87.234, train kappa:87.078
fold:0 epoch:71 step:7 train loss:0.392956, train acc:87.778, train f1:86.835, train precision:87.919, train recall:86.856, train kappa:87.310
fold:0 epoch:71 step:8 train loss:0.385715, train acc:88.034, train f1:87.202, train precision:88.416, train recall:87.336, train kappa:87.586
fold:0 epoch:71 step:9 train loss:0.385410, train acc:87.955, train f1:86.882, train precision:87.865, train recall:87.000, train kappa:87.497
fold:0 epoch:71 step:10 train loss:0.395806, train acc:87.643, train f1:86.923, train precision:88.074, train recall:87.005, train kappa:87.169
fold:0 epoch:71 step:11 train loss:0.399062, train acc:87.636, train f1:86.977, train precision:87.911, train recall:87.361, train kappa:87.166
fold:0 epoch:71        valid loss:0.661869, valid acc:83.925, valid f1:61.079, valid precision:57.986, valid recall:70.350, valid kappa:81.884
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.97570899871184, 61.27412281842221, 58.19531479414973, 70.40294035639512, 81.93822374724368]
====================================================================================================
fold:0 epoch:72 step:0 train loss:0.385136, train acc:87.924, train f1:87.184, train precision:87.840, train recall:87.613, train kappa:87.467
fold:0 epoch:72 step:1 train loss:0.394269, train acc:87.766, train f1:87.087, train precision:87.905, train recall:87.303, train kappa:87.299
fold:0 epoch:72 step:2 train loss:0.380459, train acc:88.144, train f1:87.469, train precision:88.395, train recall:87.596, train kappa:87.694
fold:0 epoch:72 step:3 train loss:0.393348, train acc:87.665, train f1:86.872, train precision:87.911, train recall:87.022, train kappa:87.190
fold:0 epoch:72 step:4 train loss:0.383556, train acc:87.811, train f1:86.995, train precision:88.361, train recall:87.005, train kappa:87.349
fold:0 epoch:72 step:5 train loss:0.380795, train acc:88.101, train f1:87.390, train precision:88.594, train recall:87.377, train kappa:87.643
fold:0 epoch:72 step:6 train loss:0.394300, train acc:87.680, train f1:86.937, train precision:88.031, train recall:87.063, train kappa:87.215
fold:0 epoch:72 step:7 train loss:0.391508, train acc:87.720, train f1:87.076, train precision:88.059, train recall:87.012, train kappa:87.260
fold:0 epoch:72 step:8 train loss:0.395332, train acc:87.552, train f1:86.753, train precision:87.626, train recall:86.937, train kappa:87.073
fold:0 epoch:72 step:9 train loss:0.383342, train acc:87.936, train f1:87.342, train precision:88.085, train recall:87.718, train kappa:87.489
fold:0 epoch:72 step:10 train loss:0.377485, train acc:88.156, train f1:87.498, train precision:88.352, train recall:87.695, train kappa:87.706
fold:0 epoch:72 step:11 train loss:0.396796, train acc:87.723, train f1:86.699, train precision:87.504, train recall:86.938, train kappa:87.243
fold:0 epoch:72        valid loss:0.663779, valid acc:84.084, valid f1:61.354, valid precision:58.056, valid recall:70.461, valid kappa:82.064
[1;31mTest score increased (83.975709 --> 84.084078).[0m
[84.08407794385262, 61.35422933744634, 58.05646112132353, 70.46069925246799, 82.06356275893825]
====================================================================================================
fold:0 epoch:73 step:0 train loss:0.383938, train acc:87.854, train f1:87.198, train precision:87.986, train recall:87.463, train kappa:87.400
fold:0 epoch:73 step:1 train loss:0.378061, train acc:87.988, train f1:87.111, train precision:88.363, train recall:87.242, train kappa:87.530
fold:0 epoch:73 step:2 train loss:0.388116, train acc:87.793, train f1:87.073, train precision:88.425, train recall:87.201, train kappa:87.330
fold:0 epoch:73 step:3 train loss:0.382538, train acc:87.997, train f1:87.149, train precision:88.220, train recall:87.310, train kappa:87.538
fold:0 epoch:73 step:4 train loss:0.384154, train acc:87.897, train f1:87.139, train precision:87.928, train recall:87.441, train kappa:87.441
fold:0 epoch:73 step:5 train loss:0.378860, train acc:88.065, train f1:87.153, train precision:87.860, train recall:87.389, train kappa:87.604
fold:0 epoch:73 step:6 train loss:0.385176, train acc:87.906, train f1:87.199, train precision:87.952, train recall:87.470, train kappa:87.445
fold:0 epoch:73 step:7 train loss:0.384110, train acc:88.010, train f1:87.297, train precision:88.036, train recall:87.572, train kappa:87.549
fold:0 epoch:73 step:8 train loss:0.386941, train acc:87.961, train f1:86.992, train precision:88.211, train recall:86.882, train kappa:87.506
fold:0 epoch:73 step:9 train loss:0.392750, train acc:87.756, train f1:86.983, train precision:88.217, train recall:87.022, train kappa:87.289
fold:0 epoch:73 step:10 train loss:0.378793, train acc:88.095, train f1:87.248, train precision:88.414, train recall:87.320, train kappa:87.645
fold:0 epoch:73 step:11 train loss:0.389898, train acc:88.177, train f1:87.681, train precision:89.163, train recall:87.564, train kappa:87.730
fold:0 epoch:73        valid loss:0.665220, valid acc:84.094, valid f1:61.454, valid precision:58.519, valid recall:70.610, valid kappa:82.073
[1;31mTest score increased (84.084078 --> 84.094301).[0m
[84.09430142924326, 61.454171495430124, 58.51907502689825, 70.60952891941359, 82.07286997038733]
====================================================================================================
fold:0 epoch:74 step:0 train loss:0.385008, train acc:87.793, train f1:86.876, train precision:88.041, train recall:87.088, train kappa:87.332
fold:0 epoch:74 step:1 train loss:0.383461, train acc:88.043, train f1:87.089, train precision:87.985, train recall:87.589, train kappa:87.592
fold:0 epoch:74 step:2 train loss:0.385028, train acc:87.994, train f1:87.387, train precision:88.230, train recall:87.638, train kappa:87.541
fold:0 epoch:74 step:3 train loss:0.376607, train acc:88.089, train f1:87.309, train precision:88.133, train recall:87.579, train kappa:87.632
fold:0 epoch:74 step:4 train loss:0.380681, train acc:88.019, train f1:87.369, train precision:88.328, train recall:87.583, train kappa:87.563
fold:0 epoch:74 step:5 train loss:0.383562, train acc:87.836, train f1:87.059, train precision:88.233, train recall:87.085, train kappa:87.367
fold:0 epoch:74 step:6 train loss:0.380499, train acc:88.010, train f1:87.280, train precision:88.499, train recall:87.471, train kappa:87.550
fold:0 epoch:74 step:7 train loss:0.380039, train acc:88.226, train f1:87.472, train precision:88.627, train recall:87.456, train kappa:87.784
fold:0 epoch:74 step:8 train loss:0.383564, train acc:87.851, train f1:87.007, train precision:87.911, train recall:87.120, train kappa:87.391
fold:0 epoch:74 step:9 train loss:0.388484, train acc:87.851, train f1:87.141, train precision:87.922, train recall:87.391, train kappa:87.388
fold:0 epoch:74 step:10 train loss:0.387680, train acc:87.753, train f1:87.161, train precision:87.963, train recall:87.324, train kappa:87.291
fold:0 epoch:74 step:11 train loss:0.375047, train acc:88.071, train f1:87.338, train precision:88.086, train recall:87.593, train kappa:87.623
fold:0 epoch:74        valid loss:0.663943, valid acc:84.168, valid f1:61.621, valid precision:58.289, valid recall:70.370, valid kappa:82.156
[1;31mTest score increased (84.094301 --> 84.167911).[0m
[84.16791052405586, 61.6210129611625, 58.2886511283099, 70.37039459727328, 82.15565870272492]
====================================================================================================
fold:0 epoch:75 step:0 train loss:0.381789, train acc:88.089, train f1:87.409, train precision:88.247, train recall:87.644, train kappa:87.627
fold:0 epoch:75 step:1 train loss:0.384312, train acc:88.083, train f1:87.356, train precision:88.429, train recall:87.346, train kappa:87.636
fold:0 epoch:75 step:2 train loss:0.386272, train acc:88.019, train f1:87.231, train precision:88.176, train recall:87.525, train kappa:87.555
fold:0 epoch:75 step:3 train loss:0.382188, train acc:88.068, train f1:87.142, train precision:87.963, train recall:87.479, train kappa:87.616
fold:0 epoch:75 step:4 train loss:0.383123, train acc:88.034, train f1:87.133, train precision:88.324, train recall:87.301, train kappa:87.577
fold:0 epoch:75 step:5 train loss:0.373859, train acc:88.156, train f1:87.321, train precision:88.558, train recall:87.419, train kappa:87.703
fold:0 epoch:75 step:6 train loss:0.381143, train acc:88.034, train f1:87.021, train precision:88.098, train recall:87.153, train kappa:87.574
fold:0 epoch:75 step:7 train loss:0.376577, train acc:88.232, train f1:87.457, train precision:88.209, train recall:87.697, train kappa:87.780
fold:0 epoch:75 step:8 train loss:0.375350, train acc:88.153, train f1:87.292, train precision:88.154, train recall:87.539, train kappa:87.708
fold:0 epoch:75 step:9 train loss:0.386864, train acc:87.766, train f1:87.256, train precision:88.119, train recall:87.369, train kappa:87.307
fold:0 epoch:75 step:10 train loss:0.372556, train acc:88.275, train f1:87.520, train precision:88.322, train recall:87.643, train kappa:87.842
fold:0 epoch:75 step:11 train loss:0.389049, train acc:87.714, train f1:87.259, train precision:88.028, train recall:87.598, train kappa:87.249
fold:0 epoch:75        valid loss:0.663016, valid acc:84.207, valid f1:61.472, valid precision:58.256, valid recall:70.585, valid kappa:82.203
[1;31mTest score increased (84.167911 --> 84.206760).[0m
[84.2067597685403, 61.47224541173705, 58.25584225302269, 70.58498485264651, 82.20293284709814]
====================================================================================================
fold:0 epoch:76 step:0 train loss:0.374665, train acc:88.181, train f1:87.493, train precision:88.559, train recall:87.564, train kappa:87.725
fold:0 epoch:76 step:1 train loss:0.378457, train acc:88.055, train f1:87.273, train precision:88.450, train recall:87.336, train kappa:87.604
fold:0 epoch:76 step:2 train loss:0.381900, train acc:87.976, train f1:87.192, train precision:88.486, train recall:87.289, train kappa:87.527
fold:0 epoch:76 step:3 train loss:0.375661, train acc:88.257, train f1:87.383, train precision:88.430, train recall:87.533, train kappa:87.816
fold:0 epoch:76 step:4 train loss:0.378450, train acc:88.141, train f1:87.480, train precision:88.402, train recall:87.657, train kappa:87.683
fold:0 epoch:76 step:5 train loss:0.374625, train acc:88.055, train f1:87.265, train precision:88.096, train recall:87.280, train kappa:87.591
fold:0 epoch:76 step:6 train loss:0.379635, train acc:88.077, train f1:87.212, train precision:88.122, train recall:87.393, train kappa:87.620
fold:0 epoch:76 step:7 train loss:0.378133, train acc:87.921, train f1:87.158, train precision:87.958, train recall:87.393, train kappa:87.464
fold:0 epoch:76 step:8 train loss:0.375603, train acc:88.120, train f1:87.505, train precision:88.439, train recall:87.684, train kappa:87.672
fold:0 epoch:76 step:9 train loss:0.379765, train acc:88.120, train f1:87.369, train precision:88.144, train recall:87.673, train kappa:87.675
fold:0 epoch:76 step:10 train loss:0.385408, train acc:87.894, train f1:87.057, train precision:88.019, train recall:87.292, train kappa:87.438
fold:0 epoch:76 step:11 train loss:0.389294, train acc:87.800, train f1:87.014, train precision:87.958, train recall:87.269, train kappa:87.337
fold:0 epoch:76        valid loss:0.664053, valid acc:84.252, valid f1:61.465, valid precision:58.254, valid recall:70.560, valid kappa:82.252
[1;31mTest score increased (84.206760 --> 84.251743).[0m
[84.2517431042591, 61.464595909354955, 58.253855663314056, 70.56006289989455, 82.2516922053145]
====================================================================================================
fold:0 epoch:77 step:0 train loss:0.380126, train acc:88.010, train f1:87.347, train precision:88.211, train recall:87.506, train kappa:87.549
fold:0 epoch:77 step:1 train loss:0.376610, train acc:88.184, train f1:87.427, train precision:88.162, train recall:87.621, train kappa:87.736
fold:0 epoch:77 step:2 train loss:0.376751, train acc:88.058, train f1:87.125, train precision:88.153, train recall:87.297, train kappa:87.598
fold:0 epoch:77 step:3 train loss:0.371671, train acc:88.229, train f1:87.399, train precision:88.652, train recall:87.501, train kappa:87.775
fold:0 epoch:77 step:4 train loss:0.370653, train acc:88.287, train f1:87.495, train precision:88.591, train recall:87.752, train kappa:87.842
fold:0 epoch:77 step:5 train loss:0.377677, train acc:88.150, train f1:87.432, train precision:88.483, train recall:87.500, train kappa:87.690
fold:0 epoch:77 step:6 train loss:0.373892, train acc:88.351, train f1:87.617, train precision:88.346, train recall:87.858, train kappa:87.916
fold:0 epoch:77 step:7 train loss:0.387511, train acc:87.637, train f1:86.917, train precision:87.727, train recall:87.132, train kappa:87.165
fold:0 epoch:77 step:8 train loss:0.379878, train acc:87.885, train f1:87.148, train precision:87.992, train recall:87.315, train kappa:87.430
fold:0 epoch:77 step:9 train loss:0.380648, train acc:87.964, train f1:87.402, train precision:88.253, train recall:87.508, train kappa:87.522
fold:0 epoch:77 step:10 train loss:0.372250, train acc:88.251, train f1:87.523, train precision:88.368, train recall:87.637, train kappa:87.810
fold:0 epoch:77 step:11 train loss:0.387121, train acc:87.627, train f1:87.129, train precision:87.783, train recall:87.526, train kappa:87.159
fold:0 epoch:77        valid loss:0.661132, valid acc:84.282, valid f1:61.503, valid precision:58.425, valid recall:70.313, valid kappa:82.280
[1;31mTest score increased (84.251743 --> 84.282414).[0m
[84.28241356043102, 61.50262092349956, 58.425265531129554, 70.31312249096973, 82.28044612909437]
====================================================================================================
fold:0 epoch:78 step:0 train loss:0.369965, train acc:88.235, train f1:87.598, train precision:88.878, train recall:87.654, train kappa:87.788
fold:0 epoch:78 step:1 train loss:0.375318, train acc:87.985, train f1:87.158, train precision:88.290, train recall:87.227, train kappa:87.523
fold:0 epoch:78 step:2 train loss:0.371849, train acc:88.239, train f1:87.359, train precision:88.545, train recall:87.406, train kappa:87.790
fold:0 epoch:78 step:3 train loss:0.366548, train acc:88.174, train f1:87.392, train precision:88.405, train recall:87.565, train kappa:87.721
fold:0 epoch:78 step:4 train loss:0.368982, train acc:88.425, train f1:87.658, train precision:88.559, train recall:87.776, train kappa:87.981
fold:0 epoch:78 step:5 train loss:0.376547, train acc:88.162, train f1:87.410, train precision:88.020, train recall:87.657, train kappa:87.720
fold:0 epoch:78 step:6 train loss:0.384419, train acc:88.043, train f1:87.326, train precision:88.089, train recall:87.641, train kappa:87.590
fold:0 epoch:78 step:7 train loss:0.377443, train acc:87.921, train f1:87.300, train precision:88.167, train recall:87.617, train kappa:87.464
fold:0 epoch:78 step:8 train loss:0.367362, train acc:88.489, train f1:87.670, train precision:88.638, train recall:87.774, train kappa:88.062
fold:0 epoch:78 step:9 train loss:0.379405, train acc:88.174, train f1:87.408, train precision:88.435, train recall:87.583, train kappa:87.721
fold:0 epoch:78 step:10 train loss:0.374013, train acc:88.174, train f1:87.518, train precision:88.671, train recall:87.548, train kappa:87.725
fold:0 epoch:78 step:11 train loss:0.379939, train acc:87.907, train f1:87.336, train precision:88.430, train recall:87.456, train kappa:87.453
fold:0 epoch:78        valid loss:0.666790, valid acc:84.174, valid f1:61.637, valid precision:58.537, valid recall:70.419, valid kappa:82.166
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.28241356043102, 61.50262092349956, 58.425265531129554, 70.31312249096973, 82.28044612909437]
====================================================================================================
fold:0 epoch:79 step:0 train loss:0.367666, train acc:88.278, train f1:87.554, train precision:88.685, train recall:87.531, train kappa:87.833
fold:0 epoch:79 step:1 train loss:0.366693, train acc:88.467, train f1:87.647, train precision:88.073, train recall:88.063, train kappa:88.032
fold:0 epoch:79 step:2 train loss:0.363441, train acc:88.455, train f1:87.773, train precision:88.504, train recall:87.944, train kappa:88.026
fold:0 epoch:79 step:3 train loss:0.373792, train acc:88.077, train f1:87.383, train precision:88.070, train recall:87.730, train kappa:87.618
fold:0 epoch:79 step:4 train loss:0.369311, train acc:88.324, train f1:87.402, train precision:88.449, train recall:87.491, train kappa:87.881
fold:0 epoch:79 step:5 train loss:0.375175, train acc:88.110, train f1:87.478, train precision:88.475, train recall:87.701, train kappa:87.670
fold:0 epoch:79 step:6 train loss:0.377120, train acc:88.208, train f1:87.552, train precision:88.604, train recall:87.712, train kappa:87.760
fold:0 epoch:79 step:7 train loss:0.368772, train acc:88.272, train f1:87.552, train precision:88.458, train recall:87.662, train kappa:87.823
fold:0 epoch:79 step:8 train loss:0.381497, train acc:87.985, train f1:87.182, train precision:88.106, train recall:87.272, train kappa:87.521
fold:0 epoch:79 step:9 train loss:0.377963, train acc:88.013, train f1:87.347, train precision:88.244, train recall:87.447, train kappa:87.557
fold:0 epoch:79 step:10 train loss:0.373705, train acc:88.406, train f1:87.681, train precision:88.313, train recall:87.991, train kappa:87.966
fold:0 epoch:79 step:11 train loss:0.372504, train acc:88.408, train f1:87.600, train precision:88.706, train recall:87.665, train kappa:87.975
fold:0 epoch:79        valid loss:0.668636, valid acc:84.260, valid f1:61.557, valid precision:58.291, valid recall:70.693, valid kappa:82.263
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.28241356043102, 61.50262092349956, 58.425265531129554, 70.31312249096973, 82.28044612909437]
====================================================================================================
fold:0 epoch:80 step:0 train loss:0.371889, train acc:88.214, train f1:87.476, train precision:88.640, train recall:87.456, train kappa:87.772
fold:0 epoch:80 step:1 train loss:0.369410, train acc:88.300, train f1:87.460, train precision:88.288, train recall:87.762, train kappa:87.855
fold:0 epoch:80 step:2 train loss:0.362004, train acc:88.519, train f1:87.684, train precision:88.823, train recall:87.852, train kappa:88.073
fold:0 epoch:80 step:3 train loss:0.362764, train acc:88.461, train f1:87.329, train precision:88.416, train recall:87.519, train kappa:88.030
fold:0 epoch:80 step:4 train loss:0.364627, train acc:88.412, train f1:87.444, train precision:88.553, train recall:87.657, train kappa:87.963
fold:0 epoch:80 step:5 train loss:0.369897, train acc:88.281, train f1:87.668, train precision:88.683, train recall:87.683, train kappa:87.836
fold:0 epoch:80 step:6 train loss:0.374051, train acc:88.129, train f1:87.526, train precision:88.235, train recall:87.821, train kappa:87.680
fold:0 epoch:80 step:7 train loss:0.372058, train acc:88.226, train f1:87.526, train precision:88.277, train recall:87.823, train kappa:87.787
fold:0 epoch:80 step:8 train loss:0.375431, train acc:88.266, train f1:87.562, train precision:88.191, train recall:87.808, train kappa:87.830
fold:0 epoch:80 step:9 train loss:0.378050, train acc:87.927, train f1:87.365, train precision:88.001, train recall:87.614, train kappa:87.473
fold:0 epoch:80 step:10 train loss:0.368674, train acc:88.412, train f1:87.642, train precision:88.461, train recall:87.834, train kappa:87.970
fold:0 epoch:80 step:11 train loss:0.372403, train acc:87.993, train f1:86.898, train precision:87.899, train recall:87.070, train kappa:87.523
fold:0 epoch:80        valid loss:0.663742, valid acc:84.436, valid f1:61.811, valid precision:58.926, valid recall:70.173, valid kappa:82.445
[1;31mTest score increased (84.282414 --> 84.435766).[0m
[84.43576584129062, 61.81109030332177, 58.9263486099316, 70.17281670049724, 82.44486418694912]
====================================================================================================
fold:0 epoch:81 step:0 train loss:0.362877, train acc:88.165, train f1:87.519, train precision:88.908, train recall:87.393, train kappa:87.716
fold:0 epoch:81 step:1 train loss:0.365849, train acc:88.348, train f1:87.539, train precision:88.699, train recall:87.478, train kappa:87.904
fold:0 epoch:81 step:2 train loss:0.357318, train acc:88.611, train f1:87.896, train precision:88.897, train recall:88.017, train kappa:88.169
fold:0 epoch:81 step:3 train loss:0.370929, train acc:88.336, train f1:87.658, train precision:88.400, train recall:87.871, train kappa:87.891
fold:0 epoch:81 step:4 train loss:0.369667, train acc:88.214, train f1:87.432, train precision:87.977, train recall:87.715, train kappa:87.764
fold:0 epoch:81 step:5 train loss:0.376673, train acc:88.000, train f1:87.280, train precision:87.912, train recall:87.522, train kappa:87.553
fold:0 epoch:81 step:6 train loss:0.364600, train acc:88.412, train f1:87.679, train precision:88.363, train recall:87.973, train kappa:87.965
fold:0 epoch:81 step:7 train loss:0.378285, train acc:87.943, train f1:87.338, train precision:88.467, train recall:87.363, train kappa:87.485
fold:0 epoch:81 step:8 train loss:0.370853, train acc:88.245, train f1:87.361, train precision:88.348, train recall:87.410, train kappa:87.807
fold:0 epoch:81 step:9 train loss:0.366400, train acc:88.342, train f1:87.543, train precision:88.339, train recall:87.788, train kappa:87.905
fold:0 epoch:81 step:10 train loss:0.367902, train acc:88.272, train f1:87.459, train precision:88.415, train recall:87.425, train kappa:87.827
fold:0 epoch:81 step:11 train loss:0.372133, train acc:88.100, train f1:87.295, train precision:87.968, train recall:87.630, train kappa:87.658
fold:0 epoch:81        valid loss:0.663698, valid acc:84.379, valid f1:61.816, valid precision:58.779, valid recall:70.416, valid kappa:82.394
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.43576584129062, 61.81109030332177, 58.9263486099316, 70.17281670049724, 82.44486418694912]
====================================================================================================
fold:0 epoch:82 step:0 train loss:0.363133, train acc:88.504, train f1:87.801, train precision:88.661, train recall:87.952, train kappa:88.069
fold:0 epoch:82 step:1 train loss:0.369719, train acc:88.242, train f1:87.579, train precision:88.160, train recall:87.901, train kappa:87.801
fold:0 epoch:82 step:2 train loss:0.365407, train acc:88.425, train f1:87.874, train precision:88.751, train recall:88.072, train kappa:87.995
fold:0 epoch:82 step:3 train loss:0.356870, train acc:88.617, train f1:87.973, train precision:88.827, train recall:88.024, train kappa:88.188
fold:0 epoch:82 step:4 train loss:0.366815, train acc:88.397, train f1:87.635, train precision:88.776, train recall:87.734, train kappa:87.956
fold:0 epoch:82 step:5 train loss:0.366911, train acc:88.239, train f1:87.391, train precision:88.461, train recall:87.574, train kappa:87.791
fold:0 epoch:82 step:6 train loss:0.368947, train acc:88.376, train f1:87.492, train precision:88.884, train recall:87.424, train kappa:87.929
fold:0 epoch:82 step:7 train loss:0.367000, train acc:88.458, train f1:87.586, train precision:88.684, train recall:87.799, train kappa:88.015
fold:0 epoch:82 step:8 train loss:0.368229, train acc:88.354, train f1:87.539, train precision:88.654, train recall:87.513, train kappa:87.917
fold:0 epoch:82 step:9 train loss:0.366841, train acc:88.617, train f1:87.997, train precision:88.800, train recall:88.241, train kappa:88.187
fold:0 epoch:82 step:10 train loss:0.370271, train acc:88.470, train f1:87.668, train precision:88.305, train recall:87.987, train kappa:88.023
fold:0 epoch:82 step:11 train loss:0.366884, train acc:88.466, train f1:87.686, train precision:88.318, train recall:87.933, train kappa:88.029
fold:0 epoch:82        valid loss:0.670313, valid acc:84.344, valid f1:61.508, valid precision:58.443, valid recall:70.243, valid kappa:82.351
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.43576584129062, 61.81109030332177, 58.9263486099316, 70.17281670049724, 82.44486418694912]
====================================================================================================
fold:0 epoch:83 step:0 train loss:0.361585, train acc:88.651, train f1:88.018, train precision:88.721, train recall:88.312, train kappa:88.217
fold:0 epoch:83 step:1 train loss:0.363845, train acc:88.358, train f1:87.596, train precision:88.401, train recall:87.881, train kappa:87.927
fold:0 epoch:83 step:2 train loss:0.362249, train acc:88.452, train f1:87.732, train precision:88.987, train recall:87.780, train kappa:88.011
fold:0 epoch:83 step:3 train loss:0.360203, train acc:88.470, train f1:87.709, train precision:88.750, train recall:87.864, train kappa:88.039
fold:0 epoch:83 step:4 train loss:0.359477, train acc:88.644, train f1:87.773, train precision:88.894, train recall:87.820, train kappa:88.212
fold:0 epoch:83 step:5 train loss:0.367918, train acc:88.248, train f1:87.517, train precision:88.425, train recall:87.784, train kappa:87.790
fold:0 epoch:83 step:6 train loss:0.367361, train acc:88.351, train f1:87.589, train precision:88.156, train recall:87.828, train kappa:87.916
fold:0 epoch:83 step:7 train loss:0.366135, train acc:88.208, train f1:87.591, train precision:88.150, train recall:87.798, train kappa:87.761
fold:0 epoch:83 step:8 train loss:0.366640, train acc:88.162, train f1:87.393, train precision:87.930, train recall:87.612, train kappa:87.714
fold:0 epoch:83 step:9 train loss:0.375683, train acc:88.174, train f1:87.403, train precision:88.264, train recall:87.411, train kappa:87.727
fold:0 epoch:83 step:10 train loss:0.366845, train acc:88.406, train f1:87.795, train precision:88.700, train recall:87.843, train kappa:87.970
fold:0 epoch:83 step:11 train loss:0.364751, train acc:88.264, train f1:87.397, train precision:88.180, train recall:87.509, train kappa:87.806
fold:0 epoch:83        valid loss:0.669488, valid acc:84.321, valid f1:61.457, valid precision:58.402, valid recall:70.228, valid kappa:82.328
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.43576584129062, 61.81109030332177, 58.9263486099316, 70.17281670049724, 82.44486418694912]
====================================================================================================
fold:0 epoch:84 step:0 train loss:0.364862, train acc:88.229, train f1:87.656, train precision:88.521, train recall:87.751, train kappa:87.783
fold:0 epoch:84 step:1 train loss:0.363721, train acc:88.333, train f1:87.614, train precision:88.682, train recall:87.813, train kappa:87.894
fold:0 epoch:84 step:2 train loss:0.362883, train acc:88.577, train f1:87.835, train precision:88.697, train recall:88.142, train kappa:88.142
fold:0 epoch:84 step:3 train loss:0.367370, train acc:88.452, train f1:87.798, train precision:88.385, train recall:88.233, train kappa:88.019
fold:0 epoch:84 step:4 train loss:0.364640, train acc:88.452, train f1:87.716, train precision:88.288, train recall:88.062, train kappa:88.018
fold:0 epoch:84 step:5 train loss:0.363800, train acc:88.455, train f1:87.486, train precision:88.353, train recall:87.710, train kappa:88.021
fold:0 epoch:84 step:6 train loss:0.367611, train acc:88.528, train f1:87.859, train precision:88.784, train recall:87.972, train kappa:88.094
fold:0 epoch:84 step:7 train loss:0.370922, train acc:88.354, train f1:87.753, train precision:88.986, train recall:87.636, train kappa:87.904
fold:0 epoch:84 step:8 train loss:0.363381, train acc:88.348, train f1:87.717, train precision:88.956, train recall:87.621, train kappa:87.901
fold:0 epoch:84 step:9 train loss:0.356655, train acc:88.617, train f1:87.902, train precision:88.845, train recall:87.927, train kappa:88.187
fold:0 epoch:84 step:10 train loss:0.363871, train acc:88.440, train f1:87.609, train precision:88.297, train recall:87.877, train kappa:88.010
fold:0 epoch:84 step:11 train loss:0.357622, train acc:88.756, train f1:88.008, train precision:88.572, train recall:88.387, train kappa:88.321
fold:0 epoch:84        valid loss:0.670130, valid acc:84.287, valid f1:61.650, valid precision:58.358, valid recall:70.329, valid kappa:82.293
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.43576584129062, 61.81109030332177, 58.9263486099316, 70.17281670049724, 82.44486418694912]
====================================================================================================
fold:0 epoch:85 step:0 train loss:0.351899, train acc:88.608, train f1:87.980, train precision:88.596, train recall:88.142, train kappa:88.178
fold:0 epoch:85 step:1 train loss:0.359730, train acc:88.452, train f1:87.702, train precision:88.097, train recall:88.073, train kappa:88.009
fold:0 epoch:85 step:2 train loss:0.358346, train acc:88.773, train f1:87.903, train precision:88.850, train recall:88.007, train kappa:88.339
fold:0 epoch:85 step:3 train loss:0.359687, train acc:88.623, train f1:87.864, train precision:88.722, train recall:88.110, train kappa:88.199
fold:0 epoch:85 step:4 train loss:0.368396, train acc:88.339, train f1:87.639, train precision:88.877, train recall:87.704, train kappa:87.895
fold:0 epoch:85 step:5 train loss:0.358971, train acc:88.535, train f1:87.724, train precision:88.898, train recall:87.688, train kappa:88.091
fold:0 epoch:85 step:6 train loss:0.370052, train acc:88.019, train f1:87.461, train precision:88.355, train recall:87.521, train kappa:87.565
fold:0 epoch:85 step:7 train loss:0.362468, train acc:88.553, train f1:87.872, train precision:88.542, train recall:88.001, train kappa:88.121
fold:0 epoch:85 step:8 train loss:0.366865, train acc:88.446, train f1:87.971, train precision:88.866, train recall:88.039, train kappa:88.018
fold:0 epoch:85 step:9 train loss:0.358260, train acc:88.708, train f1:87.934, train precision:88.596, train recall:88.173, train kappa:88.286
fold:0 epoch:85 step:10 train loss:0.362215, train acc:88.431, train f1:87.709, train precision:88.375, train recall:87.936, train kappa:87.996
fold:0 epoch:85 step:11 train loss:0.362427, train acc:88.505, train f1:87.662, train precision:88.328, train recall:87.979, train kappa:88.059
fold:0 epoch:85        valid loss:0.671362, valid acc:84.481, valid f1:61.800, valid precision:58.790, valid recall:70.346, valid kappa:82.496
[1;31mTest score increased (84.435766 --> 84.480749).[0m
[84.48074917700943, 61.80034996194025, 58.79041086611604, 70.34646407151386, 82.49586355380183]
====================================================================================================
fold:0 epoch:86 step:0 train loss:0.358549, train acc:88.586, train f1:87.872, train precision:88.559, train recall:88.124, train kappa:88.154
fold:0 epoch:86 step:1 train loss:0.361350, train acc:88.477, train f1:87.808, train precision:88.733, train recall:87.990, train kappa:88.035
fold:0 epoch:86 step:2 train loss:0.358066, train acc:88.586, train f1:87.861, train precision:88.817, train recall:88.099, train kappa:88.157
fold:0 epoch:86 step:3 train loss:0.364618, train acc:88.428, train f1:87.706, train precision:88.591, train recall:88.048, train kappa:87.993
fold:0 epoch:86 step:4 train loss:0.358449, train acc:88.507, train f1:87.833, train precision:88.899, train recall:88.000, train kappa:88.074
fold:0 epoch:86 step:5 train loss:0.363297, train acc:88.400, train f1:87.662, train precision:88.427, train recall:87.802, train kappa:87.967
fold:0 epoch:86 step:6 train loss:0.359636, train acc:88.474, train f1:87.469, train precision:88.144, train recall:87.692, train kappa:88.030
fold:0 epoch:86 step:7 train loss:0.354052, train acc:88.858, train f1:88.057, train precision:88.969, train recall:88.139, train kappa:88.431
fold:0 epoch:86 step:8 train loss:0.363293, train acc:88.544, train f1:87.919, train precision:88.688, train recall:88.071, train kappa:88.103
fold:0 epoch:86 step:9 train loss:0.350873, train acc:88.727, train f1:87.797, train precision:88.568, train recall:87.881, train kappa:88.306
fold:0 epoch:86 step:10 train loss:0.372181, train acc:88.287, train f1:87.644, train precision:88.272, train recall:87.865, train kappa:87.847
fold:0 epoch:86 step:11 train loss:0.360736, train acc:88.544, train f1:87.757, train precision:88.632, train recall:87.872, train kappa:88.105
fold:0 epoch:86        valid loss:0.674233, valid acc:84.376, valid f1:61.722, valid precision:58.700, valid recall:70.395, valid kappa:82.390
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.48074917700943, 61.80034996194025, 58.79041086611604, 70.34646407151386, 82.49586355380183]
====================================================================================================
fold:0 epoch:87 step:0 train loss:0.350723, train acc:88.684, train f1:88.136, train precision:89.224, train recall:88.213, train kappa:88.253
fold:0 epoch:87 step:1 train loss:0.365187, train acc:88.443, train f1:87.690, train precision:88.586, train recall:87.938, train kappa:88.002
fold:0 epoch:87 step:2 train loss:0.362283, train acc:88.477, train f1:87.751, train precision:88.437, train recall:88.102, train kappa:88.035
fold:0 epoch:87 step:3 train loss:0.365108, train acc:88.513, train f1:87.803, train precision:88.445, train recall:88.103, train kappa:88.089
fold:0 epoch:87 step:4 train loss:0.352628, train acc:88.864, train f1:88.130, train precision:88.598, train recall:88.514, train kappa:88.443
fold:0 epoch:87 step:5 train loss:0.354350, train acc:88.632, train f1:87.971, train precision:88.820, train recall:88.134, train kappa:88.200
fold:0 epoch:87 step:6 train loss:0.355575, train acc:88.614, train f1:87.795, train precision:88.615, train recall:87.990, train kappa:88.182
fold:0 epoch:87 step:7 train loss:0.358396, train acc:88.556, train f1:87.682, train precision:88.696, train recall:87.615, train kappa:88.116
fold:0 epoch:87 step:8 train loss:0.359160, train acc:88.535, train f1:87.727, train precision:88.537, train recall:87.920, train kappa:88.103
fold:0 epoch:87 step:9 train loss:0.362220, train acc:88.467, train f1:87.635, train precision:88.742, train recall:87.661, train kappa:88.034
fold:0 epoch:87 step:10 train loss:0.358670, train acc:88.516, train f1:87.692, train precision:88.568, train recall:87.797, train kappa:88.091
fold:0 epoch:87 step:11 train loss:0.351148, train acc:88.698, train f1:87.952, train precision:88.747, train recall:88.206, train kappa:88.255
fold:0 epoch:87        valid loss:0.668956, valid acc:84.497, valid f1:61.843, valid precision:58.855, valid recall:70.231, valid kappa:82.520
[1;31mTest score increased (84.480749 --> 84.497107).[0m
[84.49710675363445, 61.84301420556984, 58.855030043716326, 70.23139252761354, 82.52028662906334]
====================================================================================================
fold:0 epoch:88 step:0 train loss:0.353701, train acc:88.828, train f1:88.109, train precision:89.023, train recall:88.245, train kappa:88.401
fold:0 epoch:88 step:1 train loss:0.352613, train acc:88.699, train f1:88.018, train precision:88.725, train recall:88.179, train kappa:88.279
fold:0 epoch:88 step:2 train loss:0.360611, train acc:88.361, train f1:87.481, train precision:88.444, train recall:87.531, train kappa:87.916
fold:0 epoch:88 step:3 train loss:0.346331, train acc:88.815, train f1:88.031, train precision:89.119, train recall:87.975, train kappa:88.395
fold:0 epoch:88 step:4 train loss:0.351826, train acc:88.785, train f1:88.040, train precision:88.846, train recall:88.138, train kappa:88.363
fold:0 epoch:88 step:5 train loss:0.353428, train acc:88.605, train f1:87.822, train precision:88.488, train recall:88.187, train kappa:88.176
fold:0 epoch:88 step:6 train loss:0.351557, train acc:88.803, train f1:88.024, train precision:88.677, train recall:88.332, train kappa:88.381
fold:0 epoch:88 step:7 train loss:0.367791, train acc:88.300, train f1:87.484, train precision:88.044, train recall:87.837, train kappa:87.857
fold:0 epoch:88 step:8 train loss:0.364885, train acc:88.327, train f1:87.475, train precision:88.099, train recall:87.853, train kappa:87.888
fold:0 epoch:88 step:9 train loss:0.357754, train acc:88.657, train f1:87.730, train precision:88.398, train recall:88.030, train kappa:88.221
fold:0 epoch:88 step:10 train loss:0.364505, train acc:88.452, train f1:87.957, train precision:88.842, train recall:88.118, train kappa:88.013
fold:0 epoch:88 step:11 train loss:0.367615, train acc:88.215, train f1:87.480, train precision:88.415, train recall:87.640, train kappa:87.763
fold:0 epoch:88        valid loss:0.665864, valid acc:84.667, valid f1:61.793, valid precision:58.872, valid recall:70.034, valid kappa:82.703
[1;31mTest score increased (84.497107 --> 84.666817).[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:89 step:0 train loss:0.355727, train acc:88.635, train f1:88.111, train precision:89.198, train recall:88.087, train kappa:88.203
fold:0 epoch:89 step:1 train loss:0.356604, train acc:88.470, train f1:87.676, train precision:88.665, train recall:87.780, train kappa:88.038
fold:0 epoch:89 step:2 train loss:0.351260, train acc:88.785, train f1:88.132, train precision:88.982, train recall:88.233, train kappa:88.357
fold:0 epoch:89 step:3 train loss:0.357177, train acc:88.571, train f1:87.921, train precision:88.559, train recall:88.128, train kappa:88.140
fold:0 epoch:89 step:4 train loss:0.349928, train acc:88.937, train f1:88.124, train precision:88.711, train recall:88.419, train kappa:88.527
fold:0 epoch:89 step:5 train loss:0.346206, train acc:88.806, train f1:88.195, train precision:88.825, train recall:88.411, train kappa:88.378
fold:0 epoch:89 step:6 train loss:0.358409, train acc:88.586, train f1:87.868, train precision:88.714, train recall:88.084, train kappa:88.149
fold:0 epoch:89 step:7 train loss:0.348932, train acc:88.873, train f1:87.892, train precision:88.713, train recall:88.045, train kappa:88.453
fold:0 epoch:89 step:8 train loss:0.358959, train acc:88.669, train f1:87.776, train precision:88.998, train recall:87.715, train kappa:88.242
fold:0 epoch:89 step:9 train loss:0.363021, train acc:88.358, train f1:87.536, train precision:88.687, train recall:87.658, train kappa:87.916
fold:0 epoch:89 step:10 train loss:0.359316, train acc:88.550, train f1:87.669, train precision:88.517, train recall:87.964, train kappa:88.114
fold:0 epoch:89 step:11 train loss:0.349012, train acc:89.084, train f1:88.323, train precision:89.354, train recall:88.525, train kappa:88.668
fold:0 epoch:89        valid loss:0.672615, valid acc:84.401, valid f1:61.768, valid precision:58.557, valid recall:70.343, valid kappa:82.425
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:90 step:0 train loss:0.353842, train acc:88.626, train f1:87.882, train precision:88.650, train recall:87.955, train kappa:88.198
fold:0 epoch:90 step:1 train loss:0.350862, train acc:88.776, train f1:88.027, train precision:88.751, train recall:88.108, train kappa:88.356
fold:0 epoch:90 step:2 train loss:0.351616, train acc:88.766, train f1:88.056, train precision:88.720, train recall:88.320, train kappa:88.336
fold:0 epoch:90 step:3 train loss:0.353983, train acc:88.544, train f1:87.776, train precision:88.810, train recall:87.903, train kappa:88.107
fold:0 epoch:90 step:4 train loss:0.351263, train acc:88.571, train f1:87.772, train precision:88.612, train recall:87.926, train kappa:88.141
fold:0 epoch:90 step:5 train loss:0.353776, train acc:88.712, train f1:87.732, train precision:88.612, train recall:88.031, train kappa:88.284
fold:0 epoch:90 step:6 train loss:0.351488, train acc:88.742, train f1:88.049, train precision:88.865, train recall:88.233, train kappa:88.316
fold:0 epoch:90 step:7 train loss:0.360541, train acc:88.467, train f1:87.843, train precision:88.581, train recall:88.066, train kappa:88.036
fold:0 epoch:90 step:8 train loss:0.356939, train acc:88.507, train f1:87.826, train precision:88.572, train recall:88.122, train kappa:88.071
fold:0 epoch:90 step:9 train loss:0.352643, train acc:88.699, train f1:87.962, train precision:88.683, train recall:88.138, train kappa:88.279
fold:0 epoch:90 step:10 train loss:0.353113, train acc:88.718, train f1:88.191, train precision:88.735, train recall:88.496, train kappa:88.279
fold:0 epoch:90 step:11 train loss:0.357443, train acc:88.650, train f1:87.929, train precision:88.601, train recall:88.210, train kappa:88.234
fold:0 epoch:90        valid loss:0.666546, valid acc:84.464, valid f1:61.953, valid precision:58.962, valid recall:70.148, valid kappa:82.487
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:91 step:0 train loss:0.355997, train acc:88.525, train f1:88.039, train precision:88.802, train recall:88.128, train kappa:88.091
fold:0 epoch:91 step:1 train loss:0.350665, train acc:88.690, train f1:88.075, train precision:88.726, train recall:88.271, train kappa:88.259
fold:0 epoch:91 step:2 train loss:0.355748, train acc:88.727, train f1:88.231, train precision:89.075, train recall:88.283, train kappa:88.296
fold:0 epoch:91 step:3 train loss:0.347516, train acc:88.901, train f1:88.237, train precision:89.063, train recall:88.272, train kappa:88.482
fold:0 epoch:91 step:4 train loss:0.347432, train acc:88.931, train f1:88.160, train precision:88.900, train recall:88.417, train kappa:88.517
fold:0 epoch:91 step:5 train loss:0.347168, train acc:88.849, train f1:87.879, train precision:88.662, train recall:88.197, train kappa:88.425
fold:0 epoch:91 step:6 train loss:0.352111, train acc:88.751, train f1:88.149, train precision:89.006, train recall:88.327, train kappa:88.327
fold:0 epoch:91 step:7 train loss:0.356368, train acc:88.541, train f1:87.897, train precision:88.692, train recall:88.078, train kappa:88.111
fold:0 epoch:91 step:8 train loss:0.364093, train acc:88.266, train f1:87.473, train precision:88.403, train recall:87.589, train kappa:87.821
fold:0 epoch:91 step:9 train loss:0.353082, train acc:88.730, train f1:87.958, train precision:88.830, train recall:88.197, train kappa:88.305
fold:0 epoch:91 step:10 train loss:0.351428, train acc:88.806, train f1:87.958, train precision:88.887, train recall:87.999, train kappa:88.380
fold:0 epoch:91 step:11 train loss:0.358249, train acc:88.351, train f1:87.359, train precision:88.185, train recall:87.627, train kappa:87.911
fold:0 epoch:91        valid loss:0.675294, valid acc:84.528, valid f1:61.934, valid precision:58.814, valid recall:70.244, valid kappa:82.559
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:92 step:0 train loss:0.346456, train acc:88.962, train f1:88.156, train precision:88.860, train recall:88.407, train kappa:88.549
fold:0 epoch:92 step:1 train loss:0.350850, train acc:88.904, train f1:88.175, train precision:89.170, train recall:88.181, train kappa:88.489
fold:0 epoch:92 step:2 train loss:0.350089, train acc:88.806, train f1:88.196, train precision:88.946, train recall:88.430, train kappa:88.382
fold:0 epoch:92 step:3 train loss:0.351423, train acc:88.959, train f1:88.103, train precision:88.866, train recall:88.259, train kappa:88.547
fold:0 epoch:92 step:4 train loss:0.352079, train acc:88.782, train f1:87.971, train precision:88.889, train recall:88.118, train kappa:88.347
fold:0 epoch:92 step:5 train loss:0.347950, train acc:88.632, train f1:87.810, train precision:88.703, train recall:87.982, train kappa:88.204
fold:0 epoch:92 step:6 train loss:0.352920, train acc:88.498, train f1:87.635, train precision:88.615, train recall:87.797, train kappa:88.067
fold:0 epoch:92 step:7 train loss:0.352601, train acc:88.718, train f1:88.058, train precision:88.754, train recall:88.326, train kappa:88.283
fold:0 epoch:92 step:8 train loss:0.364295, train acc:88.162, train f1:87.430, train precision:88.223, train recall:87.664, train kappa:87.708
fold:0 epoch:92 step:9 train loss:0.346613, train acc:88.858, train f1:88.120, train precision:88.586, train recall:88.483, train kappa:88.438
fold:0 epoch:92 step:10 train loss:0.349839, train acc:88.782, train f1:88.166, train precision:89.120, train recall:88.186, train kappa:88.359
fold:0 epoch:92 step:11 train loss:0.349637, train acc:88.688, train f1:87.836, train precision:88.508, train recall:87.912, train kappa:88.264
fold:0 epoch:92        valid loss:0.669253, valid acc:84.620, valid f1:61.977, valid precision:58.703, valid recall:70.419, valid kappa:82.663
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:93 step:0 train loss:0.351463, train acc:88.745, train f1:88.137, train precision:89.284, train recall:88.172, train kappa:88.322
fold:0 epoch:93 step:1 train loss:0.345863, train acc:88.968, train f1:88.394, train precision:89.410, train recall:88.356, train kappa:88.556
fold:0 epoch:93 step:2 train loss:0.354749, train acc:88.724, train f1:87.958, train precision:88.620, train recall:88.171, train kappa:88.290
fold:0 epoch:93 step:3 train loss:0.347873, train acc:88.864, train f1:88.139, train precision:88.857, train recall:88.337, train kappa:88.445
fold:0 epoch:93 step:4 train loss:0.348510, train acc:88.724, train f1:87.997, train precision:88.784, train recall:88.188, train kappa:88.286
fold:0 epoch:93 step:5 train loss:0.340026, train acc:88.971, train f1:88.225, train precision:88.976, train recall:88.433, train kappa:88.558
fold:0 epoch:93 step:6 train loss:0.359130, train acc:88.403, train f1:87.816, train precision:88.564, train recall:87.982, train kappa:87.968
fold:0 epoch:93 step:7 train loss:0.346277, train acc:89.081, train f1:88.208, train precision:89.064, train recall:88.426, train kappa:88.669
fold:0 epoch:93 step:8 train loss:0.350838, train acc:88.931, train f1:88.157, train precision:89.025, train recall:88.316, train kappa:88.518
fold:0 epoch:93 step:9 train loss:0.350549, train acc:88.757, train f1:87.969, train precision:88.741, train recall:88.135, train kappa:88.328
fold:0 epoch:93 step:10 train loss:0.342692, train acc:88.983, train f1:88.160, train precision:88.873, train recall:88.300, train kappa:88.566
fold:0 epoch:93 step:11 train loss:0.351049, train acc:88.872, train f1:88.132, train precision:88.767, train recall:88.405, train kappa:88.448
fold:0 epoch:93        valid loss:0.676148, valid acc:84.571, valid f1:62.046, valid precision:58.989, valid recall:70.201, valid kappa:82.604
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:94 step:0 train loss:0.345554, train acc:89.047, train f1:88.264, train precision:89.018, train recall:88.483, train kappa:88.637
fold:0 epoch:94 step:1 train loss:0.345009, train acc:88.943, train f1:88.224, train precision:89.323, train recall:88.217, train kappa:88.522
fold:0 epoch:94 step:2 train loss:0.346099, train acc:88.681, train f1:87.956, train precision:88.894, train recall:87.981, train kappa:88.254
fold:0 epoch:94 step:3 train loss:0.352343, train acc:88.583, train f1:88.004, train precision:88.760, train recall:88.133, train kappa:88.156
fold:0 epoch:94 step:4 train loss:0.347783, train acc:88.824, train f1:87.923, train precision:88.427, train recall:88.185, train kappa:88.396
fold:0 epoch:94 step:5 train loss:0.353736, train acc:88.657, train f1:88.029, train precision:88.610, train recall:88.225, train kappa:88.238
fold:0 epoch:94 step:6 train loss:0.348489, train acc:88.828, train f1:88.120, train precision:88.768, train recall:88.353, train kappa:88.404
fold:0 epoch:94 step:7 train loss:0.351530, train acc:88.721, train f1:87.997, train precision:88.515, train recall:88.391, train kappa:88.296
fold:0 epoch:94 step:8 train loss:0.341902, train acc:88.953, train f1:88.199, train precision:89.141, train recall:88.279, train kappa:88.534
fold:0 epoch:94 step:9 train loss:0.347483, train acc:88.858, train f1:88.061, train precision:88.892, train recall:88.206, train kappa:88.435
fold:0 epoch:94 step:10 train loss:0.347383, train acc:88.882, train f1:88.176, train precision:89.100, train recall:88.311, train kappa:88.460
fold:0 epoch:94 step:11 train loss:0.355459, train acc:88.360, train f1:87.866, train precision:88.489, train recall:88.193, train kappa:87.900
fold:0 epoch:94        valid loss:0.677430, valid acc:84.475, valid f1:61.766, valid precision:58.739, valid recall:70.187, valid kappa:82.501
[1;31mEarlyStopping counter: 6 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:95 step:0 train loss:0.345624, train acc:88.834, train f1:88.291, train precision:89.018, train recall:88.445, train kappa:88.408
fold:0 epoch:95 step:1 train loss:0.343640, train acc:89.096, train f1:88.427, train precision:89.265, train recall:88.433, train kappa:88.695
fold:0 epoch:95 step:2 train loss:0.335838, train acc:89.166, train f1:88.630, train precision:89.198, train recall:88.901, train kappa:88.760
fold:0 epoch:95 step:3 train loss:0.353199, train acc:88.797, train f1:88.294, train precision:88.897, train recall:88.458, train kappa:88.378
fold:0 epoch:95 step:4 train loss:0.342347, train acc:89.124, train f1:88.278, train precision:89.105, train recall:88.429, train kappa:88.711
fold:0 epoch:95 step:5 train loss:0.338764, train acc:89.133, train f1:88.324, train precision:88.933, train recall:88.526, train kappa:88.717
fold:0 epoch:95 step:6 train loss:0.342210, train acc:89.072, train f1:88.318, train precision:89.300, train recall:88.477, train kappa:88.661
fold:0 epoch:95 step:7 train loss:0.345268, train acc:88.870, train f1:88.142, train precision:88.921, train recall:88.283, train kappa:88.442
fold:0 epoch:95 step:8 train loss:0.353016, train acc:88.629, train f1:87.863, train precision:88.758, train recall:88.085, train kappa:88.189
fold:0 epoch:95 step:9 train loss:0.353736, train acc:88.748, train f1:87.906, train precision:88.929, train recall:87.983, train kappa:88.322
fold:0 epoch:95 step:10 train loss:0.346939, train acc:88.968, train f1:88.084, train precision:89.097, train recall:88.074, train kappa:88.557
fold:0 epoch:95 step:11 train loss:0.362899, train acc:88.601, train f1:87.753, train precision:88.564, train recall:87.946, train kappa:88.173
fold:0 epoch:95        valid loss:0.676735, valid acc:84.618, valid f1:62.269, valid precision:59.427, valid recall:70.121, valid kappa:82.655
[1;31mEarlyStopping counter: 7 out of 50[0m
[84.66681661111906, 61.79342890848923, 58.87239436541719, 70.03425889186614, 82.70343716188425]
====================================================================================================
fold:0 epoch:96 step:0 train loss:0.339076, train acc:88.974, train f1:88.291, train precision:88.908, train recall:88.488, train kappa:88.550
fold:0 epoch:96 step:1 train loss:0.338732, train acc:88.977, train f1:88.038, train precision:88.890, train recall:88.068, train kappa:88.560
fold:0 epoch:96 step:2 train loss:0.352369, train acc:88.766, train f1:88.146, train precision:89.178, train recall:88.197, train kappa:88.340
fold:0 epoch:96 step:3 train loss:0.336448, train acc:89.182, train f1:88.435, train precision:89.397, train recall:88.472, train kappa:88.768
fold:0 epoch:96 step:4 train loss:0.350571, train acc:88.660, train f1:88.087, train precision:89.053, train recall:88.187, train kappa:88.234
fold:0 epoch:96 step:5 train loss:0.348700, train acc:88.928, train f1:88.086, train precision:88.700, train recall:88.389, train kappa:88.514
fold:0 epoch:96 step:6 train loss:0.340967, train acc:88.913, train f1:88.157, train precision:88.865, train recall:88.356, train kappa:88.497
fold:0 epoch:96 step:7 train loss:0.354959, train acc:88.824, train f1:88.093, train precision:88.590, train recall:88.438, train kappa:88.406
fold:0 epoch:96 step:8 train loss:0.342289, train acc:88.910, train f1:88.079, train precision:88.722, train recall:88.231, train kappa:88.500
fold:0 epoch:96 step:9 train loss:0.348137, train acc:89.014, train f1:88.344, train precision:89.149, train recall:88.462, train kappa:88.592
fold:0 epoch:96 step:10 train loss:0.347479, train acc:88.605, train f1:87.880, train precision:88.601, train recall:88.098, train kappa:88.177
fold:0 epoch:96 step:11 train loss:0.361065, train acc:88.553, train f1:87.958, train precision:89.065, train recall:88.001, train kappa:88.109
fold:0 epoch:96        valid loss:0.674839, valid acc:84.730, valid f1:62.191, valid precision:59.325, valid recall:70.030, valid kappa:82.780
[1;31mTest score increased (84.666817 --> 84.730202).[0m
[84.73020222054103, 62.19122697119334, 59.32512068498621, 70.03032758872544, 82.78007963687351]
====================================================================================================
fold:0 epoch:97 step:0 train loss:0.343923, train acc:88.876, train f1:88.151, train precision:88.992, train recall:88.263, train kappa:88.455
fold:0 epoch:97 step:1 train loss:0.350039, train acc:88.794, train f1:88.104, train precision:88.693, train recall:88.400, train kappa:88.373
fold:0 epoch:97 step:2 train loss:0.338559, train acc:89.102, train f1:88.332, train precision:89.183, train recall:88.358, train kappa:88.692
fold:0 epoch:97 step:3 train loss:0.341000, train acc:88.931, train f1:88.245, train precision:88.911, train recall:88.355, train kappa:88.511
fold:0 epoch:97 step:4 train loss:0.335234, train acc:89.236, train f1:88.619, train precision:89.304, train recall:88.670, train kappa:88.819
fold:0 epoch:97 step:5 train loss:0.345470, train acc:88.904, train f1:88.282, train precision:88.957, train recall:88.368, train kappa:88.486
fold:0 epoch:97 step:6 train loss:0.347002, train acc:88.858, train f1:88.200, train precision:88.810, train recall:88.437, train kappa:88.447
fold:0 epoch:97 step:7 train loss:0.341601, train acc:88.977, train f1:88.130, train precision:88.645, train recall:88.422, train kappa:88.566
fold:0 epoch:97 step:8 train loss:0.338088, train acc:89.139, train f1:88.319, train precision:88.898, train recall:88.579, train kappa:88.717
fold:0 epoch:97 step:9 train loss:0.350772, train acc:88.629, train f1:87.951, train precision:88.753, train recall:88.120, train kappa:88.208
fold:0 epoch:97 step:10 train loss:0.351294, train acc:88.843, train f1:88.025, train precision:88.776, train recall:88.346, train kappa:88.418
fold:0 epoch:97 step:11 train loss:0.341815, train acc:88.727, train f1:87.840, train precision:88.893, train recall:88.120, train kappa:88.322
fold:0 epoch:97        valid loss:0.680084, valid acc:84.583, valid f1:61.922, valid precision:58.959, valid recall:70.095, valid kappa:82.621
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.73020222054103, 62.19122697119334, 59.32512068498621, 70.03032758872544, 82.78007963687351]
====================================================================================================
fold:0 epoch:98 step:0 train loss:0.339918, train acc:89.032, train f1:88.083, train precision:88.756, train recall:88.286, train kappa:88.601
fold:0 epoch:98 step:1 train loss:0.341081, train acc:88.971, train f1:88.282, train precision:88.843, train recall:88.603, train kappa:88.562
fold:0 epoch:98 step:2 train loss:0.330486, train acc:89.374, train f1:88.733, train precision:89.281, train recall:88.962, train kappa:88.975
fold:0 epoch:98 step:3 train loss:0.342716, train acc:89.041, train f1:88.406, train precision:89.092, train recall:88.492, train kappa:88.623
fold:0 epoch:98 step:4 train loss:0.348664, train acc:88.834, train f1:88.170, train precision:88.906, train recall:88.232, train kappa:88.422
fold:0 epoch:98 step:5 train loss:0.345030, train acc:88.919, train f1:88.214, train precision:88.907, train recall:88.345, train kappa:88.501
fold:0 epoch:98 step:6 train loss:0.336071, train acc:89.127, train f1:88.268, train precision:89.151, train recall:88.301, train kappa:88.714
fold:0 epoch:98 step:7 train loss:0.343706, train acc:88.943, train f1:88.147, train precision:88.919, train recall:88.295, train kappa:88.530
fold:0 epoch:98 step:8 train loss:0.336439, train acc:89.099, train f1:88.281, train precision:89.227, train recall:88.318, train kappa:88.688
fold:0 epoch:98 step:9 train loss:0.347082, train acc:88.770, train f1:87.958, train precision:88.742, train recall:88.142, train kappa:88.346
fold:0 epoch:98 step:10 train loss:0.350343, train acc:88.751, train f1:88.145, train precision:88.618, train recall:88.512, train kappa:88.323
fold:0 epoch:98 step:11 train loss:0.369825, train acc:88.408, train f1:87.546, train precision:88.189, train recall:87.884, train kappa:87.972
fold:0 epoch:98        valid loss:0.678986, valid acc:84.667, valid f1:62.225, valid precision:59.239, valid recall:70.046, valid kappa:82.712
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.73020222054103, 62.19122697119334, 59.32512068498621, 70.03032758872544, 82.78007963687351]
====================================================================================================
fold:0 epoch:99 step:0 train loss:0.347077, train acc:88.815, train f1:88.069, train precision:88.624, train recall:88.287, train kappa:88.396
fold:0 epoch:99 step:1 train loss:0.332897, train acc:89.178, train f1:88.553, train precision:89.366, train recall:88.710, train kappa:88.767
fold:0 epoch:99 step:2 train loss:0.341495, train acc:88.931, train f1:88.134, train precision:88.993, train recall:88.223, train kappa:88.509
fold:0 epoch:99 step:3 train loss:0.343130, train acc:88.962, train f1:88.419, train precision:89.178, train recall:88.447, train kappa:88.538
fold:0 epoch:99 step:4 train loss:0.346770, train acc:88.763, train f1:88.090, train precision:88.954, train recall:88.101, train kappa:88.345
fold:0 epoch:99 step:5 train loss:0.341587, train acc:88.943, train f1:88.334, train precision:89.060, train recall:88.437, train kappa:88.531
fold:0 epoch:99 step:6 train loss:0.333978, train acc:89.017, train f1:88.286, train precision:88.956, train recall:88.354, train kappa:88.601
fold:0 epoch:99 step:7 train loss:0.340953, train acc:89.151, train f1:88.403, train precision:89.194, train recall:88.558, train kappa:88.738
fold:0 epoch:99 step:8 train loss:0.338766, train acc:89.090, train f1:88.267, train precision:89.274, train recall:88.471, train kappa:88.669
fold:0 epoch:99 step:9 train loss:0.342012, train acc:89.011, train f1:88.289, train precision:88.973, train recall:88.640, train kappa:88.603
fold:0 epoch:99 step:10 train loss:0.343692, train acc:89.038, train f1:88.245, train precision:88.922, train recall:88.568, train kappa:88.627
fold:0 epoch:99 step:11 train loss:0.350461, train acc:88.843, train f1:87.879, train precision:88.561, train recall:88.279, train kappa:88.421
fold:0 epoch:99        valid loss:0.679348, valid acc:84.587, valid f1:62.100, valid precision:59.137, valid recall:70.386, valid kappa:82.629
[1;31mEarlyStopping counter: 3 out of 50[0m
[Fold 0] Best Score: [84.73020222054103, 62.19122697119334, 59.32512068498621, 70.03032758872544, 82.78007963687351]
fold:1 epoch:0 step:0 train loss:4.566685, train acc:1.663, train f1:0.673, train precision:0.985, train recall:0.961, train kappa:-0.117
fold:1 epoch:0 step:1 train loss:4.234229, train acc:10.181, train f1:1.186, train precision:1.903, train recall:1.783, train kappa:2.827
fold:1 epoch:0 step:2 train loss:4.044912, train acc:14.752, train f1:1.680, train precision:2.622, train recall:2.655, train kappa:6.065
fold:1 epoch:0 step:3 train loss:3.946618, train acc:14.047, train f1:1.626, train precision:2.042, train recall:2.830, train kappa:5.462
fold:1 epoch:0 step:4 train loss:3.888333, train acc:16.003, train f1:2.807, train precision:4.093, train recall:3.583, train kappa:6.500
fold:1 epoch:0 step:5 train loss:3.772635, train acc:17.490, train f1:3.028, train precision:4.545, train recall:3.630, train kappa:7.953
fold:1 epoch:0 step:6 train loss:3.729904, train acc:18.256, train f1:2.957, train precision:5.614, train recall:3.643, train kappa:9.090
fold:1 epoch:0 step:7 train loss:3.661037, train acc:18.738, train f1:3.725, train precision:7.094, train recall:4.167, train kappa:10.067
fold:1 epoch:0 step:8 train loss:3.586139, train acc:20.413, train f1:5.154, train precision:10.093, train recall:5.505, train kappa:11.806
fold:1 epoch:0 step:9 train loss:3.514196, train acc:21.466, train f1:6.567, train precision:8.544, train recall:6.999, train kappa:12.934
fold:1 epoch:0 step:10 train loss:3.455584, train acc:23.145, train f1:7.514, train precision:11.346, train recall:8.306, train kappa:15.087
fold:1 epoch:0 step:11 train loss:3.382405, train acc:23.646, train f1:7.708, train precision:9.985, train recall:8.499, train kappa:15.719
fold:1 epoch:0        valid loss:3.418855, valid acc:11.806, valid f1:0.542, valid precision:1.720, valid recall:1.372, valid kappa:2.159
None
====================================================================================================
fold:1 epoch:1 step:0 train loss:3.320451, train acc:24.426, train f1:7.859, train precision:11.476, train recall:8.965, train kappa:16.880
fold:1 epoch:1 step:1 train loss:3.272148, train acc:24.661, train f1:8.082, train precision:12.335, train recall:9.287, train kappa:17.152
fold:1 epoch:1 step:2 train loss:3.211875, train acc:25.391, train f1:9.295, train precision:17.706, train recall:10.110, train kappa:18.184
fold:1 epoch:1 step:3 train loss:3.141397, train acc:26.447, train f1:10.796, train precision:14.875, train recall:11.481, train kappa:19.605
fold:1 epoch:1 step:4 train loss:3.093394, train acc:27.310, train f1:11.549, train precision:21.315, train recall:11.984, train kappa:20.456
fold:1 epoch:1 step:5 train loss:3.024327, train acc:28.125, train f1:13.655, train precision:19.642, train recall:14.007, train kappa:21.628
fold:1 epoch:1 step:6 train loss:2.951362, train acc:29.437, train f1:14.882, train precision:23.291, train recall:15.106, train kappa:23.143
fold:1 epoch:1 step:7 train loss:2.906414, train acc:29.901, train f1:15.585, train precision:24.141, train recall:15.895, train kappa:23.939
fold:1 epoch:1 step:8 train loss:2.835760, train acc:30.908, train f1:17.042, train precision:24.320, train recall:17.358, train kappa:25.204
fold:1 epoch:1 step:9 train loss:2.787853, train acc:31.949, train f1:18.495, train precision:26.319, train recall:18.532, train kappa:26.482
fold:1 epoch:1 step:10 train loss:2.718597, train acc:32.712, train f1:19.682, train precision:27.472, train recall:19.545, train kappa:27.502
fold:1 epoch:1 step:11 train loss:2.676656, train acc:33.607, train f1:21.307, train precision:26.418, train recall:21.202, train kappa:28.573
fold:1 epoch:1        valid loss:3.671530, valid acc:24.847, valid f1:2.620, valid precision:3.596, valid recall:4.774, valid kappa:14.004
None
====================================================================================================
fold:1 epoch:2 step:0 train loss:2.635787, train acc:34.161, train f1:22.399, train precision:29.357, train recall:22.493, train kappa:29.664
fold:1 epoch:2 step:1 train loss:2.593193, train acc:35.257, train f1:24.018, train precision:29.690, train recall:23.892, train kappa:30.827
fold:1 epoch:2 step:2 train loss:2.527764, train acc:36.084, train f1:24.751, train precision:32.016, train recall:24.958, train kappa:31.871
fold:1 epoch:2 step:3 train loss:2.491585, train acc:36.859, train f1:26.671, train precision:34.194, train recall:26.250, train kappa:32.817
fold:1 epoch:2 step:4 train loss:2.475763, train acc:37.268, train f1:27.561, train precision:35.577, train recall:27.205, train kappa:33.283
fold:1 epoch:2 step:5 train loss:2.391906, train acc:38.638, train f1:29.050, train precision:36.677, train recall:28.470, train kappa:34.765
fold:1 epoch:2 step:6 train loss:2.361651, train acc:39.706, train f1:30.260, train precision:37.312, train recall:29.585, train kappa:35.929
fold:1 epoch:2 step:7 train loss:2.317133, train acc:40.833, train f1:31.902, train precision:38.630, train recall:31.423, train kappa:37.209
fold:1 epoch:2 step:8 train loss:2.303244, train acc:41.315, train f1:32.723, train precision:41.558, train recall:32.190, train kappa:37.794
fold:1 epoch:2 step:9 train loss:2.249293, train acc:42.221, train f1:33.497, train precision:41.500, train recall:32.925, train kappa:38.753
fold:1 epoch:2 step:10 train loss:2.217854, train acc:42.957, train f1:34.769, train precision:43.437, train recall:34.160, train kappa:39.581
fold:1 epoch:2 step:11 train loss:2.148128, train acc:44.532, train f1:36.816, train precision:44.536, train recall:36.559, train kappa:41.307
fold:1 epoch:2        valid loss:3.505875, valid acc:21.670, valid f1:7.860, valid precision:13.859, valid recall:13.458, valid kappa:12.866
None
====================================================================================================
fold:1 epoch:3 step:0 train loss:2.128757, train acc:45.139, train f1:37.937, train precision:44.603, train recall:37.352, train kappa:42.074
fold:1 epoch:3 step:1 train loss:2.092613, train acc:45.728, train f1:39.114, train precision:45.570, train recall:38.252, train kappa:42.803
fold:1 epoch:3 step:2 train loss:2.071195, train acc:46.106, train f1:40.039, train precision:48.317, train recall:39.039, train kappa:43.199
fold:1 epoch:3 step:3 train loss:2.025626, train acc:47.479, train f1:42.256, train precision:47.841, train recall:41.336, train kappa:44.701
fold:1 epoch:3 step:4 train loss:2.024408, train acc:47.446, train f1:42.157, train precision:48.672, train recall:41.271, train kappa:44.702
fold:1 epoch:3 step:5 train loss:1.972627, train acc:48.169, train f1:42.549, train precision:49.198, train recall:41.315, train kappa:45.364
fold:1 epoch:3 step:6 train loss:1.949449, train acc:49.155, train f1:44.382, train precision:50.680, train recall:42.964, train kappa:46.400
fold:1 epoch:3 step:7 train loss:1.918645, train acc:50.275, train f1:45.039, train precision:50.247, train recall:44.200, train kappa:47.663
fold:1 epoch:3 step:8 train loss:1.879195, train acc:50.821, train f1:46.082, train precision:52.825, train recall:45.109, train kappa:48.279
fold:1 epoch:3 step:9 train loss:1.877857, train acc:50.873, train f1:46.271, train precision:52.484, train recall:45.251, train kappa:48.389
fold:1 epoch:3 step:10 train loss:1.827753, train acc:52.362, train f1:48.042, train precision:53.858, train recall:46.775, train kappa:49.902
fold:1 epoch:3 step:11 train loss:1.853806, train acc:51.675, train f1:47.698, train precision:52.575, train recall:46.584, train kappa:49.200
fold:1 epoch:3        valid loss:2.639606, valid acc:31.642, valid f1:20.502, valid precision:26.039, valid recall:32.320, valid kappa:25.948
None
====================================================================================================
fold:1 epoch:4 step:0 train loss:1.786767, train acc:53.018, train f1:49.167, train precision:55.022, train recall:47.623, train kappa:50.678
fold:1 epoch:4 step:1 train loss:1.766372, train acc:53.717, train f1:50.017, train precision:54.793, train recall:48.897, train kappa:51.461
fold:1 epoch:4 step:2 train loss:1.750889, train acc:54.297, train f1:51.206, train precision:55.578, train recall:49.913, train kappa:52.067
fold:1 epoch:4 step:3 train loss:1.736059, train acc:54.907, train f1:51.417, train precision:56.834, train recall:50.277, train kappa:52.694
fold:1 epoch:4 step:4 train loss:1.702911, train acc:55.615, train f1:51.665, train precision:56.177, train recall:50.428, train kappa:53.451
fold:1 epoch:4 step:5 train loss:1.646116, train acc:56.912, train f1:53.248, train precision:57.938, train recall:51.666, train kappa:54.795
fold:1 epoch:4 step:6 train loss:1.643450, train acc:57.053, train f1:53.215, train precision:58.644, train recall:51.730, train kappa:54.931
fold:1 epoch:4 step:7 train loss:1.648074, train acc:56.754, train f1:53.612, train precision:58.639, train recall:52.192, train kappa:54.646
fold:1 epoch:4 step:8 train loss:1.623877, train acc:57.431, train f1:53.974, train precision:58.623, train recall:53.165, train kappa:55.424
fold:1 epoch:4 step:9 train loss:1.602361, train acc:58.167, train f1:54.782, train precision:58.611, train recall:53.804, train kappa:56.210
fold:1 epoch:4 step:10 train loss:1.559503, train acc:59.146, train f1:56.032, train precision:59.729, train recall:55.078, train kappa:57.254
fold:1 epoch:4 step:11 train loss:1.582383, train acc:58.904, train f1:55.478, train precision:59.419, train recall:54.356, train kappa:56.992
fold:1 epoch:4        valid loss:2.272725, valid acc:35.531, valid f1:27.652, valid precision:30.558, valid recall:44.624, valid kappa:31.079
None
====================================================================================================
fold:1 epoch:5 step:0 train loss:1.544352, train acc:59.482, train f1:56.443, train precision:61.086, train recall:55.236, train kappa:57.590
fold:1 epoch:5 step:1 train loss:1.515130, train acc:60.251, train f1:57.226, train precision:61.696, train recall:55.847, train kappa:58.355
fold:1 epoch:5 step:2 train loss:1.514571, train acc:60.263, train f1:57.908, train precision:62.281, train recall:56.695, train kappa:58.445
fold:1 epoch:5 step:3 train loss:1.484915, train acc:60.995, train f1:57.789, train precision:61.590, train recall:57.071, train kappa:59.232
fold:1 epoch:5 step:4 train loss:1.478337, train acc:61.398, train f1:58.815, train precision:63.195, train recall:57.440, train kappa:59.638
fold:1 epoch:5 step:5 train loss:1.468185, train acc:62.018, train f1:59.222, train precision:63.651, train recall:58.204, train kappa:60.309
fold:1 epoch:5 step:6 train loss:1.446122, train acc:62.439, train f1:59.754, train precision:63.851, train recall:58.750, train kappa:60.765
fold:1 epoch:5 step:7 train loss:1.428692, train acc:62.976, train f1:60.004, train precision:65.278, train recall:58.463, train kappa:61.262
fold:1 epoch:5 step:8 train loss:1.426542, train acc:62.744, train f1:60.294, train precision:68.836, train recall:58.814, train kappa:61.068
fold:1 epoch:5 step:9 train loss:1.415385, train acc:62.842, train f1:60.322, train precision:65.244, train recall:59.587, train kappa:61.209
fold:1 epoch:5 step:10 train loss:1.421384, train acc:63.126, train f1:60.185, train precision:64.513, train recall:59.793, train kappa:61.502
fold:1 epoch:5 step:11 train loss:1.408180, train acc:62.648, train f1:59.984, train precision:64.665, train recall:59.167, train kappa:60.988
fold:1 epoch:5        valid loss:1.562701, valid acc:53.771, valid f1:37.039, valid precision:36.603, valid recall:54.175, valid kappa:49.372
None
====================================================================================================
fold:1 epoch:6 step:0 train loss:1.371233, train acc:63.977, train f1:61.396, train precision:65.169, train recall:60.705, train kappa:62.393
fold:1 epoch:6 step:1 train loss:1.359182, train acc:64.160, train f1:61.512, train precision:66.084, train recall:60.660, train kappa:62.589
fold:1 epoch:6 step:2 train loss:1.361482, train acc:64.557, train f1:61.622, train precision:66.669, train recall:60.665, train kappa:62.983
fold:1 epoch:6 step:3 train loss:1.345958, train acc:64.697, train f1:61.851, train precision:67.924, train recall:60.268, train kappa:63.109
fold:1 epoch:6 step:4 train loss:1.326372, train acc:65.121, train f1:62.623, train precision:67.894, train recall:61.427, train kappa:63.593
fold:1 epoch:6 step:5 train loss:1.322692, train acc:65.118, train f1:62.809, train precision:68.143, train recall:61.862, train kappa:63.547
fold:1 epoch:6 step:6 train loss:1.306433, train acc:65.860, train f1:63.520, train precision:67.116, train recall:62.561, train kappa:64.366
fold:1 epoch:6 step:7 train loss:1.295438, train acc:65.875, train f1:63.244, train precision:69.523, train recall:62.208, train kappa:64.411
fold:1 epoch:6 step:8 train loss:1.295596, train acc:65.823, train f1:63.016, train precision:67.843, train recall:62.000, train kappa:64.312
fold:1 epoch:6 step:9 train loss:1.286628, train acc:66.428, train f1:63.989, train precision:67.291, train recall:63.321, train kappa:64.994
fold:1 epoch:6 step:10 train loss:1.268678, train acc:66.946, train f1:64.130, train precision:68.334, train recall:63.610, train kappa:65.545
fold:1 epoch:6 step:11 train loss:1.272746, train acc:66.075, train f1:63.954, train precision:68.311, train recall:63.246, train kappa:64.592
fold:1 epoch:6        valid loss:1.157973, valid acc:67.980, valid f1:44.795, valid precision:43.141, valid recall:62.727, valid kappa:64.340
None
====================================================================================================
fold:1 epoch:7 step:0 train loss:1.253435, train acc:66.980, train f1:64.511, train precision:67.720, train recall:63.830, train kappa:65.567
fold:1 epoch:7 step:1 train loss:1.240953, train acc:67.529, train f1:65.057, train precision:68.540, train recall:64.105, train kappa:66.125
fold:1 epoch:7 step:2 train loss:1.233722, train acc:67.389, train f1:64.796, train precision:69.787, train recall:64.047, train kappa:65.983
fold:1 epoch:7 step:3 train loss:1.215039, train acc:67.789, train f1:65.290, train precision:70.590, train recall:64.404, train kappa:66.408
fold:1 epoch:7 step:4 train loss:1.214464, train acc:67.932, train f1:65.637, train precision:70.433, train recall:64.429, train kappa:66.533
fold:1 epoch:7 step:5 train loss:1.215796, train acc:67.923, train f1:65.485, train precision:69.081, train recall:64.645, train kappa:66.539
fold:1 epoch:7 step:6 train loss:1.210594, train acc:68.063, train f1:65.879, train precision:69.511, train recall:64.976, train kappa:66.690
fold:1 epoch:7 step:7 train loss:1.219749, train acc:67.792, train f1:65.519, train precision:70.029, train recall:64.393, train kappa:66.438
fold:1 epoch:7 step:8 train loss:1.205602, train acc:68.069, train f1:66.149, train precision:69.934, train recall:65.243, train kappa:66.694
fold:1 epoch:7 step:9 train loss:1.169993, train acc:69.058, train f1:66.487, train precision:70.929, train recall:65.583, train kappa:67.721
fold:1 epoch:7 step:10 train loss:1.180038, train acc:68.771, train f1:66.452, train precision:70.454, train recall:65.810, train kappa:67.449
fold:1 epoch:7 step:11 train loss:1.165516, train acc:68.739, train f1:66.306, train precision:69.848, train recall:65.645, train kappa:67.353
fold:1 epoch:7        valid loss:1.024059, valid acc:72.069, valid f1:47.941, valid precision:44.384, valid recall:65.249, valid kappa:68.753
None
====================================================================================================
fold:1 epoch:8 step:0 train loss:1.155024, train acc:69.394, train f1:66.915, train precision:70.870, train recall:66.195, train kappa:68.139
fold:1 epoch:8 step:1 train loss:1.151760, train acc:69.357, train f1:66.974, train precision:70.967, train recall:66.599, train kappa:68.061
fold:1 epoch:8 step:2 train loss:1.147390, train acc:69.498, train f1:67.006, train precision:71.445, train recall:66.241, train kappa:68.239
fold:1 epoch:8 step:3 train loss:1.123215, train acc:69.824, train f1:67.579, train precision:71.900, train recall:67.042, train kappa:68.558
fold:1 epoch:8 step:4 train loss:1.138438, train acc:69.907, train f1:67.843, train precision:73.144, train recall:66.918, train kappa:68.584
fold:1 epoch:8 step:5 train loss:1.135090, train acc:70.010, train f1:67.669, train precision:72.217, train recall:66.894, train kappa:68.723
fold:1 epoch:8 step:6 train loss:1.125413, train acc:70.047, train f1:67.786, train precision:72.585, train recall:66.736, train kappa:68.754
fold:1 epoch:8 step:7 train loss:1.123358, train acc:70.132, train f1:68.057, train precision:72.171, train recall:67.060, train kappa:68.824
fold:1 epoch:8 step:8 train loss:1.092610, train acc:70.596, train f1:68.588, train precision:72.697, train recall:67.482, train kappa:69.350
fold:1 epoch:8 step:9 train loss:1.102747, train acc:70.477, train f1:68.376, train precision:71.977, train recall:67.860, train kappa:69.255
fold:1 epoch:8 step:10 train loss:1.102356, train acc:70.596, train f1:68.471, train precision:72.054, train recall:67.686, train kappa:69.350
fold:1 epoch:8 step:11 train loss:1.113799, train acc:70.601, train f1:68.240, train precision:71.076, train recall:67.791, train kappa:69.385
fold:1 epoch:8        valid loss:0.951720, valid acc:74.705, valid f1:50.314, valid precision:47.899, valid recall:66.978, valid kappa:71.625
None
====================================================================================================
fold:1 epoch:9 step:0 train loss:1.097665, train acc:71.027, train f1:68.752, train precision:73.455, train recall:68.188, train kappa:69.804
fold:1 epoch:9 step:1 train loss:1.062103, train acc:71.298, train f1:69.284, train precision:73.528, train recall:68.389, train kappa:70.075
fold:1 epoch:9 step:2 train loss:1.074654, train acc:71.234, train f1:69.432, train precision:74.194, train recall:68.045, train kappa:70.026
fold:1 epoch:9 step:3 train loss:1.077804, train acc:71.127, train f1:69.325, train precision:73.822, train recall:68.335, train kappa:69.910
fold:1 epoch:9 step:4 train loss:1.048489, train acc:71.945, train f1:69.821, train precision:73.656, train recall:68.911, train kappa:70.759
fold:1 epoch:9 step:5 train loss:1.064871, train acc:71.371, train f1:69.580, train precision:74.034, train recall:68.880, train kappa:70.166
fold:1 epoch:9 step:6 train loss:1.057722, train acc:71.747, train f1:69.448, train precision:73.638, train recall:69.130, train kappa:70.565
fold:1 epoch:9 step:7 train loss:1.048677, train acc:71.729, train f1:69.386, train precision:72.750, train recall:68.636, train kappa:70.564
fold:1 epoch:9 step:8 train loss:1.052928, train acc:71.860, train f1:69.429, train precision:73.439, train recall:68.721, train kappa:70.681
fold:1 epoch:9 step:9 train loss:1.045862, train acc:71.893, train f1:69.657, train precision:73.993, train recall:68.913, train kappa:70.741
fold:1 epoch:9 step:10 train loss:1.024756, train acc:72.488, train f1:70.083, train precision:73.980, train recall:69.706, train kappa:71.344
fold:1 epoch:9 step:11 train loss:1.043434, train acc:72.368, train f1:70.240, train precision:73.590, train recall:69.720, train kappa:71.201
fold:1 epoch:9        valid loss:0.906509, valid acc:75.615, valid f1:51.223, valid precision:48.738, valid recall:67.447, valid kappa:72.673
None
====================================================================================================
fold:1 epoch:10 step:0 train loss:1.024805, train acc:72.354, train f1:70.312, train precision:73.809, train recall:69.849, train kappa:71.205
fold:1 epoch:10 step:1 train loss:1.004421, train acc:72.903, train f1:70.640, train precision:74.019, train recall:70.263, train kappa:71.785
fold:1 epoch:10 step:2 train loss:1.013743, train acc:72.775, train f1:70.741, train precision:74.409, train recall:70.161, train kappa:71.650
fold:1 epoch:10 step:3 train loss:1.027536, train acc:72.519, train f1:70.862, train precision:75.328, train recall:69.449, train kappa:71.352
fold:1 epoch:10 step:4 train loss:1.009364, train acc:72.556, train f1:70.759, train precision:75.590, train recall:69.967, train kappa:71.414
fold:1 epoch:10 step:5 train loss:1.008711, train acc:72.910, train f1:70.777, train precision:74.791, train recall:69.879, train kappa:71.781
fold:1 epoch:10 step:6 train loss:1.017279, train acc:72.495, train f1:70.686, train precision:74.642, train recall:69.648, train kappa:71.339
fold:1 epoch:10 step:7 train loss:1.004968, train acc:72.717, train f1:70.984, train precision:74.136, train recall:70.388, train kappa:71.578
fold:1 epoch:10 step:8 train loss:0.995192, train acc:72.833, train f1:71.044, train precision:74.708, train recall:70.426, train kappa:71.722
fold:1 epoch:10 step:9 train loss:0.985947, train acc:73.337, train f1:71.121, train precision:74.543, train recall:70.863, train kappa:72.230
fold:1 epoch:10 step:10 train loss:0.999519, train acc:72.806, train f1:70.649, train precision:73.795, train recall:70.307, train kappa:71.705
fold:1 epoch:10 step:11 train loss:0.975381, train acc:73.844, train f1:71.625, train precision:74.829, train recall:71.153, train kappa:72.781
fold:1 epoch:10        valid loss:0.869125, valid acc:76.553, valid f1:51.731, valid precision:49.434, valid recall:67.618, valid kappa:73.653
None
====================================================================================================
fold:1 epoch:11 step:0 train loss:0.986471, train acc:73.465, train f1:71.526, train precision:75.141, train recall:71.017, train kappa:72.359
fold:1 epoch:11 step:1 train loss:0.968485, train acc:73.907, train f1:71.979, train precision:76.075, train recall:71.269, train kappa:72.831
fold:1 epoch:11 step:2 train loss:0.965801, train acc:73.560, train f1:71.704, train precision:75.907, train recall:70.607, train kappa:72.443
fold:1 epoch:11 step:3 train loss:0.979563, train acc:73.370, train f1:71.400, train precision:75.716, train recall:70.783, train kappa:72.266
fold:1 epoch:11 step:4 train loss:0.975666, train acc:73.560, train f1:71.538, train precision:75.818, train recall:70.480, train kappa:72.453
fold:1 epoch:11 step:5 train loss:0.971487, train acc:73.386, train f1:71.591, train precision:74.790, train recall:71.231, train kappa:72.278
fold:1 epoch:11 step:6 train loss:0.955337, train acc:73.965, train f1:72.051, train precision:74.578, train recall:71.799, train kappa:72.926
fold:1 epoch:11 step:7 train loss:0.955965, train acc:74.149, train f1:72.045, train precision:73.904, train recall:72.213, train kappa:73.106
fold:1 epoch:11 step:8 train loss:0.954507, train acc:74.243, train f1:72.195, train precision:75.896, train recall:72.053, train kappa:73.186
fold:1 epoch:11 step:9 train loss:0.927891, train acc:74.554, train f1:72.485, train precision:75.984, train recall:71.990, train kappa:73.490
fold:1 epoch:11 step:10 train loss:0.925180, train acc:74.567, train f1:72.838, train precision:76.617, train recall:71.764, train kappa:73.513
fold:1 epoch:11 step:11 train loss:0.959509, train acc:73.989, train f1:72.355, train precision:76.654, train recall:71.462, train kappa:72.968
fold:1 epoch:11        valid loss:0.847920, valid acc:77.281, valid f1:52.658, valid precision:50.204, valid recall:68.097, valid kappa:74.495
None
====================================================================================================
fold:1 epoch:12 step:0 train loss:0.916774, train acc:74.918, train f1:73.056, train precision:77.689, train recall:72.288, train kappa:73.864
fold:1 epoch:12 step:1 train loss:0.939434, train acc:74.438, train f1:72.476, train precision:75.880, train recall:71.919, train kappa:73.397
fold:1 epoch:12 step:2 train loss:0.926711, train acc:74.771, train f1:73.034, train precision:76.386, train recall:72.596, train kappa:73.727
fold:1 epoch:12 step:3 train loss:0.929017, train acc:74.448, train f1:72.374, train precision:75.517, train recall:72.131, train kappa:73.397
fold:1 epoch:12 step:4 train loss:0.907476, train acc:75.006, train f1:73.336, train precision:76.918, train recall:73.037, train kappa:73.998
fold:1 epoch:12 step:5 train loss:0.913601, train acc:75.058, train f1:73.054, train precision:76.921, train recall:72.481, train kappa:74.054
fold:1 epoch:12 step:6 train loss:0.927810, train acc:74.561, train f1:72.536, train precision:74.650, train recall:72.070, train kappa:73.513
fold:1 epoch:12 step:7 train loss:0.904023, train acc:75.345, train f1:73.645, train precision:77.903, train recall:73.286, train kappa:74.353
fold:1 epoch:12 step:8 train loss:0.903388, train acc:75.339, train f1:73.406, train precision:77.519, train recall:72.887, train kappa:74.316
fold:1 epoch:12 step:9 train loss:0.901110, train acc:75.150, train f1:73.603, train precision:77.293, train recall:72.963, train kappa:74.143
fold:1 epoch:12 step:10 train loss:0.906231, train acc:74.988, train f1:73.211, train precision:75.989, train recall:72.746, train kappa:73.987
fold:1 epoch:12 step:11 train loss:0.885994, train acc:75.823, train f1:73.656, train precision:77.530, train recall:73.353, train kappa:74.835
fold:1 epoch:12        valid loss:0.820210, valid acc:77.903, valid f1:53.512, valid precision:51.252, valid recall:68.826, valid kappa:75.151
None
====================================================================================================
fold:1 epoch:13 step:0 train loss:0.899374, train acc:75.189, train f1:73.421, train precision:76.591, train recall:72.777, train kappa:74.171
fold:1 epoch:13 step:1 train loss:0.892859, train acc:75.052, train f1:73.512, train precision:77.180, train recall:72.666, train kappa:74.021
fold:1 epoch:13 step:2 train loss:0.884080, train acc:75.821, train f1:73.611, train precision:77.064, train recall:73.019, train kappa:74.837
fold:1 epoch:13 step:3 train loss:0.884084, train acc:75.870, train f1:74.009, train precision:77.245, train recall:73.382, train kappa:74.870
fold:1 epoch:13 step:4 train loss:0.870852, train acc:75.851, train f1:74.031, train precision:77.362, train recall:73.482, train kappa:74.871
fold:1 epoch:13 step:5 train loss:0.888362, train acc:75.510, train f1:73.603, train precision:76.763, train recall:73.544, train kappa:74.536
fold:1 epoch:13 step:6 train loss:0.872399, train acc:75.790, train f1:73.808, train precision:77.062, train recall:73.566, train kappa:74.805
fold:1 epoch:13 step:7 train loss:0.880795, train acc:75.735, train f1:73.993, train precision:76.912, train recall:73.770, train kappa:74.749
fold:1 epoch:13 step:8 train loss:0.880250, train acc:75.674, train f1:74.115, train precision:77.878, train recall:73.397, train kappa:74.673
fold:1 epoch:13 step:9 train loss:0.865125, train acc:75.940, train f1:74.314, train precision:77.560, train recall:73.745, train kappa:74.933
fold:1 epoch:13 step:10 train loss:0.857652, train acc:76.169, train f1:74.698, train precision:78.185, train recall:74.103, train kappa:75.203
fold:1 epoch:13 step:11 train loss:0.856538, train acc:76.305, train f1:74.573, train precision:77.420, train recall:73.897, train kappa:75.345
fold:1 epoch:13        valid loss:0.812498, valid acc:77.840, valid f1:53.724, valid precision:51.354, valid recall:69.677, valid kappa:75.136
None
====================================================================================================
fold:1 epoch:14 step:0 train loss:0.851792, train acc:76.462, train f1:74.831, train precision:77.359, train recall:74.622, train kappa:75.490
fold:1 epoch:14 step:1 train loss:0.858402, train acc:76.404, train f1:74.688, train precision:78.409, train recall:74.112, train kappa:75.455
fold:1 epoch:14 step:2 train loss:0.853626, train acc:76.434, train f1:74.785, train precision:78.465, train recall:74.420, train kappa:75.487
fold:1 epoch:14 step:3 train loss:0.864328, train acc:76.031, train f1:74.477, train precision:77.697, train recall:74.094, train kappa:75.076
fold:1 epoch:14 step:4 train loss:0.842090, train acc:76.584, train f1:74.747, train precision:77.774, train recall:74.466, train kappa:75.630
fold:1 epoch:14 step:5 train loss:0.843310, train acc:77.072, train f1:75.049, train precision:77.806, train recall:74.905, train kappa:76.154
fold:1 epoch:14 step:6 train loss:0.848922, train acc:76.556, train f1:74.656, train precision:77.843, train recall:74.329, train kappa:75.601
fold:1 epoch:14 step:7 train loss:0.828851, train acc:76.730, train f1:74.891, train precision:77.767, train recall:74.482, train kappa:75.780
fold:1 epoch:14 step:8 train loss:0.839995, train acc:76.797, train f1:75.314, train precision:78.650, train recall:74.660, train kappa:75.851
fold:1 epoch:14 step:9 train loss:0.828942, train acc:76.956, train f1:75.223, train precision:78.036, train recall:74.638, train kappa:76.002
fold:1 epoch:14 step:10 train loss:0.829747, train acc:77.136, train f1:75.573, train precision:78.024, train recall:75.378, train kappa:76.231
fold:1 epoch:14 step:11 train loss:0.834244, train acc:76.344, train f1:74.935, train precision:77.318, train recall:74.796, train kappa:75.405
fold:1 epoch:14        valid loss:0.794021, valid acc:78.439, valid f1:54.145, valid precision:51.477, valid recall:69.330, valid kappa:75.790
None
====================================================================================================
fold:1 epoch:15 step:0 train loss:0.814354, train acc:77.560, train f1:75.873, train precision:78.914, train recall:75.544, train kappa:76.647
fold:1 epoch:15 step:1 train loss:0.815750, train acc:77.304, train f1:75.804, train precision:78.350, train recall:75.240, train kappa:76.386
fold:1 epoch:15 step:2 train loss:0.818869, train acc:77.219, train f1:75.514, train precision:77.775, train recall:75.470, train kappa:76.293
fold:1 epoch:15 step:3 train loss:0.832351, train acc:76.801, train f1:75.309, train precision:77.962, train recall:75.015, train kappa:75.855
fold:1 epoch:15 step:4 train loss:0.821013, train acc:77.011, train f1:75.222, train precision:78.682, train recall:74.858, train kappa:76.075
fold:1 epoch:15 step:5 train loss:0.811178, train acc:77.252, train f1:75.461, train precision:78.564, train recall:75.091, train kappa:76.353
fold:1 epoch:15 step:6 train loss:0.816348, train acc:77.481, train f1:75.722, train precision:78.990, train recall:75.310, train kappa:76.561
fold:1 epoch:15 step:7 train loss:0.801765, train acc:77.640, train f1:75.912, train precision:78.902, train recall:75.367, train kappa:76.741
fold:1 epoch:15 step:8 train loss:0.807787, train acc:77.359, train f1:75.967, train precision:79.008, train recall:75.744, train kappa:76.441
fold:1 epoch:15 step:9 train loss:0.805204, train acc:77.545, train f1:75.926, train precision:79.208, train recall:75.771, train kappa:76.655
fold:1 epoch:15 step:10 train loss:0.820905, train acc:76.877, train f1:75.396, train precision:78.069, train recall:75.008, train kappa:75.948
fold:1 epoch:15 step:11 train loss:0.816305, train acc:76.392, train f1:74.876, train precision:77.623, train recall:74.819, train kappa:75.487
fold:1 epoch:15        valid loss:0.782482, valid acc:78.835, valid f1:54.612, valid precision:52.388, valid recall:69.304, valid kappa:76.209
None
====================================================================================================
fold:1 epoch:16 step:0 train loss:0.803011, train acc:77.383, train f1:75.816, train precision:78.689, train recall:75.461, train kappa:76.481
fold:1 epoch:16 step:1 train loss:0.814275, train acc:77.042, train f1:75.923, train precision:78.841, train recall:75.496, train kappa:76.113
fold:1 epoch:16 step:2 train loss:0.801778, train acc:77.634, train f1:75.944, train precision:79.847, train recall:75.626, train kappa:76.711
fold:1 epoch:16 step:3 train loss:0.798236, train acc:77.652, train f1:76.125, train precision:79.265, train recall:75.456, train kappa:76.768
fold:1 epoch:16 step:4 train loss:0.782517, train acc:78.055, train f1:76.148, train precision:79.506, train recall:75.833, train kappa:77.171
fold:1 epoch:16 step:5 train loss:0.785455, train acc:77.911, train f1:76.395, train precision:79.874, train recall:76.092, train kappa:77.023
fold:1 epoch:16 step:6 train loss:0.791422, train acc:77.887, train f1:76.079, train precision:78.489, train recall:75.967, train kappa:77.005
fold:1 epoch:16 step:7 train loss:0.777379, train acc:78.067, train f1:76.275, train precision:79.232, train recall:76.191, train kappa:77.181
fold:1 epoch:16 step:8 train loss:0.781697, train acc:78.070, train f1:76.370, train precision:79.978, train recall:76.058, train kappa:77.169
fold:1 epoch:16 step:9 train loss:0.792337, train acc:77.954, train f1:76.579, train precision:79.346, train recall:76.206, train kappa:77.066
fold:1 epoch:16 step:10 train loss:0.779363, train acc:78.171, train f1:76.622, train precision:78.947, train recall:76.413, train kappa:77.300
fold:1 epoch:16 step:11 train loss:0.779803, train acc:78.419, train f1:76.797, train precision:78.844, train recall:76.791, train kappa:77.551
fold:1 epoch:16        valid loss:0.775645, valid acc:78.915, valid f1:54.275, valid precision:51.654, valid recall:69.246, valid kappa:76.334
None
====================================================================================================
fold:1 epoch:17 step:0 train loss:0.785605, train acc:78.006, train f1:76.457, train precision:79.274, train recall:76.260, train kappa:77.137
fold:1 epoch:17 step:1 train loss:0.776948, train acc:78.104, train f1:76.584, train precision:80.868, train recall:76.094, train kappa:77.233
fold:1 epoch:17 step:2 train loss:0.783939, train acc:78.210, train f1:76.644, train precision:80.193, train recall:76.303, train kappa:77.322
fold:1 epoch:17 step:3 train loss:0.768366, train acc:78.360, train f1:76.907, train precision:79.651, train recall:76.488, train kappa:77.489
fold:1 epoch:17 step:4 train loss:0.766788, train acc:78.616, train f1:76.889, train precision:79.398, train recall:76.697, train kappa:77.754
fold:1 epoch:17 step:5 train loss:0.758769, train acc:78.650, train f1:76.965, train precision:79.219, train recall:76.912, train kappa:77.790
fold:1 epoch:17 step:6 train loss:0.762796, train acc:78.540, train f1:76.988, train precision:80.633, train recall:76.569, train kappa:77.686
fold:1 epoch:17 step:7 train loss:0.776432, train acc:78.061, train f1:76.838, train precision:79.436, train recall:76.560, train kappa:77.188
fold:1 epoch:17 step:8 train loss:0.770064, train acc:78.262, train f1:76.746, train precision:79.501, train recall:76.434, train kappa:77.398
fold:1 epoch:17 step:9 train loss:0.753828, train acc:78.610, train f1:76.954, train precision:80.546, train recall:76.965, train kappa:77.741
fold:1 epoch:17 step:10 train loss:0.761921, train acc:78.577, train f1:77.221, train precision:80.257, train recall:76.866, train kappa:77.714
fold:1 epoch:17 step:11 train loss:0.760720, train acc:78.525, train f1:76.618, train precision:78.700, train recall:76.469, train kappa:77.685
fold:1 epoch:17        valid loss:0.759064, valid acc:79.410, valid f1:55.137, valid precision:52.575, valid recall:69.479, valid kappa:76.859
None
====================================================================================================
fold:1 epoch:18 step:0 train loss:0.753517, train acc:78.641, train f1:77.135, train precision:79.574, train recall:76.954, train kappa:77.796
fold:1 epoch:18 step:1 train loss:0.747837, train acc:79.218, train f1:77.981, train precision:80.891, train recall:77.495, train kappa:78.381
fold:1 epoch:18 step:2 train loss:0.767143, train acc:78.436, train f1:77.015, train precision:79.698, train recall:76.950, train kappa:77.602
fold:1 epoch:18 step:3 train loss:0.745891, train acc:78.867, train f1:77.397, train precision:79.816, train recall:77.276, train kappa:78.040
fold:1 epoch:18 step:4 train loss:0.753688, train acc:78.629, train f1:77.218, train precision:79.871, train recall:77.000, train kappa:77.779
fold:1 epoch:18 step:5 train loss:0.737030, train acc:79.126, train f1:77.729, train precision:80.332, train recall:77.755, train kappa:78.299
fold:1 epoch:18 step:6 train loss:0.732559, train acc:79.163, train f1:77.530, train precision:81.004, train recall:77.083, train kappa:78.310
fold:1 epoch:18 step:7 train loss:0.736861, train acc:79.160, train f1:77.507, train precision:80.692, train recall:77.241, train kappa:78.314
fold:1 epoch:18 step:8 train loss:0.743598, train acc:78.925, train f1:77.311, train precision:80.329, train recall:77.105, train kappa:78.068
fold:1 epoch:18 step:9 train loss:0.742032, train acc:79.041, train f1:77.408, train precision:80.913, train recall:77.334, train kappa:78.185
fold:1 epoch:18 step:10 train loss:0.728317, train acc:79.318, train f1:77.879, train precision:80.463, train recall:77.568, train kappa:78.501
fold:1 epoch:18 step:11 train loss:0.747643, train acc:78.699, train f1:77.507, train precision:80.035, train recall:77.462, train kappa:77.873
fold:1 epoch:18        valid loss:0.750133, valid acc:79.618, valid f1:55.501, valid precision:53.410, valid recall:69.957, valid kappa:77.103
None
====================================================================================================
fold:1 epoch:19 step:0 train loss:0.720283, train acc:79.401, train f1:77.788, train precision:80.326, train recall:77.697, train kappa:78.603
fold:1 epoch:19 step:1 train loss:0.732485, train acc:79.199, train f1:78.052, train precision:80.562, train recall:77.977, train kappa:78.393
fold:1 epoch:19 step:2 train loss:0.732860, train acc:79.047, train f1:77.535, train precision:79.261, train recall:77.662, train kappa:78.213
fold:1 epoch:19 step:3 train loss:0.719467, train acc:79.663, train f1:78.180, train precision:80.468, train recall:78.232, train kappa:78.842
fold:1 epoch:19 step:4 train loss:0.727930, train acc:79.651, train f1:78.303, train precision:81.678, train recall:77.952, train kappa:78.837
fold:1 epoch:19 step:5 train loss:0.711537, train acc:79.678, train f1:78.297, train precision:80.956, train recall:78.038, train kappa:78.852
fold:1 epoch:19 step:6 train loss:0.734618, train acc:79.086, train f1:77.809, train precision:80.826, train recall:77.214, train kappa:78.246
fold:1 epoch:19 step:7 train loss:0.732788, train acc:79.111, train f1:77.811, train precision:81.185, train recall:77.291, train kappa:78.271
fold:1 epoch:19 step:8 train loss:0.717850, train acc:79.614, train f1:78.165, train precision:80.788, train recall:78.014, train kappa:78.802
fold:1 epoch:19 step:9 train loss:0.732479, train acc:79.462, train f1:78.012, train precision:80.735, train recall:77.868, train kappa:78.654
fold:1 epoch:19 step:10 train loss:0.710725, train acc:79.794, train f1:78.103, train precision:80.749, train recall:78.319, train kappa:78.983
fold:1 epoch:19 step:11 train loss:0.725488, train acc:79.336, train f1:77.915, train precision:80.475, train recall:77.784, train kappa:78.510
fold:1 epoch:19        valid loss:0.738007, valid acc:80.095, valid f1:55.712, valid precision:54.200, valid recall:69.658, valid kappa:77.614
None
====================================================================================================
fold:1 epoch:20 step:0 train loss:0.698049, train acc:80.161, train f1:78.533, train precision:80.520, train recall:78.711, train kappa:79.384
fold:1 epoch:20 step:1 train loss:0.698197, train acc:79.794, train f1:78.299, train precision:80.594, train recall:78.131, train kappa:78.992
fold:1 epoch:20 step:2 train loss:0.716610, train acc:79.633, train f1:78.371, train precision:81.195, train recall:78.141, train kappa:78.826
fold:1 epoch:20 step:3 train loss:0.720055, train acc:79.700, train f1:78.551, train precision:81.171, train recall:78.423, train kappa:78.895
fold:1 epoch:20 step:4 train loss:0.705528, train acc:80.045, train f1:78.356, train precision:80.701, train recall:78.338, train kappa:79.240
fold:1 epoch:20 step:5 train loss:0.700403, train acc:80.295, train f1:78.719, train precision:80.915, train recall:78.735, train kappa:79.527
fold:1 epoch:20 step:6 train loss:0.705819, train acc:80.063, train f1:78.582, train precision:80.787, train recall:78.492, train kappa:79.278
fold:1 epoch:20 step:7 train loss:0.715672, train acc:79.547, train f1:78.327, train precision:80.765, train recall:78.161, train kappa:78.738
fold:1 epoch:20 step:8 train loss:0.704182, train acc:79.922, train f1:78.725, train precision:81.242, train recall:78.561, train kappa:79.111
fold:1 epoch:20 step:9 train loss:0.711125, train acc:79.709, train f1:78.322, train precision:81.053, train recall:78.056, train kappa:78.891
fold:1 epoch:20 step:10 train loss:0.695624, train acc:80.331, train f1:78.812, train precision:82.333, train recall:78.485, train kappa:79.555
fold:1 epoch:20 step:11 train loss:0.688203, train acc:80.793, train f1:78.991, train precision:81.427, train recall:79.099, train kappa:80.026
fold:1 epoch:20        valid loss:0.728689, valid acc:80.424, valid f1:55.965, valid precision:54.461, valid recall:69.483, valid kappa:77.972
None
====================================================================================================
fold:1 epoch:21 step:0 train loss:0.686242, train acc:80.371, train f1:78.779, train precision:81.110, train recall:78.818, train kappa:79.587
fold:1 epoch:21 step:1 train loss:0.684620, train acc:80.426, train f1:79.161, train precision:81.641, train recall:79.222, train kappa:79.657
fold:1 epoch:21 step:2 train loss:0.691852, train acc:80.151, train f1:78.746, train precision:81.534, train recall:78.457, train kappa:79.386
fold:1 epoch:21 step:3 train loss:0.701195, train acc:80.038, train f1:78.700, train precision:81.155, train recall:78.624, train kappa:79.270
fold:1 epoch:21 step:4 train loss:0.699309, train acc:80.008, train f1:78.842, train precision:80.818, train recall:78.840, train kappa:79.225
fold:1 epoch:21 step:5 train loss:0.693224, train acc:79.984, train f1:78.738, train precision:80.848, train recall:78.801, train kappa:79.189
fold:1 epoch:21 step:6 train loss:0.687925, train acc:80.322, train f1:78.928, train precision:81.347, train recall:78.953, train kappa:79.540
fold:1 epoch:21 step:7 train loss:0.702838, train acc:80.173, train f1:78.688, train precision:81.010, train recall:78.606, train kappa:79.369
fold:1 epoch:21 step:8 train loss:0.682806, train acc:80.438, train f1:79.083, train precision:81.632, train recall:78.995, train kappa:79.641
fold:1 epoch:21 step:9 train loss:0.681382, train acc:80.621, train f1:79.204, train precision:81.999, train recall:78.889, train kappa:79.847
fold:1 epoch:21 step:10 train loss:0.673897, train acc:80.801, train f1:79.569, train precision:82.054, train recall:79.151, train kappa:80.046
fold:1 epoch:21 step:11 train loss:0.674855, train acc:80.697, train f1:79.442, train precision:82.203, train recall:79.273, train kappa:79.931
fold:1 epoch:21        valid loss:0.730516, valid acc:80.234, valid f1:55.882, valid precision:53.682, valid recall:69.848, valid kappa:77.774
None
====================================================================================================
fold:1 epoch:22 step:0 train loss:0.682001, train acc:80.463, train f1:79.182, train precision:81.751, train recall:79.017, train kappa:79.686
fold:1 epoch:22 step:1 train loss:0.676935, train acc:80.435, train f1:79.196, train precision:81.544, train recall:79.241, train kappa:79.675
fold:1 epoch:22 step:2 train loss:0.680528, train acc:80.261, train f1:78.828, train precision:81.137, train recall:79.013, train kappa:79.476
fold:1 epoch:22 step:3 train loss:0.664691, train acc:80.978, train f1:79.545, train precision:81.626, train recall:79.809, train kappa:80.244
fold:1 epoch:22 step:4 train loss:0.666905, train acc:80.869, train f1:79.277, train precision:81.425, train recall:79.488, train kappa:80.107
fold:1 epoch:22 step:5 train loss:0.687334, train acc:80.142, train f1:79.133, train precision:81.235, train recall:79.088, train kappa:79.361
fold:1 epoch:22 step:6 train loss:0.667803, train acc:80.881, train f1:79.430, train precision:82.079, train recall:78.973, train kappa:80.122
fold:1 epoch:22 step:7 train loss:0.659171, train acc:80.814, train f1:79.587, train precision:82.054, train recall:79.238, train kappa:80.041
fold:1 epoch:22 step:8 train loss:0.668779, train acc:80.695, train f1:79.458, train precision:81.988, train recall:79.194, train kappa:79.944
fold:1 epoch:22 step:9 train loss:0.671698, train acc:80.673, train f1:79.205, train precision:81.668, train recall:79.224, train kappa:79.904
fold:1 epoch:22 step:10 train loss:0.674934, train acc:80.658, train f1:79.077, train precision:81.159, train recall:79.295, train kappa:79.892
fold:1 epoch:22 step:11 train loss:0.658761, train acc:81.141, train f1:79.981, train precision:81.665, train recall:80.156, train kappa:80.407
fold:1 epoch:22        valid loss:0.724114, valid acc:80.504, valid f1:56.747, valid precision:54.612, valid recall:70.438, valid kappa:78.088
None
====================================================================================================
fold:1 epoch:23 step:0 train loss:0.664059, train acc:80.978, train f1:79.701, train precision:81.752, train recall:79.845, train kappa:80.249
fold:1 epoch:23 step:1 train loss:0.658564, train acc:80.920, train f1:79.470, train precision:82.063, train recall:79.536, train kappa:80.157
fold:1 epoch:23 step:2 train loss:0.663800, train acc:80.844, train f1:79.795, train precision:82.117, train recall:79.956, train kappa:80.089
fold:1 epoch:23 step:3 train loss:0.655944, train acc:81.030, train f1:80.021, train precision:82.440, train recall:79.689, train kappa:80.288
fold:1 epoch:23 step:4 train loss:0.669062, train acc:80.490, train f1:79.466, train precision:82.081, train recall:78.961, train kappa:79.707
fold:1 epoch:23 step:5 train loss:0.654429, train acc:80.807, train f1:79.715, train precision:82.369, train recall:79.357, train kappa:80.048
fold:1 epoch:23 step:6 train loss:0.652304, train acc:81.125, train f1:79.918, train precision:82.468, train recall:79.745, train kappa:80.385
fold:1 epoch:23 step:7 train loss:0.669986, train acc:80.731, train f1:79.609, train precision:81.722, train recall:79.706, train kappa:79.969
fold:1 epoch:23 step:8 train loss:0.652264, train acc:81.223, train f1:79.674, train precision:81.384, train recall:79.932, train kappa:80.493
fold:1 epoch:23 step:9 train loss:0.657023, train acc:81.146, train f1:79.788, train precision:81.951, train recall:80.063, train kappa:80.405
fold:1 epoch:23 step:10 train loss:0.656550, train acc:81.223, train f1:79.848, train precision:82.047, train recall:80.112, train kappa:80.487
fold:1 epoch:23 step:11 train loss:0.652112, train acc:81.112, train f1:79.897, train precision:82.201, train recall:80.341, train kappa:80.376
fold:1 epoch:23        valid loss:0.715058, valid acc:80.968, valid f1:56.924, valid precision:55.257, valid recall:70.433, valid kappa:78.584
None
====================================================================================================
fold:1 epoch:24 step:0 train loss:0.652385, train acc:81.384, train f1:80.259, train precision:83.118, train recall:80.240, train kappa:80.645
fold:1 epoch:24 step:1 train loss:0.647578, train acc:81.320, train f1:79.932, train precision:82.620, train recall:79.698, train kappa:80.566
fold:1 epoch:24 step:2 train loss:0.641485, train acc:81.329, train f1:80.106, train precision:83.086, train recall:79.676, train kappa:80.587
fold:1 epoch:24 step:3 train loss:0.636736, train acc:81.702, train f1:80.339, train precision:83.079, train recall:80.028, train kappa:80.962
fold:1 epoch:24 step:4 train loss:0.646061, train acc:81.238, train f1:80.143, train precision:82.913, train recall:79.923, train kappa:80.505
fold:1 epoch:24 step:5 train loss:0.630308, train acc:81.909, train f1:80.700, train precision:82.754, train recall:80.584, train kappa:81.206
fold:1 epoch:24 step:6 train loss:0.645615, train acc:81.287, train f1:80.325, train precision:82.228, train recall:80.465, train kappa:80.560
fold:1 epoch:24 step:7 train loss:0.644364, train acc:81.049, train f1:79.981, train precision:81.638, train recall:80.320, train kappa:80.320
fold:1 epoch:24 step:8 train loss:0.657234, train acc:81.180, train f1:79.783, train precision:81.348, train recall:80.294, train kappa:80.453
fold:1 epoch:24 step:9 train loss:0.639917, train acc:81.586, train f1:80.161, train precision:82.242, train recall:80.154, train kappa:80.854
fold:1 epoch:24 step:10 train loss:0.636789, train acc:81.564, train f1:80.083, train precision:83.020, train recall:79.915, train kappa:80.841
fold:1 epoch:24 step:11 train loss:0.644380, train acc:81.459, train f1:79.914, train precision:82.030, train recall:79.793, train kappa:80.726
fold:1 epoch:24        valid loss:0.709651, valid acc:81.185, valid f1:56.731, valid precision:54.689, valid recall:69.932, valid kappa:78.812
None
====================================================================================================
fold:1 epoch:25 step:0 train loss:0.622091, train acc:82.083, train f1:80.484, train precision:83.119, train recall:80.405, train kappa:81.361
fold:1 epoch:25 step:1 train loss:0.633254, train acc:81.686, train f1:80.259, train precision:83.690, train recall:80.127, train kappa:80.957
fold:1 epoch:25 step:2 train loss:0.612334, train acc:82.175, train f1:80.942, train precision:83.580, train recall:80.837, train kappa:81.473
fold:1 epoch:25 step:3 train loss:0.617588, train acc:82.281, train f1:81.030, train precision:83.772, train recall:81.169, train kappa:81.590
fold:1 epoch:25 step:4 train loss:0.637895, train acc:81.464, train f1:80.153, train precision:81.979, train recall:80.521, train kappa:80.735
fold:1 epoch:25 step:5 train loss:0.634557, train acc:81.604, train f1:80.400, train precision:82.146, train recall:80.797, train kappa:80.886
fold:1 epoch:25 step:6 train loss:0.636441, train acc:81.641, train f1:80.586, train precision:82.251, train recall:80.796, train kappa:80.938
fold:1 epoch:25 step:7 train loss:0.626711, train acc:81.863, train f1:80.462, train precision:82.120, train recall:80.512, train kappa:81.148
fold:1 epoch:25 step:8 train loss:0.631730, train acc:81.870, train f1:80.474, train precision:82.550, train recall:80.304, train kappa:81.164
fold:1 epoch:25 step:9 train loss:0.630394, train acc:81.830, train f1:80.826, train precision:82.915, train recall:80.743, train kappa:81.120
fold:1 epoch:25 step:10 train loss:0.638673, train acc:81.238, train f1:80.165, train precision:82.576, train recall:79.954, train kappa:80.495
fold:1 epoch:25 step:11 train loss:0.625371, train acc:81.691, train f1:80.221, train precision:82.754, train recall:80.280, train kappa:80.969
fold:1 epoch:25        valid loss:0.706594, valid acc:81.181, valid f1:57.180, valid precision:55.117, valid recall:70.220, valid kappa:78.820
None
====================================================================================================
fold:1 epoch:26 step:0 train loss:0.632830, train acc:81.476, train f1:80.286, train precision:82.544, train recall:80.269, train kappa:80.749
fold:1 epoch:26 step:1 train loss:0.622293, train acc:81.927, train f1:80.724, train precision:82.871, train recall:80.906, train kappa:81.222
fold:1 epoch:26 step:2 train loss:0.614742, train acc:82.108, train f1:81.032, train precision:83.693, train recall:81.048, train kappa:81.415
fold:1 epoch:26 step:3 train loss:0.624253, train acc:81.973, train f1:80.601, train precision:82.614, train recall:80.772, train kappa:81.272
fold:1 epoch:26 step:4 train loss:0.624744, train acc:81.760, train f1:80.501, train precision:82.471, train recall:80.637, train kappa:81.060
fold:1 epoch:26 step:5 train loss:0.627597, train acc:81.860, train f1:80.508, train precision:82.109, train recall:80.694, train kappa:81.146
fold:1 epoch:26 step:6 train loss:0.604633, train acc:82.294, train f1:80.823, train precision:83.212, train recall:80.743, train kappa:81.600
fold:1 epoch:26 step:7 train loss:0.622154, train acc:81.879, train f1:80.672, train precision:82.669, train recall:80.790, train kappa:81.166
fold:1 epoch:26 step:8 train loss:0.611863, train acc:82.315, train f1:80.956, train precision:83.104, train recall:80.976, train kappa:81.620
fold:1 epoch:26 step:9 train loss:0.615745, train acc:82.013, train f1:81.094, train precision:83.177, train recall:81.021, train kappa:81.304
fold:1 epoch:26 step:10 train loss:0.610376, train acc:82.385, train f1:81.050, train precision:82.898, train recall:81.127, train kappa:81.678
fold:1 epoch:26 step:11 train loss:0.619408, train acc:82.058, train f1:81.188, train precision:83.267, train recall:81.226, train kappa:81.367
fold:1 epoch:26        valid loss:0.707204, valid acc:81.254, valid f1:57.177, valid precision:54.474, valid recall:70.303, valid kappa:78.923
None
====================================================================================================
fold:1 epoch:27 step:0 train loss:0.598880, train acc:82.645, train f1:81.221, train precision:83.039, train recall:81.473, train kappa:81.963
fold:1 epoch:27 step:1 train loss:0.613564, train acc:81.995, train f1:80.963, train precision:82.466, train recall:81.197, train kappa:81.291
fold:1 epoch:27 step:2 train loss:0.597292, train acc:82.587, train f1:81.367, train precision:83.357, train recall:81.511, train kappa:81.906
fold:1 epoch:27 step:3 train loss:0.600283, train acc:82.285, train f1:80.951, train precision:83.120, train recall:80.889, train kappa:81.611
fold:1 epoch:27 step:4 train loss:0.619136, train acc:82.019, train f1:80.865, train precision:82.919, train recall:80.757, train kappa:81.312
fold:1 epoch:27 step:5 train loss:0.607948, train acc:82.202, train f1:81.304, train precision:83.990, train recall:80.965, train kappa:81.495
fold:1 epoch:27 step:6 train loss:0.613866, train acc:82.001, train f1:80.699, train precision:83.304, train recall:80.524, train kappa:81.292
fold:1 epoch:27 step:7 train loss:0.609842, train acc:82.053, train f1:80.864, train precision:82.783, train recall:81.198, train kappa:81.349
fold:1 epoch:27 step:8 train loss:0.598659, train acc:82.410, train f1:81.143, train precision:83.422, train recall:81.301, train kappa:81.735
fold:1 epoch:27 step:9 train loss:0.604651, train acc:82.361, train f1:80.983, train precision:82.678, train recall:81.416, train kappa:81.669
fold:1 epoch:27 step:10 train loss:0.614146, train acc:82.047, train f1:80.775, train precision:82.783, train recall:80.913, train kappa:81.341
fold:1 epoch:27 step:11 train loss:0.612469, train acc:82.444, train f1:81.699, train precision:83.690, train recall:81.815, train kappa:81.759
fold:1 epoch:27        valid loss:0.695788, valid acc:81.583, valid f1:57.561, valid precision:55.229, valid recall:70.006, valid kappa:79.258
None
====================================================================================================
fold:1 epoch:28 step:0 train loss:0.607165, train acc:82.211, train f1:81.217, train precision:83.784, train recall:81.113, train kappa:81.517
fold:1 epoch:28 step:1 train loss:0.589443, train acc:82.745, train f1:81.545, train precision:83.560, train recall:81.384, train kappa:82.070
fold:1 epoch:28 step:2 train loss:0.589384, train acc:82.697, train f1:81.708, train precision:83.741, train recall:81.724, train kappa:82.017
fold:1 epoch:28 step:3 train loss:0.603704, train acc:82.358, train f1:81.466, train precision:83.106, train recall:81.572, train kappa:81.679
fold:1 epoch:28 step:4 train loss:0.591706, train acc:82.809, train f1:81.817, train precision:83.697, train recall:81.796, train kappa:82.145
fold:1 epoch:28 step:5 train loss:0.588275, train acc:82.767, train f1:81.460, train precision:83.102, train recall:81.467, train kappa:82.099
fold:1 epoch:28 step:6 train loss:0.591705, train acc:82.565, train f1:81.326, train precision:83.118, train recall:81.413, train kappa:81.873
fold:1 epoch:28 step:7 train loss:0.584890, train acc:82.800, train f1:81.588, train precision:83.773, train recall:81.616, train kappa:82.115
fold:1 epoch:28 step:8 train loss:0.600290, train acc:82.590, train f1:81.247, train precision:83.306, train recall:81.291, train kappa:81.899
fold:1 epoch:28 step:9 train loss:0.605923, train acc:82.217, train f1:81.160, train precision:83.063, train recall:81.410, train kappa:81.521
fold:1 epoch:28 step:10 train loss:0.605993, train acc:82.098, train f1:80.870, train precision:82.971, train recall:81.198, train kappa:81.407
fold:1 epoch:28 step:11 train loss:0.606323, train acc:82.386, train f1:81.156, train precision:82.854, train recall:81.562, train kappa:81.709
fold:1 epoch:28        valid loss:0.697572, valid acc:81.438, valid f1:57.389, valid precision:55.046, valid recall:70.301, valid kappa:79.111
None
====================================================================================================
fold:1 epoch:29 step:0 train loss:0.588436, train acc:82.834, train f1:81.725, train precision:83.829, train recall:81.928, train kappa:82.168
fold:1 epoch:29 step:1 train loss:0.591735, train acc:82.761, train f1:81.493, train precision:83.391, train recall:81.630, train kappa:82.101
fold:1 epoch:29 step:2 train loss:0.583520, train acc:82.761, train f1:81.602, train precision:83.558, train recall:81.584, train kappa:82.085
fold:1 epoch:29 step:3 train loss:0.587681, train acc:82.764, train f1:81.571, train precision:83.704, train recall:81.598, train kappa:82.079
fold:1 epoch:29 step:4 train loss:0.585830, train acc:82.678, train f1:81.680, train precision:84.118, train recall:81.653, train kappa:81.998
fold:1 epoch:29 step:5 train loss:0.577319, train acc:83.051, train f1:81.840, train precision:84.587, train recall:81.651, train kappa:82.389
fold:1 epoch:29 step:6 train loss:0.582403, train acc:83.139, train f1:81.874, train precision:83.721, train recall:82.028, train kappa:82.470
fold:1 epoch:29 step:7 train loss:0.587516, train acc:82.733, train f1:81.619, train precision:83.867, train recall:81.573, train kappa:82.058
fold:1 epoch:29 step:8 train loss:0.586371, train acc:82.758, train f1:81.442, train precision:83.290, train recall:81.547, train kappa:82.079
fold:1 epoch:29 step:9 train loss:0.591851, train acc:82.693, train f1:81.529, train precision:83.215, train recall:81.632, train kappa:82.017
fold:1 epoch:29 step:10 train loss:0.588767, train acc:82.733, train f1:81.711, train precision:83.234, train recall:82.028, train kappa:82.071
fold:1 epoch:29 step:11 train loss:0.582671, train acc:82.994, train f1:81.492, train precision:83.312, train recall:81.488, train kappa:82.340
fold:1 epoch:29        valid loss:0.697141, valid acc:81.661, valid f1:57.639, valid precision:54.941, valid recall:70.564, valid kappa:79.379
None
====================================================================================================
fold:1 epoch:30 step:0 train loss:0.573560, train acc:83.130, train f1:81.991, train precision:83.516, train recall:82.601, train kappa:82.478
fold:1 epoch:30 step:1 train loss:0.575910, train acc:82.901, train f1:81.963, train precision:83.630, train recall:82.127, train kappa:82.257
fold:1 epoch:30 step:2 train loss:0.579834, train acc:83.142, train f1:82.019, train precision:83.825, train recall:82.104, train kappa:82.491
fold:1 epoch:30 step:3 train loss:0.588872, train acc:82.852, train f1:81.467, train precision:83.836, train recall:81.413, train kappa:82.185
fold:1 epoch:30 step:4 train loss:0.568181, train acc:83.002, train f1:81.824, train precision:83.812, train recall:81.809, train kappa:82.326
fold:1 epoch:30 step:5 train loss:0.565012, train acc:83.447, train f1:82.506, train precision:84.585, train recall:82.437, train kappa:82.802
fold:1 epoch:30 step:6 train loss:0.579566, train acc:82.993, train f1:81.880, train precision:83.801, train recall:82.006, train kappa:82.329
fold:1 epoch:30 step:7 train loss:0.585577, train acc:82.822, train f1:81.481, train precision:83.383, train recall:81.645, train kappa:82.139
fold:1 epoch:30 step:8 train loss:0.582714, train acc:82.892, train f1:81.686, train precision:83.568, train recall:81.835, train kappa:82.213
fold:1 epoch:30 step:9 train loss:0.573696, train acc:83.212, train f1:82.162, train precision:84.107, train recall:82.468, train kappa:82.560
fold:1 epoch:30 step:10 train loss:0.564034, train acc:83.386, train f1:82.357, train precision:84.429, train recall:82.328, train kappa:82.749
fold:1 epoch:30 step:11 train loss:0.584749, train acc:82.849, train f1:81.787, train precision:83.240, train recall:82.003, train kappa:82.184
fold:1 epoch:30        valid loss:0.688517, valid acc:81.882, valid f1:57.812, valid precision:54.790, valid recall:70.637, valid kappa:79.615
None
====================================================================================================
fold:1 epoch:31 step:0 train loss:0.570070, train acc:83.322, train f1:82.187, train precision:84.124, train recall:82.178, train kappa:82.686
fold:1 epoch:31 step:1 train loss:0.565299, train acc:83.133, train f1:82.119, train precision:83.838, train recall:82.230, train kappa:82.473
fold:1 epoch:31 step:2 train loss:0.566822, train acc:83.398, train f1:82.224, train precision:84.256, train recall:82.165, train kappa:82.739
fold:1 epoch:31 step:3 train loss:0.563729, train acc:83.502, train f1:82.259, train precision:84.136, train recall:82.430, train kappa:82.844
fold:1 epoch:31 step:4 train loss:0.582370, train acc:82.928, train f1:81.920, train precision:83.815, train recall:82.121, train kappa:82.277
fold:1 epoch:31 step:5 train loss:0.565079, train acc:83.191, train f1:81.949, train precision:83.895, train recall:82.058, train kappa:82.537
fold:1 epoch:31 step:6 train loss:0.567248, train acc:83.475, train f1:82.243, train precision:83.802, train recall:82.545, train kappa:82.836
fold:1 epoch:31 step:7 train loss:0.571180, train acc:83.276, train f1:82.198, train precision:84.087, train recall:82.547, train kappa:82.623
fold:1 epoch:31 step:8 train loss:0.576061, train acc:83.234, train f1:82.165, train precision:84.139, train recall:82.298, train kappa:82.594
fold:1 epoch:31 step:9 train loss:0.573199, train acc:82.855, train f1:81.790, train precision:83.459, train recall:81.980, train kappa:82.180
fold:1 epoch:31 step:10 train loss:0.551105, train acc:83.728, train f1:82.561, train precision:84.565, train recall:82.559, train kappa:83.092
fold:1 epoch:31 step:11 train loss:0.564443, train acc:83.670, train f1:82.487, train precision:84.208, train recall:82.623, train kappa:83.048
fold:1 epoch:31        valid loss:0.686409, valid acc:82.174, valid f1:58.187, valid precision:54.961, valid recall:70.581, valid kappa:79.932
[82.17433087288119, 58.18700358918678, 54.960718132362274, 70.58146030405133, 79.93150265996113]
====================================================================================================
fold:1 epoch:32 step:0 train loss:0.553111, train acc:83.441, train f1:82.288, train precision:83.746, train recall:82.554, train kappa:82.796
fold:1 epoch:32 step:1 train loss:0.557164, train acc:83.704, train f1:82.264, train precision:84.037, train recall:82.481, train kappa:83.061
fold:1 epoch:32 step:2 train loss:0.554869, train acc:83.591, train f1:82.488, train precision:84.534, train recall:82.401, train kappa:82.950
fold:1 epoch:32 step:3 train loss:0.566128, train acc:83.145, train f1:82.169, train precision:83.960, train recall:82.349, train kappa:82.493
fold:1 epoch:32 step:4 train loss:0.558730, train acc:83.292, train f1:82.318, train precision:84.572, train recall:82.132, train kappa:82.641
fold:1 epoch:32 step:5 train loss:0.558545, train acc:83.438, train f1:82.346, train precision:84.200, train recall:82.379, train kappa:82.787
fold:1 epoch:32 step:6 train loss:0.569242, train acc:83.008, train f1:82.090, train precision:83.506, train recall:82.546, train kappa:82.345
fold:1 epoch:32 step:7 train loss:0.560842, train acc:83.438, train f1:82.254, train precision:83.851, train recall:82.523, train kappa:82.812
fold:1 epoch:32 step:8 train loss:0.559654, train acc:83.694, train f1:82.692, train precision:84.324, train recall:82.972, train kappa:83.077
fold:1 epoch:32 step:9 train loss:0.553085, train acc:83.640, train f1:82.469, train precision:84.047, train recall:82.729, train kappa:82.998
fold:1 epoch:32 step:10 train loss:0.554633, train acc:83.667, train f1:82.661, train precision:84.435, train recall:82.906, train kappa:83.035
fold:1 epoch:32 step:11 train loss:0.549760, train acc:83.544, train f1:82.283, train precision:83.976, train recall:82.483, train kappa:82.912
fold:1 epoch:32        valid loss:0.679535, valid acc:82.146, valid f1:58.129, valid precision:55.388, valid recall:70.382, valid kappa:79.888
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.17433087288119, 58.18700358918678, 54.960718132362274, 70.58146030405133, 79.93150265996113]
====================================================================================================
fold:1 epoch:33 step:0 train loss:0.558142, train acc:83.466, train f1:82.434, train precision:84.774, train recall:82.310, train kappa:82.810
fold:1 epoch:33 step:1 train loss:0.553023, train acc:83.575, train f1:82.652, train precision:84.780, train recall:82.476, train kappa:82.933
fold:1 epoch:33 step:2 train loss:0.540540, train acc:84.192, train f1:83.155, train precision:85.375, train recall:83.160, train kappa:83.562
fold:1 epoch:33 step:3 train loss:0.544989, train acc:83.783, train f1:82.552, train precision:84.585, train recall:82.543, train kappa:83.161
fold:1 epoch:33 step:4 train loss:0.549012, train acc:83.679, train f1:82.509, train precision:84.034, train recall:82.657, train kappa:83.039
fold:1 epoch:33 step:5 train loss:0.543096, train acc:83.914, train f1:82.872, train precision:84.531, train recall:83.006, train kappa:83.299
fold:1 epoch:33 step:6 train loss:0.557201, train acc:83.578, train f1:82.473, train precision:83.926, train recall:82.673, train kappa:82.939
fold:1 epoch:33 step:7 train loss:0.559846, train acc:83.362, train f1:82.293, train precision:83.772, train recall:82.713, train kappa:82.719
fold:1 epoch:33 step:8 train loss:0.550725, train acc:83.572, train f1:82.496, train precision:84.204, train recall:82.737, train kappa:82.935
fold:1 epoch:33 step:9 train loss:0.566499, train acc:83.313, train f1:82.060, train precision:84.174, train recall:82.285, train kappa:82.663
fold:1 epoch:33 step:10 train loss:0.548991, train acc:83.438, train f1:82.292, train precision:83.930, train recall:82.455, train kappa:82.805
fold:1 epoch:33 step:11 train loss:0.566146, train acc:83.226, train f1:82.271, train precision:84.286, train recall:82.585, train kappa:82.573
fold:1 epoch:33        valid loss:0.677737, valid acc:82.242, valid f1:58.066, valid precision:54.942, valid recall:70.360, valid kappa:80.007
[1;31mTest score increased (82.174331 --> 82.241806).[0m
[82.24180587645941, 58.0658562894274, 54.941531378545264, 70.35999973415596, 80.00690243542967]
====================================================================================================
fold:1 epoch:34 step:0 train loss:0.545407, train acc:84.119, train f1:82.826, train precision:84.985, train recall:82.835, train kappa:83.500
fold:1 epoch:34 step:1 train loss:0.550752, train acc:83.612, train f1:82.808, train precision:84.638, train recall:82.988, train kappa:82.979
fold:1 epoch:34 step:2 train loss:0.542505, train acc:83.856, train f1:82.830, train precision:84.090, train recall:83.042, train kappa:83.235
fold:1 epoch:34 step:3 train loss:0.549883, train acc:83.762, train f1:82.574, train precision:83.858, train recall:82.951, train kappa:83.136
fold:1 epoch:34 step:4 train loss:0.531859, train acc:84.329, train f1:83.338, train precision:84.984, train recall:83.524, train kappa:83.738
fold:1 epoch:34 step:5 train loss:0.547284, train acc:83.807, train f1:82.558, train precision:83.955, train recall:82.872, train kappa:83.166
fold:1 epoch:34 step:6 train loss:0.538416, train acc:84.042, train f1:82.876, train precision:84.860, train recall:83.039, train kappa:83.411
fold:1 epoch:34 step:7 train loss:0.546645, train acc:83.960, train f1:82.907, train precision:84.963, train recall:82.913, train kappa:83.333
fold:1 epoch:34 step:8 train loss:0.535571, train acc:84.097, train f1:82.983, train precision:84.854, train recall:83.112, train kappa:83.480
fold:1 epoch:34 step:9 train loss:0.539803, train acc:84.149, train f1:83.179, train precision:84.935, train recall:83.340, train kappa:83.538
fold:1 epoch:34 step:10 train loss:0.550418, train acc:83.630, train f1:82.655, train precision:84.482, train recall:82.733, train kappa:83.004
fold:1 epoch:34 step:11 train loss:0.551418, train acc:83.380, train f1:82.494, train precision:83.706, train recall:82.922, train kappa:82.733
fold:1 epoch:34        valid loss:0.682263, valid acc:82.305, valid f1:58.621, valid precision:55.537, valid recall:70.753, valid kappa:80.087
[1;31mTest score increased (82.241806 --> 82.305191).[0m
[82.30519148588137, 58.621171807451425, 55.53728382448572, 70.752838488863, 80.08749913565242]
====================================================================================================
fold:1 epoch:35 step:0 train loss:0.541254, train acc:83.798, train f1:82.714, train precision:84.369, train recall:82.986, train kappa:83.167
fold:1 epoch:35 step:1 train loss:0.550393, train acc:83.585, train f1:82.610, train precision:84.271, train recall:83.030, train kappa:82.954
fold:1 epoch:35 step:2 train loss:0.539420, train acc:84.067, train f1:83.122, train precision:84.669, train recall:83.323, train kappa:83.443
fold:1 epoch:35 step:3 train loss:0.526796, train acc:84.286, train f1:83.232, train precision:84.996, train recall:83.349, train kappa:83.677
fold:1 epoch:35 step:4 train loss:0.523145, train acc:84.296, train f1:83.087, train precision:84.674, train recall:83.135, train kappa:83.688
fold:1 epoch:35 step:5 train loss:0.538228, train acc:84.018, train f1:83.124, train precision:84.794, train recall:83.254, train kappa:83.389
fold:1 epoch:35 step:6 train loss:0.538229, train acc:84.109, train f1:83.078, train precision:84.963, train recall:82.952, train kappa:83.486
fold:1 epoch:35 step:7 train loss:0.535552, train acc:83.914, train f1:83.055, train precision:84.403, train recall:83.285, train kappa:83.300
fold:1 epoch:35 step:8 train loss:0.525320, train acc:84.570, train f1:83.264, train precision:84.991, train recall:83.526, train kappa:83.979
fold:1 epoch:35 step:9 train loss:0.539197, train acc:84.055, train f1:82.895, train precision:84.773, train recall:82.929, train kappa:83.441
fold:1 epoch:35 step:10 train loss:0.538485, train acc:84.079, train f1:82.940, train precision:84.843, train recall:83.189, train kappa:83.469
fold:1 epoch:35 step:11 train loss:0.535789, train acc:84.191, train f1:83.390, train precision:85.385, train recall:83.425, train kappa:83.569
fold:1 epoch:35        valid loss:0.674401, valid acc:82.651, valid f1:58.829, valid precision:55.988, valid recall:70.546, valid kappa:80.450
[1;31mTest score increased (82.305191 --> 82.650745).[0m
[82.65074529208498, 58.82940121136717, 55.98836424009133, 70.54594775251482, 80.44975399980517]
====================================================================================================
fold:1 epoch:36 step:0 train loss:0.529736, train acc:84.180, train f1:83.205, train precision:85.370, train recall:83.349, train kappa:83.565
fold:1 epoch:36 step:1 train loss:0.533729, train acc:84.213, train f1:83.269, train precision:85.013, train recall:83.587, train kappa:83.595
fold:1 epoch:36 step:2 train loss:0.524356, train acc:84.290, train f1:83.340, train precision:84.787, train recall:83.526, train kappa:83.680
fold:1 epoch:36 step:3 train loss:0.525913, train acc:84.219, train f1:83.206, train precision:84.461, train recall:83.478, train kappa:83.600
fold:1 epoch:36 step:4 train loss:0.527533, train acc:84.207, train f1:83.244, train precision:84.698, train recall:83.373, train kappa:83.595
fold:1 epoch:36 step:5 train loss:0.534065, train acc:84.134, train f1:83.189, train precision:84.633, train recall:83.335, train kappa:83.527
fold:1 epoch:36 step:6 train loss:0.525589, train acc:84.256, train f1:83.222, train precision:84.847, train recall:83.366, train kappa:83.649
fold:1 epoch:36 step:7 train loss:0.531325, train acc:84.335, train f1:83.315, train precision:85.025, train recall:83.432, train kappa:83.741
fold:1 epoch:36 step:8 train loss:0.516698, train acc:84.540, train f1:83.318, train precision:85.167, train recall:83.350, train kappa:83.941
fold:1 epoch:36 step:9 train loss:0.525213, train acc:84.445, train f1:83.549, train precision:85.516, train recall:83.491, train kappa:83.846
fold:1 epoch:36 step:10 train loss:0.528478, train acc:84.528, train f1:83.329, train precision:85.191, train recall:83.499, train kappa:83.916
fold:1 epoch:36 step:11 train loss:0.520507, train acc:84.461, train f1:83.643, train precision:85.742, train recall:83.864, train kappa:83.868
fold:1 epoch:36        valid loss:0.681254, valid acc:82.440, valid f1:58.390, valid precision:55.307, valid recall:70.663, valid kappa:80.234
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.65074529208498, 58.82940121136717, 55.98836424009133, 70.54594775251482, 80.44975399980517]
====================================================================================================
fold:1 epoch:37 step:0 train loss:0.516135, train acc:84.720, train f1:83.576, train precision:85.098, train recall:83.767, train kappa:84.123
fold:1 epoch:37 step:1 train loss:0.523840, train acc:84.369, train f1:83.388, train precision:84.681, train recall:83.798, train kappa:83.773
fold:1 epoch:37 step:2 train loss:0.514044, train acc:84.506, train f1:83.500, train precision:85.052, train recall:83.813, train kappa:83.907
fold:1 epoch:37 step:3 train loss:0.528077, train acc:84.311, train f1:83.094, train precision:84.661, train recall:83.385, train kappa:83.705
fold:1 epoch:37 step:4 train loss:0.529143, train acc:84.119, train f1:83.117, train precision:84.456, train recall:83.523, train kappa:83.509
fold:1 epoch:37 step:5 train loss:0.528285, train acc:84.229, train f1:83.405, train precision:85.335, train recall:83.478, train kappa:83.607
fold:1 epoch:37 step:6 train loss:0.519608, train acc:84.415, train f1:83.407, train precision:85.623, train recall:83.327, train kappa:83.824
fold:1 epoch:37 step:7 train loss:0.529237, train acc:84.158, train f1:83.223, train precision:85.364, train recall:83.171, train kappa:83.541
fold:1 epoch:37 step:8 train loss:0.518222, train acc:84.509, train f1:83.513, train precision:84.921, train recall:83.888, train kappa:83.902
fold:1 epoch:37 step:9 train loss:0.514541, train acc:84.470, train f1:83.599, train precision:85.148, train recall:83.817, train kappa:83.870
fold:1 epoch:37 step:10 train loss:0.515215, train acc:84.650, train f1:83.496, train precision:85.058, train recall:83.869, train kappa:84.070
fold:1 epoch:37 step:11 train loss:0.512960, train acc:84.857, train f1:83.798, train precision:85.534, train recall:83.973, train kappa:84.273
fold:1 epoch:37        valid loss:0.674555, valid acc:82.710, valid f1:58.881, valid precision:55.688, valid recall:70.576, valid kappa:80.527
[1;31mTest score increased (82.650745 --> 82.710042).[0m
[82.71004150735068, 58.88133140483556, 55.687674482097, 70.57571256333031, 80.52690866296363]
====================================================================================================
fold:1 epoch:38 step:0 train loss:0.518229, train acc:84.558, train f1:83.689, train precision:85.151, train recall:83.988, train kappa:83.968
fold:1 epoch:38 step:1 train loss:0.515389, train acc:84.668, train f1:83.609, train precision:84.947, train recall:83.722, train kappa:84.086
fold:1 epoch:38 step:2 train loss:0.514975, train acc:84.689, train f1:83.587, train precision:85.271, train recall:83.737, train kappa:84.085
fold:1 epoch:38 step:3 train loss:0.516081, train acc:84.564, train f1:83.523, train precision:85.020, train recall:83.608, train kappa:83.952
fold:1 epoch:38 step:4 train loss:0.530274, train acc:84.161, train f1:83.249, train precision:85.483, train recall:83.125, train kappa:83.541
fold:1 epoch:38 step:5 train loss:0.510173, train acc:84.570, train f1:83.415, train precision:85.491, train recall:83.484, train kappa:83.961
fold:1 epoch:38 step:6 train loss:0.515479, train acc:84.494, train f1:83.493, train precision:85.155, train recall:83.799, train kappa:83.904
fold:1 epoch:38 step:7 train loss:0.507980, train acc:84.802, train f1:83.657, train precision:84.976, train recall:84.115, train kappa:84.229
fold:1 epoch:38 step:8 train loss:0.513368, train acc:84.811, train f1:83.418, train precision:84.236, train recall:84.174, train kappa:84.238
fold:1 epoch:38 step:9 train loss:0.511373, train acc:84.653, train f1:83.770, train precision:85.347, train recall:84.007, train kappa:84.070
fold:1 epoch:38 step:10 train loss:0.510893, train acc:84.634, train f1:83.629, train precision:85.201, train recall:83.872, train kappa:84.033
fold:1 epoch:38 step:11 train loss:0.518493, train acc:84.287, train f1:83.338, train precision:85.187, train recall:83.387, train kappa:83.677
fold:1 epoch:38        valid loss:0.666178, valid acc:82.968, valid f1:59.270, valid precision:56.390, valid recall:70.610, valid kappa:80.813
[1;31mTest score increased (82.710042 --> 82.967673).[0m
[82.9676733391948, 59.270027166715344, 56.38957094222785, 70.61023416257993, 80.81268078207458]
====================================================================================================
fold:1 epoch:39 step:0 train loss:0.501850, train acc:84.897, train f1:83.593, train precision:85.480, train recall:83.423, train kappa:84.312
fold:1 epoch:39 step:1 train loss:0.510729, train acc:84.717, train f1:83.790, train precision:85.847, train recall:83.693, train kappa:84.119
fold:1 epoch:39 step:2 train loss:0.503614, train acc:84.863, train f1:83.738, train precision:85.574, train recall:83.790, train kappa:84.286
fold:1 epoch:39 step:3 train loss:0.509527, train acc:84.702, train f1:83.866, train precision:85.525, train recall:84.130, train kappa:84.101
fold:1 epoch:39 step:4 train loss:0.510199, train acc:84.579, train f1:83.492, train precision:84.936, train recall:83.774, train kappa:83.986
fold:1 epoch:39 step:5 train loss:0.508506, train acc:84.760, train f1:83.992, train precision:85.249, train recall:84.357, train kappa:84.182
fold:1 epoch:39 step:6 train loss:0.510832, train acc:84.518, train f1:83.626, train precision:84.740, train recall:84.051, train kappa:83.928
fold:1 epoch:39 step:7 train loss:0.507607, train acc:84.753, train f1:83.574, train precision:84.771, train recall:83.940, train kappa:84.159
fold:1 epoch:39 step:8 train loss:0.512909, train acc:84.561, train f1:83.810, train precision:85.560, train recall:83.893, train kappa:83.956
fold:1 epoch:39 step:9 train loss:0.505989, train acc:84.506, train f1:83.677, train precision:85.338, train recall:83.695, train kappa:83.912
fold:1 epoch:39 step:10 train loss:0.515444, train acc:84.622, train f1:83.643, train precision:85.336, train recall:83.820, train kappa:84.033
fold:1 epoch:39 step:11 train loss:0.483990, train acc:85.658, train f1:84.173, train precision:86.043, train recall:84.420, train kappa:85.098
fold:1 epoch:39        valid loss:0.668068, valid acc:82.890, valid f1:59.052, valid precision:55.964, valid recall:70.487, valid kappa:80.727
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.9676733391948, 59.270027166715344, 56.38957094222785, 70.61023416257993, 80.81268078207458]
====================================================================================================
fold:1 epoch:40 step:0 train loss:0.503721, train acc:84.860, train f1:83.964, train precision:85.341, train recall:84.277, train kappa:84.281
fold:1 epoch:40 step:1 train loss:0.497474, train acc:85.004, train f1:83.933, train precision:85.240, train recall:84.360, train kappa:84.432
fold:1 epoch:40 step:2 train loss:0.503055, train acc:84.845, train f1:84.009, train precision:85.592, train recall:84.243, train kappa:84.271
fold:1 epoch:40 step:3 train loss:0.498998, train acc:85.007, train f1:83.950, train precision:85.444, train recall:84.025, train kappa:84.417
fold:1 epoch:40 step:4 train loss:0.506929, train acc:84.821, train f1:83.654, train precision:85.113, train recall:83.823, train kappa:84.229
fold:1 epoch:40 step:5 train loss:0.510576, train acc:84.592, train f1:83.673, train precision:85.391, train recall:83.759, train kappa:83.995
fold:1 epoch:40 step:6 train loss:0.503682, train acc:84.927, train f1:83.991, train precision:85.561, train recall:84.063, train kappa:84.343
fold:1 epoch:40 step:7 train loss:0.501260, train acc:85.147, train f1:84.350, train precision:85.753, train recall:84.451, train kappa:84.583
fold:1 epoch:40 step:8 train loss:0.501391, train acc:84.766, train f1:83.843, train precision:85.429, train recall:83.945, train kappa:84.183
fold:1 epoch:40 step:9 train loss:0.494973, train acc:85.199, train f1:84.258, train precision:85.457, train recall:84.590, train kappa:84.624
fold:1 epoch:40 step:10 train loss:0.502820, train acc:84.930, train f1:83.781, train precision:85.256, train recall:84.132, train kappa:84.347
fold:1 epoch:40 step:11 train loss:0.510385, train acc:84.500, train f1:83.751, train precision:85.030, train recall:84.303, train kappa:83.902
fold:1 epoch:40        valid loss:0.670658, valid acc:82.867, valid f1:59.148, valid precision:55.983, valid recall:70.354, valid kappa:80.706
[1;31mEarlyStopping counter: 2 out of 50[0m
[82.9676733391948, 59.270027166715344, 56.38957094222785, 70.61023416257993, 80.81268078207458]
====================================================================================================
fold:1 epoch:41 step:0 train loss:0.495031, train acc:85.077, train f1:84.134, train precision:85.575, train recall:84.398, train kappa:84.505
fold:1 epoch:41 step:1 train loss:0.497395, train acc:84.927, train f1:83.761, train precision:85.068, train recall:84.128, train kappa:84.345
fold:1 epoch:41 step:2 train loss:0.494845, train acc:84.924, train f1:83.829, train precision:85.553, train recall:83.823, train kappa:84.340
fold:1 epoch:41 step:3 train loss:0.504247, train acc:84.753, train f1:84.031, train precision:85.480, train recall:84.262, train kappa:84.163
fold:1 epoch:41 step:4 train loss:0.506042, train acc:84.796, train f1:83.938, train precision:85.205, train recall:84.184, train kappa:84.200
fold:1 epoch:41 step:5 train loss:0.503336, train acc:84.698, train f1:83.853, train precision:85.456, train recall:83.888, train kappa:84.102
fold:1 epoch:41 step:6 train loss:0.501266, train acc:84.991, train f1:83.810, train precision:85.581, train recall:83.801, train kappa:84.403
fold:1 epoch:41 step:7 train loss:0.498933, train acc:84.808, train f1:83.969, train precision:85.456, train recall:84.355, train kappa:84.237
fold:1 epoch:41 step:8 train loss:0.489849, train acc:85.196, train f1:84.227, train precision:85.479, train recall:84.632, train kappa:84.625
fold:1 epoch:41 step:9 train loss:0.488281, train acc:85.425, train f1:84.456, train precision:85.799, train recall:84.846, train kappa:84.866
fold:1 epoch:41 step:10 train loss:0.505881, train acc:84.769, train f1:83.745, train precision:85.187, train recall:84.115, train kappa:84.195
fold:1 epoch:41 step:11 train loss:0.502555, train acc:84.847, train f1:84.115, train precision:86.028, train recall:84.154, train kappa:84.277
fold:1 epoch:41        valid loss:0.663487, valid acc:83.054, valid f1:59.385, valid precision:56.433, valid recall:70.556, valid kappa:80.906
[1;31mTest score increased (82.967673 --> 83.053551).[0m
[83.05355061647617, 59.38525693929091, 56.43284014027422, 70.55593120114949, 80.90559649992824]
====================================================================================================
fold:1 epoch:42 step:0 train loss:0.491451, train acc:85.199, train f1:84.358, train precision:85.751, train recall:84.455, train kappa:84.626
fold:1 epoch:42 step:1 train loss:0.490119, train acc:85.272, train f1:84.009, train precision:85.838, train recall:84.066, train kappa:84.700
fold:1 epoch:42 step:2 train loss:0.489962, train acc:85.223, train f1:84.141, train precision:85.734, train recall:84.400, train kappa:84.653
fold:1 epoch:42 step:3 train loss:0.494816, train acc:84.991, train f1:84.006, train precision:85.460, train recall:84.148, train kappa:84.425
fold:1 epoch:42 step:4 train loss:0.496176, train acc:84.998, train f1:84.245, train precision:85.484, train recall:84.570, train kappa:84.426
fold:1 epoch:42 step:5 train loss:0.483633, train acc:85.303, train f1:84.132, train precision:85.489, train recall:84.419, train kappa:84.729
fold:1 epoch:42 step:6 train loss:0.497380, train acc:85.007, train f1:84.272, train precision:85.719, train recall:84.511, train kappa:84.430
fold:1 epoch:42 step:7 train loss:0.489812, train acc:85.056, train f1:84.113, train precision:85.708, train recall:84.374, train kappa:84.480
fold:1 epoch:42 step:8 train loss:0.499606, train acc:85.049, train f1:84.184, train precision:85.976, train recall:84.304, train kappa:84.486
fold:1 epoch:42 step:9 train loss:0.487636, train acc:85.422, train f1:84.523, train precision:86.412, train recall:84.540, train kappa:84.847
fold:1 epoch:42 step:10 train loss:0.490692, train acc:85.342, train f1:84.480, train precision:86.009, train recall:84.684, train kappa:84.772
fold:1 epoch:42 step:11 train loss:0.468183, train acc:86.025, train f1:84.855, train precision:86.442, train recall:84.849, train kappa:85.502
fold:1 epoch:42        valid loss:0.666527, valid acc:83.039, valid f1:59.624, valid precision:56.547, valid recall:70.717, valid kappa:80.896
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.05355061647617, 59.38525693929091, 56.43284014027422, 70.55593120114949, 80.90559649992824]
====================================================================================================
fold:1 epoch:43 step:0 train loss:0.483345, train acc:85.376, train f1:84.384, train precision:85.939, train recall:84.530, train kappa:84.807
fold:1 epoch:43 step:1 train loss:0.476475, train acc:85.504, train f1:84.498, train precision:86.172, train recall:84.537, train kappa:84.932
fold:1 epoch:43 step:2 train loss:0.485927, train acc:85.400, train f1:84.394, train precision:85.762, train recall:84.718, train kappa:84.845
fold:1 epoch:43 step:3 train loss:0.485054, train acc:85.425, train f1:84.595, train precision:85.987, train recall:84.955, train kappa:84.873
fold:1 epoch:43 step:4 train loss:0.490151, train acc:85.190, train f1:84.159, train precision:85.854, train recall:84.359, train kappa:84.627
fold:1 epoch:43 step:5 train loss:0.483453, train acc:85.324, train f1:84.363, train precision:85.772, train recall:84.614, train kappa:84.764
fold:1 epoch:43 step:6 train loss:0.490728, train acc:85.129, train f1:84.233, train precision:85.891, train recall:84.160, train kappa:84.570
fold:1 epoch:43 step:7 train loss:0.492326, train acc:85.150, train f1:84.409, train precision:86.048, train recall:84.390, train kappa:84.577
fold:1 epoch:43 step:8 train loss:0.486400, train acc:85.229, train f1:84.273, train precision:85.750, train recall:84.404, train kappa:84.651
fold:1 epoch:43 step:9 train loss:0.485306, train acc:85.410, train f1:84.443, train precision:85.805, train recall:84.701, train kappa:84.839
fold:1 epoch:43 step:10 train loss:0.485274, train acc:85.245, train f1:84.269, train precision:85.827, train recall:84.461, train kappa:84.674
fold:1 epoch:43 step:11 train loss:0.485028, train acc:85.098, train f1:84.136, train precision:85.356, train recall:84.473, train kappa:84.514
fold:1 epoch:43        valid loss:0.665460, valid acc:83.011, valid f1:59.366, valid precision:56.250, valid recall:70.761, valid kappa:80.866
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.05355061647617, 59.38525693929091, 56.43284014027422, 70.55593120114949, 80.90559649992824]
====================================================================================================
fold:1 epoch:44 step:0 train loss:0.476427, train acc:85.458, train f1:84.398, train precision:85.956, train recall:84.512, train kappa:84.896
fold:1 epoch:44 step:1 train loss:0.483431, train acc:85.376, train f1:84.554, train precision:86.401, train recall:84.610, train kappa:84.815
fold:1 epoch:44 step:2 train loss:0.475931, train acc:85.678, train f1:84.547, train precision:86.236, train recall:84.705, train kappa:85.132
fold:1 epoch:44 step:3 train loss:0.478119, train acc:85.562, train f1:84.715, train precision:86.310, train recall:84.964, train kappa:85.008
fold:1 epoch:44 step:4 train loss:0.474732, train acc:85.693, train f1:84.702, train precision:85.914, train recall:85.029, train kappa:85.136
fold:1 epoch:44 step:5 train loss:0.474179, train acc:85.611, train f1:84.703, train precision:86.191, train recall:84.966, train kappa:85.065
fold:1 epoch:44 step:6 train loss:0.487748, train acc:85.098, train f1:84.233, train precision:85.433, train recall:84.543, train kappa:84.525
fold:1 epoch:44 step:7 train loss:0.485701, train acc:85.437, train f1:84.340, train precision:85.624, train recall:84.749, train kappa:84.874
fold:1 epoch:44 step:8 train loss:0.480784, train acc:85.464, train f1:84.584, train precision:85.819, train recall:84.923, train kappa:84.905
fold:1 epoch:44 step:9 train loss:0.490776, train acc:85.092, train f1:84.197, train precision:85.446, train recall:84.513, train kappa:84.524
fold:1 epoch:44 step:10 train loss:0.492367, train acc:85.120, train f1:84.318, train precision:85.730, train recall:84.458, train kappa:84.549
fold:1 epoch:44 step:11 train loss:0.470579, train acc:86.015, train f1:84.776, train precision:86.481, train recall:85.127, train kappa:85.476
fold:1 epoch:44        valid loss:0.665869, valid acc:83.229, valid f1:59.587, valid precision:56.549, valid recall:70.836, valid kappa:81.102
[1;31mTest score increased (83.053551 --> 83.229395).[0m
[83.22939456519516, 59.58726216824374, 56.54892816645235, 70.83580535049279, 81.10219135270074]
====================================================================================================
fold:1 epoch:45 step:0 train loss:0.459304, train acc:86.053, train f1:85.182, train precision:86.882, train recall:85.142, train kappa:85.517
fold:1 epoch:45 step:1 train loss:0.477796, train acc:85.638, train f1:84.630, train precision:86.231, train recall:84.885, train kappa:85.086
fold:1 epoch:45 step:2 train loss:0.478583, train acc:85.504, train f1:84.522, train precision:86.189, train recall:84.615, train kappa:84.944
fold:1 epoch:45 step:3 train loss:0.480626, train acc:85.437, train f1:84.513, train precision:85.734, train recall:84.933, train kappa:84.875
fold:1 epoch:45 step:4 train loss:0.476168, train acc:85.547, train f1:84.644, train precision:86.139, train recall:84.774, train kappa:84.990
fold:1 epoch:45 step:5 train loss:0.471984, train acc:85.623, train f1:84.678, train precision:85.974, train recall:84.960, train kappa:85.061
fold:1 epoch:45 step:6 train loss:0.474614, train acc:85.638, train f1:84.684, train precision:85.924, train recall:84.919, train kappa:85.086
fold:1 epoch:45 step:7 train loss:0.486780, train acc:85.385, train f1:84.311, train precision:86.046, train recall:84.451, train kappa:84.829
fold:1 epoch:45 step:8 train loss:0.479593, train acc:85.416, train f1:84.496, train precision:86.117, train recall:84.688, train kappa:84.853
fold:1 epoch:45 step:9 train loss:0.485236, train acc:85.236, train f1:84.308, train precision:85.584, train recall:84.446, train kappa:84.664
fold:1 epoch:45 step:10 train loss:0.478230, train acc:85.590, train f1:84.663, train precision:85.987, train recall:84.898, train kappa:85.045
fold:1 epoch:45 step:11 train loss:0.479484, train acc:85.532, train f1:84.669, train precision:86.073, train recall:84.800, train kappa:84.971
fold:1 epoch:45        valid loss:0.663125, valid acc:83.238, valid f1:59.739, valid precision:56.597, valid recall:70.638, valid kappa:81.118
[1;31mTest score increased (83.229395 --> 83.237573).[0m
[83.23757335350767, 59.73869239654914, 56.59667032600364, 70.63815647323527, 81.11786351401216]
====================================================================================================
fold:1 epoch:46 step:0 train loss:0.466859, train acc:85.892, train f1:85.038, train precision:86.258, train recall:85.313, train kappa:85.344
fold:1 epoch:46 step:1 train loss:0.476027, train acc:85.559, train f1:84.582, train precision:85.984, train recall:84.850, train kappa:85.001
fold:1 epoch:46 step:2 train loss:0.475228, train acc:85.645, train f1:84.743, train precision:86.031, train recall:85.063, train kappa:85.104
fold:1 epoch:46 step:3 train loss:0.460474, train acc:86.060, train f1:85.114, train precision:86.330, train recall:85.382, train kappa:85.530
fold:1 epoch:46 step:4 train loss:0.468471, train acc:85.944, train f1:84.757, train precision:86.342, train recall:84.917, train kappa:85.397
fold:1 epoch:46 step:5 train loss:0.466305, train acc:85.901, train f1:85.087, train precision:86.547, train recall:85.220, train kappa:85.365
fold:1 epoch:46 step:6 train loss:0.474050, train acc:85.361, train f1:84.627, train precision:86.086, train recall:84.833, train kappa:84.794
fold:1 epoch:46 step:7 train loss:0.487900, train acc:85.104, train f1:84.260, train precision:85.843, train recall:84.361, train kappa:84.535
fold:1 epoch:46 step:8 train loss:0.485490, train acc:85.306, train f1:84.188, train precision:85.581, train recall:84.547, train kappa:84.730
fold:1 epoch:46 step:9 train loss:0.465435, train acc:85.901, train f1:84.890, train precision:86.118, train recall:85.187, train kappa:85.362
fold:1 epoch:46 step:10 train loss:0.469516, train acc:85.962, train f1:84.940, train precision:86.302, train recall:85.174, train kappa:85.434
fold:1 epoch:46 step:11 train loss:0.496156, train acc:85.040, train f1:84.340, train precision:85.727, train recall:84.661, train kappa:84.463
fold:1 epoch:46        valid loss:0.658839, valid acc:83.377, valid f1:60.074, valid precision:57.054, valid recall:70.588, valid kappa:81.270
[1;31mTest score increased (83.237573 --> 83.376613).[0m
[83.37661275482037, 60.07364185694166, 57.054468516838405, 70.5884732400982, 81.27023006705532]
====================================================================================================
fold:1 epoch:47 step:0 train loss:0.471873, train acc:85.645, train f1:84.704, train precision:86.102, train recall:84.853, train kappa:85.091
fold:1 epoch:47 step:1 train loss:0.458876, train acc:86.087, train f1:85.182, train precision:86.562, train recall:85.422, train kappa:85.568
fold:1 epoch:47 step:2 train loss:0.456213, train acc:86.032, train f1:85.151, train precision:86.678, train recall:85.337, train kappa:85.508
fold:1 epoch:47 step:3 train loss:0.462934, train acc:85.880, train f1:84.913, train precision:86.250, train recall:85.039, train kappa:85.344
fold:1 epoch:47 step:4 train loss:0.466584, train acc:85.696, train f1:84.862, train precision:86.465, train recall:84.915, train kappa:85.140
fold:1 epoch:47 step:5 train loss:0.462176, train acc:85.855, train f1:84.664, train precision:86.221, train recall:84.872, train kappa:85.311
fold:1 epoch:47 step:6 train loss:0.471453, train acc:85.733, train f1:84.706, train precision:86.431, train recall:84.876, train kappa:85.182
fold:1 epoch:47 step:7 train loss:0.470237, train acc:85.645, train f1:84.789, train precision:86.323, train recall:84.960, train kappa:85.087
fold:1 epoch:47 step:8 train loss:0.461293, train acc:85.992, train f1:85.153, train precision:86.308, train recall:85.384, train kappa:85.444
fold:1 epoch:47 step:9 train loss:0.475845, train acc:85.577, train f1:84.699, train precision:85.656, train recall:85.019, train kappa:85.020
fold:1 epoch:47 step:10 train loss:0.478438, train acc:85.492, train f1:84.768, train precision:85.795, train recall:85.079, train kappa:84.944
fold:1 epoch:47 step:11 train loss:0.473622, train acc:85.503, train f1:84.568, train precision:85.606, train recall:85.081, train kappa:84.927
fold:1 epoch:47        valid loss:0.660157, valid acc:83.481, valid f1:60.017, valid precision:56.910, valid recall:70.784, valid kappa:81.387
[1;31mTest score increased (83.376613 --> 83.480892).[0m
[83.4808923058049, 60.01735731064258, 56.910375416652656, 70.78366573285147, 81.38714234497253]
====================================================================================================
fold:1 epoch:48 step:0 train loss:0.459514, train acc:85.916, train f1:85.014, train precision:86.516, train recall:85.092, train kappa:85.376
fold:1 epoch:48 step:1 train loss:0.465728, train acc:85.800, train f1:84.877, train precision:86.636, train recall:85.079, train kappa:85.236
fold:1 epoch:48 step:2 train loss:0.470607, train acc:85.739, train f1:84.871, train precision:86.407, train recall:85.020, train kappa:85.183
fold:1 epoch:48 step:3 train loss:0.457636, train acc:86.130, train f1:85.421, train precision:87.116, train recall:85.402, train kappa:85.610
fold:1 epoch:48 step:4 train loss:0.461499, train acc:85.840, train f1:84.850, train precision:86.182, train recall:85.008, train kappa:85.294
fold:1 epoch:48 step:5 train loss:0.461397, train acc:86.145, train f1:85.221, train precision:86.335, train recall:85.576, train kappa:85.606
fold:1 epoch:48 step:6 train loss:0.459890, train acc:85.938, train f1:85.093, train precision:86.033, train recall:85.543, train kappa:85.410
fold:1 epoch:48 step:7 train loss:0.460067, train acc:86.075, train f1:85.191, train precision:86.363, train recall:85.439, train kappa:85.548
fold:1 epoch:48 step:8 train loss:0.467688, train acc:85.739, train f1:84.866, train precision:85.974, train recall:85.170, train kappa:85.194
fold:1 epoch:48 step:9 train loss:0.461321, train acc:86.069, train f1:85.103, train precision:86.462, train recall:85.427, train kappa:85.530
fold:1 epoch:48 step:10 train loss:0.468357, train acc:85.580, train f1:84.736, train precision:86.449, train recall:84.882, train kappa:85.035
fold:1 epoch:48 step:11 train loss:0.448422, train acc:86.478, train f1:85.679, train precision:87.274, train recall:85.945, train kappa:85.953
fold:1 epoch:48        valid loss:0.658842, valid acc:83.487, valid f1:60.012, valid precision:57.082, valid recall:70.543, valid kappa:81.396
[1;31mTest score increased (83.480892 --> 83.487026).[0m
[83.48702639703927, 60.01188562943736, 57.08235176647891, 70.54283834352499, 81.39575846309613]
====================================================================================================
fold:1 epoch:49 step:0 train loss:0.454960, train acc:86.160, train f1:85.362, train precision:86.901, train recall:85.375, train kappa:85.636
fold:1 epoch:49 step:1 train loss:0.445956, train acc:86.377, train f1:85.358, train precision:86.944, train recall:85.413, train kappa:85.857
fold:1 epoch:49 step:2 train loss:0.464799, train acc:85.962, train f1:85.238, train precision:86.596, train recall:85.298, train kappa:85.424
fold:1 epoch:49 step:3 train loss:0.460107, train acc:85.788, train f1:85.121, train precision:86.104, train recall:85.508, train kappa:85.245
fold:1 epoch:49 step:4 train loss:0.468140, train acc:85.580, train f1:84.823, train precision:85.947, train recall:85.109, train kappa:85.038
fold:1 epoch:49 step:5 train loss:0.462426, train acc:85.947, train f1:85.169, train precision:85.991, train recall:85.717, train kappa:85.408
fold:1 epoch:49 step:6 train loss:0.451783, train acc:85.913, train f1:84.942, train precision:86.008, train recall:85.185, train kappa:85.362
fold:1 epoch:49 step:7 train loss:0.461954, train acc:85.748, train f1:84.807, train precision:86.183, train recall:84.918, train kappa:85.202
fold:1 epoch:49 step:8 train loss:0.462489, train acc:86.069, train f1:85.189, train precision:86.734, train recall:85.366, train kappa:85.526
fold:1 epoch:49 step:9 train loss:0.451358, train acc:86.316, train f1:85.394, train precision:86.796, train recall:85.482, train kappa:85.793
fold:1 epoch:49 step:10 train loss:0.452517, train acc:86.359, train f1:85.397, train precision:86.787, train recall:85.542, train kappa:85.832
fold:1 epoch:49 step:11 train loss:0.450437, train acc:86.333, train f1:85.541, train precision:86.892, train recall:85.656, train kappa:85.822
fold:1 epoch:49        valid loss:0.658698, valid acc:83.479, valid f1:60.101, valid precision:57.101, valid recall:70.724, valid kappa:81.386
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.48702639703927, 60.01188562943736, 57.08235176647891, 70.54283834352499, 81.39575846309613]
====================================================================================================
fold:1 epoch:50 step:0 train loss:0.455433, train acc:86.130, train f1:85.110, train precision:86.583, train recall:85.302, train kappa:85.608
fold:1 epoch:50 step:1 train loss:0.456211, train acc:86.011, train f1:85.083, train precision:86.513, train recall:85.297, train kappa:85.479
fold:1 epoch:50 step:2 train loss:0.448775, train acc:86.395, train f1:85.210, train precision:86.527, train recall:85.513, train kappa:85.870
fold:1 epoch:50 step:3 train loss:0.452247, train acc:86.139, train f1:85.387, train precision:86.789, train recall:85.641, train kappa:85.604
fold:1 epoch:50 step:4 train loss:0.457599, train acc:85.959, train f1:85.114, train precision:86.379, train recall:85.435, train kappa:85.422
fold:1 epoch:50 step:5 train loss:0.458620, train acc:86.115, train f1:85.258, train precision:86.837, train recall:85.336, train kappa:85.578
fold:1 epoch:50 step:6 train loss:0.455408, train acc:86.139, train f1:85.233, train precision:86.540, train recall:85.479, train kappa:85.600
fold:1 epoch:50 step:7 train loss:0.455481, train acc:86.176, train f1:85.304, train precision:86.289, train recall:85.571, train kappa:85.652
fold:1 epoch:50 step:8 train loss:0.461280, train acc:85.999, train f1:85.189, train precision:86.516, train recall:85.338, train kappa:85.470
fold:1 epoch:50 step:9 train loss:0.450628, train acc:85.834, train f1:85.171, train precision:86.312, train recall:85.418, train kappa:85.294
fold:1 epoch:50 step:10 train loss:0.454334, train acc:86.218, train f1:85.363, train precision:86.449, train recall:85.641, train kappa:85.681
fold:1 epoch:50 step:11 train loss:0.482205, train acc:85.426, train f1:84.440, train precision:85.519, train recall:85.057, train kappa:84.869
fold:1 epoch:50        valid loss:0.655097, valid acc:83.616, valid f1:60.102, valid precision:57.292, valid recall:70.527, valid kappa:81.534
[1;31mTest score increased (83.487026 --> 83.615842).[0m
[83.61584231296133, 60.101979504201985, 57.29234663505056, 70.5268572730663, 81.53357580681853]
====================================================================================================
fold:1 epoch:51 step:0 train loss:0.451743, train acc:86.060, train f1:85.057, train precision:86.287, train recall:85.363, train kappa:85.526
fold:1 epoch:51 step:1 train loss:0.445523, train acc:86.377, train f1:85.264, train precision:86.976, train recall:85.546, train kappa:85.855
fold:1 epoch:51 step:2 train loss:0.453321, train acc:86.066, train f1:85.162, train precision:87.067, train recall:85.181, train kappa:85.526
fold:1 epoch:51 step:3 train loss:0.455259, train acc:85.989, train f1:85.119, train precision:86.680, train recall:85.212, train kappa:85.458
fold:1 epoch:51 step:4 train loss:0.441328, train acc:86.346, train f1:85.629, train precision:86.884, train recall:85.830, train kappa:85.828
fold:1 epoch:51 step:5 train loss:0.442680, train acc:86.554, train f1:85.565, train precision:86.521, train recall:85.966, train kappa:86.046
fold:1 epoch:51 step:6 train loss:0.452023, train acc:86.377, train f1:85.532, train precision:86.597, train recall:86.018, train kappa:85.846
fold:1 epoch:51 step:7 train loss:0.451494, train acc:86.246, train f1:85.552, train precision:86.444, train recall:85.967, train kappa:85.725
fold:1 epoch:51 step:8 train loss:0.452937, train acc:86.160, train f1:85.122, train precision:86.301, train recall:85.406, train kappa:85.629
fold:1 epoch:51 step:9 train loss:0.457179, train acc:86.160, train f1:85.225, train precision:86.781, train recall:85.408, train kappa:85.633
fold:1 epoch:51 step:10 train loss:0.455656, train acc:85.980, train f1:85.131, train precision:86.357, train recall:85.276, train kappa:85.433
fold:1 epoch:51 step:11 train loss:0.450971, train acc:85.764, train f1:85.363, train precision:87.258, train recall:85.404, train kappa:85.238
fold:1 epoch:51        valid loss:0.659503, valid acc:83.477, valid f1:60.355, valid precision:57.292, valid recall:70.718, valid kappa:81.388
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.61584231296133, 60.101979504201985, 57.29234663505056, 70.5268572730663, 81.53357580681853]
====================================================================================================
fold:1 epoch:52 step:0 train loss:0.444072, train acc:86.356, train f1:85.570, train precision:86.743, train recall:85.710, train kappa:85.829
fold:1 epoch:52 step:1 train loss:0.438939, train acc:86.603, train f1:85.820, train precision:86.805, train recall:86.070, train kappa:86.095
fold:1 epoch:52 step:2 train loss:0.445069, train acc:86.316, train f1:85.483, train precision:86.665, train recall:85.809, train kappa:85.791
fold:1 epoch:52 step:3 train loss:0.441863, train acc:86.603, train f1:85.677, train precision:86.891, train recall:86.069, train kappa:86.092
fold:1 epoch:52 step:4 train loss:0.456503, train acc:85.986, train f1:85.301, train precision:86.681, train recall:85.534, train kappa:85.453
fold:1 epoch:52 step:5 train loss:0.450239, train acc:85.968, train f1:85.068, train precision:86.697, train recall:85.162, train kappa:85.420
fold:1 epoch:52 step:6 train loss:0.456139, train acc:86.044, train f1:85.228, train precision:86.659, train recall:85.360, train kappa:85.505
fold:1 epoch:52 step:7 train loss:0.445250, train acc:86.481, train f1:85.492, train precision:86.815, train recall:85.756, train kappa:85.956
fold:1 epoch:52 step:8 train loss:0.448725, train acc:86.252, train f1:85.316, train precision:86.360, train recall:85.733, train kappa:85.738
fold:1 epoch:52 step:9 train loss:0.446028, train acc:86.484, train f1:85.647, train precision:86.547, train recall:85.974, train kappa:85.968
fold:1 epoch:52 step:10 train loss:0.447606, train acc:86.325, train f1:85.334, train precision:86.516, train recall:85.596, train kappa:85.812
fold:1 epoch:52 step:11 train loss:0.446308, train acc:86.102, train f1:85.009, train precision:86.437, train recall:85.251, train kappa:85.577
fold:1 epoch:52        valid loss:0.659898, valid acc:83.618, valid f1:60.056, valid precision:56.861, valid recall:70.580, valid kappa:81.534
[1;31mTest score increased (83.615842 --> 83.617887).[0m
[83.61788701003945, 60.055829533156455, 56.86109293856592, 70.5801074886142, 81.53446590863773]
====================================================================================================
fold:1 epoch:53 step:0 train loss:0.440521, train acc:86.395, train f1:85.484, train precision:86.973, train recall:85.644, train kappa:85.873
fold:1 epoch:53 step:1 train loss:0.442609, train acc:86.499, train f1:85.536, train precision:87.025, train recall:85.748, train kappa:85.970
fold:1 epoch:53 step:2 train loss:0.438913, train acc:86.526, train f1:85.804, train precision:87.244, train recall:86.077, train kappa:86.013
fold:1 epoch:53 step:3 train loss:0.439750, train acc:86.636, train f1:85.699, train precision:87.142, train recall:86.010, train kappa:86.130
fold:1 epoch:53 step:4 train loss:0.446736, train acc:86.578, train f1:85.463, train precision:86.725, train recall:85.724, train kappa:86.069
fold:1 epoch:53 step:5 train loss:0.453539, train acc:86.166, train f1:85.123, train precision:86.201, train recall:85.450, train kappa:85.636
fold:1 epoch:53 step:6 train loss:0.437490, train acc:86.679, train f1:85.856, train precision:87.113, train recall:85.999, train kappa:86.170
fold:1 epoch:53 step:7 train loss:0.446226, train acc:86.234, train f1:85.298, train precision:86.593, train recall:85.332, train kappa:85.705
fold:1 epoch:53 step:8 train loss:0.450725, train acc:86.105, train f1:85.242, train precision:86.487, train recall:85.500, train kappa:85.581
fold:1 epoch:53 step:9 train loss:0.447811, train acc:86.078, train f1:85.395, train precision:86.500, train recall:85.601, train kappa:85.543
fold:1 epoch:53 step:10 train loss:0.447231, train acc:86.310, train f1:85.548, train precision:86.439, train recall:85.916, train kappa:85.786
fold:1 epoch:53 step:11 train loss:0.448863, train acc:86.304, train f1:85.454, train precision:86.320, train recall:85.776, train kappa:85.775
fold:1 epoch:53        valid loss:0.656274, valid acc:83.647, valid f1:60.576, valid precision:57.436, valid recall:70.787, valid kappa:81.575
[1;31mTest score increased (83.617887 --> 83.646513).[0m
[83.64651276913325, 60.57582497276146, 57.4355184415002, 70.78651782481406, 81.57542050442375]
====================================================================================================
fold:1 epoch:54 step:0 train loss:0.434599, train acc:86.633, train f1:85.578, train precision:86.777, train recall:85.882, train kappa:86.130
fold:1 epoch:54 step:1 train loss:0.440010, train acc:86.511, train f1:85.743, train precision:86.874, train recall:86.197, train kappa:86.008
fold:1 epoch:54 step:2 train loss:0.442883, train acc:86.325, train f1:85.513, train precision:86.692, train recall:85.778, train kappa:85.804
fold:1 epoch:54 step:3 train loss:0.433841, train acc:86.600, train f1:85.602, train precision:86.874, train recall:85.762, train kappa:86.081
fold:1 epoch:54 step:4 train loss:0.437960, train acc:86.313, train f1:85.427, train precision:86.938, train recall:85.514, train kappa:85.774
fold:1 epoch:54 step:5 train loss:0.442773, train acc:86.371, train f1:85.419, train precision:86.929, train recall:85.593, train kappa:85.835
fold:1 epoch:54 step:6 train loss:0.442143, train acc:86.523, train f1:85.735, train precision:87.048, train recall:85.844, train kappa:86.009
fold:1 epoch:54 step:7 train loss:0.429899, train acc:86.804, train f1:85.926, train precision:87.165, train recall:86.083, train kappa:86.288
fold:1 epoch:54 step:8 train loss:0.452800, train acc:85.980, train f1:85.480, train precision:86.962, train recall:85.656, train kappa:85.451
fold:1 epoch:54 step:9 train loss:0.433715, train acc:86.783, train f1:85.865, train precision:87.016, train recall:86.147, train kappa:86.282
fold:1 epoch:54 step:10 train loss:0.445210, train acc:86.374, train f1:85.426, train precision:86.421, train recall:85.861, train kappa:85.856
fold:1 epoch:54 step:11 train loss:0.459174, train acc:86.082, train f1:85.133, train precision:85.854, train recall:85.890, train kappa:85.587
fold:1 epoch:54        valid loss:0.657302, valid acc:83.739, valid f1:60.391, valid precision:57.350, valid recall:70.536, valid kappa:81.679
[1;31mTest score increased (83.646513 --> 83.738524).[0m
[83.73852413764901, 60.391097471243285, 57.349523604415275, 70.53594833888361, 81.67949198112524]
====================================================================================================
fold:1 epoch:55 step:0 train loss:0.437604, train acc:86.624, train f1:85.793, train precision:86.880, train recall:86.053, train kappa:86.110
fold:1 epoch:55 step:1 train loss:0.440346, train acc:86.627, train f1:85.822, train precision:86.894, train recall:86.093, train kappa:86.114
fold:1 epoch:55 step:2 train loss:0.441539, train acc:86.414, train f1:85.565, train precision:86.859, train recall:85.637, train kappa:85.883
fold:1 epoch:55 step:3 train loss:0.434239, train acc:86.563, train f1:85.537, train precision:87.081, train recall:85.567, train kappa:86.061
fold:1 epoch:55 step:4 train loss:0.440116, train acc:86.465, train f1:85.714, train precision:86.940, train recall:85.930, train kappa:85.949
fold:1 epoch:55 step:5 train loss:0.434733, train acc:86.453, train f1:85.703, train precision:86.789, train recall:85.930, train kappa:85.940
fold:1 epoch:55 step:6 train loss:0.437117, train acc:86.398, train f1:85.283, train precision:86.414, train recall:85.633, train kappa:85.882
fold:1 epoch:55 step:7 train loss:0.437211, train acc:86.691, train f1:85.919, train precision:87.215, train recall:86.229, train kappa:86.187
fold:1 epoch:55 step:8 train loss:0.428950, train acc:86.914, train f1:86.141, train precision:87.035, train recall:86.448, train kappa:86.408
fold:1 epoch:55 step:9 train loss:0.443615, train acc:86.481, train f1:85.791, train precision:86.891, train recall:85.975, train kappa:85.972
fold:1 epoch:55 step:10 train loss:0.426225, train acc:86.996, train f1:86.044, train precision:87.332, train recall:86.242, train kappa:86.493
fold:1 epoch:55 step:11 train loss:0.431213, train acc:86.710, train f1:85.567, train precision:86.934, train recall:85.853, train kappa:86.195
fold:1 epoch:55        valid loss:0.659958, valid acc:83.636, valid f1:60.308, valid precision:57.146, valid recall:70.526, valid kappa:81.563
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.73852413764901, 60.391097471243285, 57.349523604415275, 70.53594833888361, 81.67949198112524]
====================================================================================================
fold:1 epoch:56 step:0 train loss:0.429403, train acc:86.688, train f1:85.809, train precision:87.001, train recall:86.068, train kappa:86.176
fold:1 epoch:56 step:1 train loss:0.431953, train acc:86.853, train f1:86.205, train precision:87.563, train recall:86.432, train kappa:86.359
fold:1 epoch:56 step:2 train loss:0.424810, train acc:86.749, train f1:85.861, train precision:87.474, train recall:86.075, train kappa:86.258
fold:1 epoch:56 step:3 train loss:0.430165, train acc:86.804, train f1:85.780, train precision:86.904, train recall:85.939, train kappa:86.293
fold:1 epoch:56 step:4 train loss:0.429056, train acc:86.697, train f1:85.761, train precision:86.966, train recall:85.966, train kappa:86.181
fold:1 epoch:56 step:5 train loss:0.422071, train acc:87.036, train f1:86.367, train precision:87.551, train recall:86.592, train kappa:86.554
fold:1 epoch:56 step:6 train loss:0.432804, train acc:86.746, train f1:85.772, train precision:86.880, train recall:86.153, train kappa:86.242
fold:1 epoch:56 step:7 train loss:0.437091, train acc:86.670, train f1:86.042, train precision:87.062, train recall:86.276, train kappa:86.160
fold:1 epoch:56 step:8 train loss:0.439004, train acc:86.609, train f1:85.907, train precision:86.807, train recall:86.132, train kappa:86.096
fold:1 epoch:56 step:9 train loss:0.432369, train acc:86.670, train f1:85.845, train precision:86.734, train recall:86.159, train kappa:86.160
fold:1 epoch:56 step:10 train loss:0.430597, train acc:86.713, train f1:85.737, train precision:86.653, train recall:86.028, train kappa:86.198
fold:1 epoch:56 step:11 train loss:0.430914, train acc:86.816, train f1:86.506, train precision:88.078, train recall:86.424, train kappa:86.303
fold:1 epoch:56        valid loss:0.656889, valid acc:83.869, valid f1:60.753, valid precision:57.828, valid recall:70.709, valid kappa:81.819
[1;31mTest score increased (83.738524 --> 83.869385).[0m
[83.86938475064919, 60.75320074829848, 57.82777969058736, 70.70884983132277, 81.81862447106634]
====================================================================================================
fold:1 epoch:57 step:0 train loss:0.427954, train acc:86.755, train f1:85.959, train precision:87.066, train recall:86.253, train kappa:86.249
fold:1 epoch:57 step:1 train loss:0.432303, train acc:86.661, train f1:85.754, train precision:87.244, train recall:86.039, train kappa:86.144
fold:1 epoch:57 step:2 train loss:0.429502, train acc:86.777, train f1:85.887, train precision:87.163, train recall:86.246, train kappa:86.275
fold:1 epoch:57 step:3 train loss:0.430094, train acc:86.948, train f1:85.790, train precision:87.311, train recall:85.932, train kappa:86.448
fold:1 epoch:57 step:4 train loss:0.433667, train acc:86.743, train f1:85.915, train precision:87.275, train recall:86.076, train kappa:86.240
fold:1 epoch:57 step:5 train loss:0.422259, train acc:87.109, train f1:86.215, train precision:87.326, train recall:86.353, train kappa:86.625
fold:1 epoch:57 step:6 train loss:0.430823, train acc:86.606, train f1:85.702, train precision:86.574, train recall:86.119, train kappa:86.086
fold:1 epoch:57 step:7 train loss:0.433177, train acc:86.707, train f1:85.862, train precision:86.773, train recall:86.178, train kappa:86.190
fold:1 epoch:57 step:8 train loss:0.430547, train acc:86.905, train f1:86.107, train precision:87.107, train recall:86.373, train kappa:86.416
fold:1 epoch:57 step:9 train loss:0.429651, train acc:86.877, train f1:86.087, train precision:86.950, train recall:86.393, train kappa:86.366
fold:1 epoch:57 step:10 train loss:0.441277, train acc:86.356, train f1:85.800, train precision:86.898, train recall:86.135, train kappa:85.850
fold:1 epoch:57 step:11 train loss:0.430099, train acc:86.565, train f1:85.735, train precision:87.462, train recall:85.982, train kappa:86.053
fold:1 epoch:57        valid loss:0.659544, valid acc:83.890, valid f1:60.734, valid precision:57.809, valid recall:70.582, valid kappa:81.841
[1;31mTest score increased (83.869385 --> 83.889832).[0m
[83.88983172143047, 60.73391385390211, 57.80940471732371, 70.58191996773454, 81.84116258883786]
====================================================================================================
fold:1 epoch:58 step:0 train loss:0.428088, train acc:86.813, train f1:85.905, train precision:87.167, train recall:86.294, train kappa:86.310
fold:1 epoch:58 step:1 train loss:0.433490, train acc:86.536, train f1:85.665, train precision:87.090, train recall:86.018, train kappa:86.025
fold:1 epoch:58 step:2 train loss:0.425999, train acc:86.890, train f1:86.025, train precision:87.221, train recall:86.302, train kappa:86.376
fold:1 epoch:58 step:3 train loss:0.422215, train acc:86.893, train f1:86.109, train precision:87.167, train recall:86.404, train kappa:86.389
fold:1 epoch:58 step:4 train loss:0.419521, train acc:87.216, train f1:86.558, train precision:87.765, train recall:86.681, train kappa:86.733
fold:1 epoch:58 step:5 train loss:0.428066, train acc:86.807, train f1:85.966, train precision:87.052, train recall:86.139, train kappa:86.305
fold:1 epoch:58 step:6 train loss:0.429260, train acc:86.740, train f1:85.907, train precision:87.002, train recall:86.117, train kappa:86.237
fold:1 epoch:58 step:7 train loss:0.422359, train acc:86.935, train f1:86.175, train precision:87.489, train recall:86.231, train kappa:86.430
fold:1 epoch:58 step:8 train loss:0.433969, train acc:86.630, train f1:85.870, train precision:87.012, train recall:86.115, train kappa:86.130
fold:1 epoch:58 step:9 train loss:0.424084, train acc:86.908, train f1:86.126, train precision:87.481, train recall:86.388, train kappa:86.413
fold:1 epoch:58 step:10 train loss:0.429911, train acc:86.880, train f1:85.976, train precision:87.126, train recall:86.187, train kappa:86.377
fold:1 epoch:58 step:11 train loss:0.424275, train acc:86.719, train f1:85.916, train precision:86.838, train recall:86.268, train kappa:86.210
fold:1 epoch:58        valid loss:0.654158, valid acc:84.119, valid f1:60.931, valid precision:57.936, valid recall:70.543, valid kappa:82.095
[1;31mTest score increased (83.889832 --> 84.118838).[0m
[84.11883779418079, 60.93144028409869, 57.93641129101218, 70.5430495273122, 82.09507759221813]
====================================================================================================
fold:1 epoch:59 step:0 train loss:0.422588, train acc:87.122, train f1:86.541, train precision:88.074, train recall:86.653, train kappa:86.633
fold:1 epoch:59 step:1 train loss:0.416233, train acc:87.082, train f1:86.292, train precision:87.489, train recall:86.595, train kappa:86.592
fold:1 epoch:59 step:2 train loss:0.419581, train acc:87.106, train f1:86.133, train precision:87.193, train recall:86.351, train kappa:86.611
fold:1 epoch:59 step:3 train loss:0.425085, train acc:86.990, train f1:86.190, train precision:87.117, train recall:86.379, train kappa:86.487
fold:1 epoch:59 step:4 train loss:0.418626, train acc:87.030, train f1:86.339, train precision:87.344, train recall:86.528, train kappa:86.539
fold:1 epoch:59 step:5 train loss:0.427803, train acc:86.639, train f1:85.783, train precision:86.801, train recall:86.098, train kappa:86.134
fold:1 epoch:59 step:6 train loss:0.424578, train acc:86.978, train f1:86.091, train precision:87.232, train recall:86.184, train kappa:86.483
fold:1 epoch:59 step:7 train loss:0.417097, train acc:86.963, train f1:86.009, train precision:87.306, train recall:86.117, train kappa:86.474
fold:1 epoch:59 step:8 train loss:0.420280, train acc:86.972, train f1:86.036, train precision:87.414, train recall:86.256, train kappa:86.465
fold:1 epoch:59 step:9 train loss:0.422417, train acc:87.100, train f1:86.202, train precision:87.679, train recall:86.506, train kappa:86.597
fold:1 epoch:59 step:10 train loss:0.428840, train acc:86.710, train f1:85.902, train precision:87.004, train recall:86.143, train kappa:86.211
fold:1 epoch:59 step:11 train loss:0.426895, train acc:86.845, train f1:85.496, train precision:86.337, train recall:85.914, train kappa:86.335
fold:1 epoch:59        valid loss:0.662100, valid acc:83.759, valid f1:60.591, valid precision:57.224, valid recall:70.789, valid kappa:81.704
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.11883779418079, 60.93144028409869, 57.93641129101218, 70.5430495273122, 82.09507759221813]
====================================================================================================
fold:1 epoch:60 step:0 train loss:0.418886, train acc:87.125, train f1:86.200, train precision:87.012, train recall:86.752, train kappa:86.632
fold:1 epoch:60 step:1 train loss:0.418851, train acc:86.978, train f1:86.072, train precision:86.894, train recall:86.432, train kappa:86.485
fold:1 epoch:60 step:2 train loss:0.423188, train acc:86.942, train f1:86.130, train precision:87.467, train recall:86.320, train kappa:86.437
fold:1 epoch:60 step:3 train loss:0.421337, train acc:86.871, train f1:86.139, train precision:87.717, train recall:86.136, train kappa:86.370
fold:1 epoch:60 step:4 train loss:0.412351, train acc:87.302, train f1:86.404, train precision:88.068, train recall:86.562, train kappa:86.810
fold:1 epoch:60 step:5 train loss:0.416435, train acc:87.033, train f1:86.195, train precision:87.433, train recall:86.360, train kappa:86.533
fold:1 epoch:60 step:6 train loss:0.418037, train acc:87.057, train f1:86.145, train precision:87.219, train recall:86.279, train kappa:86.563
fold:1 epoch:60 step:7 train loss:0.415312, train acc:87.198, train f1:86.322, train precision:87.160, train recall:86.673, train kappa:86.716
fold:1 epoch:60 step:8 train loss:0.423579, train acc:86.887, train f1:86.172, train precision:86.953, train recall:86.486, train kappa:86.400
fold:1 epoch:60 step:9 train loss:0.418150, train acc:86.993, train f1:86.180, train precision:87.106, train recall:86.567, train kappa:86.494
fold:1 epoch:60 step:10 train loss:0.422671, train acc:86.951, train f1:86.098, train precision:87.326, train recall:86.278, train kappa:86.451
fold:1 epoch:60 step:11 train loss:0.449317, train acc:85.976, train f1:85.182, train precision:86.157, train recall:85.625, train kappa:85.454
fold:1 epoch:60        valid loss:0.651492, valid acc:84.045, valid f1:60.823, valid precision:57.612, valid recall:70.546, valid kappa:82.016
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.11883779418079, 60.93144028409869, 57.93641129101218, 70.5430495273122, 82.09507759221813]
====================================================================================================
fold:1 epoch:61 step:0 train loss:0.407868, train acc:87.436, train f1:86.499, train precision:87.527, train recall:86.784, train kappa:86.947
fold:1 epoch:61 step:1 train loss:0.416215, train acc:87.009, train f1:86.270, train precision:87.450, train recall:86.547, train kappa:86.518
fold:1 epoch:61 step:2 train loss:0.406389, train acc:87.384, train f1:86.511, train precision:87.594, train recall:86.764, train kappa:86.908
fold:1 epoch:61 step:3 train loss:0.424659, train acc:86.896, train f1:86.182, train precision:87.374, train recall:86.400, train kappa:86.394
fold:1 epoch:61 step:4 train loss:0.411385, train acc:87.164, train f1:86.282, train precision:87.220, train recall:86.552, train kappa:86.679
fold:1 epoch:61 step:5 train loss:0.417891, train acc:87.067, train f1:86.374, train precision:87.436, train recall:86.567, train kappa:86.558
fold:1 epoch:61 step:6 train loss:0.425546, train acc:86.795, train f1:85.900, train precision:87.005, train recall:86.003, train kappa:86.288
fold:1 epoch:61 step:7 train loss:0.428200, train acc:86.682, train f1:86.070, train precision:87.171, train recall:86.182, train kappa:86.176
fold:1 epoch:61 step:8 train loss:0.423054, train acc:86.874, train f1:86.026, train precision:86.988, train recall:86.212, train kappa:86.379
fold:1 epoch:61 step:9 train loss:0.418439, train acc:87.045, train f1:86.190, train precision:87.267, train recall:86.374, train kappa:86.550
fold:1 epoch:61 step:10 train loss:0.410862, train acc:87.332, train f1:86.423, train precision:87.639, train recall:86.720, train kappa:86.855
fold:1 epoch:61 step:11 train loss:0.412754, train acc:87.540, train f1:86.446, train precision:87.532, train recall:86.818, train kappa:87.075
fold:1 epoch:61        valid loss:0.659071, valid acc:83.982, valid f1:60.917, valid precision:57.849, valid recall:70.870, valid kappa:81.950
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.11883779418079, 60.93144028409869, 57.93641129101218, 70.5430495273122, 82.09507759221813]
====================================================================================================
fold:1 epoch:62 step:0 train loss:0.416218, train acc:87.100, train f1:86.504, train precision:87.359, train recall:86.960, train kappa:86.618
fold:1 epoch:62 step:1 train loss:0.417768, train acc:86.920, train f1:86.094, train precision:87.221, train recall:86.372, train kappa:86.426
fold:1 epoch:62 step:2 train loss:0.412944, train acc:87.064, train f1:86.083, train precision:87.134, train recall:86.448, train kappa:86.574
fold:1 epoch:62 step:3 train loss:0.411779, train acc:87.103, train f1:86.357, train precision:87.519, train recall:86.477, train kappa:86.609
fold:1 epoch:62 step:4 train loss:0.413711, train acc:87.057, train f1:86.175, train precision:87.043, train recall:86.453, train kappa:86.554
fold:1 epoch:62 step:5 train loss:0.406670, train acc:87.329, train f1:86.691, train precision:88.004, train recall:86.716, train kappa:86.845
fold:1 epoch:62 step:6 train loss:0.411764, train acc:87.250, train f1:86.298, train precision:87.478, train recall:86.421, train kappa:86.760
fold:1 epoch:62 step:7 train loss:0.416483, train acc:87.082, train f1:86.406, train precision:87.258, train recall:86.742, train kappa:86.599
fold:1 epoch:62 step:8 train loss:0.411372, train acc:87.387, train f1:86.247, train precision:86.994, train recall:86.691, train kappa:86.897
fold:1 epoch:62 step:9 train loss:0.411354, train acc:87.210, train f1:86.315, train precision:87.203, train recall:86.684, train kappa:86.723
fold:1 epoch:62 step:10 train loss:0.411224, train acc:87.256, train f1:86.463, train precision:87.685, train recall:86.774, train kappa:86.778
fold:1 epoch:62 step:11 train loss:0.413326, train acc:87.163, train f1:86.163, train precision:87.167, train recall:86.412, train kappa:86.686
fold:1 epoch:62        valid loss:0.656692, valid acc:84.254, valid f1:61.217, valid precision:58.561, valid recall:70.476, valid kappa:82.236
[1;31mTest score increased (84.118838 --> 84.253788).[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:63 step:0 train loss:0.415453, train acc:87.247, train f1:86.373, train precision:88.064, train recall:86.480, train kappa:86.763
fold:1 epoch:63 step:1 train loss:0.409779, train acc:87.192, train f1:86.239, train precision:87.711, train recall:86.357, train kappa:86.699
fold:1 epoch:63 step:2 train loss:0.407088, train acc:87.262, train f1:86.589, train precision:87.763, train recall:86.623, train kappa:86.779
fold:1 epoch:63 step:3 train loss:0.410876, train acc:87.088, train f1:86.228, train precision:87.142, train recall:86.505, train kappa:86.596
fold:1 epoch:63 step:4 train loss:0.411993, train acc:87.216, train f1:86.417, train precision:87.512, train recall:86.721, train kappa:86.725
fold:1 epoch:63 step:5 train loss:0.412748, train acc:87.152, train f1:86.407, train precision:87.373, train recall:86.679, train kappa:86.664
fold:1 epoch:63 step:6 train loss:0.419549, train acc:86.972, train f1:86.503, train precision:87.499, train recall:86.817, train kappa:86.479
fold:1 epoch:63 step:7 train loss:0.405901, train acc:87.451, train f1:86.602, train precision:87.776, train recall:86.789, train kappa:86.976
fold:1 epoch:63 step:8 train loss:0.408064, train acc:87.289, train f1:86.557, train precision:87.474, train recall:86.789, train kappa:86.803
fold:1 epoch:63 step:9 train loss:0.404574, train acc:87.384, train f1:86.478, train precision:87.647, train recall:86.578, train kappa:86.898
fold:1 epoch:63 step:10 train loss:0.424467, train acc:86.780, train f1:85.810, train precision:86.919, train recall:86.073, train kappa:86.283
fold:1 epoch:63 step:11 train loss:0.410771, train acc:87.260, train f1:86.340, train precision:87.488, train recall:86.537, train kappa:86.763
fold:1 epoch:63        valid loss:0.651197, valid acc:84.172, valid f1:61.114, valid precision:58.118, valid recall:70.517, valid kappa:82.156
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:64 step:0 train loss:0.411546, train acc:87.338, train f1:86.543, train precision:87.814, train recall:86.740, train kappa:86.863
fold:1 epoch:64 step:1 train loss:0.410972, train acc:87.155, train f1:86.280, train precision:87.390, train recall:86.508, train kappa:86.666
fold:1 epoch:64 step:2 train loss:0.396310, train acc:87.653, train f1:86.626, train precision:87.685, train recall:86.939, train kappa:87.182
fold:1 epoch:64 step:3 train loss:0.403193, train acc:87.476, train f1:86.679, train precision:87.536, train recall:87.027, train kappa:86.995
fold:1 epoch:64 step:4 train loss:0.404338, train acc:87.244, train f1:86.443, train precision:87.439, train recall:86.683, train kappa:86.764
fold:1 epoch:64 step:5 train loss:0.404554, train acc:87.506, train f1:86.778, train precision:87.833, train recall:86.921, train kappa:87.035
fold:1 epoch:64 step:6 train loss:0.418231, train acc:87.024, train f1:86.265, train precision:87.384, train recall:86.572, train kappa:86.527
fold:1 epoch:64 step:7 train loss:0.416889, train acc:87.003, train f1:86.266, train precision:87.635, train recall:86.330, train kappa:86.509
fold:1 epoch:64 step:8 train loss:0.409813, train acc:87.115, train f1:86.333, train precision:87.563, train recall:86.428, train kappa:86.618
fold:1 epoch:64 step:9 train loss:0.414990, train acc:87.164, train f1:86.401, train precision:87.256, train recall:86.852, train kappa:86.676
fold:1 epoch:64 step:10 train loss:0.406587, train acc:87.277, train f1:86.400, train precision:86.955, train recall:86.799, train kappa:86.800
fold:1 epoch:64 step:11 train loss:0.399534, train acc:87.665, train f1:86.402, train precision:87.120, train recall:86.751, train kappa:87.179
fold:1 epoch:64        valid loss:0.655873, valid acc:84.119, valid f1:61.157, valid precision:57.980, valid recall:70.626, valid kappa:82.104
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:65 step:0 train loss:0.407878, train acc:87.253, train f1:86.158, train precision:87.291, train recall:86.243, train kappa:86.764
fold:1 epoch:65 step:1 train loss:0.415693, train acc:87.082, train f1:86.266, train precision:87.414, train recall:86.425, train kappa:86.585
fold:1 epoch:65 step:2 train loss:0.400231, train acc:87.500, train f1:86.606, train precision:87.946, train recall:86.767, train kappa:87.026
fold:1 epoch:65 step:3 train loss:0.405085, train acc:87.442, train f1:86.497, train precision:87.738, train recall:86.735, train kappa:86.967
fold:1 epoch:65 step:4 train loss:0.399327, train acc:87.576, train f1:86.685, train precision:87.810, train recall:86.945, train kappa:87.102
fold:1 epoch:65 step:5 train loss:0.403027, train acc:87.405, train f1:86.490, train precision:87.596, train recall:86.791, train kappa:86.925
fold:1 epoch:65 step:6 train loss:0.398122, train acc:87.659, train f1:86.885, train precision:87.832, train recall:87.129, train kappa:87.191
fold:1 epoch:65 step:7 train loss:0.411955, train acc:87.186, train f1:86.414, train precision:87.197, train recall:86.670, train kappa:86.704
fold:1 epoch:65 step:8 train loss:0.403141, train acc:87.402, train f1:86.555, train precision:87.349, train recall:86.815, train kappa:86.915
fold:1 epoch:65 step:9 train loss:0.404459, train acc:87.286, train f1:86.366, train precision:87.237, train recall:86.627, train kappa:86.809
fold:1 epoch:65 step:10 train loss:0.407245, train acc:87.259, train f1:86.620, train precision:87.386, train recall:86.941, train kappa:86.775
fold:1 epoch:65 step:11 train loss:0.398052, train acc:87.443, train f1:86.508, train precision:87.855, train recall:86.627, train kappa:86.954
fold:1 epoch:65        valid loss:0.658242, valid acc:84.182, valid f1:60.955, valid precision:57.846, valid recall:70.669, valid kappa:82.175
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:66 step:0 train loss:0.402149, train acc:87.476, train f1:86.571, train precision:87.574, train recall:86.941, train kappa:86.996
fold:1 epoch:66 step:1 train loss:0.390667, train acc:87.839, train f1:87.003, train precision:88.205, train recall:87.096, train kappa:87.372
fold:1 epoch:66 step:2 train loss:0.397475, train acc:87.552, train f1:86.690, train precision:87.724, train recall:87.161, train kappa:87.088
fold:1 epoch:66 step:3 train loss:0.402400, train acc:87.457, train f1:86.787, train precision:87.854, train recall:87.208, train kappa:86.989
fold:1 epoch:66 step:4 train loss:0.403244, train acc:87.372, train f1:86.571, train precision:87.337, train recall:86.893, train kappa:86.882
fold:1 epoch:66 step:5 train loss:0.403050, train acc:87.524, train f1:86.710, train precision:87.624, train recall:86.838, train kappa:87.042
fold:1 epoch:66 step:6 train loss:0.404813, train acc:87.454, train f1:86.627, train precision:87.616, train recall:86.818, train kappa:86.982
fold:1 epoch:66 step:7 train loss:0.396079, train acc:87.610, train f1:86.699, train precision:87.575, train recall:86.902, train kappa:87.150
fold:1 epoch:66 step:8 train loss:0.403708, train acc:87.280, train f1:86.478, train precision:87.609, train recall:86.577, train kappa:86.804
fold:1 epoch:66 step:9 train loss:0.408841, train acc:87.112, train f1:86.561, train precision:87.626, train recall:86.960, train kappa:86.614
fold:1 epoch:66 step:10 train loss:0.411543, train acc:87.253, train f1:86.522, train precision:87.736, train recall:86.886, train kappa:86.765
fold:1 epoch:66 step:11 train loss:0.411185, train acc:87.424, train f1:86.368, train precision:87.634, train recall:86.552, train kappa:86.936
fold:1 epoch:66        valid loss:0.661586, valid acc:84.025, valid f1:61.172, valid precision:58.095, valid recall:70.614, valid kappa:81.997
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:67 step:0 train loss:0.396615, train acc:87.503, train f1:86.530, train precision:87.397, train recall:87.044, train kappa:87.035
fold:1 epoch:67 step:1 train loss:0.402957, train acc:87.497, train f1:86.784, train precision:87.770, train recall:87.110, train kappa:87.022
fold:1 epoch:67 step:2 train loss:0.399800, train acc:87.555, train f1:86.844, train precision:88.063, train recall:87.018, train kappa:87.089
fold:1 epoch:67 step:3 train loss:0.396694, train acc:87.503, train f1:86.903, train precision:88.148, train recall:87.128, train kappa:87.029
fold:1 epoch:67 step:4 train loss:0.409058, train acc:87.213, train f1:86.372, train precision:87.467, train recall:86.589, train kappa:86.730
fold:1 epoch:67 step:5 train loss:0.400031, train acc:87.469, train f1:86.678, train precision:87.901, train recall:86.696, train kappa:86.984
fold:1 epoch:67 step:6 train loss:0.401189, train acc:87.595, train f1:86.813, train precision:87.690, train recall:87.025, train kappa:87.122
fold:1 epoch:67 step:7 train loss:0.400206, train acc:87.527, train f1:86.536, train precision:87.654, train recall:86.607, train kappa:87.049
fold:1 epoch:67 step:8 train loss:0.395602, train acc:87.601, train f1:86.727, train precision:87.903, train recall:86.765, train kappa:87.123
fold:1 epoch:67 step:9 train loss:0.410184, train acc:87.164, train f1:86.433, train precision:87.277, train recall:86.710, train kappa:86.667
fold:1 epoch:67 step:10 train loss:0.395322, train acc:87.555, train f1:86.698, train precision:87.734, train recall:86.986, train kappa:87.087
fold:1 epoch:67 step:11 train loss:0.411910, train acc:86.912, train f1:86.362, train precision:87.384, train recall:86.623, train kappa:86.417
fold:1 epoch:67        valid loss:0.652561, valid acc:84.197, valid f1:61.057, valid precision:58.023, valid recall:70.295, valid kappa:82.188
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:68 step:0 train loss:0.400627, train acc:87.540, train f1:86.770, train precision:87.702, train recall:87.112, train kappa:87.061
fold:1 epoch:68 step:1 train loss:0.395103, train acc:87.613, train f1:86.544, train precision:87.416, train recall:86.886, train kappa:87.139
fold:1 epoch:68 step:2 train loss:0.394707, train acc:87.619, train f1:86.710, train precision:87.578, train recall:87.067, train kappa:87.147
fold:1 epoch:68 step:3 train loss:0.392879, train acc:87.689, train f1:86.947, train precision:87.705, train recall:87.355, train kappa:87.225
fold:1 epoch:68 step:4 train loss:0.399529, train acc:87.619, train f1:86.814, train precision:87.663, train recall:87.216, train kappa:87.144
fold:1 epoch:68 step:5 train loss:0.398927, train acc:87.534, train f1:86.865, train precision:87.970, train recall:86.991, train kappa:87.064
fold:1 epoch:68 step:6 train loss:0.401264, train acc:87.540, train f1:86.821, train precision:87.861, train recall:86.905, train kappa:87.061
fold:1 epoch:68 step:7 train loss:0.392010, train acc:87.784, train f1:86.808, train precision:88.080, train recall:86.788, train kappa:87.329
fold:1 epoch:68 step:8 train loss:0.398744, train acc:87.375, train f1:86.597, train precision:87.806, train recall:86.639, train kappa:86.898
fold:1 epoch:68 step:9 train loss:0.402963, train acc:87.415, train f1:86.598, train precision:87.529, train recall:86.906, train kappa:86.939
fold:1 epoch:68 step:10 train loss:0.394154, train acc:87.564, train f1:86.693, train precision:87.331, train recall:87.176, train kappa:87.091
fold:1 epoch:68 step:11 train loss:0.400663, train acc:87.463, train f1:86.357, train precision:86.914, train recall:86.933, train kappa:86.992
fold:1 epoch:68        valid loss:0.662211, valid acc:84.131, valid f1:60.911, valid precision:57.744, valid recall:70.525, valid kappa:82.113
[1;31mEarlyStopping counter: 6 out of 50[0m
[84.25378780133724, 61.21748545337064, 58.56064894329946, 70.47576736944025, 82.23629893396478]
====================================================================================================
fold:1 epoch:69 step:0 train loss:0.382523, train acc:87.915, train f1:86.971, train precision:88.000, train recall:87.244, train kappa:87.465
fold:1 epoch:69 step:1 train loss:0.405928, train acc:87.305, train f1:86.446, train precision:87.656, train recall:86.699, train kappa:86.828
fold:1 epoch:69 step:2 train loss:0.398549, train acc:87.518, train f1:86.734, train precision:88.342, train recall:86.893, train kappa:87.044
fold:1 epoch:69 step:3 train loss:0.398102, train acc:87.650, train f1:86.862, train precision:87.967, train recall:87.073, train kappa:87.173
fold:1 epoch:69 step:4 train loss:0.396412, train acc:87.769, train f1:87.085, train precision:87.923, train recall:87.385, train kappa:87.309
fold:1 epoch:69 step:5 train loss:0.397910, train acc:87.469, train f1:86.631, train precision:87.442, train recall:86.905, train kappa:87.001
fold:1 epoch:69 step:6 train loss:0.401397, train acc:87.589, train f1:86.898, train precision:87.517, train recall:87.295, train kappa:87.125
fold:1 epoch:69 step:7 train loss:0.395180, train acc:87.671, train f1:86.981, train precision:87.664, train recall:87.315, train kappa:87.199
fold:1 epoch:69 step:8 train loss:0.385026, train acc:87.817, train f1:87.073, train precision:88.046, train recall:87.293, train kappa:87.351
fold:1 epoch:69 step:9 train loss:0.395420, train acc:87.720, train f1:86.834, train precision:88.021, train recall:87.072, train kappa:87.250
fold:1 epoch:69 step:10 train loss:0.405824, train acc:87.335, train f1:86.401, train precision:87.743, train recall:86.688, train kappa:86.840
fold:1 epoch:69 step:11 train loss:0.390432, train acc:87.858, train f1:87.091, train precision:88.430, train recall:87.399, train kappa:87.389
fold:1 epoch:69        valid loss:0.654900, valid acc:84.513, valid f1:61.452, valid precision:58.551, valid recall:70.362, valid kappa:82.540
[1;31mTest score increased (84.253788 --> 84.513464).[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:70 step:0 train loss:0.394219, train acc:87.802, train f1:87.045, train precision:88.469, train recall:87.246, train kappa:87.324
fold:1 epoch:70 step:1 train loss:0.390696, train acc:87.814, train f1:86.910, train precision:87.806, train recall:87.128, train kappa:87.355
fold:1 epoch:70 step:2 train loss:0.393057, train acc:87.741, train f1:87.020, train precision:87.973, train recall:87.174, train kappa:87.282
fold:1 epoch:70 step:3 train loss:0.391537, train acc:87.869, train f1:87.173, train precision:88.042, train recall:87.304, train kappa:87.412
fold:1 epoch:70 step:4 train loss:0.387873, train acc:87.881, train f1:87.081, train precision:87.739, train recall:87.342, train kappa:87.427
fold:1 epoch:70 step:5 train loss:0.398055, train acc:87.518, train f1:86.856, train precision:87.543, train recall:87.158, train kappa:87.041
fold:1 epoch:70 step:6 train loss:0.393791, train acc:87.537, train f1:86.437, train precision:87.356, train recall:86.698, train kappa:87.065
fold:1 epoch:70 step:7 train loss:0.389174, train acc:87.808, train f1:86.967, train precision:88.074, train recall:87.054, train kappa:87.336
fold:1 epoch:70 step:8 train loss:0.398398, train acc:87.576, train f1:86.747, train precision:87.941, train recall:86.927, train kappa:87.103
fold:1 epoch:70 step:9 train loss:0.400071, train acc:87.512, train f1:86.753, train precision:88.089, train recall:86.956, train kappa:87.033
fold:1 epoch:70 step:10 train loss:0.393156, train acc:87.662, train f1:86.875, train precision:87.657, train recall:87.289, train kappa:87.205
fold:1 epoch:70 step:11 train loss:0.404726, train acc:87.434, train f1:86.834, train precision:87.803, train recall:87.348, train kappa:86.963
fold:1 epoch:70        valid loss:0.659101, valid acc:84.258, valid f1:61.169, valid precision:57.993, valid recall:70.458, valid kappa:82.253
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:71 step:0 train loss:0.389201, train acc:87.662, train f1:86.752, train precision:87.738, train recall:86.995, train kappa:87.198
fold:1 epoch:71 step:1 train loss:0.390914, train acc:87.759, train f1:86.951, train precision:87.886, train recall:87.135, train kappa:87.282
fold:1 epoch:71 step:2 train loss:0.382347, train acc:87.924, train f1:87.061, train precision:88.146, train recall:87.240, train kappa:87.464
fold:1 epoch:71 step:3 train loss:0.390234, train acc:87.888, train f1:87.113, train precision:88.222, train recall:87.207, train kappa:87.437
fold:1 epoch:71 step:4 train loss:0.388096, train acc:87.820, train f1:87.050, train precision:88.106, train recall:87.132, train kappa:87.363
fold:1 epoch:71 step:5 train loss:0.397092, train acc:87.598, train f1:86.837, train precision:87.662, train recall:87.144, train kappa:87.133
fold:1 epoch:71 step:6 train loss:0.388437, train acc:87.714, train f1:87.062, train precision:87.788, train recall:87.353, train kappa:87.247
fold:1 epoch:71 step:7 train loss:0.386737, train acc:87.909, train f1:86.858, train precision:87.823, train recall:87.120, train kappa:87.449
fold:1 epoch:71 step:8 train loss:0.399444, train acc:87.555, train f1:86.851, train precision:87.550, train recall:87.256, train kappa:87.086
fold:1 epoch:71 step:9 train loss:0.387673, train acc:87.793, train f1:86.969, train precision:87.964, train recall:87.240, train kappa:87.320
fold:1 epoch:71 step:10 train loss:0.393666, train acc:87.610, train f1:86.862, train precision:87.994, train recall:87.086, train kappa:87.138
fold:1 epoch:71 step:11 train loss:0.394407, train acc:87.665, train f1:86.706, train precision:87.999, train recall:87.112, train kappa:87.185
fold:1 epoch:71        valid loss:0.659749, valid acc:84.430, valid f1:61.315, valid precision:58.304, valid recall:70.417, valid kappa:82.442
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:72 step:0 train loss:0.382528, train acc:87.952, train f1:87.073, train precision:88.156, train recall:87.336, train kappa:87.498
fold:1 epoch:72 step:1 train loss:0.393823, train acc:87.573, train f1:86.891, train precision:88.166, train recall:86.881, train kappa:87.099
fold:1 epoch:72 step:2 train loss:0.389269, train acc:87.793, train f1:86.974, train precision:88.181, train recall:86.974, train kappa:87.325
fold:1 epoch:72 step:3 train loss:0.381896, train acc:88.068, train f1:87.321, train precision:88.267, train recall:87.551, train kappa:87.611
fold:1 epoch:72 step:4 train loss:0.393605, train acc:87.479, train f1:86.793, train precision:87.617, train recall:87.031, train kappa:87.010
fold:1 epoch:72 step:5 train loss:0.382439, train acc:88.159, train f1:87.587, train precision:88.306, train recall:87.772, train kappa:87.719
fold:1 epoch:72 step:6 train loss:0.393593, train acc:87.534, train f1:86.939, train precision:87.610, train recall:87.347, train kappa:87.060
fold:1 epoch:72 step:7 train loss:0.384847, train acc:88.000, train f1:87.078, train precision:87.653, train recall:87.566, train kappa:87.552
fold:1 epoch:72 step:8 train loss:0.396100, train acc:87.659, train f1:86.947, train precision:87.740, train recall:87.259, train kappa:87.183
fold:1 epoch:72 step:9 train loss:0.385018, train acc:87.973, train f1:87.271, train precision:88.176, train recall:87.519, train kappa:87.512
fold:1 epoch:72 step:10 train loss:0.387179, train acc:87.811, train f1:87.004, train precision:88.436, train recall:87.113, train kappa:87.349
fold:1 epoch:72 step:11 train loss:0.395067, train acc:87.492, train f1:86.188, train precision:87.265, train recall:86.409, train kappa:87.002
fold:1 epoch:72        valid loss:0.660680, valid acc:84.374, valid f1:61.457, valid precision:58.488, valid recall:70.615, valid kappa:82.380
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:73 step:0 train loss:0.381258, train acc:87.872, train f1:87.093, train precision:88.130, train recall:87.230, train kappa:87.409
fold:1 epoch:73 step:1 train loss:0.379069, train acc:88.083, train f1:87.179, train precision:87.995, train recall:87.510, train kappa:87.622
fold:1 epoch:73 step:2 train loss:0.383894, train acc:87.912, train f1:87.264, train precision:87.853, train recall:87.674, train kappa:87.448
fold:1 epoch:73 step:3 train loss:0.393055, train acc:87.579, train f1:86.563, train precision:87.168, train recall:86.953, train kappa:87.109
fold:1 epoch:73 step:4 train loss:0.393146, train acc:87.595, train f1:87.072, train precision:87.864, train recall:87.381, train kappa:87.139
fold:1 epoch:73 step:5 train loss:0.395484, train acc:87.350, train f1:86.517, train precision:87.311, train recall:86.837, train kappa:86.872
fold:1 epoch:73 step:6 train loss:0.382409, train acc:88.025, train f1:87.058, train precision:88.075, train recall:87.328, train kappa:87.571
fold:1 epoch:73 step:7 train loss:0.389870, train acc:87.613, train f1:86.813, train precision:88.110, train recall:86.789, train kappa:87.137
fold:1 epoch:73 step:8 train loss:0.381269, train acc:87.875, train f1:87.139, train precision:88.268, train recall:87.207, train kappa:87.413
fold:1 epoch:73 step:9 train loss:0.389049, train acc:87.881, train f1:87.151, train precision:88.341, train recall:87.192, train kappa:87.426
fold:1 epoch:73 step:10 train loss:0.389564, train acc:87.744, train f1:87.081, train precision:87.814, train recall:87.367, train kappa:87.288
fold:1 epoch:73 step:11 train loss:0.386891, train acc:87.559, train f1:86.803, train precision:87.782, train recall:87.138, train kappa:87.089
fold:1 epoch:73        valid loss:0.656081, valid acc:84.462, valid f1:61.295, valid precision:58.259, valid recall:70.251, valid kappa:82.483
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:74 step:0 train loss:0.375725, train acc:88.162, train f1:87.327, train precision:88.076, train recall:87.750, train kappa:87.715
fold:1 epoch:74 step:1 train loss:0.383609, train acc:88.040, train f1:87.305, train precision:88.332, train recall:87.566, train kappa:87.599
fold:1 epoch:74 step:2 train loss:0.387049, train acc:87.946, train f1:87.246, train precision:88.152, train recall:87.599, train kappa:87.491
fold:1 epoch:74 step:3 train loss:0.380248, train acc:87.817, train f1:87.161, train precision:88.161, train recall:87.393, train kappa:87.351
fold:1 epoch:74 step:4 train loss:0.383987, train acc:88.000, train f1:86.953, train precision:87.921, train recall:87.126, train kappa:87.541
fold:1 epoch:74 step:5 train loss:0.383723, train acc:87.799, train f1:87.036, train precision:88.248, train recall:87.074, train kappa:87.331
fold:1 epoch:74 step:6 train loss:0.384686, train acc:87.836, train f1:87.025, train precision:87.823, train recall:87.200, train kappa:87.370
fold:1 epoch:74 step:7 train loss:0.379892, train acc:88.034, train f1:87.218, train precision:87.804, train recall:87.534, train kappa:87.578
fold:1 epoch:74 step:8 train loss:0.387569, train acc:88.110, train f1:87.510, train precision:88.172, train recall:87.796, train kappa:87.660
fold:1 epoch:74 step:9 train loss:0.385442, train acc:87.936, train f1:87.085, train precision:87.653, train recall:87.436, train kappa:87.484
fold:1 epoch:74 step:10 train loss:0.386002, train acc:87.714, train f1:86.972, train precision:87.902, train recall:87.250, train kappa:87.248
fold:1 epoch:74 step:11 train loss:0.376427, train acc:88.206, train f1:87.132, train precision:87.832, train recall:87.557, train kappa:87.760
fold:1 epoch:74        valid loss:0.659964, valid acc:84.387, valid f1:61.123, valid precision:58.185, valid recall:70.243, valid kappa:82.398
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.51346433025947, 61.45154016998637, 58.5507590996656, 70.36174138311948, 82.53978912475996]
====================================================================================================
fold:1 epoch:75 step:0 train loss:0.377686, train acc:88.345, train f1:87.420, train precision:88.487, train recall:87.772, train kappa:87.904
fold:1 epoch:75 step:1 train loss:0.384385, train acc:87.643, train f1:86.824, train precision:87.689, train recall:87.177, train kappa:87.171
fold:1 epoch:75 step:2 train loss:0.390032, train acc:87.787, train f1:86.898, train precision:87.731, train recall:87.185, train kappa:87.336
fold:1 epoch:75 step:3 train loss:0.382637, train acc:87.991, train f1:87.244, train precision:88.219, train recall:87.520, train kappa:87.526
fold:1 epoch:75 step:4 train loss:0.379254, train acc:88.181, train f1:87.216, train precision:88.214, train recall:87.441, train kappa:87.722
fold:1 epoch:75 step:5 train loss:0.372953, train acc:88.052, train f1:87.202, train precision:88.094, train recall:87.341, train kappa:87.602
fold:1 epoch:75 step:6 train loss:0.379042, train acc:88.013, train f1:87.443, train precision:88.391, train recall:87.588, train kappa:87.565
fold:1 epoch:75 step:7 train loss:0.392913, train acc:87.500, train f1:86.795, train precision:87.578, train recall:87.068, train kappa:87.022
fold:1 epoch:75 step:8 train loss:0.376986, train acc:88.254, train f1:87.490, train precision:88.426, train recall:87.614, train kappa:87.815
fold:1 epoch:75 step:9 train loss:0.391988, train acc:87.598, train f1:86.879, train precision:87.670, train recall:87.082, train kappa:87.130
fold:1 epoch:75 step:10 train loss:0.378324, train acc:88.303, train f1:87.496, train precision:88.325, train recall:87.706, train kappa:87.856
fold:1 epoch:75 step:11 train loss:0.387197, train acc:87.839, train f1:86.951, train precision:87.818, train recall:87.412, train kappa:87.382
fold:1 epoch:75        valid loss:0.658549, valid acc:84.655, valid f1:61.618, valid precision:58.622, valid recall:70.156, valid kappa:82.693
[1;31mTest score increased (84.513464 --> 84.654548).[0m
[84.6545484286503, 61.61767762009983, 58.622069854866645, 70.15637980908089, 82.69328260282722]
====================================================================================================
fold:1 epoch:76 step:0 train loss:0.373573, train acc:88.208, train f1:87.424, train precision:88.642, train recall:87.568, train kappa:87.758
fold:1 epoch:76 step:1 train loss:0.386798, train acc:87.936, train f1:87.236, train precision:88.655, train recall:87.303, train kappa:87.467
fold:1 epoch:76 step:2 train loss:0.380835, train acc:87.930, train f1:87.131, train precision:88.127, train recall:87.323, train kappa:87.475
fold:1 epoch:76 step:3 train loss:0.374223, train acc:88.150, train f1:87.425, train precision:88.189, train recall:87.723, train kappa:87.707
fold:1 epoch:76 step:4 train loss:0.378576, train acc:87.988, train f1:87.079, train precision:87.869, train recall:87.372, train kappa:87.526
fold:1 epoch:76 step:5 train loss:0.386576, train acc:87.888, train f1:87.367, train precision:88.110, train recall:87.757, train kappa:87.432
fold:1 epoch:76 step:6 train loss:0.380801, train acc:88.095, train f1:87.174, train precision:87.727, train recall:87.505, train kappa:87.653
fold:1 epoch:76 step:7 train loss:0.378154, train acc:88.190, train f1:87.334, train precision:88.244, train recall:87.483, train kappa:87.737
fold:1 epoch:76 step:8 train loss:0.387674, train acc:87.778, train f1:87.011, train precision:88.128, train recall:87.126, train kappa:87.319
fold:1 epoch:76 step:9 train loss:0.373093, train acc:88.150, train f1:87.232, train precision:88.350, train recall:87.351, train kappa:87.697
fold:1 epoch:76 step:10 train loss:0.388066, train acc:87.811, train f1:86.962, train precision:87.897, train recall:87.208, train kappa:87.353
fold:1 epoch:76 step:11 train loss:0.384979, train acc:87.723, train f1:87.007, train precision:87.863, train recall:87.425, train kappa:87.249
fold:1 epoch:76        valid loss:0.659016, valid acc:84.464, valid f1:61.317, valid precision:58.080, valid recall:70.408, valid kappa:82.491
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.6545484286503, 61.61767762009983, 58.622069854866645, 70.15637980908089, 82.69328260282722]
====================================================================================================
fold:1 epoch:77 step:0 train loss:0.368116, train acc:88.443, train f1:87.619, train precision:88.441, train recall:87.855, train kappa:88.004
fold:1 epoch:77 step:1 train loss:0.378586, train acc:87.997, train f1:87.228, train precision:87.894, train recall:87.546, train kappa:87.546
fold:1 epoch:77 step:2 train loss:0.377820, train acc:88.098, train f1:87.409, train precision:88.233, train recall:87.652, train kappa:87.656
fold:1 epoch:77 step:3 train loss:0.384544, train acc:87.714, train f1:86.946, train precision:87.799, train recall:87.221, train kappa:87.255
fold:1 epoch:77 step:4 train loss:0.371030, train acc:88.351, train f1:87.452, train precision:88.535, train recall:87.560, train kappa:87.913
fold:1 epoch:77 step:5 train loss:0.374890, train acc:88.144, train f1:87.457, train precision:88.551, train recall:87.561, train kappa:87.693
fold:1 epoch:77 step:6 train loss:0.378507, train acc:87.857, train f1:87.071, train precision:87.967, train recall:87.285, train kappa:87.394
fold:1 epoch:77 step:7 train loss:0.382963, train acc:87.967, train f1:87.225, train precision:87.953, train recall:87.707, train kappa:87.511
fold:1 epoch:77 step:8 train loss:0.382690, train acc:88.028, train f1:87.365, train precision:88.062, train recall:87.734, train kappa:87.561
fold:1 epoch:77 step:9 train loss:0.378227, train acc:88.052, train f1:87.182, train precision:88.081, train recall:87.532, train kappa:87.602
fold:1 epoch:77 step:10 train loss:0.376492, train acc:88.116, train f1:87.431, train precision:88.388, train recall:87.596, train kappa:87.660
fold:1 epoch:77 step:11 train loss:0.381211, train acc:87.945, train f1:87.274, train precision:88.499, train recall:87.292, train kappa:87.498
fold:1 epoch:77        valid loss:0.656004, valid acc:84.444, valid f1:61.227, valid precision:57.958, valid recall:70.405, valid kappa:82.468
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.6545484286503, 61.61767762009983, 58.622069854866645, 70.15637980908089, 82.69328260282722]
====================================================================================================
fold:1 epoch:78 step:0 train loss:0.375607, train acc:88.156, train f1:87.464, train precision:88.490, train recall:87.660, train kappa:87.704
fold:1 epoch:78 step:1 train loss:0.363099, train acc:88.528, train f1:87.843, train precision:88.835, train recall:87.827, train kappa:88.084
fold:1 epoch:78 step:2 train loss:0.380204, train acc:87.885, train f1:87.209, train precision:87.993, train recall:87.426, train kappa:87.429
fold:1 epoch:78 step:3 train loss:0.374076, train acc:88.135, train f1:87.459, train precision:88.326, train recall:87.720, train kappa:87.687
fold:1 epoch:78 step:4 train loss:0.380990, train acc:88.013, train f1:87.280, train precision:88.139, train recall:87.401, train kappa:87.565
fold:1 epoch:78 step:5 train loss:0.382809, train acc:87.811, train f1:86.984, train precision:87.824, train recall:87.240, train kappa:87.355
fold:1 epoch:78 step:6 train loss:0.373603, train acc:88.226, train f1:87.583, train precision:88.557, train recall:87.765, train kappa:87.777
fold:1 epoch:78 step:7 train loss:0.379036, train acc:88.077, train f1:87.121, train precision:87.879, train recall:87.449, train kappa:87.623
fold:1 epoch:78 step:8 train loss:0.380960, train acc:87.936, train f1:87.361, train precision:88.317, train recall:87.455, train kappa:87.475
fold:1 epoch:78 step:9 train loss:0.386381, train acc:87.955, train f1:87.067, train precision:87.723, train recall:87.351, train kappa:87.497
fold:1 epoch:78 step:10 train loss:0.376396, train acc:88.159, train f1:87.294, train precision:88.055, train recall:87.655, train kappa:87.711
fold:1 epoch:78 step:11 train loss:0.369393, train acc:88.486, train f1:87.662, train precision:88.657, train recall:87.856, train kappa:88.065
fold:1 epoch:78        valid loss:0.662758, valid acc:84.552, valid f1:61.650, valid precision:58.304, valid recall:70.569, valid kappa:82.586
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.6545484286503, 61.61767762009983, 58.622069854866645, 70.15637980908089, 82.69328260282722]
====================================================================================================
fold:1 epoch:79 step:0 train loss:0.371316, train acc:88.229, train f1:87.294, train precision:87.966, train recall:87.681, train kappa:87.785
fold:1 epoch:79 step:1 train loss:0.361967, train acc:88.742, train f1:87.782, train precision:88.598, train recall:88.093, train kappa:88.320
fold:1 epoch:79 step:2 train loss:0.372713, train acc:88.269, train f1:87.431, train precision:88.398, train recall:87.567, train kappa:87.813
fold:1 epoch:79 step:3 train loss:0.386064, train acc:87.750, train f1:86.851, train precision:88.029, train recall:87.013, train kappa:87.284
fold:1 epoch:79 step:4 train loss:0.370695, train acc:88.297, train f1:87.283, train precision:88.515, train recall:87.334, train kappa:87.857
fold:1 epoch:79 step:5 train loss:0.371193, train acc:88.168, train f1:87.317, train precision:88.256, train recall:87.566, train kappa:87.713
fold:1 epoch:79 step:6 train loss:0.372826, train acc:88.126, train f1:87.519, train precision:88.493, train recall:87.721, train kappa:87.688
fold:1 epoch:79 step:7 train loss:0.382775, train acc:87.805, train f1:87.120, train precision:88.080, train recall:87.328, train kappa:87.335
fold:1 epoch:79 step:8 train loss:0.377680, train acc:88.016, train f1:87.404, train precision:88.301, train recall:87.643, train kappa:87.568
fold:1 epoch:79 step:9 train loss:0.384935, train acc:87.949, train f1:87.203, train precision:87.650, train recall:87.594, train kappa:87.492
fold:1 epoch:79 step:10 train loss:0.372108, train acc:88.293, train f1:87.565, train precision:88.128, train recall:87.799, train kappa:87.854
fold:1 epoch:79 step:11 train loss:0.381914, train acc:88.013, train f1:87.330, train precision:88.390, train recall:87.518, train kappa:87.561
fold:1 epoch:79        valid loss:0.658900, valid acc:84.702, valid f1:61.410, valid precision:58.348, valid recall:69.899, valid kappa:82.747
[1;31mTest score increased (84.654548 --> 84.701576).[0m
[84.70157646144723, 61.4104161434983, 58.348010657727514, 69.89876113139296, 82.74734061090804]
====================================================================================================
fold:1 epoch:80 step:0 train loss:0.366947, train acc:88.275, train f1:87.489, train precision:88.461, train recall:87.694, train kappa:87.827
fold:1 epoch:80 step:1 train loss:0.364827, train acc:88.364, train f1:87.454, train precision:88.566, train recall:87.517, train kappa:87.926
fold:1 epoch:80 step:2 train loss:0.377058, train acc:88.101, train f1:87.446, train precision:88.278, train recall:87.675, train kappa:87.652
fold:1 epoch:80 step:3 train loss:0.377187, train acc:88.058, train f1:87.313, train precision:88.199, train recall:87.619, train kappa:87.604
fold:1 epoch:80 step:4 train loss:0.367633, train acc:88.403, train f1:87.324, train precision:88.050, train recall:87.703, train kappa:87.956
fold:1 epoch:80 step:5 train loss:0.374322, train acc:88.181, train f1:87.508, train precision:88.288, train recall:87.781, train kappa:87.743
fold:1 epoch:80 step:6 train loss:0.377955, train acc:88.138, train f1:87.339, train precision:88.058, train recall:87.616, train kappa:87.694
fold:1 epoch:80 step:7 train loss:0.368853, train acc:88.290, train f1:87.413, train precision:88.163, train recall:87.674, train kappa:87.852
fold:1 epoch:80 step:8 train loss:0.379791, train acc:88.049, train f1:87.199, train precision:88.104, train recall:87.408, train kappa:87.592
fold:1 epoch:80 step:9 train loss:0.372892, train acc:88.266, train f1:87.480, train precision:88.228, train recall:87.762, train kappa:87.812
fold:1 epoch:80 step:10 train loss:0.374331, train acc:88.068, train f1:87.177, train precision:88.090, train recall:87.363, train kappa:87.611
fold:1 epoch:80 step:11 train loss:0.376071, train acc:87.810, train f1:87.251, train precision:88.122, train recall:87.746, train kappa:87.371
fold:1 epoch:80        valid loss:0.661723, valid acc:84.544, valid f1:61.684, valid precision:58.369, valid recall:70.246, valid kappa:82.573
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.70157646144723, 61.4104161434983, 58.348010657727514, 69.89876113139296, 82.74734061090804]
====================================================================================================
fold:1 epoch:81 step:0 train loss:0.366108, train acc:88.470, train f1:87.524, train precision:88.266, train recall:87.669, train kappa:88.036
fold:1 epoch:81 step:1 train loss:0.363501, train acc:88.617, train f1:87.749, train precision:88.391, train recall:87.957, train kappa:88.179
fold:1 epoch:81 step:2 train loss:0.374775, train acc:88.089, train f1:87.344, train precision:88.273, train recall:87.349, train kappa:87.640
fold:1 epoch:81 step:3 train loss:0.368783, train acc:88.251, train f1:87.383, train precision:88.116, train recall:87.722, train kappa:87.806
fold:1 epoch:81 step:4 train loss:0.370398, train acc:88.312, train f1:87.410, train precision:88.298, train recall:87.566, train kappa:87.864
fold:1 epoch:81 step:5 train loss:0.372723, train acc:88.220, train f1:87.538, train precision:88.398, train recall:87.786, train kappa:87.779
fold:1 epoch:81 step:6 train loss:0.375610, train acc:88.272, train f1:87.514, train precision:88.646, train recall:87.631, train kappa:87.836
fold:1 epoch:81 step:7 train loss:0.358492, train acc:88.620, train f1:87.995, train precision:88.888, train recall:88.270, train kappa:88.189
fold:1 epoch:81 step:8 train loss:0.365906, train acc:88.336, train f1:87.759, train precision:88.741, train recall:87.905, train kappa:87.898
fold:1 epoch:81 step:9 train loss:0.376026, train acc:88.174, train f1:87.461, train precision:87.985, train recall:87.928, train kappa:87.735
fold:1 epoch:81 step:10 train loss:0.377175, train acc:88.058, train f1:87.419, train precision:87.970, train recall:87.722, train kappa:87.597
fold:1 epoch:81 step:11 train loss:0.372835, train acc:88.611, train f1:87.713, train precision:88.461, train recall:88.035, train kappa:88.164
fold:1 epoch:81        valid loss:0.657700, valid acc:84.700, valid f1:61.763, valid precision:58.799, valid recall:70.403, valid kappa:82.748
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.70157646144723, 61.4104161434983, 58.348010657727514, 69.89876113139296, 82.74734061090804]
====================================================================================================
fold:1 epoch:82 step:0 train loss:0.368210, train acc:88.040, train f1:87.347, train precision:88.157, train recall:87.604, train kappa:87.583
fold:1 epoch:82 step:1 train loss:0.374779, train acc:88.120, train f1:87.379, train precision:88.261, train recall:87.550, train kappa:87.670
fold:1 epoch:82 step:2 train loss:0.373251, train acc:88.248, train f1:87.362, train precision:88.604, train recall:87.470, train kappa:87.806
fold:1 epoch:82 step:3 train loss:0.368355, train acc:88.251, train f1:87.411, train precision:88.086, train recall:87.705, train kappa:87.800
fold:1 epoch:82 step:4 train loss:0.365308, train acc:88.556, train f1:87.593, train precision:88.477, train recall:87.863, train kappa:88.120
fold:1 epoch:82 step:5 train loss:0.371367, train acc:88.239, train f1:87.434, train precision:88.249, train recall:87.666, train kappa:87.806
fold:1 epoch:82 step:6 train loss:0.366344, train acc:88.422, train f1:87.837, train precision:88.570, train recall:88.072, train kappa:87.985
fold:1 epoch:82 step:7 train loss:0.369998, train acc:88.260, train f1:87.482, train precision:88.145, train recall:87.720, train kappa:87.814
fold:1 epoch:82 step:8 train loss:0.365216, train acc:88.510, train f1:87.682, train precision:88.335, train recall:88.012, train kappa:88.069
fold:1 epoch:82 step:9 train loss:0.366145, train acc:88.492, train f1:87.928, train precision:88.770, train recall:88.103, train kappa:88.052
fold:1 epoch:82 step:10 train loss:0.371444, train acc:88.379, train f1:87.543, train precision:88.600, train recall:87.670, train kappa:87.945
fold:1 epoch:82 step:11 train loss:0.371794, train acc:88.071, train f1:87.489, train precision:88.578, train recall:87.811, train kappa:87.619
fold:1 epoch:82        valid loss:0.661420, valid acc:84.802, valid f1:61.931, valid precision:58.944, valid recall:70.304, valid kappa:82.858
[1;31mTest score increased (84.701576 --> 84.801767).[0m
[84.8017666182755, 61.93092728478412, 58.944198912173675, 70.30405939999828, 82.85806647823154]
====================================================================================================
fold:1 epoch:83 step:0 train loss:0.365253, train acc:88.403, train f1:87.559, train precision:88.511, train recall:87.784, train kappa:87.965
fold:1 epoch:83 step:1 train loss:0.359414, train acc:88.605, train f1:87.655, train precision:88.799, train recall:87.691, train kappa:88.161
fold:1 epoch:83 step:2 train loss:0.374468, train acc:88.171, train f1:87.455, train precision:88.134, train recall:87.755, train kappa:87.716
fold:1 epoch:83 step:3 train loss:0.365941, train acc:88.477, train f1:87.757, train precision:88.521, train recall:87.994, train kappa:88.047
fold:1 epoch:83 step:4 train loss:0.365774, train acc:88.422, train f1:87.786, train precision:88.627, train recall:87.987, train kappa:87.985
fold:1 epoch:83 step:5 train loss:0.375173, train acc:88.220, train f1:87.454, train precision:88.085, train recall:87.754, train kappa:87.780
fold:1 epoch:83 step:6 train loss:0.373987, train acc:88.162, train f1:87.369, train precision:88.282, train recall:87.626, train kappa:87.719
fold:1 epoch:83 step:7 train loss:0.359760, train acc:88.504, train f1:87.767, train precision:88.487, train recall:87.966, train kappa:88.068
fold:1 epoch:83 step:8 train loss:0.360429, train acc:88.437, train f1:87.562, train precision:88.378, train recall:87.780, train kappa:87.994
fold:1 epoch:83 step:9 train loss:0.371305, train acc:88.235, train f1:87.470, train precision:88.379, train recall:87.500, train kappa:87.790
fold:1 epoch:83 step:10 train loss:0.368478, train acc:88.104, train f1:87.398, train precision:88.300, train recall:87.430, train kappa:87.655
fold:1 epoch:83 step:11 train loss:0.364986, train acc:88.177, train f1:87.476, train precision:88.229, train recall:87.836, train kappa:87.741
fold:1 epoch:83        valid loss:0.661690, valid acc:84.755, valid f1:61.958, valid precision:58.830, valid recall:70.541, valid kappa:82.810
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.8017666182755, 61.93092728478412, 58.944198912173675, 70.30405939999828, 82.85806647823154]
====================================================================================================
fold:1 epoch:84 step:0 train loss:0.356124, train acc:88.806, train f1:88.097, train precision:88.568, train recall:88.564, train kappa:88.388
fold:1 epoch:84 step:1 train loss:0.369781, train acc:88.260, train f1:87.495, train precision:88.044, train recall:87.984, train kappa:87.826
fold:1 epoch:84 step:2 train loss:0.361749, train acc:88.379, train f1:87.511, train precision:88.324, train recall:87.810, train kappa:87.934
fold:1 epoch:84 step:3 train loss:0.365410, train acc:88.242, train f1:87.377, train precision:88.132, train recall:87.666, train kappa:87.792
fold:1 epoch:84 step:4 train loss:0.370043, train acc:88.293, train f1:87.528, train precision:88.275, train recall:87.876, train kappa:87.852
fold:1 epoch:84 step:5 train loss:0.360087, train acc:88.629, train f1:87.667, train precision:88.579, train recall:87.926, train kappa:88.199
fold:1 epoch:84 step:6 train loss:0.366249, train acc:88.416, train f1:87.624, train precision:88.532, train recall:87.712, train kappa:87.966
fold:1 epoch:84 step:7 train loss:0.368757, train acc:88.004, train f1:87.458, train precision:88.219, train recall:87.579, train kappa:87.552
fold:1 epoch:84 step:8 train loss:0.368432, train acc:88.162, train f1:87.483, train precision:88.184, train recall:87.619, train kappa:87.708
fold:1 epoch:84 step:9 train loss:0.366429, train acc:88.443, train f1:87.611, train precision:88.253, train recall:87.893, train kappa:88.003
fold:1 epoch:84 step:10 train loss:0.372220, train acc:88.162, train f1:87.637, train precision:88.480, train recall:87.750, train kappa:87.725
fold:1 epoch:84 step:11 train loss:0.362557, train acc:88.331, train f1:87.492, train precision:88.445, train recall:87.814, train kappa:87.912
fold:1 epoch:84        valid loss:0.663179, valid acc:84.528, valid f1:61.633, valid precision:58.355, valid recall:70.593, valid kappa:82.565
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.8017666182755, 61.93092728478412, 58.944198912173675, 70.30405939999828, 82.85806647823154]
====================================================================================================
fold:1 epoch:85 step:0 train loss:0.363109, train acc:88.364, train f1:87.621, train precision:88.199, train recall:88.000, train kappa:87.925
fold:1 epoch:85 step:1 train loss:0.361782, train acc:88.446, train f1:87.720, train precision:88.193, train recall:88.158, train kappa:88.003
fold:1 epoch:85 step:2 train loss:0.360325, train acc:88.516, train f1:87.620, train precision:88.386, train recall:87.942, train kappa:88.074
fold:1 epoch:85 step:3 train loss:0.356725, train acc:88.568, train f1:87.793, train precision:88.955, train recall:87.913, train kappa:88.131
fold:1 epoch:85 step:4 train loss:0.364753, train acc:88.370, train f1:87.356, train precision:88.728, train recall:87.469, train kappa:87.930
fold:1 epoch:85 step:5 train loss:0.372941, train acc:88.062, train f1:87.304, train precision:88.469, train recall:87.411, train kappa:87.612
fold:1 epoch:85 step:6 train loss:0.359833, train acc:88.297, train f1:87.581, train precision:88.592, train recall:87.780, train kappa:87.854
fold:1 epoch:85 step:7 train loss:0.364947, train acc:88.477, train f1:87.442, train precision:88.170, train recall:87.745, train kappa:88.037
fold:1 epoch:85 step:8 train loss:0.366461, train acc:88.434, train f1:87.758, train precision:88.238, train recall:88.185, train kappa:88.005
fold:1 epoch:85 step:9 train loss:0.361900, train acc:88.455, train f1:87.597, train precision:87.908, train recall:88.005, train kappa:88.034
fold:1 epoch:85 step:10 train loss:0.365777, train acc:88.388, train f1:87.645, train precision:88.153, train recall:87.984, train kappa:87.949
fold:1 epoch:85 step:11 train loss:0.373853, train acc:87.791, train f1:87.376, train precision:87.813, train recall:87.847, train kappa:87.336
fold:1 epoch:85        valid loss:0.661749, valid acc:84.710, valid f1:61.316, valid precision:58.161, valid recall:70.061, valid kappa:82.759
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.8017666182755, 61.93092728478412, 58.944198912173675, 70.30405939999828, 82.85806647823154]
====================================================================================================
fold:1 epoch:86 step:0 train loss:0.363261, train acc:88.461, train f1:87.755, train precision:88.809, train recall:87.902, train kappa:88.032
fold:1 epoch:86 step:1 train loss:0.356436, train acc:88.541, train f1:87.746, train precision:88.875, train recall:87.820, train kappa:88.107
fold:1 epoch:86 step:2 train loss:0.360595, train acc:88.397, train f1:87.547, train precision:88.497, train recall:87.647, train kappa:87.959
fold:1 epoch:86 step:3 train loss:0.357351, train acc:88.733, train f1:87.873, train precision:88.780, train recall:87.981, train kappa:88.300
fold:1 epoch:86 step:4 train loss:0.357309, train acc:88.690, train f1:87.962, train precision:88.714, train recall:88.237, train kappa:88.262
fold:1 epoch:86 step:5 train loss:0.361405, train acc:88.406, train f1:87.606, train precision:88.145, train recall:88.056, train kappa:87.968
fold:1 epoch:86 step:6 train loss:0.370547, train acc:88.220, train f1:87.427, train precision:87.992, train recall:87.853, train kappa:87.774
fold:1 epoch:86 step:7 train loss:0.361324, train acc:88.513, train f1:87.865, train precision:88.658, train recall:88.189, train kappa:88.077
fold:1 epoch:86 step:8 train loss:0.358595, train acc:88.638, train f1:87.943, train precision:88.906, train recall:88.097, train kappa:88.207
fold:1 epoch:86 step:9 train loss:0.364564, train acc:88.406, train f1:87.712, train precision:88.864, train recall:87.847, train kappa:87.970
fold:1 epoch:86 step:10 train loss:0.362846, train acc:88.422, train f1:87.538, train precision:88.623, train recall:87.679, train kappa:87.986
fold:1 epoch:86 step:11 train loss:0.368626, train acc:88.380, train f1:87.346, train precision:88.210, train recall:87.625, train kappa:87.930
fold:1 epoch:86        valid loss:0.663209, valid acc:84.751, valid f1:62.068, valid precision:58.959, valid recall:70.296, valid kappa:82.809
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.8017666182755, 61.93092728478412, 58.944198912173675, 70.30405939999828, 82.85806647823154]
====================================================================================================
fold:1 epoch:87 step:0 train loss:0.353421, train acc:88.583, train f1:87.674, train precision:88.453, train recall:87.821, train kappa:88.156
fold:1 epoch:87 step:1 train loss:0.355543, train acc:88.794, train f1:88.032, train precision:88.500, train recall:88.459, train kappa:88.362
fold:1 epoch:87 step:2 train loss:0.354419, train acc:88.828, train f1:88.065, train precision:88.649, train recall:88.373, train kappa:88.418
fold:1 epoch:87 step:3 train loss:0.363137, train acc:88.361, train f1:87.597, train precision:88.101, train recall:87.975, train kappa:87.915
fold:1 epoch:87 step:4 train loss:0.361886, train acc:88.550, train f1:87.924, train precision:88.732, train recall:88.066, train kappa:88.119
fold:1 epoch:87 step:5 train loss:0.365318, train acc:88.351, train f1:87.568, train precision:88.401, train recall:87.781, train kappa:87.902
fold:1 epoch:87 step:6 train loss:0.358032, train acc:88.611, train f1:87.843, train precision:88.607, train recall:88.078, train kappa:88.178
fold:1 epoch:87 step:7 train loss:0.360846, train acc:88.397, train f1:87.564, train precision:88.632, train recall:87.635, train kappa:87.962
fold:1 epoch:87 step:8 train loss:0.350843, train acc:88.846, train f1:87.969, train precision:88.738, train recall:88.245, train kappa:88.423
fold:1 epoch:87 step:9 train loss:0.351593, train acc:88.861, train f1:88.065, train precision:88.917, train recall:88.268, train kappa:88.438
fold:1 epoch:87 step:10 train loss:0.367120, train acc:88.422, train f1:87.747, train precision:88.502, train recall:87.898, train kappa:87.988
fold:1 epoch:87 step:11 train loss:0.361514, train acc:88.312, train f1:87.521, train precision:88.246, train recall:87.894, train kappa:87.880
fold:1 epoch:87        valid loss:0.666677, valid acc:84.828, valid f1:61.806, valid precision:58.708, valid recall:70.117, valid kappa:82.890
[1;31mTest score increased (84.801767 --> 84.828348).[0m
[84.82834768029116, 61.80551346318908, 58.708140331217976, 70.11745152597717, 82.88968525951567]
====================================================================================================
fold:1 epoch:88 step:0 train loss:0.357694, train acc:88.559, train f1:87.748, train precision:88.368, train recall:87.988, train kappa:88.121
fold:1 epoch:88 step:1 train loss:0.351932, train acc:88.895, train f1:88.131, train precision:88.984, train recall:88.326, train kappa:88.480
fold:1 epoch:88 step:2 train loss:0.350401, train acc:88.928, train f1:88.097, train precision:89.086, train recall:88.189, train kappa:88.508
fold:1 epoch:88 step:3 train loss:0.359966, train acc:88.705, train f1:87.907, train precision:88.784, train recall:88.186, train kappa:88.276
fold:1 epoch:88 step:4 train loss:0.364881, train acc:88.437, train f1:87.642, train precision:88.473, train recall:87.943, train kappa:87.996
fold:1 epoch:88 step:5 train loss:0.359141, train acc:88.577, train f1:87.860, train precision:88.714, train recall:88.077, train kappa:88.146
fold:1 epoch:88 step:6 train loss:0.357855, train acc:88.589, train f1:88.015, train precision:88.730, train recall:88.271, train kappa:88.170
fold:1 epoch:88 step:7 train loss:0.340804, train acc:89.017, train f1:88.116, train precision:88.772, train recall:88.363, train kappa:88.601
fold:1 epoch:88 step:8 train loss:0.362032, train acc:88.391, train f1:87.645, train precision:88.475, train recall:87.838, train kappa:87.953
fold:1 epoch:88 step:9 train loss:0.370795, train acc:88.275, train f1:87.425, train precision:88.121, train recall:87.699, train kappa:87.828
fold:1 epoch:88 step:10 train loss:0.361209, train acc:88.467, train f1:87.853, train precision:88.611, train recall:88.066, train kappa:88.038
fold:1 epoch:88 step:11 train loss:0.371201, train acc:88.254, train f1:87.724, train precision:88.473, train recall:88.041, train kappa:87.793
fold:1 epoch:88        valid loss:0.667912, valid acc:84.714, valid f1:61.449, valid precision:58.239, valid recall:70.123, valid kappa:82.767
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.82834768029116, 61.80551346318908, 58.708140331217976, 70.11745152597717, 82.88968525951567]
====================================================================================================
fold:1 epoch:89 step:0 train loss:0.351294, train acc:88.947, train f1:88.319, train precision:88.901, train recall:88.633, train kappa:88.530
fold:1 epoch:89 step:1 train loss:0.356139, train acc:88.681, train f1:88.011, train precision:88.972, train recall:88.056, train kappa:88.264
fold:1 epoch:89 step:2 train loss:0.351619, train acc:88.791, train f1:87.998, train precision:88.663, train recall:88.200, train kappa:88.377
fold:1 epoch:89 step:3 train loss:0.355720, train acc:88.531, train f1:87.863, train precision:88.493, train recall:88.107, train kappa:88.095
fold:1 epoch:89 step:4 train loss:0.357121, train acc:88.696, train f1:87.621, train precision:88.270, train recall:87.819, train kappa:88.252
fold:1 epoch:89 step:5 train loss:0.354190, train acc:88.531, train f1:87.726, train precision:88.367, train recall:88.020, train kappa:88.101
fold:1 epoch:89 step:6 train loss:0.355037, train acc:88.605, train f1:87.781, train precision:88.470, train recall:88.041, train kappa:88.173
fold:1 epoch:89 step:7 train loss:0.359156, train acc:88.687, train f1:87.993, train precision:88.919, train recall:88.209, train kappa:88.257
fold:1 epoch:89 step:8 train loss:0.365328, train acc:88.412, train f1:87.843, train precision:88.511, train recall:88.162, train kappa:87.978
fold:1 epoch:89 step:9 train loss:0.358236, train acc:88.391, train f1:87.583, train precision:88.112, train recall:87.990, train kappa:87.956
fold:1 epoch:89 step:10 train loss:0.356510, train acc:88.596, train f1:87.814, train precision:88.418, train recall:88.222, train kappa:88.159
fold:1 epoch:89 step:11 train loss:0.348293, train acc:88.901, train f1:87.834, train precision:88.649, train recall:88.115, train kappa:88.489
fold:1 epoch:89        valid loss:0.668726, valid acc:84.884, valid f1:61.985, valid precision:59.055, valid recall:70.010, valid kappa:82.949
[1;31mTest score increased (84.828348 --> 84.883555).[0m
[84.88355450140061, 61.98540912975727, 59.05515583300789, 70.01044689495451, 82.9492209320654]
====================================================================================================
fold:1 epoch:90 step:0 train loss:0.364293, train acc:88.293, train f1:87.666, train precision:88.299, train recall:87.956, train kappa:87.848
fold:1 epoch:90 step:1 train loss:0.352381, train acc:88.708, train f1:87.960, train precision:88.681, train recall:88.026, train kappa:88.282
fold:1 epoch:90 step:2 train loss:0.352597, train acc:88.611, train f1:87.970, train precision:88.738, train recall:88.147, train kappa:88.188
fold:1 epoch:90 step:3 train loss:0.354789, train acc:88.599, train f1:87.800, train precision:88.551, train recall:88.024, train kappa:88.176
fold:1 epoch:90 step:4 train loss:0.342779, train acc:89.008, train f1:88.360, train precision:89.231, train recall:88.510, train kappa:88.589
fold:1 epoch:90 step:5 train loss:0.355523, train acc:88.748, train f1:87.896, train precision:88.681, train recall:88.192, train kappa:88.316
fold:1 epoch:90 step:6 train loss:0.349951, train acc:88.831, train f1:87.990, train precision:88.676, train recall:88.191, train kappa:88.405
fold:1 epoch:90 step:7 train loss:0.367469, train acc:88.269, train f1:87.465, train precision:88.094, train recall:87.790, train kappa:87.828
fold:1 epoch:90 step:8 train loss:0.355898, train acc:88.608, train f1:87.956, train precision:88.497, train recall:88.377, train kappa:88.169
fold:1 epoch:90 step:9 train loss:0.352621, train acc:88.544, train f1:87.637, train precision:88.467, train recall:87.782, train kappa:88.118
fold:1 epoch:90 step:10 train loss:0.352281, train acc:88.800, train f1:88.178, train precision:89.279, train recall:88.206, train kappa:88.378
fold:1 epoch:90 step:11 train loss:0.364114, train acc:88.447, train f1:87.963, train precision:89.046, train recall:87.947, train kappa:88.004
fold:1 epoch:90        valid loss:0.666880, valid acc:84.847, valid f1:62.105, valid precision:59.376, valid recall:70.131, valid kappa:82.907
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.88355450140061, 61.98540912975727, 59.05515583300789, 70.01044689495451, 82.9492209320654]
====================================================================================================
fold:1 epoch:91 step:0 train loss:0.352510, train acc:88.654, train f1:87.850, train precision:88.698, train recall:88.066, train kappa:88.226
fold:1 epoch:91 step:1 train loss:0.347511, train acc:89.047, train f1:88.456, train precision:89.207, train recall:88.702, train kappa:88.643
fold:1 epoch:91 step:2 train loss:0.362974, train acc:88.342, train f1:87.631, train precision:87.859, train recall:88.118, train kappa:87.905
fold:1 epoch:91 step:3 train loss:0.357126, train acc:88.489, train f1:87.827, train precision:88.234, train recall:88.185, train kappa:88.059
fold:1 epoch:91 step:4 train loss:0.343505, train acc:88.937, train f1:88.194, train precision:88.750, train recall:88.397, train kappa:88.512
fold:1 epoch:91 step:5 train loss:0.352492, train acc:88.748, train f1:87.863, train precision:88.622, train recall:88.037, train kappa:88.318
fold:1 epoch:91 step:6 train loss:0.355350, train acc:88.644, train f1:88.008, train precision:89.165, train recall:88.021, train kappa:88.214
fold:1 epoch:91 step:7 train loss:0.362822, train acc:88.452, train f1:87.776, train precision:88.968, train recall:87.877, train kappa:88.018
fold:1 epoch:91 step:8 train loss:0.348699, train acc:88.824, train f1:87.984, train precision:88.898, train recall:88.226, train kappa:88.391
fold:1 epoch:91 step:9 train loss:0.362045, train acc:88.419, train f1:87.696, train precision:88.543, train recall:87.946, train kappa:87.986
fold:1 epoch:91 step:10 train loss:0.347505, train acc:88.766, train f1:87.804, train precision:88.466, train recall:88.037, train kappa:88.346
fold:1 epoch:91 step:11 train loss:0.353553, train acc:88.891, train f1:88.200, train precision:88.652, train recall:88.418, train kappa:88.467
fold:1 epoch:91        valid loss:0.671150, valid acc:84.818, valid f1:62.153, valid precision:59.217, valid recall:70.427, valid kappa:82.879
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.88355450140061, 61.98540912975727, 59.05515583300789, 70.01044689495451, 82.9492209320654]
====================================================================================================
fold:1 epoch:92 step:0 train loss:0.349393, train acc:88.800, train f1:87.993, train precision:88.509, train recall:88.219, train kappa:88.384
fold:1 epoch:92 step:1 train loss:0.347606, train acc:88.821, train f1:87.939, train precision:88.515, train recall:88.255, train kappa:88.407
fold:1 epoch:92 step:2 train loss:0.349928, train acc:88.904, train f1:87.949, train precision:89.028, train recall:88.141, train kappa:88.478
fold:1 epoch:92 step:3 train loss:0.344132, train acc:88.950, train f1:87.988, train precision:88.945, train recall:88.155, train kappa:88.519
fold:1 epoch:92 step:4 train loss:0.354296, train acc:88.556, train f1:87.665, train precision:88.856, train recall:87.769, train kappa:88.132
fold:1 epoch:92 step:5 train loss:0.346391, train acc:88.943, train f1:88.104, train precision:89.044, train recall:88.165, train kappa:88.512
fold:1 epoch:92 step:6 train loss:0.358474, train acc:88.791, train f1:88.039, train precision:88.675, train recall:88.372, train kappa:88.367
fold:1 epoch:92 step:7 train loss:0.358106, train acc:88.501, train f1:87.777, train precision:88.171, train recall:88.189, train kappa:88.066
fold:1 epoch:92 step:8 train loss:0.344839, train acc:88.791, train f1:88.115, train precision:88.461, train recall:88.514, train kappa:88.374
fold:1 epoch:92 step:9 train loss:0.355379, train acc:88.467, train f1:87.761, train precision:88.463, train recall:88.008, train kappa:88.036
fold:1 epoch:92 step:10 train loss:0.359430, train acc:88.544, train f1:87.987, train precision:88.526, train recall:88.326, train kappa:88.117
fold:1 epoch:92 step:11 train loss:0.350780, train acc:88.804, train f1:88.141, train precision:88.873, train recall:88.313, train kappa:88.379
fold:1 epoch:92        valid loss:0.665865, valid acc:84.953, valid f1:62.207, valid precision:59.207, valid recall:70.337, valid kappa:83.025
[1;31mTest score increased (84.883555 --> 84.953074).[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:93 step:0 train loss:0.347677, train acc:88.687, train f1:87.815, train precision:88.716, train recall:87.993, train kappa:88.250
fold:1 epoch:93 step:1 train loss:0.361129, train acc:88.492, train f1:87.834, train precision:88.683, train recall:88.091, train kappa:88.052
fold:1 epoch:93 step:2 train loss:0.349819, train acc:88.547, train f1:87.757, train precision:88.642, train recall:87.859, train kappa:88.113
fold:1 epoch:93 step:3 train loss:0.348392, train acc:88.913, train f1:88.183, train precision:88.679, train recall:88.482, train kappa:88.493
fold:1 epoch:93 step:4 train loss:0.347848, train acc:88.876, train f1:88.084, train precision:88.721, train recall:88.343, train kappa:88.459
fold:1 epoch:93 step:5 train loss:0.345547, train acc:88.855, train f1:88.091, train precision:88.667, train recall:88.366, train kappa:88.433
fold:1 epoch:93 step:6 train loss:0.358696, train acc:88.382, train f1:87.855, train precision:88.471, train recall:88.082, train kappa:87.943
fold:1 epoch:93 step:7 train loss:0.353048, train acc:88.760, train f1:88.145, train precision:88.761, train recall:88.399, train kappa:88.338
fold:1 epoch:93 step:8 train loss:0.345653, train acc:89.008, train f1:88.090, train precision:88.919, train recall:88.215, train kappa:88.599
fold:1 epoch:93 step:9 train loss:0.350728, train acc:88.669, train f1:87.863, train precision:88.324, train recall:88.208, train kappa:88.244
fold:1 epoch:93 step:10 train loss:0.357773, train acc:88.544, train f1:87.804, train precision:88.631, train recall:87.870, train kappa:88.117
fold:1 epoch:93 step:11 train loss:0.335750, train acc:89.171, train f1:88.786, train precision:89.726, train recall:88.847, train kappa:88.764
fold:1 epoch:93        valid loss:0.669848, valid acc:84.857, valid f1:61.944, valid precision:58.896, valid recall:70.204, valid kappa:82.919
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:94 step:0 train loss:0.348834, train acc:88.748, train f1:88.033, train precision:88.903, train recall:88.201, train kappa:88.323
fold:1 epoch:94 step:1 train loss:0.342586, train acc:88.852, train f1:88.109, train precision:88.793, train recall:88.400, train kappa:88.429
fold:1 epoch:94 step:2 train loss:0.349406, train acc:88.947, train f1:88.138, train precision:88.845, train recall:88.334, train kappa:88.523
fold:1 epoch:94 step:3 train loss:0.345625, train acc:88.940, train f1:88.182, train precision:88.853, train recall:88.474, train kappa:88.535
fold:1 epoch:94 step:4 train loss:0.353551, train acc:88.611, train f1:87.754, train precision:88.362, train recall:88.055, train kappa:88.180
fold:1 epoch:94 step:5 train loss:0.352040, train acc:88.641, train f1:88.014, train precision:88.843, train recall:88.235, train kappa:88.215
fold:1 epoch:94 step:6 train loss:0.351390, train acc:88.889, train f1:88.084, train precision:88.857, train recall:88.162, train kappa:88.471
fold:1 epoch:94 step:7 train loss:0.349688, train acc:88.550, train f1:87.760, train precision:88.606, train recall:87.837, train kappa:88.106
fold:1 epoch:94 step:8 train loss:0.355438, train acc:88.788, train f1:88.045, train precision:88.835, train recall:88.278, train kappa:88.355
fold:1 epoch:94 step:9 train loss:0.342558, train acc:88.901, train f1:88.023, train precision:88.896, train recall:88.111, train kappa:88.491
fold:1 epoch:94 step:10 train loss:0.351286, train acc:88.815, train f1:88.058, train precision:88.550, train recall:88.371, train kappa:88.394
fold:1 epoch:94 step:11 train loss:0.354573, train acc:88.823, train f1:87.690, train precision:88.118, train recall:88.123, train kappa:88.402
fold:1 epoch:94        valid loss:0.673862, valid acc:84.810, valid f1:61.797, valid precision:58.662, valid recall:69.978, valid kappa:82.869
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:95 step:0 train loss:0.342294, train acc:89.148, train f1:88.556, train precision:89.306, train recall:88.687, train kappa:88.749
fold:1 epoch:95 step:1 train loss:0.345891, train acc:88.776, train f1:87.855, train precision:88.620, train recall:88.159, train kappa:88.347
fold:1 epoch:95 step:2 train loss:0.347196, train acc:88.861, train f1:87.999, train precision:88.973, train recall:88.212, train kappa:88.442
fold:1 epoch:95 step:3 train loss:0.341973, train acc:88.858, train f1:88.199, train precision:88.924, train recall:88.527, train kappa:88.435
fold:1 epoch:95 step:4 train loss:0.348213, train acc:88.712, train f1:88.137, train precision:88.926, train recall:88.358, train kappa:88.280
fold:1 epoch:95 step:5 train loss:0.339119, train acc:89.175, train f1:88.376, train precision:89.067, train recall:88.588, train kappa:88.765
fold:1 epoch:95 step:6 train loss:0.351412, train acc:88.788, train f1:87.970, train precision:88.625, train recall:88.142, train kappa:88.367
fold:1 epoch:95 step:7 train loss:0.352490, train acc:88.577, train f1:87.973, train precision:88.546, train recall:88.194, train kappa:88.143
fold:1 epoch:95 step:8 train loss:0.350491, train acc:88.852, train f1:88.055, train precision:88.813, train recall:88.186, train kappa:88.435
fold:1 epoch:95 step:9 train loss:0.350269, train acc:88.779, train f1:88.104, train precision:88.682, train recall:88.340, train kappa:88.358
fold:1 epoch:95 step:10 train loss:0.354658, train acc:88.803, train f1:88.115, train precision:88.615, train recall:88.495, train kappa:88.383
fold:1 epoch:95 step:11 train loss:0.352574, train acc:88.109, train f1:87.627, train precision:88.505, train recall:87.700, train kappa:87.647
fold:1 epoch:95        valid loss:0.671154, valid acc:84.875, valid f1:61.921, valid precision:58.701, valid recall:70.093, valid kappa:82.943
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:96 step:0 train loss:0.343147, train acc:89.026, train f1:88.161, train precision:88.818, train recall:88.436, train kappa:88.621
fold:1 epoch:96 step:1 train loss:0.346586, train acc:88.898, train f1:88.050, train precision:88.774, train recall:88.361, train kappa:88.472
fold:1 epoch:96 step:2 train loss:0.346058, train acc:88.733, train f1:87.968, train precision:88.750, train recall:88.192, train kappa:88.314
fold:1 epoch:96 step:3 train loss:0.337793, train acc:88.962, train f1:88.279, train precision:88.897, train recall:88.465, train kappa:88.542
fold:1 epoch:96 step:4 train loss:0.347432, train acc:88.791, train f1:87.987, train precision:88.616, train recall:88.207, train kappa:88.382
fold:1 epoch:96 step:5 train loss:0.344531, train acc:88.989, train f1:88.095, train precision:88.775, train recall:88.329, train kappa:88.575
fold:1 epoch:96 step:6 train loss:0.353667, train acc:88.794, train f1:88.080, train precision:88.728, train recall:88.347, train kappa:88.359
fold:1 epoch:96 step:7 train loss:0.347993, train acc:88.840, train f1:88.166, train precision:88.782, train recall:88.365, train kappa:88.413
fold:1 epoch:96 step:8 train loss:0.349693, train acc:88.858, train f1:88.149, train precision:88.794, train recall:88.424, train kappa:88.443
fold:1 epoch:96 step:9 train loss:0.354297, train acc:88.580, train f1:87.947, train precision:88.581, train recall:88.119, train kappa:88.146
fold:1 epoch:96 step:10 train loss:0.344950, train acc:89.130, train f1:88.300, train precision:89.046, train recall:88.577, train kappa:88.716
fold:1 epoch:96 step:11 train loss:0.336955, train acc:89.248, train f1:88.324, train precision:89.128, train recall:88.639, train kappa:88.844
fold:1 epoch:96        valid loss:0.672797, valid acc:84.761, valid f1:61.870, valid precision:58.731, valid recall:70.179, valid kappa:82.819
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:97 step:0 train loss:0.343122, train acc:88.983, train f1:88.125, train precision:88.793, train recall:88.376, train kappa:88.574
fold:1 epoch:97 step:1 train loss:0.339286, train acc:89.188, train f1:88.476, train precision:89.076, train recall:88.727, train kappa:88.785
fold:1 epoch:97 step:2 train loss:0.341584, train acc:89.041, train f1:88.360, train precision:88.965, train recall:88.647, train kappa:88.619
fold:1 epoch:97 step:3 train loss:0.339464, train acc:89.053, train f1:88.026, train precision:88.752, train recall:88.268, train kappa:88.640
fold:1 epoch:97 step:4 train loss:0.344846, train acc:88.995, train f1:88.157, train precision:89.055, train recall:88.238, train kappa:88.574
fold:1 epoch:97 step:5 train loss:0.350292, train acc:88.657, train f1:87.984, train precision:88.776, train recall:88.059, train kappa:88.221
fold:1 epoch:97 step:6 train loss:0.341256, train acc:88.971, train f1:88.200, train precision:88.829, train recall:88.469, train kappa:88.552
fold:1 epoch:97 step:7 train loss:0.349504, train acc:88.651, train f1:87.974, train precision:88.808, train recall:88.206, train kappa:88.227
fold:1 epoch:97 step:8 train loss:0.343305, train acc:88.791, train f1:88.046, train precision:88.803, train recall:88.235, train kappa:88.374
fold:1 epoch:97 step:9 train loss:0.351973, train acc:88.693, train f1:87.958, train precision:88.781, train recall:88.093, train kappa:88.266
fold:1 epoch:97 step:10 train loss:0.348183, train acc:88.864, train f1:87.964, train precision:88.594, train recall:88.258, train kappa:88.450
fold:1 epoch:97 step:11 train loss:0.355278, train acc:88.331, train f1:87.595, train precision:88.018, train recall:88.169, train kappa:87.887
fold:1 epoch:97        valid loss:0.669755, valid acc:84.953, valid f1:61.962, valid precision:58.878, valid recall:70.118, valid kappa:83.032
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.95307420205697, 62.2069917045773, 59.206906599723666, 70.33688330085346, 83.02499165125803]
====================================================================================================
fold:1 epoch:98 step:0 train loss:0.340144, train acc:89.069, train f1:88.203, train precision:88.819, train recall:88.509, train kappa:88.658
fold:1 epoch:98 step:1 train loss:0.343990, train acc:88.980, train f1:88.359, train precision:88.919, train recall:88.657, train kappa:88.566
fold:1 epoch:98 step:2 train loss:0.333779, train acc:89.188, train f1:88.416, train precision:89.282, train recall:88.569, train kappa:88.787
fold:1 epoch:98 step:3 train loss:0.342398, train acc:89.096, train f1:88.233, train precision:89.033, train recall:88.376, train kappa:88.689
fold:1 epoch:98 step:4 train loss:0.343751, train acc:89.075, train f1:88.301, train precision:89.054, train recall:88.481, train kappa:88.661
fold:1 epoch:98 step:5 train loss:0.345669, train acc:88.806, train f1:88.182, train precision:89.029, train recall:88.328, train kappa:88.375
fold:1 epoch:98 step:6 train loss:0.346504, train acc:88.745, train f1:87.971, train precision:88.609, train recall:88.201, train kappa:88.311
fold:1 epoch:98 step:7 train loss:0.344038, train acc:88.901, train f1:88.063, train precision:88.574, train recall:88.322, train kappa:88.488
fold:1 epoch:98 step:8 train loss:0.337721, train acc:89.038, train f1:88.354, train precision:88.801, train recall:88.655, train kappa:88.635
fold:1 epoch:98 step:9 train loss:0.344916, train acc:89.066, train f1:88.187, train precision:88.877, train recall:88.567, train kappa:88.641
fold:1 epoch:98 step:10 train loss:0.350540, train acc:88.745, train f1:88.129, train precision:88.786, train recall:88.335, train kappa:88.328
fold:1 epoch:98 step:11 train loss:0.355859, train acc:88.775, train f1:87.927, train precision:88.640, train recall:88.162, train kappa:88.340
fold:1 epoch:98        valid loss:0.670388, valid acc:85.055, valid f1:62.444, valid precision:59.793, valid recall:69.935, valid kappa:83.136
[1;31mTest score increased (84.953074 --> 85.055309).[0m
[85.05530905596336, 62.44358433777797, 59.79330254581949, 69.93520648435702, 83.13641189203804]
====================================================================================================
fold:1 epoch:99 step:0 train loss:0.338611, train acc:88.907, train f1:88.101, train precision:89.177, train recall:88.129, train kappa:88.485
fold:1 epoch:99 step:1 train loss:0.339727, train acc:88.986, train f1:88.390, train precision:89.074, train recall:88.660, train kappa:88.573
fold:1 epoch:99 step:2 train loss:0.335153, train acc:89.090, train f1:88.497, train precision:89.259, train recall:88.581, train kappa:88.669
fold:1 epoch:99 step:3 train loss:0.342330, train acc:89.066, train f1:88.237, train precision:88.914, train recall:88.571, train kappa:88.652
fold:1 epoch:99 step:4 train loss:0.347548, train acc:88.870, train f1:88.236, train precision:88.779, train recall:88.546, train kappa:88.448
fold:1 epoch:99 step:5 train loss:0.340675, train acc:88.931, train f1:88.006, train precision:88.471, train recall:88.354, train kappa:88.514
fold:1 epoch:99 step:6 train loss:0.344604, train acc:88.904, train f1:88.215, train precision:88.954, train recall:88.407, train kappa:88.496
fold:1 epoch:99 step:7 train loss:0.349744, train acc:88.794, train f1:88.279, train precision:89.065, train recall:88.543, train kappa:88.370
fold:1 epoch:99 step:8 train loss:0.346321, train acc:88.702, train f1:87.764, train precision:88.669, train recall:87.928, train kappa:88.270
fold:1 epoch:99 step:9 train loss:0.340802, train acc:89.038, train f1:88.332, train precision:89.168, train recall:88.409, train kappa:88.629
fold:1 epoch:99 step:10 train loss:0.342817, train acc:89.078, train f1:87.974, train precision:88.549, train recall:88.329, train kappa:88.672
fold:1 epoch:99 step:11 train loss:0.333020, train acc:89.074, train f1:88.182, train precision:88.638, train recall:88.593, train kappa:88.659
fold:1 epoch:99        valid loss:0.672889, valid acc:84.941, valid f1:61.936, valid precision:58.875, valid recall:70.021, valid kappa:83.016
[1;31mEarlyStopping counter: 1 out of 50[0m
[Fold 1] Best Score: [85.05530905596336, 62.44358433777797, 59.79330254581949, 69.93520648435702, 83.13641189203804]
fold:2 epoch:0 step:0 train loss:4.673041, train acc:0.970, train f1:0.815, train precision:0.981, train recall:1.288, train kappa:0.044
fold:2 epoch:0 step:1 train loss:4.336502, train acc:8.173, train f1:1.470, train precision:1.935, train recall:2.037, train kappa:2.704
fold:2 epoch:0 step:2 train loss:4.085772, train acc:12.305, train f1:1.985, train precision:2.133, train recall:3.067, train kappa:4.490
fold:2 epoch:0 step:3 train loss:3.934909, train acc:15.378, train f1:2.593, train precision:2.927, train recall:3.439, train kappa:6.426
fold:2 epoch:0 step:4 train loss:3.858876, train acc:18.121, train f1:3.333, train precision:4.079, train recall:4.457, train kappa:8.794
fold:2 epoch:0 step:5 train loss:3.819060, train acc:18.130, train f1:3.887, train precision:4.970, train recall:4.815, train kappa:8.904
fold:2 epoch:0 step:6 train loss:3.782123, train acc:18.195, train f1:4.183, train precision:5.908, train recall:5.022, train kappa:9.010
fold:2 epoch:0 step:7 train loss:3.700812, train acc:19.159, train f1:4.484, train precision:5.073, train recall:5.190, train kappa:10.223
fold:2 epoch:0 step:8 train loss:3.635912, train acc:21.335, train f1:4.670, train precision:7.314, train recall:5.476, train kappa:12.445
fold:2 epoch:0 step:9 train loss:3.586941, train acc:21.466, train f1:4.824, train precision:9.205, train recall:5.502, train kappa:12.765
fold:2 epoch:0 step:10 train loss:3.507123, train acc:22.318, train f1:5.776, train precision:8.784, train recall:6.317, train kappa:13.785
fold:2 epoch:0 step:11 train loss:3.443329, train acc:23.144, train f1:6.184, train precision:7.855, train recall:7.119, train kappa:15.158
fold:2 epoch:0        valid loss:3.369735, valid acc:25.593, valid f1:0.570, valid precision:0.986, valid recall:1.216, valid kappa:0.856
None
====================================================================================================
fold:2 epoch:1 step:0 train loss:3.419437, train acc:23.538, train f1:6.541, train precision:13.351, train recall:7.553, train kappa:15.807
fold:2 epoch:1 step:1 train loss:3.310709, train acc:24.701, train f1:7.821, train precision:11.185, train recall:8.654, train kappa:17.336
fold:2 epoch:1 step:2 train loss:3.236112, train acc:25.989, train f1:9.098, train precision:15.998, train recall:9.764, train kappa:18.805
fold:2 epoch:1 step:3 train loss:3.212285, train acc:25.632, train f1:9.336, train precision:14.270, train recall:10.077, train kappa:18.667
fold:2 epoch:1 step:4 train loss:3.116338, train acc:27.347, train f1:10.396, train precision:17.355, train recall:10.840, train kappa:20.252
fold:2 epoch:1 step:5 train loss:3.071602, train acc:27.612, train f1:11.707, train precision:17.447, train recall:12.184, train kappa:20.995
fold:2 epoch:1 step:6 train loss:3.025108, train acc:28.259, train f1:13.119, train precision:20.584, train recall:13.459, train kappa:21.977
fold:2 epoch:1 step:7 train loss:2.967162, train acc:29.657, train f1:13.962, train precision:22.934, train recall:14.503, train kappa:23.662
fold:2 epoch:1 step:8 train loss:2.902158, train acc:30.136, train f1:15.111, train precision:22.890, train recall:15.812, train kappa:24.369
fold:2 epoch:1 step:9 train loss:2.845518, train acc:30.597, train f1:16.507, train precision:24.423, train recall:16.981, train kappa:25.107
fold:2 epoch:1 step:10 train loss:2.771607, train acc:31.824, train f1:17.923, train precision:25.828, train recall:17.788, train kappa:26.401
fold:2 epoch:1 step:11 train loss:2.724599, train acc:32.275, train f1:18.690, train precision:26.335, train recall:18.909, train kappa:26.921
fold:2 epoch:1        valid loss:3.323808, valid acc:23.177, valid f1:3.303, valid precision:5.966, valid recall:4.732, valid kappa:14.579
None
====================================================================================================
fold:2 epoch:2 step:0 train loss:2.665161, train acc:34.015, train f1:21.258, train precision:30.197, train recall:20.870, train kappa:29.170
fold:2 epoch:2 step:1 train loss:2.610367, train acc:34.619, train f1:22.183, train precision:33.116, train recall:21.919, train kappa:29.810
fold:2 epoch:2 step:2 train loss:2.557250, train acc:36.102, train f1:23.889, train precision:32.884, train recall:23.836, train kappa:31.737
fold:2 epoch:2 step:3 train loss:2.501838, train acc:37.250, train f1:26.460, train precision:33.663, train recall:26.606, train kappa:33.191
fold:2 epoch:2 step:4 train loss:2.455439, train acc:38.110, train f1:27.602, train precision:34.806, train recall:27.852, train kappa:34.206
fold:2 epoch:2 step:5 train loss:2.407624, train acc:39.673, train f1:29.276, train precision:36.790, train recall:29.534, train kappa:35.949
fold:2 epoch:2 step:6 train loss:2.360501, train acc:40.314, train f1:30.332, train precision:38.154, train recall:30.832, train kappa:36.680
fold:2 epoch:2 step:7 train loss:2.326921, train acc:41.064, train f1:31.491, train precision:39.459, train recall:31.387, train kappa:37.498
fold:2 epoch:2 step:8 train loss:2.257268, train acc:42.288, train f1:32.755, train precision:40.530, train recall:32.827, train kappa:38.760
fold:2 epoch:2 step:9 train loss:2.236927, train acc:42.694, train f1:33.730, train precision:42.158, train recall:33.433, train kappa:39.161
fold:2 epoch:2 step:10 train loss:2.182462, train acc:44.647, train f1:36.146, train precision:44.819, train recall:35.570, train kappa:41.397
fold:2 epoch:2 step:11 train loss:2.107236, train acc:45.362, train f1:37.869, train precision:44.542, train recall:36.911, train kappa:42.187
fold:2 epoch:2        valid loss:2.729539, valid acc:33.478, valid f1:14.343, valid precision:21.248, valid recall:20.980, valid kappa:24.455
None
====================================================================================================
fold:2 epoch:3 step:0 train loss:2.104848, train acc:46.576, train f1:39.119, train precision:45.249, train recall:38.344, train kappa:43.563
fold:2 epoch:3 step:1 train loss:2.070957, train acc:46.750, train f1:39.404, train precision:46.118, train recall:38.781, train kappa:43.787
fold:2 epoch:3 step:2 train loss:2.052171, train acc:47.891, train f1:41.007, train precision:46.886, train recall:40.732, train kappa:45.055
fold:2 epoch:3 step:3 train loss:1.982745, train acc:48.889, train f1:42.957, train precision:49.892, train recall:42.479, train kappa:46.184
fold:2 epoch:3 step:4 train loss:1.981971, train acc:49.200, train f1:42.617, train precision:50.028, train recall:41.789, train kappa:46.389
fold:2 epoch:3 step:5 train loss:1.937830, train acc:50.146, train f1:44.140, train precision:50.819, train recall:42.998, train kappa:47.480
fold:2 epoch:3 step:6 train loss:1.914478, train acc:50.415, train f1:44.703, train precision:51.736, train recall:43.368, train kappa:47.734
fold:2 epoch:3 step:7 train loss:1.869009, train acc:51.260, train f1:46.026, train precision:51.538, train recall:44.564, train kappa:48.716
fold:2 epoch:3 step:8 train loss:1.856427, train acc:51.569, train f1:46.383, train precision:50.751, train recall:45.416, train kappa:49.101
fold:2 epoch:3 step:9 train loss:1.832133, train acc:52.747, train f1:47.902, train precision:52.454, train recall:47.369, train kappa:50.411
fold:2 epoch:3 step:10 train loss:1.804978, train acc:53.427, train f1:49.103, train precision:54.098, train recall:48.344, train kappa:51.136
fold:2 epoch:3 step:11 train loss:1.799027, train acc:54.049, train f1:49.251, train precision:54.623, train recall:48.152, train kappa:51.701
fold:2 epoch:3        valid loss:2.261609, valid acc:39.520, valid f1:20.084, valid precision:25.532, valid recall:34.457, valid kappa:33.334
None
====================================================================================================
fold:2 epoch:4 step:0 train loss:1.757949, train acc:54.822, train f1:50.554, train precision:56.405, train recall:49.231, train kappa:52.553
fold:2 epoch:4 step:1 train loss:1.718805, train acc:55.142, train f1:50.936, train precision:56.394, train recall:49.773, train kappa:52.869
fold:2 epoch:4 step:2 train loss:1.698900, train acc:55.856, train f1:51.823, train precision:57.339, train recall:50.301, train kappa:53.641
fold:2 epoch:4 step:3 train loss:1.703564, train acc:55.893, train f1:51.655, train precision:57.054, train recall:50.537, train kappa:53.790
fold:2 epoch:4 step:4 train loss:1.667896, train acc:56.979, train f1:52.969, train precision:56.843, train recall:52.255, train kappa:54.985
fold:2 epoch:4 step:5 train loss:1.638788, train acc:57.730, train f1:53.944, train precision:58.210, train recall:52.859, train kappa:55.761
fold:2 epoch:4 step:6 train loss:1.618503, train acc:58.154, train f1:54.478, train precision:58.227, train recall:53.600, train kappa:56.181
fold:2 epoch:4 step:7 train loss:1.601073, train acc:58.902, train f1:55.113, train precision:59.881, train recall:54.172, train kappa:56.977
fold:2 epoch:4 step:8 train loss:1.570403, train acc:59.717, train f1:55.811, train precision:60.649, train recall:55.010, train kappa:57.806
fold:2 epoch:4 step:9 train loss:1.567643, train acc:59.003, train f1:56.018, train precision:61.822, train recall:54.598, train kappa:57.069
fold:2 epoch:4 step:10 train loss:1.554917, train acc:60.046, train f1:56.428, train precision:60.640, train recall:55.409, train kappa:58.176
fold:2 epoch:4 step:11 train loss:1.531107, train acc:60.081, train f1:56.591, train precision:60.182, train recall:55.811, train kappa:58.299
fold:2 epoch:4        valid loss:1.962007, valid acc:43.325, valid f1:24.267, valid precision:30.505, valid recall:40.885, valid kappa:37.911
None
====================================================================================================
fold:2 epoch:5 step:0 train loss:1.518503, train acc:60.440, train f1:57.497, train precision:60.748, train recall:57.025, train kappa:58.671
fold:2 epoch:5 step:1 train loss:1.488837, train acc:61.078, train f1:57.764, train precision:61.542, train recall:57.540, train kappa:59.335
fold:2 epoch:5 step:2 train loss:1.475256, train acc:61.340, train f1:58.308, train precision:62.243, train recall:57.458, train kappa:59.581
fold:2 epoch:5 step:3 train loss:1.460695, train acc:62.003, train f1:58.660, train precision:63.231, train recall:57.771, train kappa:60.239
fold:2 epoch:5 step:4 train loss:1.454857, train acc:62.030, train f1:58.922, train precision:63.381, train recall:57.559, train kappa:60.281
fold:2 epoch:5 step:5 train loss:1.440128, train acc:62.543, train f1:59.582, train precision:64.363, train recall:58.468, train kappa:60.816
fold:2 epoch:5 step:6 train loss:1.429712, train acc:62.521, train f1:59.534, train precision:66.088, train recall:58.229, train kappa:60.816
fold:2 epoch:5 step:7 train loss:1.431533, train acc:62.793, train f1:59.476, train precision:62.759, train recall:58.838, train kappa:61.115
fold:2 epoch:5 step:8 train loss:1.417621, train acc:63.446, train f1:60.706, train precision:63.719, train recall:60.295, train kappa:61.864
fold:2 epoch:5 step:9 train loss:1.418216, train acc:62.985, train f1:60.353, train precision:63.273, train recall:60.112, train kappa:61.397
fold:2 epoch:5 step:10 train loss:1.378063, train acc:64.230, train f1:61.591, train precision:65.344, train recall:61.468, train kappa:62.721
fold:2 epoch:5 step:11 train loss:1.366408, train acc:63.710, train f1:61.322, train precision:65.276, train recall:60.702, train kappa:62.125
fold:2 epoch:5        valid loss:1.376255, valid acc:61.652, valid f1:39.588, valid precision:38.773, valid recall:54.796, valid kappa:57.202
None
====================================================================================================
fold:2 epoch:6 step:0 train loss:1.376507, train acc:64.166, train f1:61.825, train precision:67.114, train recall:61.047, train kappa:62.628
fold:2 epoch:6 step:1 train loss:1.350094, train acc:64.722, train f1:62.297, train precision:66.438, train recall:61.058, train kappa:63.140
fold:2 epoch:6 step:2 train loss:1.322099, train acc:65.469, train f1:62.842, train precision:66.841, train recall:61.923, train kappa:63.930
fold:2 epoch:6 step:3 train loss:1.330678, train acc:65.182, train f1:62.741, train precision:65.974, train recall:61.550, train kappa:63.630
fold:2 epoch:6 step:4 train loss:1.305565, train acc:65.884, train f1:63.447, train precision:67.731, train recall:62.596, train kappa:64.422
fold:2 epoch:6 step:5 train loss:1.301822, train acc:65.732, train f1:63.233, train precision:67.347, train recall:62.358, train kappa:64.240
fold:2 epoch:6 step:6 train loss:1.264408, train acc:66.675, train f1:64.066, train precision:67.632, train recall:63.768, train kappa:65.256
fold:2 epoch:6 step:7 train loss:1.292540, train acc:66.373, train f1:64.357, train precision:67.505, train recall:63.588, train kappa:64.909
fold:2 epoch:6 step:8 train loss:1.280930, train acc:66.373, train f1:63.807, train precision:67.006, train recall:63.169, train kappa:64.938
fold:2 epoch:6 step:9 train loss:1.274622, train acc:66.809, train f1:64.345, train precision:67.492, train recall:63.699, train kappa:65.391
fold:2 epoch:6 step:10 train loss:1.258362, train acc:67.105, train f1:64.606, train precision:67.713, train recall:64.231, train kappa:65.675
fold:2 epoch:6 step:11 train loss:1.225490, train acc:67.658, train f1:65.208, train precision:68.944, train recall:64.780, train kappa:66.275
fold:2 epoch:6        valid loss:1.108319, valid acc:69.280, valid f1:46.264, valid precision:43.031, valid recall:63.534, valid kappa:65.680
None
====================================================================================================
fold:2 epoch:7 step:0 train loss:1.226087, train acc:67.828, train f1:65.307, train precision:67.738, train recall:64.857, train kappa:66.431
fold:2 epoch:7 step:1 train loss:1.222294, train acc:67.856, train f1:65.295, train precision:68.629, train recall:64.966, train kappa:66.493
fold:2 epoch:7 step:2 train loss:1.201300, train acc:68.573, train f1:66.076, train precision:69.216, train recall:65.360, train kappa:67.228
fold:2 epoch:7 step:3 train loss:1.219109, train acc:68.161, train f1:65.669, train precision:70.139, train recall:65.009, train kappa:66.799
fold:2 epoch:7 step:4 train loss:1.220371, train acc:67.862, train f1:65.518, train precision:68.805, train recall:64.786, train kappa:66.494
fold:2 epoch:7 step:5 train loss:1.183163, train acc:69.122, train f1:66.799, train precision:70.774, train recall:65.756, train kappa:67.800
fold:2 epoch:7 step:6 train loss:1.205189, train acc:68.369, train f1:66.145, train precision:69.960, train recall:65.370, train kappa:67.031
fold:2 epoch:7 step:7 train loss:1.188042, train acc:68.652, train f1:66.335, train precision:70.092, train recall:65.660, train kappa:67.329
fold:2 epoch:7 step:8 train loss:1.178101, train acc:68.823, train f1:66.893, train precision:69.988, train recall:66.636, train kappa:67.537
fold:2 epoch:7 step:9 train loss:1.166114, train acc:69.083, train f1:66.632, train precision:69.258, train recall:66.346, train kappa:67.787
fold:2 epoch:7 step:10 train loss:1.164092, train acc:69.333, train f1:67.259, train precision:71.688, train recall:66.717, train kappa:68.035
fold:2 epoch:7 step:11 train loss:1.146717, train acc:69.887, train f1:67.871, train precision:70.147, train recall:67.588, train kappa:68.629
fold:2 epoch:7        valid loss:1.013792, valid acc:71.611, valid f1:48.759, valid precision:45.528, valid recall:66.580, valid kappa:68.329
None
====================================================================================================
fold:2 epoch:8 step:0 train loss:1.139644, train acc:69.821, train f1:67.440, train precision:70.974, train recall:66.488, train kappa:68.518
fold:2 epoch:8 step:1 train loss:1.152380, train acc:69.525, train f1:67.444, train precision:71.910, train recall:66.946, train kappa:68.268
fold:2 epoch:8 step:2 train loss:1.128869, train acc:70.367, train f1:68.057, train precision:71.385, train recall:67.246, train kappa:69.111
fold:2 epoch:8 step:3 train loss:1.134920, train acc:70.020, train f1:68.172, train precision:71.840, train recall:67.563, train kappa:68.779
fold:2 epoch:8 step:4 train loss:1.123433, train acc:70.407, train f1:68.300, train precision:72.268, train recall:67.879, train kappa:69.150
fold:2 epoch:8 step:5 train loss:1.109661, train acc:70.749, train f1:68.624, train precision:72.859, train recall:68.113, train kappa:69.517
fold:2 epoch:8 step:6 train loss:1.120699, train acc:70.172, train f1:67.952, train precision:71.192, train recall:67.682, train kappa:68.919
fold:2 epoch:8 step:7 train loss:1.102833, train acc:70.715, train f1:68.745, train precision:71.835, train recall:68.135, train kappa:69.494
fold:2 epoch:8 step:8 train loss:1.100591, train acc:70.999, train f1:68.777, train precision:71.755, train recall:68.178, train kappa:69.784
fold:2 epoch:8 step:9 train loss:1.084349, train acc:70.874, train f1:68.684, train precision:71.398, train recall:68.142, train kappa:69.643
fold:2 epoch:8 step:10 train loss:1.070240, train acc:71.475, train f1:69.384, train precision:73.728, train recall:68.749, train kappa:70.292
fold:2 epoch:8 step:11 train loss:1.094219, train acc:71.065, train f1:69.346, train precision:72.847, train recall:68.571, train kappa:69.882
fold:2 epoch:8        valid loss:0.968301, valid acc:73.681, valid f1:49.520, valid precision:45.912, valid recall:67.546, valid kappa:70.573
None
====================================================================================================
fold:2 epoch:9 step:0 train loss:1.056405, train acc:71.884, train f1:69.734, train precision:72.666, train recall:69.456, train kappa:70.717
fold:2 epoch:9 step:1 train loss:1.062138, train acc:71.509, train f1:69.560, train precision:74.078, train recall:68.974, train kappa:70.324
fold:2 epoch:9 step:2 train loss:1.059567, train acc:71.475, train f1:69.305, train precision:72.637, train recall:68.811, train kappa:70.257
fold:2 epoch:9 step:3 train loss:1.076749, train acc:71.268, train f1:69.378, train precision:73.015, train recall:68.614, train kappa:70.067
fold:2 epoch:9 step:4 train loss:1.059197, train acc:71.680, train f1:69.561, train precision:73.827, train recall:69.036, train kappa:70.488
fold:2 epoch:9 step:5 train loss:1.050123, train acc:72.070, train f1:70.129, train precision:73.420, train recall:69.576, train kappa:70.932
fold:2 epoch:9 step:6 train loss:1.041078, train acc:72.229, train f1:70.094, train precision:72.952, train recall:69.569, train kappa:71.085
fold:2 epoch:9 step:7 train loss:1.049858, train acc:72.006, train f1:69.997, train precision:73.343, train recall:69.397, train kappa:70.828
fold:2 epoch:9 step:8 train loss:1.048257, train acc:71.954, train f1:69.694, train precision:72.022, train recall:69.440, train kappa:70.808
fold:2 epoch:9 step:9 train loss:1.029177, train acc:72.775, train f1:70.727, train precision:73.334, train recall:70.209, train kappa:71.657
fold:2 epoch:9 step:10 train loss:1.032303, train acc:72.369, train f1:70.534, train precision:74.805, train recall:70.002, train kappa:71.238
fold:2 epoch:9 step:11 train loss:1.011965, train acc:72.715, train f1:71.125, train precision:75.630, train recall:70.670, train kappa:71.559
fold:2 epoch:9        valid loss:0.915254, valid acc:75.055, valid f1:50.835, valid precision:49.122, valid recall:68.145, valid kappa:72.053
None
====================================================================================================
fold:2 epoch:10 step:0 train loss:1.020322, train acc:72.958, train f1:70.912, train precision:75.088, train recall:70.338, train kappa:71.858
fold:2 epoch:10 step:1 train loss:1.015974, train acc:72.717, train f1:70.754, train precision:73.689, train recall:70.239, train kappa:71.572
fold:2 epoch:10 step:2 train loss:1.022773, train acc:72.672, train f1:70.721, train precision:74.239, train recall:70.223, train kappa:71.542
fold:2 epoch:10 step:3 train loss:1.006437, train acc:72.983, train f1:71.223, train precision:74.544, train recall:70.855, train kappa:71.889
fold:2 epoch:10 step:4 train loss:0.998862, train acc:73.090, train f1:71.238, train precision:75.302, train recall:70.728, train kappa:71.988
fold:2 epoch:10 step:5 train loss:0.984261, train acc:73.181, train f1:71.108, train precision:74.780, train recall:70.360, train kappa:72.053
fold:2 epoch:10 step:6 train loss:0.994880, train acc:73.172, train f1:71.147, train precision:76.888, train recall:70.240, train kappa:72.067
fold:2 epoch:10 step:7 train loss:0.986471, train acc:73.373, train f1:71.200, train precision:76.337, train recall:70.862, train kappa:72.266
fold:2 epoch:10 step:8 train loss:0.976989, train acc:73.456, train f1:71.759, train precision:75.808, train recall:71.161, train kappa:72.346
fold:2 epoch:10 step:9 train loss:0.979874, train acc:73.593, train f1:71.388, train precision:74.991, train recall:71.041, train kappa:72.502
fold:2 epoch:10 step:10 train loss:0.985125, train acc:73.587, train f1:71.552, train precision:74.723, train recall:71.546, train kappa:72.511
fold:2 epoch:10 step:11 train loss:0.980036, train acc:73.950, train f1:72.036, train precision:75.485, train recall:71.817, train kappa:72.903
fold:2 epoch:10        valid loss:0.872903, valid acc:76.286, valid f1:52.486, valid precision:49.677, valid recall:68.580, valid kappa:73.405
None
====================================================================================================
fold:2 epoch:11 step:0 train loss:0.959952, train acc:74.185, train f1:72.440, train precision:76.152, train recall:71.752, train kappa:73.113
fold:2 epoch:11 step:1 train loss:0.972774, train acc:73.596, train f1:71.708, train precision:75.454, train recall:71.107, train kappa:72.493
fold:2 epoch:11 step:2 train loss:0.961231, train acc:73.868, train f1:71.964, train precision:75.378, train recall:71.078, train kappa:72.784
fold:2 epoch:11 step:3 train loss:0.962627, train acc:73.996, train f1:72.314, train precision:75.734, train recall:71.683, train kappa:72.930
fold:2 epoch:11 step:4 train loss:0.949633, train acc:74.384, train f1:72.375, train precision:75.220, train recall:71.865, train kappa:73.332
fold:2 epoch:11 step:5 train loss:0.943838, train acc:74.487, train f1:72.438, train precision:75.186, train recall:72.447, train kappa:73.471
fold:2 epoch:11 step:6 train loss:0.959119, train acc:74.207, train f1:72.193, train precision:74.971, train recall:72.141, train kappa:73.168
fold:2 epoch:11 step:7 train loss:0.945701, train acc:74.472, train f1:72.378, train precision:76.254, train recall:72.139, train kappa:73.445
fold:2 epoch:11 step:8 train loss:0.927814, train acc:75.162, train f1:73.051, train precision:77.119, train recall:72.569, train kappa:74.121
fold:2 epoch:11 step:9 train loss:0.917423, train acc:75.137, train f1:73.099, train precision:76.444, train recall:72.827, train kappa:74.125
fold:2 epoch:11 step:10 train loss:0.932099, train acc:74.796, train f1:73.046, train precision:77.189, train recall:72.222, train kappa:73.746
fold:2 epoch:11 step:11 train loss:0.934188, train acc:75.224, train f1:74.004, train precision:77.887, train recall:73.054, train kappa:74.228
fold:2 epoch:11        valid loss:0.849605, valid acc:76.797, valid f1:52.703, valid precision:50.478, valid recall:69.577, valid kappa:73.988
None
====================================================================================================
fold:2 epoch:12 step:0 train loss:0.928077, train acc:74.640, train f1:73.012, train precision:76.529, train recall:72.282, train kappa:73.604
fold:2 epoch:12 step:1 train loss:0.918076, train acc:75.034, train f1:73.406, train precision:76.526, train recall:72.654, train kappa:74.013
fold:2 epoch:12 step:2 train loss:0.902846, train acc:75.427, train f1:73.761, train precision:76.856, train recall:73.591, train kappa:74.439
fold:2 epoch:12 step:3 train loss:0.921982, train acc:75.064, train f1:73.495, train precision:75.876, train recall:73.218, train kappa:74.067
fold:2 epoch:12 step:4 train loss:0.907738, train acc:75.531, train f1:73.577, train precision:76.683, train recall:73.494, train kappa:74.543
fold:2 epoch:12 step:5 train loss:0.904959, train acc:75.388, train f1:73.468, train precision:76.042, train recall:73.155, train kappa:74.384
fold:2 epoch:12 step:6 train loss:0.910393, train acc:75.217, train f1:73.510, train precision:76.782, train recall:73.024, train kappa:74.208
fold:2 epoch:12 step:7 train loss:0.886343, train acc:75.882, train f1:74.063, train precision:77.688, train recall:73.323, train kappa:74.886
fold:2 epoch:12 step:8 train loss:0.914841, train acc:75.195, train f1:73.420, train precision:78.186, train recall:72.724, train kappa:74.179
fold:2 epoch:12 step:9 train loss:0.889711, train acc:75.616, train f1:73.915, train precision:77.317, train recall:73.592, train kappa:74.621
fold:2 epoch:12 step:10 train loss:0.899589, train acc:75.455, train f1:73.833, train precision:76.575, train recall:73.888, train kappa:74.468
fold:2 epoch:12 step:11 train loss:0.874617, train acc:75.997, train f1:73.989, train precision:76.645, train recall:74.021, train kappa:75.028
fold:2 epoch:12        valid loss:0.841424, valid acc:76.805, valid f1:52.613, valid precision:49.793, valid recall:69.898, valid kappa:74.035
None
====================================================================================================
fold:2 epoch:13 step:0 train loss:0.889923, train acc:75.793, train f1:74.059, train precision:76.585, train recall:73.929, train kappa:74.829
fold:2 epoch:13 step:1 train loss:0.881190, train acc:75.742, train f1:74.323, train precision:77.457, train recall:73.905, train kappa:74.769
fold:2 epoch:13 step:2 train loss:0.879281, train acc:75.769, train f1:74.089, train precision:77.433, train recall:73.361, train kappa:74.762
fold:2 epoch:13 step:3 train loss:0.871835, train acc:76.230, train f1:74.392, train precision:77.979, train recall:73.732, train kappa:75.235
fold:2 epoch:13 step:4 train loss:0.865141, train acc:76.318, train f1:74.483, train precision:78.155, train recall:73.879, train kappa:75.358
fold:2 epoch:13 step:5 train loss:0.889510, train acc:75.934, train f1:74.024, train precision:77.445, train recall:73.603, train kappa:74.949
fold:2 epoch:13 step:6 train loss:0.872087, train acc:76.059, train f1:74.485, train precision:77.819, train recall:74.046, train kappa:75.080
fold:2 epoch:13 step:7 train loss:0.852171, train acc:76.517, train f1:74.917, train precision:78.196, train recall:74.553, train kappa:75.564
fold:2 epoch:13 step:8 train loss:0.880402, train acc:75.623, train f1:74.071, train precision:76.838, train recall:73.777, train kappa:74.640
fold:2 epoch:13 step:9 train loss:0.854008, train acc:76.529, train f1:74.749, train precision:77.915, train recall:74.395, train kappa:75.582
fold:2 epoch:13 step:10 train loss:0.841206, train acc:76.764, train f1:75.159, train precision:78.271, train recall:74.832, train kappa:75.842
fold:2 epoch:13 step:11 train loss:0.836310, train acc:77.541, train f1:75.963, train precision:79.538, train recall:75.659, train kappa:76.633
fold:2 epoch:13        valid loss:0.808719, valid acc:77.864, valid f1:53.402, valid precision:50.556, valid recall:70.322, valid kappa:75.173
None
====================================================================================================
fold:2 epoch:14 step:0 train loss:0.864419, train acc:76.071, train f1:74.392, train precision:76.891, train recall:73.891, train kappa:75.070
fold:2 epoch:14 step:1 train loss:0.849105, train acc:76.764, train f1:75.232, train precision:77.916, train recall:74.966, train kappa:75.832
fold:2 epoch:14 step:2 train loss:0.828053, train acc:77.377, train f1:75.521, train precision:78.359, train recall:75.448, train kappa:76.471
fold:2 epoch:14 step:3 train loss:0.837134, train acc:76.816, train f1:75.212, train precision:78.473, train recall:74.987, train kappa:75.879
fold:2 epoch:14 step:4 train loss:0.849889, train acc:76.584, train f1:74.975, train precision:78.250, train recall:74.517, train kappa:75.633
fold:2 epoch:14 step:5 train loss:0.853994, train acc:76.428, train f1:75.021, train precision:78.156, train recall:74.517, train kappa:75.490
fold:2 epoch:14 step:6 train loss:0.837773, train acc:76.743, train f1:74.817, train precision:77.708, train recall:74.618, train kappa:75.789
fold:2 epoch:14 step:7 train loss:0.837164, train acc:76.956, train f1:75.509, train precision:78.414, train recall:74.899, train kappa:76.025
fold:2 epoch:14 step:8 train loss:0.834836, train acc:76.846, train f1:75.011, train precision:77.379, train recall:74.907, train kappa:75.895
fold:2 epoch:14 step:9 train loss:0.841532, train acc:76.730, train f1:75.360, train precision:77.868, train recall:74.947, train kappa:75.816
fold:2 epoch:14 step:10 train loss:0.841715, train acc:76.663, train f1:75.246, train precision:77.976, train recall:74.821, train kappa:75.738
fold:2 epoch:14 step:11 train loss:0.807865, train acc:77.338, train f1:75.778, train precision:78.655, train recall:75.484, train kappa:76.444
fold:2 epoch:14        valid loss:0.805350, valid acc:77.909, valid f1:53.725, valid precision:50.863, valid recall:70.000, valid kappa:75.249
None
====================================================================================================
fold:2 epoch:15 step:0 train loss:0.830916, train acc:77.240, train f1:75.783, train precision:78.299, train recall:75.640, train kappa:76.348
fold:2 epoch:15 step:1 train loss:0.811833, train acc:77.591, train f1:75.892, train precision:79.071, train recall:75.957, train kappa:76.704
fold:2 epoch:15 step:2 train loss:0.825248, train acc:77.213, train f1:75.575, train precision:78.186, train recall:75.335, train kappa:76.307
fold:2 epoch:15 step:3 train loss:0.808522, train acc:77.521, train f1:76.169, train precision:79.627, train recall:75.897, train kappa:76.609
fold:2 epoch:15 step:4 train loss:0.813481, train acc:77.432, train f1:75.759, train precision:78.883, train recall:75.319, train kappa:76.511
fold:2 epoch:15 step:5 train loss:0.826548, train acc:77.017, train f1:75.402, train precision:80.154, train recall:74.962, train kappa:76.076
fold:2 epoch:15 step:6 train loss:0.816853, train acc:77.258, train f1:75.652, train precision:79.442, train recall:75.197, train kappa:76.335
fold:2 epoch:15 step:7 train loss:0.795546, train acc:77.802, train f1:76.488, train precision:79.197, train recall:76.130, train kappa:76.921
fold:2 epoch:15 step:8 train loss:0.785826, train acc:77.902, train f1:76.214, train precision:78.471, train recall:76.054, train kappa:77.010
fold:2 epoch:15 step:9 train loss:0.813876, train acc:77.457, train f1:76.022, train precision:78.352, train recall:76.017, train kappa:76.547
fold:2 epoch:15 step:10 train loss:0.793493, train acc:77.960, train f1:76.485, train precision:79.238, train recall:76.227, train kappa:77.100
fold:2 epoch:15 step:11 train loss:0.786892, train acc:78.390, train f1:76.721, train precision:80.485, train recall:76.417, train kappa:77.532
fold:2 epoch:15        valid loss:0.791265, valid acc:78.439, valid f1:54.405, valid precision:51.387, valid recall:70.263, valid kappa:75.816
None
====================================================================================================
fold:2 epoch:16 step:0 train loss:0.791308, train acc:77.933, train f1:76.393, train precision:78.942, train recall:76.250, train kappa:77.049
fold:2 epoch:16 step:1 train loss:0.793271, train acc:77.786, train f1:76.337, train precision:78.894, train recall:76.072, train kappa:76.902
fold:2 epoch:16 step:2 train loss:0.790836, train acc:77.985, train f1:76.421, train precision:79.589, train recall:76.044, train kappa:77.103
fold:2 epoch:16 step:3 train loss:0.792854, train acc:78.070, train f1:76.642, train precision:79.401, train recall:76.329, train kappa:77.216
fold:2 epoch:16 step:4 train loss:0.783538, train acc:78.293, train f1:76.303, train precision:78.610, train recall:76.235, train kappa:77.425
fold:2 epoch:16 step:5 train loss:0.795655, train acc:78.049, train f1:76.389, train precision:79.348, train recall:76.267, train kappa:77.170
fold:2 epoch:16 step:6 train loss:0.788647, train acc:78.220, train f1:76.456, train precision:78.861, train recall:76.287, train kappa:77.350
fold:2 epoch:16 step:7 train loss:0.787418, train acc:78.262, train f1:76.705, train precision:79.470, train recall:76.778, train kappa:77.399
fold:2 epoch:16 step:8 train loss:0.775177, train acc:78.455, train f1:76.921, train precision:79.037, train recall:76.873, train kappa:77.584
fold:2 epoch:16 step:9 train loss:0.786786, train acc:77.963, train f1:76.518, train precision:78.995, train recall:76.373, train kappa:77.071
fold:2 epoch:16 step:10 train loss:0.771761, train acc:78.506, train f1:77.053, train precision:80.147, train recall:76.523, train kappa:77.634
fold:2 epoch:16 step:11 train loss:0.784337, train acc:77.985, train f1:76.504, train precision:79.018, train recall:75.996, train kappa:77.063
fold:2 epoch:16        valid loss:0.761478, valid acc:79.291, valid f1:55.698, valid precision:52.849, valid recall:70.249, valid kappa:76.742
None
====================================================================================================
fold:2 epoch:17 step:0 train loss:0.757268, train acc:78.772, train f1:77.551, train precision:80.539, train recall:76.860, train kappa:77.923
fold:2 epoch:17 step:1 train loss:0.777107, train acc:78.348, train f1:77.341, train precision:80.296, train recall:76.927, train kappa:77.504
fold:2 epoch:17 step:2 train loss:0.755532, train acc:78.662, train f1:77.115, train precision:79.689, train recall:76.909, train kappa:77.826
fold:2 epoch:17 step:3 train loss:0.764590, train acc:78.702, train f1:77.031, train precision:79.723, train recall:76.625, train kappa:77.842
fold:2 epoch:17 step:4 train loss:0.754044, train acc:79.147, train f1:77.499, train precision:79.669, train recall:77.523, train kappa:78.307
fold:2 epoch:17 step:5 train loss:0.763384, train acc:78.699, train f1:77.170, train precision:79.531, train recall:77.303, train kappa:77.836
fold:2 epoch:17 step:6 train loss:0.770541, train acc:78.461, train f1:76.622, train precision:79.255, train recall:76.701, train kappa:77.582
fold:2 epoch:17 step:7 train loss:0.775423, train acc:78.403, train f1:76.752, train precision:79.704, train recall:76.771, train kappa:77.535
fold:2 epoch:17 step:8 train loss:0.754983, train acc:78.763, train f1:77.323, train precision:80.309, train recall:76.901, train kappa:77.903
fold:2 epoch:17 step:9 train loss:0.765708, train acc:78.546, train f1:77.069, train precision:80.377, train recall:76.575, train kappa:77.699
fold:2 epoch:17 step:10 train loss:0.759078, train acc:78.653, train f1:77.139, train precision:80.014, train recall:76.849, train kappa:77.806
fold:2 epoch:17 step:11 train loss:0.751041, train acc:79.490, train f1:77.825, train precision:80.232, train recall:77.601, train kappa:78.680
fold:2 epoch:17        valid loss:0.763772, valid acc:79.187, valid f1:55.363, valid precision:52.058, valid recall:70.697, valid kappa:76.637
None
====================================================================================================
fold:2 epoch:18 step:0 train loss:0.745618, train acc:79.196, train f1:77.577, train precision:80.375, train recall:77.403, train kappa:78.384
fold:2 epoch:18 step:1 train loss:0.760708, train acc:78.516, train f1:77.393, train precision:79.320, train recall:77.527, train kappa:77.672
fold:2 epoch:18 step:2 train loss:0.740856, train acc:79.221, train f1:77.795, train precision:80.319, train recall:77.594, train kappa:78.400
fold:2 epoch:18 step:3 train loss:0.738914, train acc:79.480, train f1:77.866, train precision:80.229, train recall:77.633, train kappa:78.675
fold:2 epoch:18 step:4 train loss:0.749649, train acc:78.836, train f1:77.311, train precision:80.326, train recall:77.022, train kappa:77.985
fold:2 epoch:18 step:5 train loss:0.735957, train acc:79.263, train f1:77.656, train precision:80.126, train recall:77.488, train kappa:78.434
fold:2 epoch:18 step:6 train loss:0.729511, train acc:79.703, train f1:78.302, train precision:81.294, train recall:78.092, train kappa:78.886
fold:2 epoch:18 step:7 train loss:0.735897, train acc:79.025, train f1:77.740, train precision:80.952, train recall:77.091, train kappa:78.192
fold:2 epoch:18 step:8 train loss:0.735687, train acc:79.364, train f1:78.026, train precision:80.929, train recall:78.152, train kappa:78.541
fold:2 epoch:18 step:9 train loss:0.740730, train acc:79.202, train f1:77.968, train precision:80.144, train recall:78.016, train kappa:78.385
fold:2 epoch:18 step:10 train loss:0.734749, train acc:79.306, train f1:77.924, train precision:79.874, train recall:78.094, train kappa:78.458
fold:2 epoch:18 step:11 train loss:0.733689, train acc:79.587, train f1:77.794, train precision:80.110, train recall:77.878, train kappa:78.788
fold:2 epoch:18        valid loss:0.749971, valid acc:79.668, valid f1:55.476, valid precision:52.239, valid recall:70.951, valid kappa:77.163
None
====================================================================================================
fold:2 epoch:19 step:0 train loss:0.719750, train acc:79.782, train f1:78.298, train precision:80.881, train recall:78.186, train kappa:78.959
fold:2 epoch:19 step:1 train loss:0.717626, train acc:80.096, train f1:78.626, train precision:81.525, train recall:78.155, train kappa:79.299
fold:2 epoch:19 step:2 train loss:0.734957, train acc:79.431, train f1:78.032, train precision:80.736, train recall:77.659, train kappa:78.613
fold:2 epoch:19 step:3 train loss:0.727233, train acc:79.550, train f1:78.125, train precision:80.940, train recall:77.605, train kappa:78.734
fold:2 epoch:19 step:4 train loss:0.719498, train acc:79.681, train f1:78.216, train precision:80.703, train recall:77.978, train kappa:78.854
fold:2 epoch:19 step:5 train loss:0.704539, train acc:80.142, train f1:78.616, train precision:80.816, train recall:78.525, train kappa:79.371
fold:2 epoch:19 step:6 train loss:0.724989, train acc:79.449, train f1:78.098, train precision:80.366, train recall:78.425, train kappa:78.639
fold:2 epoch:19 step:7 train loss:0.722143, train acc:79.727, train f1:78.361, train precision:80.941, train recall:78.374, train kappa:78.923
fold:2 epoch:19 step:8 train loss:0.724928, train acc:79.492, train f1:78.008, train precision:80.195, train recall:78.011, train kappa:78.693
fold:2 epoch:19 step:9 train loss:0.709803, train acc:79.959, train f1:78.645, train precision:80.667, train recall:78.691, train kappa:79.181
fold:2 epoch:19 step:10 train loss:0.717547, train acc:79.785, train f1:78.311, train precision:80.774, train recall:78.155, train kappa:78.981
fold:2 epoch:19 step:11 train loss:0.706229, train acc:80.581, train f1:79.177, train precision:82.281, train recall:78.794, train kappa:79.796
fold:2 epoch:19        valid loss:0.741785, valid acc:79.894, valid f1:55.964, valid precision:52.822, valid recall:70.725, valid kappa:77.387
None
====================================================================================================
fold:2 epoch:20 step:0 train loss:0.707626, train acc:79.865, train f1:78.507, train precision:81.151, train recall:78.275, train kappa:79.052
fold:2 epoch:20 step:1 train loss:0.714583, train acc:79.996, train f1:78.800, train precision:81.909, train recall:78.404, train kappa:79.192
fold:2 epoch:20 step:2 train loss:0.698676, train acc:80.136, train f1:78.393, train precision:80.742, train recall:78.288, train kappa:79.340
fold:2 epoch:20 step:3 train loss:0.702631, train acc:80.280, train f1:79.094, train precision:81.757, train recall:78.703, train kappa:79.504
fold:2 epoch:20 step:4 train loss:0.698557, train acc:80.466, train f1:78.876, train precision:82.005, train recall:78.764, train kappa:79.706
fold:2 epoch:20 step:5 train loss:0.702079, train acc:80.313, train f1:79.088, train precision:80.874, train recall:79.435, train kappa:79.543
fold:2 epoch:20 step:6 train loss:0.712142, train acc:79.672, train f1:78.440, train precision:80.402, train recall:78.635, train kappa:78.886
fold:2 epoch:20 step:7 train loss:0.692831, train acc:80.600, train f1:79.149, train precision:81.053, train recall:79.383, train kappa:79.835
fold:2 epoch:20 step:8 train loss:0.714557, train acc:79.956, train f1:78.618, train precision:80.528, train recall:78.749, train kappa:79.157
fold:2 epoch:20 step:9 train loss:0.698852, train acc:80.096, train f1:78.871, train precision:81.335, train recall:78.746, train kappa:79.317
fold:2 epoch:20 step:10 train loss:0.697698, train acc:80.243, train f1:78.834, train precision:81.576, train recall:78.539, train kappa:79.447
fold:2 epoch:20 step:11 train loss:0.695826, train acc:80.494, train f1:79.122, train precision:81.332, train recall:79.080, train kappa:79.718
fold:2 epoch:20        valid loss:0.731742, valid acc:80.207, valid f1:55.782, valid precision:52.357, valid recall:70.444, valid kappa:77.740
None
====================================================================================================
fold:2 epoch:21 step:0 train loss:0.693417, train acc:80.338, train f1:79.016, train precision:81.252, train recall:78.838, train kappa:79.553
fold:2 epoch:21 step:1 train loss:0.688865, train acc:80.463, train f1:79.108, train precision:80.923, train recall:79.052, train kappa:79.690
fold:2 epoch:21 step:2 train loss:0.694695, train acc:80.307, train f1:78.911, train precision:81.025, train recall:79.172, train kappa:79.535
fold:2 epoch:21 step:3 train loss:0.684370, train acc:80.518, train f1:79.080, train precision:81.404, train recall:79.045, train kappa:79.768
fold:2 epoch:21 step:4 train loss:0.687056, train acc:80.396, train f1:79.071, train precision:81.641, train recall:78.859, train kappa:79.620
fold:2 epoch:21 step:5 train loss:0.685684, train acc:80.240, train f1:78.998, train precision:81.502, train recall:78.695, train kappa:79.469
fold:2 epoch:21 step:6 train loss:0.681810, train acc:80.789, train f1:79.416, train precision:82.506, train recall:79.154, train kappa:80.014
fold:2 epoch:21 step:7 train loss:0.670178, train acc:80.939, train f1:79.537, train precision:81.790, train recall:79.501, train kappa:80.186
fold:2 epoch:21 step:8 train loss:0.686360, train acc:80.612, train f1:79.486, train precision:82.212, train recall:79.580, train kappa:79.836
fold:2 epoch:21 step:9 train loss:0.684047, train acc:80.414, train f1:78.899, train precision:81.144, train recall:78.879, train kappa:79.647
fold:2 epoch:21 step:10 train loss:0.685568, train acc:80.481, train f1:78.946, train precision:80.969, train recall:79.063, train kappa:79.699
fold:2 epoch:21 step:11 train loss:0.679354, train acc:80.214, train f1:79.053, train precision:80.826, train recall:78.933, train kappa:79.426
fold:2 epoch:21        valid loss:0.732845, valid acc:80.193, valid f1:55.797, valid precision:53.400, valid recall:70.563, valid kappa:77.739
None
====================================================================================================
fold:2 epoch:22 step:0 train loss:0.686129, train acc:80.432, train f1:79.077, train precision:80.931, train recall:79.092, train kappa:79.653
fold:2 epoch:22 step:1 train loss:0.676864, train acc:80.704, train f1:79.269, train precision:81.532, train recall:79.217, train kappa:79.940
fold:2 epoch:22 step:2 train loss:0.664060, train acc:80.795, train f1:79.343, train precision:81.593, train recall:79.218, train kappa:80.040
fold:2 epoch:22 step:3 train loss:0.664264, train acc:81.012, train f1:79.347, train precision:81.551, train recall:79.431, train kappa:80.260
fold:2 epoch:22 step:4 train loss:0.666445, train acc:81.012, train f1:79.515, train precision:81.572, train recall:79.795, train kappa:80.263
fold:2 epoch:22 step:5 train loss:0.654485, train acc:81.305, train f1:80.175, train precision:82.305, train recall:80.049, train kappa:80.584
fold:2 epoch:22 step:6 train loss:0.672852, train acc:81.018, train f1:79.733, train precision:81.591, train recall:79.995, train kappa:80.282
fold:2 epoch:22 step:7 train loss:0.680047, train acc:80.585, train f1:79.448, train precision:81.294, train recall:79.556, train kappa:79.825
fold:2 epoch:22 step:8 train loss:0.658716, train acc:81.091, train f1:79.654, train precision:81.885, train recall:79.350, train kappa:80.325
fold:2 epoch:22 step:9 train loss:0.653518, train acc:81.497, train f1:80.202, train precision:82.578, train recall:80.002, train kappa:80.758
fold:2 epoch:22 step:10 train loss:0.681602, train acc:80.646, train f1:79.292, train precision:82.342, train recall:78.853, train kappa:79.880
fold:2 epoch:22 step:11 train loss:0.675598, train acc:81.064, train f1:79.957, train precision:82.737, train recall:79.897, train kappa:80.314
fold:2 epoch:22        valid loss:0.730714, valid acc:80.222, valid f1:56.053, valid precision:53.555, valid recall:71.033, valid kappa:77.784
None
====================================================================================================
fold:2 epoch:23 step:0 train loss:0.652429, train acc:81.488, train f1:79.862, train precision:82.223, train recall:80.001, train kappa:80.769
fold:2 epoch:23 step:1 train loss:0.650050, train acc:81.381, train f1:79.857, train precision:81.656, train recall:80.083, train kappa:80.646
fold:2 epoch:23 step:2 train loss:0.648385, train acc:81.384, train f1:79.871, train precision:81.593, train recall:80.391, train kappa:80.654
fold:2 epoch:23 step:3 train loss:0.658068, train acc:81.253, train f1:79.795, train precision:81.690, train recall:79.965, train kappa:80.507
fold:2 epoch:23 step:4 train loss:0.657870, train acc:81.015, train f1:79.637, train precision:83.024, train recall:79.347, train kappa:80.266
fold:2 epoch:23 step:5 train loss:0.659689, train acc:81.436, train f1:80.218, train precision:82.663, train recall:79.956, train kappa:80.699
fold:2 epoch:23 step:6 train loss:0.657541, train acc:81.033, train f1:80.027, train precision:82.685, train recall:79.579, train kappa:80.276
fold:2 epoch:23 step:7 train loss:0.646941, train acc:81.464, train f1:80.322, train precision:82.843, train recall:80.194, train kappa:80.734
fold:2 epoch:23 step:8 train loss:0.657432, train acc:81.363, train f1:80.222, train precision:82.523, train recall:80.086, train kappa:80.634
fold:2 epoch:23 step:9 train loss:0.643459, train acc:81.735, train f1:80.545, train precision:82.422, train recall:80.629, train kappa:81.027
fold:2 epoch:23 step:10 train loss:0.647128, train acc:81.586, train f1:80.322, train precision:82.182, train recall:80.503, train kappa:80.856
fold:2 epoch:23 step:11 train loss:0.660106, train acc:81.382, train f1:80.096, train precision:81.933, train recall:80.443, train kappa:80.670
fold:2 epoch:23        valid loss:0.723041, valid acc:80.616, valid f1:56.363, valid precision:53.316, valid recall:70.903, valid kappa:78.203
None
====================================================================================================
fold:2 epoch:24 step:0 train loss:0.646616, train acc:81.390, train f1:79.997, train precision:81.572, train recall:80.224, train kappa:80.644
fold:2 epoch:24 step:1 train loss:0.648145, train acc:81.433, train f1:79.876, train precision:82.159, train recall:80.036, train kappa:80.693
fold:2 epoch:24 step:2 train loss:0.650644, train acc:81.201, train f1:79.779, train precision:82.348, train recall:79.674, train kappa:80.462
fold:2 epoch:24 step:3 train loss:0.635505, train acc:81.854, train f1:80.587, train precision:82.727, train recall:80.390, train kappa:81.143
fold:2 epoch:24 step:4 train loss:0.643727, train acc:81.699, train f1:80.614, train precision:83.216, train recall:80.306, train kappa:80.987
fold:2 epoch:24 step:5 train loss:0.636726, train acc:81.815, train f1:80.512, train precision:83.205, train recall:80.305, train kappa:81.094
fold:2 epoch:24 step:6 train loss:0.630122, train acc:81.720, train f1:80.470, train precision:83.361, train recall:80.534, train kappa:81.003
fold:2 epoch:24 step:7 train loss:0.633306, train acc:81.586, train f1:80.139, train precision:81.773, train recall:80.367, train kappa:80.864
fold:2 epoch:24 step:8 train loss:0.641190, train acc:81.595, train f1:80.276, train precision:82.009, train recall:80.819, train kappa:80.884
fold:2 epoch:24 step:9 train loss:0.642015, train acc:81.567, train f1:80.369, train precision:82.015, train recall:80.873, train kappa:80.851
fold:2 epoch:24 step:10 train loss:0.631694, train acc:81.824, train f1:80.629, train precision:83.145, train recall:80.742, train kappa:81.114
fold:2 epoch:24 step:11 train loss:0.621870, train acc:82.000, train f1:80.588, train precision:82.886, train recall:80.167, train kappa:81.298
fold:2 epoch:24        valid loss:0.706887, valid acc:81.052, valid f1:57.090, valid precision:53.912, valid recall:70.469, valid kappa:78.668
None
====================================================================================================
fold:2 epoch:25 step:0 train loss:0.631505, train acc:81.985, train f1:80.634, train precision:83.180, train recall:80.606, train kappa:81.272
fold:2 epoch:25 step:1 train loss:0.633017, train acc:81.732, train f1:80.376, train precision:83.188, train recall:80.079, train kappa:81.025
fold:2 epoch:25 step:2 train loss:0.620473, train acc:81.921, train f1:80.594, train precision:82.547, train recall:80.524, train kappa:81.201
fold:2 epoch:25 step:3 train loss:0.631882, train acc:81.970, train f1:80.948, train precision:84.311, train recall:80.881, train kappa:81.265
fold:2 epoch:25 step:4 train loss:0.627546, train acc:81.958, train f1:80.780, train precision:83.337, train recall:80.970, train kappa:81.267
fold:2 epoch:25 step:5 train loss:0.636098, train acc:81.625, train f1:80.241, train precision:82.159, train recall:80.279, train kappa:80.902
fold:2 epoch:25 step:6 train loss:0.617651, train acc:82.141, train f1:80.739, train precision:83.147, train recall:81.011, train kappa:81.436
fold:2 epoch:25 step:7 train loss:0.625218, train acc:81.873, train f1:80.742, train precision:82.720, train recall:80.929, train kappa:81.154
fold:2 epoch:25 step:8 train loss:0.629414, train acc:81.894, train f1:80.721, train precision:82.551, train recall:80.976, train kappa:81.178
fold:2 epoch:25 step:9 train loss:0.618311, train acc:82.138, train f1:80.984, train precision:83.144, train recall:80.774, train kappa:81.445
fold:2 epoch:25 step:10 train loss:0.628589, train acc:81.870, train f1:80.656, train precision:83.494, train recall:80.447, train kappa:81.143
fold:2 epoch:25 step:11 train loss:0.619800, train acc:81.913, train f1:80.744, train precision:82.984, train recall:80.516, train kappa:81.179
fold:2 epoch:25        valid loss:0.704008, valid acc:81.115, valid f1:57.205, valid precision:55.050, valid recall:70.829, valid kappa:78.741
None
====================================================================================================
fold:2 epoch:26 step:0 train loss:0.614810, train acc:82.346, train f1:81.015, train precision:83.551, train recall:80.942, train kappa:81.656
fold:2 epoch:26 step:1 train loss:0.626438, train acc:81.842, train f1:80.724, train precision:82.644, train recall:80.995, train kappa:81.113
fold:2 epoch:26 step:2 train loss:0.623007, train acc:82.236, train f1:81.142, train precision:82.880, train recall:81.387, train kappa:81.531
fold:2 epoch:26 step:3 train loss:0.611165, train acc:82.397, train f1:81.091, train precision:82.980, train recall:81.320, train kappa:81.711
fold:2 epoch:26 step:4 train loss:0.627623, train acc:81.885, train f1:80.847, train precision:82.878, train recall:80.978, train kappa:81.175
fold:2 epoch:26 step:5 train loss:0.619417, train acc:82.025, train f1:80.749, train precision:82.623, train recall:80.729, train kappa:81.339
fold:2 epoch:26 step:6 train loss:0.611583, train acc:82.193, train f1:80.944, train precision:83.287, train recall:80.851, train kappa:81.500
fold:2 epoch:26 step:7 train loss:0.610106, train acc:82.422, train f1:81.130, train precision:83.195, train recall:81.180, train kappa:81.725
fold:2 epoch:26 step:8 train loss:0.608599, train acc:82.422, train f1:81.114, train precision:83.018, train recall:81.114, train kappa:81.732
fold:2 epoch:26 step:9 train loss:0.607579, train acc:82.480, train f1:81.229, train precision:84.417, train recall:81.376, train kappa:81.777
fold:2 epoch:26 step:10 train loss:0.614368, train acc:82.068, train f1:80.708, train precision:82.748, train recall:80.822, train kappa:81.376
fold:2 epoch:26 step:11 train loss:0.637946, train acc:81.546, train f1:80.453, train precision:82.296, train recall:80.598, train kappa:80.838
fold:2 epoch:26        valid loss:0.705136, valid acc:81.195, valid f1:57.298, valid precision:54.657, valid recall:70.830, valid kappa:78.847
None
====================================================================================================
fold:2 epoch:27 step:0 train loss:0.598897, train acc:82.654, train f1:81.306, train precision:83.442, train recall:81.321, train kappa:81.973
fold:2 epoch:27 step:1 train loss:0.606616, train acc:82.452, train f1:81.038, train precision:82.790, train recall:81.220, train kappa:81.771
fold:2 epoch:27 step:2 train loss:0.615776, train acc:82.144, train f1:81.140, train precision:83.546, train recall:81.281, train kappa:81.456
fold:2 epoch:27 step:3 train loss:0.607695, train acc:82.507, train f1:81.065, train precision:83.519, train recall:81.388, train kappa:81.835
fold:2 epoch:27 step:4 train loss:0.614790, train acc:82.162, train f1:80.910, train precision:82.518, train recall:81.124, train kappa:81.460
fold:2 epoch:27 step:5 train loss:0.598139, train acc:82.553, train f1:81.196, train precision:82.966, train recall:81.261, train kappa:81.877
fold:2 epoch:27 step:6 train loss:0.601792, train acc:82.559, train f1:81.478, train precision:83.585, train recall:81.371, train kappa:81.864
fold:2 epoch:27 step:7 train loss:0.611372, train acc:82.080, train f1:81.297, train precision:83.261, train recall:81.213, train kappa:81.373
fold:2 epoch:27 step:8 train loss:0.594413, train acc:82.794, train f1:81.652, train precision:84.179, train recall:81.349, train kappa:82.114
fold:2 epoch:27 step:9 train loss:0.594925, train acc:82.623, train f1:81.463, train precision:83.951, train recall:81.508, train kappa:81.936
fold:2 epoch:27 step:10 train loss:0.601790, train acc:82.666, train f1:81.523, train precision:83.245, train recall:81.784, train kappa:81.989
fold:2 epoch:27 step:11 train loss:0.607503, train acc:82.289, train f1:81.306, train precision:83.075, train recall:81.616, train kappa:81.617
fold:2 epoch:27        valid loss:0.700899, valid acc:81.446, valid f1:57.484, valid precision:54.903, valid recall:70.817, valid kappa:79.117
None
====================================================================================================
fold:2 epoch:28 step:0 train loss:0.583970, train acc:83.035, train f1:81.695, train precision:83.719, train recall:81.829, train kappa:82.364
fold:2 epoch:28 step:1 train loss:0.589253, train acc:82.971, train f1:81.605, train precision:84.069, train recall:81.743, train kappa:82.297
fold:2 epoch:28 step:2 train loss:0.593991, train acc:82.663, train f1:81.293, train precision:83.210, train recall:81.353, train kappa:81.981
fold:2 epoch:28 step:3 train loss:0.593702, train acc:82.538, train f1:81.246, train precision:83.225, train recall:81.269, train kappa:81.855
fold:2 epoch:28 step:4 train loss:0.583033, train acc:83.127, train f1:81.914, train precision:83.809, train recall:82.069, train kappa:82.478
fold:2 epoch:28 step:5 train loss:0.602523, train acc:82.394, train f1:81.264, train precision:83.187, train recall:81.492, train kappa:81.710
fold:2 epoch:28 step:6 train loss:0.600261, train acc:82.559, train f1:81.267, train precision:83.074, train recall:81.480, train kappa:81.886
fold:2 epoch:28 step:7 train loss:0.602151, train acc:82.474, train f1:81.631, train precision:83.437, train recall:81.580, train kappa:81.786
fold:2 epoch:28 step:8 train loss:0.591964, train acc:82.870, train f1:81.578, train precision:83.741, train recall:81.583, train kappa:82.190
fold:2 epoch:28 step:9 train loss:0.592827, train acc:82.922, train f1:81.833, train precision:83.660, train recall:81.976, train kappa:82.244
fold:2 epoch:28 step:10 train loss:0.590906, train acc:82.919, train f1:81.943, train precision:84.447, train recall:81.807, train kappa:82.269
fold:2 epoch:28 step:11 train loss:0.592210, train acc:83.013, train f1:82.168, train precision:84.422, train recall:81.906, train kappa:82.340
fold:2 epoch:28        valid loss:0.699476, valid acc:81.526, valid f1:57.502, valid precision:54.597, valid recall:71.006, valid kappa:79.205
None
====================================================================================================
fold:2 epoch:29 step:0 train loss:0.592627, train acc:82.587, train f1:81.651, train precision:84.188, train recall:81.622, train kappa:81.917
fold:2 epoch:29 step:1 train loss:0.568106, train acc:83.640, train f1:82.138, train precision:83.821, train recall:82.422, train kappa:83.016
fold:2 epoch:29 step:2 train loss:0.577807, train acc:83.179, train f1:81.768, train precision:83.372, train recall:82.287, train kappa:82.515
fold:2 epoch:29 step:3 train loss:0.590888, train acc:82.812, train f1:81.658, train precision:83.288, train recall:81.922, train kappa:82.127
fold:2 epoch:29 step:4 train loss:0.578292, train acc:83.173, train f1:81.954, train precision:83.923, train recall:82.096, train kappa:82.505
fold:2 epoch:29 step:5 train loss:0.590142, train acc:82.812, train f1:81.788, train precision:84.231, train recall:81.703, train kappa:82.136
fold:2 epoch:29 step:6 train loss:0.584951, train acc:82.993, train f1:81.850, train precision:84.183, train recall:81.691, train kappa:82.327
fold:2 epoch:29 step:7 train loss:0.585681, train acc:82.980, train f1:82.187, train precision:84.932, train recall:82.004, train kappa:82.312
fold:2 epoch:29 step:8 train loss:0.585372, train acc:82.971, train f1:81.889, train precision:84.077, train recall:81.971, train kappa:82.304
fold:2 epoch:29 step:9 train loss:0.584884, train acc:82.834, train f1:81.447, train precision:83.602, train recall:81.634, train kappa:82.176
fold:2 epoch:29 step:10 train loss:0.585786, train acc:82.977, train f1:81.750, train precision:83.624, train recall:82.034, train kappa:82.328
fold:2 epoch:29 step:11 train loss:0.585936, train acc:82.984, train f1:81.400, train precision:84.024, train recall:81.928, train kappa:82.317
fold:2 epoch:29        valid loss:0.699172, valid acc:81.401, valid f1:57.272, valid precision:54.258, valid recall:70.874, valid kappa:79.085
None
====================================================================================================
fold:2 epoch:30 step:0 train loss:0.575503, train acc:83.392, train f1:82.278, train precision:83.741, train recall:82.596, train kappa:82.737
fold:2 epoch:30 step:1 train loss:0.567536, train acc:83.463, train f1:82.298, train precision:84.523, train recall:82.405, train kappa:82.820
fold:2 epoch:30 step:2 train loss:0.568414, train acc:83.615, train f1:82.281, train precision:84.756, train recall:82.323, train kappa:82.971
fold:2 epoch:30 step:3 train loss:0.572370, train acc:83.255, train f1:82.228, train precision:84.340, train recall:82.242, train kappa:82.594
fold:2 epoch:30 step:4 train loss:0.576206, train acc:83.221, train f1:82.383, train precision:85.067, train recall:82.062, train kappa:82.559
fold:2 epoch:30 step:5 train loss:0.579283, train acc:83.209, train f1:82.083, train precision:84.606, train recall:81.777, train kappa:82.557
fold:2 epoch:30 step:6 train loss:0.569547, train acc:83.121, train f1:82.094, train precision:83.922, train recall:82.261, train kappa:82.474
fold:2 epoch:30 step:7 train loss:0.573405, train acc:83.478, train f1:82.332, train precision:84.135, train recall:82.632, train kappa:82.840
fold:2 epoch:30 step:8 train loss:0.581518, train acc:83.115, train f1:81.994, train precision:83.632, train recall:82.331, train kappa:82.451
fold:2 epoch:30 step:9 train loss:0.571790, train acc:83.429, train f1:82.167, train precision:83.804, train recall:82.405, train kappa:82.792
fold:2 epoch:30 step:10 train loss:0.571837, train acc:83.078, train f1:81.857, train precision:83.250, train recall:82.081, train kappa:82.419
fold:2 epoch:30 step:11 train loss:0.552769, train acc:83.592, train f1:82.026, train precision:84.370, train recall:82.108, train kappa:82.958
fold:2 epoch:30        valid loss:0.685705, valid acc:82.037, valid f1:58.247, valid precision:55.638, valid recall:70.977, valid kappa:79.778
None
====================================================================================================
fold:2 epoch:31 step:0 train loss:0.562822, train acc:83.630, train f1:82.447, train precision:84.227, train recall:82.524, train kappa:82.977
fold:2 epoch:31 step:1 train loss:0.566554, train acc:83.380, train f1:82.043, train precision:84.067, train recall:82.127, train kappa:82.746
fold:2 epoch:31 step:2 train loss:0.570653, train acc:83.304, train f1:82.085, train precision:84.407, train recall:82.235, train kappa:82.639
fold:2 epoch:31 step:3 train loss:0.562784, train acc:83.563, train f1:82.259, train precision:84.245, train recall:82.335, train kappa:82.928
fold:2 epoch:31 step:4 train loss:0.566802, train acc:83.447, train f1:82.168, train precision:84.025, train recall:82.292, train kappa:82.806
fold:2 epoch:31 step:5 train loss:0.554058, train acc:83.600, train f1:82.704, train precision:84.562, train recall:82.714, train kappa:82.961
fold:2 epoch:31 step:6 train loss:0.575448, train acc:83.060, train f1:82.199, train precision:83.902, train recall:82.377, train kappa:82.406
fold:2 epoch:31 step:7 train loss:0.551821, train acc:83.850, train f1:82.778, train precision:84.420, train recall:82.981, train kappa:83.216
fold:2 epoch:31 step:8 train loss:0.574202, train acc:83.322, train f1:82.460, train precision:84.343, train recall:82.622, train kappa:82.678
fold:2 epoch:31 step:9 train loss:0.554705, train acc:83.548, train f1:82.288, train precision:84.689, train recall:82.168, train kappa:82.902
fold:2 epoch:31 step:10 train loss:0.567161, train acc:83.398, train f1:82.110, train precision:83.907, train recall:82.334, train kappa:82.759
fold:2 epoch:31 step:11 train loss:0.577504, train acc:83.071, train f1:81.942, train precision:84.486, train recall:82.268, train kappa:82.412
fold:2 epoch:31        valid loss:0.690306, valid acc:81.947, valid f1:58.258, valid precision:55.843, valid recall:71.115, valid kappa:79.675
[81.94736949720898, 58.258412742169355, 55.84291556280869, 71.11481792179084, 79.67534660368096]
====================================================================================================
fold:2 epoch:32 step:0 train loss:0.558408, train acc:83.694, train f1:82.279, train precision:84.088, train recall:82.612, train kappa:83.060
fold:2 epoch:32 step:1 train loss:0.564535, train acc:83.429, train f1:82.283, train precision:83.819, train recall:82.683, train kappa:82.781
fold:2 epoch:32 step:2 train loss:0.561799, train acc:83.554, train f1:82.212, train precision:84.754, train recall:82.309, train kappa:82.909
fold:2 epoch:32 step:3 train loss:0.557916, train acc:83.716, train f1:82.551, train precision:84.425, train recall:82.654, train kappa:83.088
fold:2 epoch:32 step:4 train loss:0.550407, train acc:83.984, train f1:82.904, train precision:85.111, train recall:82.801, train kappa:83.359
fold:2 epoch:32 step:5 train loss:0.563968, train acc:83.435, train f1:82.581, train precision:84.210, train recall:82.651, train kappa:82.791
fold:2 epoch:32 step:6 train loss:0.550042, train acc:83.841, train f1:82.742, train precision:84.359, train recall:82.856, train kappa:83.216
fold:2 epoch:32 step:7 train loss:0.555551, train acc:83.612, train f1:82.693, train precision:84.695, train recall:82.568, train kappa:82.978
fold:2 epoch:32 step:8 train loss:0.553834, train acc:83.844, train f1:82.734, train precision:84.440, train recall:82.864, train kappa:83.213
fold:2 epoch:32 step:9 train loss:0.545339, train acc:83.856, train f1:82.608, train precision:84.430, train recall:82.871, train kappa:83.210
fold:2 epoch:32 step:10 train loss:0.559709, train acc:83.536, train f1:82.477, train precision:84.479, train recall:82.533, train kappa:82.897
fold:2 epoch:32 step:11 train loss:0.546094, train acc:84.316, train f1:82.846, train precision:85.024, train recall:83.121, train kappa:83.739
fold:2 epoch:32        valid loss:0.681929, valid acc:82.064, valid f1:57.947, valid precision:54.942, valid recall:70.846, valid kappa:79.819
[1;31mTest score increased (81.947369 --> 82.063917).[0m
[82.06391723066227, 57.947218375704765, 54.94176417938855, 70.84572137542352, 79.81852589572726]
====================================================================================================
fold:2 epoch:33 step:0 train loss:0.549831, train acc:83.948, train f1:82.753, train precision:85.022, train recall:83.046, train kappa:83.331
fold:2 epoch:33 step:1 train loss:0.549718, train acc:84.018, train f1:82.820, train precision:84.796, train recall:82.920, train kappa:83.402
fold:2 epoch:33 step:2 train loss:0.546214, train acc:83.755, train f1:82.798, train precision:84.413, train recall:83.234, train kappa:83.132
fold:2 epoch:33 step:3 train loss:0.543052, train acc:84.119, train f1:82.738, train precision:84.556, train recall:82.952, train kappa:83.507
fold:2 epoch:33 step:4 train loss:0.541329, train acc:84.125, train f1:82.641, train precision:84.366, train recall:82.677, train kappa:83.507
fold:2 epoch:33 step:5 train loss:0.548575, train acc:83.981, train f1:82.859, train precision:84.765, train recall:83.040, train kappa:83.354
fold:2 epoch:33 step:6 train loss:0.544756, train acc:83.737, train f1:82.621, train precision:84.494, train recall:82.802, train kappa:83.104
fold:2 epoch:33 step:7 train loss:0.544649, train acc:83.926, train f1:82.944, train precision:85.272, train recall:82.936, train kappa:83.293
fold:2 epoch:33 step:8 train loss:0.544342, train acc:83.841, train f1:82.843, train precision:84.618, train recall:82.874, train kappa:83.222
fold:2 epoch:33 step:9 train loss:0.553798, train acc:83.832, train f1:82.773, train precision:84.709, train recall:82.799, train kappa:83.194
fold:2 epoch:33 step:10 train loss:0.549731, train acc:83.792, train f1:82.951, train precision:84.829, train recall:83.124, train kappa:83.156
fold:2 epoch:33 step:11 train loss:0.545878, train acc:83.959, train f1:82.524, train precision:84.552, train recall:82.791, train kappa:83.314
fold:2 epoch:33        valid loss:0.688012, valid acc:82.029, valid f1:58.195, valid precision:55.041, valid recall:70.947, valid kappa:79.763
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.06391723066227, 57.947218375704765, 54.94176417938855, 70.84572137542352, 79.81852589572726]
====================================================================================================
fold:2 epoch:34 step:0 train loss:0.538670, train acc:84.097, train f1:82.999, train precision:85.329, train recall:83.118, train kappa:83.490
fold:2 epoch:34 step:1 train loss:0.537455, train acc:84.396, train f1:83.070, train precision:85.063, train recall:83.274, train kappa:83.789
fold:2 epoch:34 step:2 train loss:0.550188, train acc:84.024, train f1:82.951, train precision:85.591, train recall:82.986, train kappa:83.404
fold:2 epoch:34 step:3 train loss:0.542526, train acc:84.048, train f1:82.817, train precision:84.797, train recall:83.123, train kappa:83.430
fold:2 epoch:34 step:4 train loss:0.545025, train acc:84.073, train f1:82.817, train precision:85.062, train recall:83.104, train kappa:83.463
fold:2 epoch:34 step:5 train loss:0.542758, train acc:84.131, train f1:83.070, train precision:84.733, train recall:83.324, train kappa:83.525
fold:2 epoch:34 step:6 train loss:0.526365, train acc:84.479, train f1:83.143, train precision:84.850, train recall:83.438, train kappa:83.876
fold:2 epoch:34 step:7 train loss:0.538108, train acc:84.061, train f1:82.968, train precision:84.134, train recall:83.373, train kappa:83.442
fold:2 epoch:34 step:8 train loss:0.532214, train acc:84.103, train f1:83.049, train precision:85.101, train recall:83.060, train kappa:83.476
fold:2 epoch:34 step:9 train loss:0.531688, train acc:84.378, train f1:83.520, train precision:85.742, train recall:83.389, train kappa:83.760
fold:2 epoch:34 step:10 train loss:0.547084, train acc:83.994, train f1:83.035, train precision:85.082, train recall:83.042, train kappa:83.362
fold:2 epoch:34 step:11 train loss:0.550397, train acc:83.621, train f1:82.997, train precision:84.563, train recall:83.241, train kappa:82.994
fold:2 epoch:34        valid loss:0.675741, valid acc:82.369, valid f1:59.184, valid precision:56.065, valid recall:70.952, valid kappa:80.141
[1;31mTest score increased (82.063917 --> 82.368577).[0m
[82.36857709530334, 59.18370624162152, 56.06542961629037, 70.95191521877933, 80.14055448539582]
====================================================================================================
fold:2 epoch:35 step:0 train loss:0.535636, train acc:84.082, train f1:83.302, train precision:85.425, train recall:83.079, train kappa:83.450
fold:2 epoch:35 step:1 train loss:0.528696, train acc:84.183, train f1:83.002, train precision:84.844, train recall:82.882, train kappa:83.567
fold:2 epoch:35 step:2 train loss:0.533582, train acc:84.155, train f1:83.351, train precision:84.904, train recall:83.581, train kappa:83.543
fold:2 epoch:35 step:3 train loss:0.549212, train acc:83.716, train f1:82.828, train precision:83.935, train recall:83.230, train kappa:83.094
fold:2 epoch:35 step:4 train loss:0.532275, train acc:84.381, train f1:83.393, train precision:84.946, train recall:83.857, train kappa:83.796
fold:2 epoch:35 step:5 train loss:0.532359, train acc:84.344, train f1:83.199, train precision:84.849, train recall:83.438, train kappa:83.728
fold:2 epoch:35 step:6 train loss:0.537094, train acc:84.305, train f1:83.282, train precision:85.299, train recall:83.500, train kappa:83.693
fold:2 epoch:35 step:7 train loss:0.533763, train acc:84.393, train f1:83.370, train precision:85.079, train recall:83.474, train kappa:83.793
fold:2 epoch:35 step:8 train loss:0.532409, train acc:84.268, train f1:82.887, train precision:84.793, train recall:82.980, train kappa:83.652
fold:2 epoch:35 step:9 train loss:0.531841, train acc:84.167, train f1:83.260, train precision:84.628, train recall:83.395, train kappa:83.544
fold:2 epoch:35 step:10 train loss:0.522500, train acc:84.531, train f1:83.355, train precision:85.179, train recall:83.340, train kappa:83.931
fold:2 epoch:35 step:11 train loss:0.536440, train acc:84.133, train f1:83.153, train precision:84.708, train recall:83.382, train kappa:83.533
fold:2 epoch:35        valid loss:0.682735, valid acc:82.174, valid f1:58.494, valid precision:55.448, valid recall:71.020, valid kappa:79.936
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.36857709530334, 59.18370624162152, 56.06542961629037, 70.95191521877933, 80.14055448539582]
====================================================================================================
fold:2 epoch:36 step:0 train loss:0.519667, train acc:84.442, train f1:83.507, train precision:85.150, train recall:83.708, train kappa:83.837
fold:2 epoch:36 step:1 train loss:0.526668, train acc:84.610, train f1:83.562, train precision:85.279, train recall:83.818, train kappa:84.020
fold:2 epoch:36 step:2 train loss:0.524631, train acc:84.302, train f1:83.213, train precision:84.571, train recall:83.603, train kappa:83.684
fold:2 epoch:36 step:3 train loss:0.522437, train acc:84.576, train f1:83.579, train precision:85.634, train recall:83.909, train kappa:83.985
fold:2 epoch:36 step:4 train loss:0.526179, train acc:84.482, train f1:83.296, train precision:85.593, train recall:83.430, train kappa:83.885
fold:2 epoch:36 step:5 train loss:0.525327, train acc:84.372, train f1:83.258, train precision:85.633, train recall:83.132, train kappa:83.760
fold:2 epoch:36 step:6 train loss:0.518165, train acc:84.735, train f1:83.743, train precision:86.001, train recall:83.475, train kappa:84.138
fold:2 epoch:36 step:7 train loss:0.525202, train acc:84.491, train f1:83.371, train precision:84.919, train recall:83.630, train kappa:83.889
fold:2 epoch:36 step:8 train loss:0.532925, train acc:84.348, train f1:83.191, train precision:84.746, train recall:83.488, train kappa:83.735
fold:2 epoch:36 step:9 train loss:0.530273, train acc:84.073, train f1:83.123, train precision:84.885, train recall:83.262, train kappa:83.456
fold:2 epoch:36 step:10 train loss:0.529782, train acc:84.235, train f1:83.210, train precision:84.970, train recall:83.396, train kappa:83.630
fold:2 epoch:36 step:11 train loss:0.529650, train acc:84.577, train f1:83.687, train precision:85.493, train recall:83.860, train kappa:83.985
fold:2 epoch:36        valid loss:0.680576, valid acc:82.344, valid f1:58.762, valid precision:55.595, valid recall:70.949, valid kappa:80.121
[1;31mEarlyStopping counter: 2 out of 50[0m
[82.36857709530334, 59.18370624162152, 56.06542961629037, 70.95191521877933, 80.14055448539582]
====================================================================================================
fold:2 epoch:37 step:0 train loss:0.521644, train acc:84.369, train f1:83.440, train precision:85.274, train recall:83.559, train kappa:83.772
fold:2 epoch:37 step:1 train loss:0.517611, train acc:84.650, train f1:83.791, train precision:85.568, train recall:83.777, train kappa:84.060
fold:2 epoch:37 step:2 train loss:0.523448, train acc:84.271, train f1:83.212, train precision:84.969, train recall:83.232, train kappa:83.669
fold:2 epoch:37 step:3 train loss:0.518857, train acc:84.717, train f1:83.760, train precision:85.576, train recall:83.900, train kappa:84.117
fold:2 epoch:37 step:4 train loss:0.508367, train acc:84.885, train f1:83.851, train precision:85.350, train recall:83.973, train kappa:84.292
fold:2 epoch:37 step:5 train loss:0.514227, train acc:84.814, train f1:83.924, train precision:85.871, train recall:84.205, train kappa:84.223
fold:2 epoch:37 step:6 train loss:0.515246, train acc:84.854, train f1:83.881, train precision:85.788, train recall:83.908, train kappa:84.255
fold:2 epoch:37 step:7 train loss:0.510920, train acc:84.879, train f1:83.779, train precision:85.506, train recall:83.940, train kappa:84.291
fold:2 epoch:37 step:8 train loss:0.523447, train acc:84.320, train f1:83.599, train precision:85.455, train recall:83.791, train kappa:83.724
fold:2 epoch:37 step:9 train loss:0.520792, train acc:84.656, train f1:83.469, train precision:85.444, train recall:83.609, train kappa:84.063
fold:2 epoch:37 step:10 train loss:0.518764, train acc:84.665, train f1:83.556, train precision:85.338, train recall:83.593, train kappa:84.061
fold:2 epoch:37 step:11 train loss:0.504281, train acc:84.953, train f1:83.664, train precision:85.818, train recall:83.710, train kappa:84.372
fold:2 epoch:37        valid loss:0.678152, valid acc:82.360, valid f1:58.662, valid precision:55.454, valid recall:70.920, valid kappa:80.145
[1;31mEarlyStopping counter: 3 out of 50[0m
[82.36857709530334, 59.18370624162152, 56.06542961629037, 70.95191521877933, 80.14055448539582]
====================================================================================================
fold:2 epoch:38 step:0 train loss:0.514400, train acc:84.756, train f1:83.408, train precision:84.844, train recall:83.773, train kappa:84.163
fold:2 epoch:38 step:1 train loss:0.511161, train acc:84.921, train f1:83.876, train precision:85.182, train recall:84.179, train kappa:84.350
fold:2 epoch:38 step:2 train loss:0.506529, train acc:84.918, train f1:83.686, train precision:85.187, train recall:84.060, train kappa:84.337
fold:2 epoch:38 step:3 train loss:0.508922, train acc:85.031, train f1:84.044, train precision:85.855, train recall:84.377, train kappa:84.451
fold:2 epoch:38 step:4 train loss:0.518679, train acc:84.454, train f1:83.556, train precision:85.073, train recall:83.823, train kappa:83.860
fold:2 epoch:38 step:5 train loss:0.512236, train acc:84.683, train f1:83.571, train precision:85.051, train recall:83.921, train kappa:84.088
fold:2 epoch:38 step:6 train loss:0.514355, train acc:84.915, train f1:83.874, train precision:85.563, train recall:84.007, train kappa:84.331
fold:2 epoch:38 step:7 train loss:0.511015, train acc:84.641, train f1:83.590, train precision:85.878, train recall:83.580, train kappa:84.049
fold:2 epoch:38 step:8 train loss:0.512715, train acc:84.689, train f1:83.847, train precision:85.556, train recall:83.893, train kappa:84.088
fold:2 epoch:38 step:9 train loss:0.510470, train acc:84.763, train f1:83.686, train precision:85.374, train recall:83.814, train kappa:84.167
fold:2 epoch:38 step:10 train loss:0.500676, train acc:85.159, train f1:84.093, train precision:86.020, train recall:84.064, train kappa:84.585
fold:2 epoch:38 step:11 train loss:0.514921, train acc:84.905, train f1:84.065, train precision:85.719, train recall:84.444, train kappa:84.332
fold:2 epoch:38        valid loss:0.681001, valid acc:82.375, valid f1:58.661, valid precision:55.327, valid recall:71.191, valid kappa:80.161
[1;31mTest score increased (82.368577 --> 82.374711).[0m
[82.37471118653772, 58.66118952816978, 55.327374646954794, 71.19093576284891, 80.16104747943419]
====================================================================================================
fold:2 epoch:39 step:0 train loss:0.516332, train acc:84.808, train f1:83.905, train precision:85.800, train recall:84.189, train kappa:84.222
fold:2 epoch:39 step:1 train loss:0.509710, train acc:84.744, train f1:83.694, train precision:85.506, train recall:84.075, train kappa:84.168
fold:2 epoch:39 step:2 train loss:0.512239, train acc:84.842, train f1:83.813, train precision:85.892, train recall:84.037, train kappa:84.252
fold:2 epoch:39 step:3 train loss:0.503132, train acc:84.967, train f1:83.858, train precision:85.857, train recall:84.130, train kappa:84.380
fold:2 epoch:39 step:4 train loss:0.505932, train acc:85.104, train f1:84.274, train precision:86.004, train recall:84.424, train kappa:84.532
fold:2 epoch:39 step:5 train loss:0.500559, train acc:85.190, train f1:84.184, train precision:85.588, train recall:84.435, train kappa:84.620
fold:2 epoch:39 step:6 train loss:0.514591, train acc:84.778, train f1:83.896, train precision:85.728, train recall:83.946, train kappa:84.186
fold:2 epoch:39 step:7 train loss:0.506495, train acc:84.869, train f1:83.845, train precision:85.777, train recall:83.857, train kappa:84.288
fold:2 epoch:39 step:8 train loss:0.502670, train acc:85.153, train f1:84.205, train precision:85.458, train recall:84.423, train kappa:84.581
fold:2 epoch:39 step:9 train loss:0.499763, train acc:85.016, train f1:84.045, train precision:85.722, train recall:84.170, train kappa:84.434
fold:2 epoch:39 step:10 train loss:0.508823, train acc:84.912, train f1:83.794, train precision:85.199, train recall:84.002, train kappa:84.324
fold:2 epoch:39 step:11 train loss:0.506817, train acc:84.886, train f1:83.579, train precision:85.065, train recall:83.986, train kappa:84.321
fold:2 epoch:39        valid loss:0.675113, valid acc:82.542, valid f1:59.010, valid precision:55.847, valid recall:71.075, valid kappa:80.341
[1;31mTest score increased (82.374711 --> 82.542376).[0m
[82.5423763469442, 59.01034052450014, 55.84671170710722, 71.07549291019848, 80.3407961086901]
====================================================================================================
fold:2 epoch:40 step:0 train loss:0.488657, train acc:85.413, train f1:84.408, train precision:86.543, train recall:84.447, train kappa:84.861
fold:2 epoch:40 step:1 train loss:0.492244, train acc:85.226, train f1:84.148, train precision:85.925, train recall:84.329, train kappa:84.658
fold:2 epoch:40 step:2 train loss:0.506673, train acc:85.028, train f1:84.170, train precision:86.290, train recall:84.412, train kappa:84.451
fold:2 epoch:40 step:3 train loss:0.497294, train acc:85.019, train f1:83.989, train precision:85.583, train recall:84.254, train kappa:84.453
fold:2 epoch:40 step:4 train loss:0.501981, train acc:84.995, train f1:83.858, train precision:85.296, train recall:84.045, train kappa:84.416
fold:2 epoch:40 step:5 train loss:0.499106, train acc:85.352, train f1:84.259, train precision:85.822, train recall:84.452, train kappa:84.786
fold:2 epoch:40 step:6 train loss:0.506857, train acc:85.007, train f1:83.967, train precision:86.016, train recall:84.067, train kappa:84.430
fold:2 epoch:40 step:7 train loss:0.497174, train acc:85.297, train f1:84.256, train precision:86.116, train recall:84.340, train kappa:84.723
fold:2 epoch:40 step:8 train loss:0.494465, train acc:85.233, train f1:84.153, train precision:85.816, train recall:84.254, train kappa:84.657
fold:2 epoch:40 step:9 train loss:0.498541, train acc:85.098, train f1:84.307, train precision:85.912, train recall:84.548, train kappa:84.520
fold:2 epoch:40 step:10 train loss:0.509549, train acc:84.982, train f1:83.880, train precision:85.221, train recall:84.389, train kappa:84.392
fold:2 epoch:40 step:11 train loss:0.498071, train acc:85.619, train f1:84.393, train precision:85.809, train recall:85.005, train kappa:85.056
fold:2 epoch:40        valid loss:0.667064, valid acc:82.820, valid f1:59.506, valid precision:56.417, valid recall:71.115, valid kappa:80.653
[1;31mTest score increased (82.542376 --> 82.820455).[0m
[82.8204551495696, 59.505952337951626, 56.41731529936486, 71.11521664884242, 80.65311121437331]
====================================================================================================
fold:2 epoch:41 step:0 train loss:0.495942, train acc:85.196, train f1:84.079, train precision:85.946, train recall:84.258, train kappa:84.618
fold:2 epoch:41 step:1 train loss:0.494071, train acc:85.065, train f1:84.233, train precision:86.262, train recall:84.043, train kappa:84.483
fold:2 epoch:41 step:2 train loss:0.497992, train acc:84.991, train f1:84.201, train precision:85.912, train recall:84.124, train kappa:84.397
fold:2 epoch:41 step:3 train loss:0.488776, train acc:85.526, train f1:84.344, train precision:85.825, train recall:84.405, train kappa:84.960
fold:2 epoch:41 step:4 train loss:0.492169, train acc:85.342, train f1:84.523, train precision:85.997, train recall:84.680, train kappa:84.782
fold:2 epoch:41 step:5 train loss:0.488298, train acc:85.239, train f1:84.234, train precision:85.732, train recall:84.270, train kappa:84.661
fold:2 epoch:41 step:6 train loss:0.488168, train acc:85.458, train f1:84.551, train precision:86.051, train recall:84.634, train kappa:84.901
fold:2 epoch:41 step:7 train loss:0.495276, train acc:85.083, train f1:84.023, train precision:85.160, train recall:84.443, train kappa:84.516
fold:2 epoch:41 step:8 train loss:0.493963, train acc:85.196, train f1:84.193, train precision:85.538, train recall:84.519, train kappa:84.624
fold:2 epoch:41 step:9 train loss:0.496150, train acc:85.126, train f1:84.312, train precision:86.462, train recall:84.419, train kappa:84.552
fold:2 epoch:41 step:10 train loss:0.490118, train acc:85.580, train f1:84.602, train precision:86.260, train recall:84.748, train kappa:85.034
fold:2 epoch:41 step:11 train loss:0.502518, train acc:85.301, train f1:84.303, train precision:86.107, train recall:84.604, train kappa:84.731
fold:2 epoch:41        valid loss:0.669183, valid acc:82.921, valid f1:59.543, valid precision:56.508, valid recall:71.022, valid kappa:80.760
[1;31mTest score increased (82.820455 --> 82.920645).[0m
[82.92064530639786, 59.542697507696786, 56.50824089450125, 71.0220830218058, 80.7600365169569]
====================================================================================================
fold:2 epoch:42 step:0 train loss:0.492714, train acc:85.376, train f1:84.447, train precision:86.140, train recall:84.606, train kappa:84.815
fold:2 epoch:42 step:1 train loss:0.478276, train acc:85.596, train f1:84.624, train precision:86.266, train recall:84.813, train kappa:85.034
fold:2 epoch:42 step:2 train loss:0.491882, train acc:85.306, train f1:84.428, train precision:85.658, train recall:84.555, train kappa:84.738
fold:2 epoch:42 step:3 train loss:0.489417, train acc:85.562, train f1:84.615, train precision:85.936, train recall:84.977, train kappa:85.003
fold:2 epoch:42 step:4 train loss:0.498047, train acc:85.049, train f1:84.128, train precision:85.695, train recall:84.434, train kappa:84.474
fold:2 epoch:42 step:5 train loss:0.474582, train acc:86.020, train f1:84.770, train precision:86.531, train recall:85.046, train kappa:85.472
fold:2 epoch:42 step:6 train loss:0.489917, train acc:85.257, train f1:84.358, train precision:86.154, train recall:84.334, train kappa:84.687
fold:2 epoch:42 step:7 train loss:0.492090, train acc:85.077, train f1:84.283, train precision:86.013, train recall:84.301, train kappa:84.504
fold:2 epoch:42 step:8 train loss:0.487736, train acc:85.358, train f1:84.273, train precision:85.939, train recall:84.408, train kappa:84.800
fold:2 epoch:42 step:9 train loss:0.482162, train acc:85.370, train f1:84.457, train precision:86.026, train recall:84.648, train kappa:84.804
fold:2 epoch:42 step:10 train loss:0.490131, train acc:85.571, train f1:84.598, train precision:86.225, train recall:84.818, train kappa:85.019
fold:2 epoch:42 step:11 train loss:0.500429, train acc:85.011, train f1:83.916, train precision:84.781, train recall:84.465, train kappa:84.438
fold:2 epoch:42        valid loss:0.676327, valid acc:82.696, valid f1:59.216, valid precision:56.086, valid recall:71.006, valid kappa:80.514
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.92064530639786, 59.542697507696786, 56.50824089450125, 71.0220830218058, 80.7600365169569]
====================================================================================================
fold:2 epoch:43 step:0 train loss:0.488851, train acc:85.315, train f1:84.367, train precision:85.615, train recall:84.758, train kappa:84.766
fold:2 epoch:43 step:1 train loss:0.484247, train acc:85.602, train f1:84.454, train precision:86.089, train recall:84.585, train kappa:85.046
fold:2 epoch:43 step:2 train loss:0.488426, train acc:85.345, train f1:84.603, train precision:86.394, train recall:84.840, train kappa:84.788
fold:2 epoch:43 step:3 train loss:0.466593, train acc:86.026, train f1:84.845, train precision:86.406, train recall:85.025, train kappa:85.485
fold:2 epoch:43 step:4 train loss:0.484458, train acc:85.483, train f1:84.587, train precision:86.340, train recall:84.768, train kappa:84.925
fold:2 epoch:43 step:5 train loss:0.483106, train acc:85.443, train f1:84.348, train precision:86.147, train recall:84.502, train kappa:84.887
fold:2 epoch:43 step:6 train loss:0.491828, train acc:85.226, train f1:84.543, train precision:86.040, train recall:84.573, train kappa:84.654
fold:2 epoch:43 step:7 train loss:0.478375, train acc:85.608, train f1:84.786, train precision:86.493, train recall:84.945, train kappa:85.048
fold:2 epoch:43 step:8 train loss:0.488761, train acc:85.297, train f1:84.302, train precision:85.892, train recall:84.682, train kappa:84.727
fold:2 epoch:43 step:9 train loss:0.476048, train acc:85.779, train f1:84.653, train precision:86.087, train recall:84.948, train kappa:85.221
fold:2 epoch:43 step:10 train loss:0.482950, train acc:85.474, train f1:84.500, train precision:86.017, train recall:84.626, train kappa:84.905
fold:2 epoch:43 step:11 train loss:0.484389, train acc:85.542, train f1:84.657, train precision:85.829, train recall:84.912, train kappa:85.001
fold:2 epoch:43        valid loss:0.668171, valid acc:83.013, valid f1:59.703, valid precision:56.975, valid recall:70.703, valid kappa:80.861
[1;31mTest score increased (82.920645 --> 83.012657).[0m
[83.01265667491361, 59.70258810735156, 56.97519301707625, 70.70263829583223, 80.861358858091]
====================================================================================================
fold:2 epoch:44 step:0 train loss:0.470131, train acc:86.005, train f1:84.902, train precision:86.621, train recall:85.125, train kappa:85.454
fold:2 epoch:44 step:1 train loss:0.483261, train acc:85.342, train f1:84.421, train precision:86.337, train recall:84.478, train kappa:84.776
fold:2 epoch:44 step:2 train loss:0.473971, train acc:85.571, train f1:84.538, train precision:86.395, train recall:84.636, train kappa:85.019
fold:2 epoch:44 step:3 train loss:0.476031, train acc:85.721, train f1:84.783, train precision:86.638, train recall:84.907, train kappa:85.165
fold:2 epoch:44 step:4 train loss:0.480420, train acc:85.706, train f1:84.843, train precision:86.431, train recall:85.148, train kappa:85.158
fold:2 epoch:44 step:5 train loss:0.472471, train acc:85.626, train f1:84.666, train precision:85.947, train recall:84.942, train kappa:85.083
fold:2 epoch:44 step:6 train loss:0.478851, train acc:85.391, train f1:84.573, train precision:85.951, train recall:84.776, train kappa:84.829
fold:2 epoch:44 step:7 train loss:0.480137, train acc:85.495, train f1:84.530, train precision:86.025, train recall:84.532, train kappa:84.938
fold:2 epoch:44 step:8 train loss:0.481795, train acc:85.355, train f1:84.459, train precision:85.869, train recall:84.512, train kappa:84.795
fold:2 epoch:44 step:9 train loss:0.484766, train acc:85.364, train f1:84.369, train precision:85.523, train recall:84.939, train kappa:84.805
fold:2 epoch:44 step:10 train loss:0.477341, train acc:85.571, train f1:84.662, train precision:85.823, train recall:85.083, train kappa:85.014
fold:2 epoch:44 step:11 train loss:0.471177, train acc:85.812, train f1:85.035, train precision:86.464, train recall:85.293, train kappa:85.261
fold:2 epoch:44        valid loss:0.667589, valid acc:83.125, valid f1:59.671, valid precision:56.832, valid recall:70.750, valid kappa:80.981
[1;31mTest score increased (83.012657 --> 83.125115).[0m
[83.12511501421065, 59.67108994135856, 56.831592139970724, 70.75038969058211, 80.98095996378873]
====================================================================================================
fold:2 epoch:45 step:0 train loss:0.469280, train acc:85.797, train f1:84.870, train precision:86.871, train recall:84.810, train kappa:85.255
fold:2 epoch:45 step:1 train loss:0.485583, train acc:85.492, train f1:84.610, train precision:86.611, train recall:84.573, train kappa:84.933
fold:2 epoch:45 step:2 train loss:0.473995, train acc:85.864, train f1:84.785, train precision:86.885, train recall:84.837, train kappa:85.317
fold:2 epoch:45 step:3 train loss:0.469272, train acc:85.913, train f1:84.840, train precision:86.631, train recall:85.195, train kappa:85.365
fold:2 epoch:45 step:4 train loss:0.466885, train acc:85.941, train f1:84.993, train precision:86.269, train recall:85.309, train kappa:85.387
fold:2 epoch:45 step:5 train loss:0.480224, train acc:85.703, train f1:84.750, train precision:86.081, train recall:84.945, train kappa:85.169
fold:2 epoch:45 step:6 train loss:0.471012, train acc:85.919, train f1:85.048, train precision:86.008, train recall:85.359, train kappa:85.380
fold:2 epoch:45 step:7 train loss:0.471087, train acc:85.632, train f1:84.773, train precision:85.853, train recall:85.133, train kappa:85.090
fold:2 epoch:45 step:8 train loss:0.466023, train acc:85.864, train f1:84.888, train precision:86.716, train recall:84.808, train kappa:85.311
fold:2 epoch:45 step:9 train loss:0.480736, train acc:85.486, train f1:84.610, train precision:86.320, train recall:84.751, train kappa:84.929
fold:2 epoch:45 step:10 train loss:0.463343, train acc:86.102, train f1:85.113, train precision:86.418, train recall:85.424, train kappa:85.561
fold:2 epoch:45 step:11 train loss:0.465487, train acc:86.063, train f1:85.033, train precision:86.708, train recall:85.112, train kappa:85.507
fold:2 epoch:45        valid loss:0.666847, valid acc:83.052, valid f1:59.638, valid precision:56.549, valid recall:70.961, valid kappa:80.904
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.12511501421065, 59.67108994135856, 56.831592139970724, 70.75038969058211, 80.98095996378873]
====================================================================================================
fold:2 epoch:46 step:0 train loss:0.468938, train acc:85.968, train f1:85.086, train precision:86.532, train recall:85.213, train kappa:85.419
fold:2 epoch:46 step:1 train loss:0.464305, train acc:85.953, train f1:85.001, train precision:86.192, train recall:85.359, train kappa:85.408
fold:2 epoch:46 step:2 train loss:0.467651, train acc:85.892, train f1:85.012, train precision:86.309, train recall:85.162, train kappa:85.356
fold:2 epoch:46 step:3 train loss:0.462795, train acc:85.861, train f1:84.961, train precision:86.087, train recall:85.416, train kappa:85.320
fold:2 epoch:46 step:4 train loss:0.461523, train acc:86.066, train f1:85.003, train precision:86.280, train recall:85.342, train kappa:85.530
fold:2 epoch:46 step:5 train loss:0.480072, train acc:85.483, train f1:84.429, train precision:86.241, train recall:84.623, train kappa:84.916
fold:2 epoch:46 step:6 train loss:0.459142, train acc:86.035, train f1:85.164, train precision:86.686, train recall:85.288, train kappa:85.492
fold:2 epoch:46 step:7 train loss:0.466837, train acc:86.011, train f1:84.990, train precision:86.440, train recall:85.091, train kappa:85.476
fold:2 epoch:46 step:8 train loss:0.473192, train acc:85.800, train f1:85.075, train precision:86.657, train recall:85.192, train kappa:85.273
fold:2 epoch:46 step:9 train loss:0.478402, train acc:85.699, train f1:84.552, train precision:85.795, train recall:85.004, train kappa:85.143
fold:2 epoch:46 step:10 train loss:0.475802, train acc:85.614, train f1:84.782, train precision:85.935, train recall:85.233, train kappa:85.068
fold:2 epoch:46 step:11 train loss:0.470343, train acc:85.629, train f1:84.663, train precision:85.631, train recall:85.100, train kappa:85.094
fold:2 epoch:46        valid loss:0.661923, valid acc:83.256, valid f1:59.888, valid precision:56.896, valid recall:70.825, valid kappa:81.136
[1;31mTest score increased (83.125115 --> 83.255976).[0m
[83.25597562721083, 59.88828425033604, 56.895576219466705, 70.82540522071697, 81.13647479087905]
====================================================================================================
fold:2 epoch:47 step:0 train loss:0.461160, train acc:86.166, train f1:85.387, train precision:86.968, train recall:85.646, train kappa:85.641
fold:2 epoch:47 step:1 train loss:0.460984, train acc:86.234, train f1:85.386, train precision:87.149, train recall:85.441, train kappa:85.702
fold:2 epoch:47 step:2 train loss:0.466225, train acc:85.721, train f1:84.876, train precision:86.691, train recall:84.825, train kappa:85.161
fold:2 epoch:47 step:3 train loss:0.461067, train acc:85.971, train f1:84.656, train precision:86.400, train recall:84.794, train kappa:85.421
fold:2 epoch:47 step:4 train loss:0.456963, train acc:86.279, train f1:85.483, train precision:86.898, train recall:85.672, train kappa:85.756
fold:2 epoch:47 step:5 train loss:0.468125, train acc:86.099, train f1:85.245, train precision:86.410, train recall:85.612, train kappa:85.580
fold:2 epoch:47 step:6 train loss:0.465871, train acc:86.087, train f1:85.099, train precision:86.282, train recall:85.563, train kappa:85.554
fold:2 epoch:47 step:7 train loss:0.453476, train acc:86.377, train f1:85.290, train precision:86.734, train recall:85.473, train kappa:85.850
fold:2 epoch:47 step:8 train loss:0.466645, train acc:85.779, train f1:85.117, train precision:86.895, train recall:85.257, train kappa:85.238
fold:2 epoch:47 step:9 train loss:0.470105, train acc:85.852, train f1:84.794, train precision:86.260, train recall:85.005, train kappa:85.294
fold:2 epoch:47 step:10 train loss:0.469118, train acc:85.840, train f1:84.776, train precision:86.608, train recall:84.932, train kappa:85.294
fold:2 epoch:47 step:11 train loss:0.481357, train acc:85.590, train f1:84.534, train precision:86.159, train recall:84.698, train kappa:85.038
fold:2 epoch:47        valid loss:0.667609, valid acc:83.039, valid f1:60.111, valid precision:56.812, valid recall:71.341, valid kappa:80.907
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.25597562721083, 59.88828425033604, 56.895576219466705, 70.82540522071697, 81.13647479087905]
====================================================================================================
fold:2 epoch:48 step:0 train loss:0.458158, train acc:86.206, train f1:85.277, train precision:86.727, train recall:85.316, train kappa:85.688
fold:2 epoch:48 step:1 train loss:0.454057, train acc:86.282, train f1:85.158, train precision:86.080, train recall:85.589, train kappa:85.739
fold:2 epoch:48 step:2 train loss:0.456579, train acc:86.136, train f1:85.331, train precision:86.097, train recall:85.828, train kappa:85.608
fold:2 epoch:48 step:3 train loss:0.456928, train acc:86.047, train f1:85.258, train precision:86.805, train recall:85.468, train kappa:85.523
fold:2 epoch:48 step:4 train loss:0.457589, train acc:86.105, train f1:85.097, train precision:86.746, train recall:85.147, train kappa:85.562
fold:2 epoch:48 step:5 train loss:0.453645, train acc:86.328, train f1:85.395, train precision:87.423, train recall:85.316, train kappa:85.805
fold:2 epoch:48 step:6 train loss:0.463232, train acc:85.822, train f1:84.868, train precision:86.590, train recall:85.063, train kappa:85.279
fold:2 epoch:48 step:7 train loss:0.460550, train acc:86.029, train f1:85.251, train precision:86.752, train recall:85.410, train kappa:85.487
fold:2 epoch:48 step:8 train loss:0.457674, train acc:86.316, train f1:85.253, train precision:86.628, train recall:85.600, train kappa:85.792
fold:2 epoch:48 step:9 train loss:0.468618, train acc:85.745, train f1:84.718, train precision:86.060, train recall:85.167, train kappa:85.203
fold:2 epoch:48 step:10 train loss:0.473735, train acc:85.834, train f1:85.018, train precision:86.165, train recall:85.265, train kappa:85.283
fold:2 epoch:48 step:11 train loss:0.457106, train acc:86.140, train f1:85.297, train precision:86.476, train recall:85.475, train kappa:85.609
fold:2 epoch:48        valid loss:0.667789, valid acc:83.213, valid f1:60.160, valid precision:56.670, valid recall:70.983, valid kappa:81.097
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.25597562721083, 59.88828425033604, 56.895576219466705, 70.82540522071697, 81.13647479087905]
====================================================================================================
fold:2 epoch:49 step:0 train loss:0.462584, train acc:86.014, train f1:85.478, train precision:86.844, train recall:85.686, train kappa:85.484
fold:2 epoch:49 step:1 train loss:0.454878, train acc:86.108, train f1:85.296, train precision:86.279, train recall:85.612, train kappa:85.573
fold:2 epoch:49 step:2 train loss:0.457952, train acc:86.292, train f1:85.433, train precision:86.756, train recall:85.480, train kappa:85.766
fold:2 epoch:49 step:3 train loss:0.446209, train acc:86.462, train f1:85.478, train precision:86.965, train recall:85.499, train kappa:85.947
fold:2 epoch:49 step:4 train loss:0.449385, train acc:86.322, train f1:85.384, train precision:87.078, train recall:85.450, train kappa:85.791
fold:2 epoch:49 step:5 train loss:0.452980, train acc:86.124, train f1:85.221, train precision:87.013, train recall:85.296, train kappa:85.597
fold:2 epoch:49 step:6 train loss:0.448061, train acc:86.316, train f1:85.443, train precision:86.783, train recall:85.625, train kappa:85.790
fold:2 epoch:49 step:7 train loss:0.451651, train acc:86.151, train f1:85.147, train precision:86.411, train recall:85.460, train kappa:85.618
fold:2 epoch:49 step:8 train loss:0.451002, train acc:86.298, train f1:85.367, train precision:86.794, train recall:85.573, train kappa:85.770
fold:2 epoch:49 step:9 train loss:0.451611, train acc:86.432, train f1:85.469, train precision:87.125, train recall:85.865, train kappa:85.915
fold:2 epoch:49 step:10 train loss:0.462149, train acc:85.931, train f1:85.120, train precision:86.482, train recall:85.373, train kappa:85.388
fold:2 epoch:49 step:11 train loss:0.451417, train acc:86.237, train f1:85.272, train precision:87.201, train recall:85.345, train kappa:85.678
fold:2 epoch:49        valid loss:0.663424, valid acc:83.458, valid f1:60.257, valid precision:57.175, valid recall:70.759, valid kappa:81.358
[1;31mTest score increased (83.255976 --> 83.458401).[0m
[83.45840063794549, 60.256934043498546, 57.17491602205945, 70.75873910558424, 81.35845309091667]
====================================================================================================
fold:2 epoch:50 step:0 train loss:0.449677, train acc:86.420, train f1:85.507, train precision:87.098, train recall:85.646, train kappa:85.880
fold:2 epoch:50 step:1 train loss:0.448713, train acc:86.066, train f1:85.203, train precision:86.368, train recall:85.390, train kappa:85.529
fold:2 epoch:50 step:2 train loss:0.452435, train acc:86.218, train f1:85.309, train precision:86.867, train recall:85.302, train kappa:85.683
fold:2 epoch:50 step:3 train loss:0.447536, train acc:86.450, train f1:85.703, train precision:86.888, train recall:86.030, train kappa:85.937
fold:2 epoch:50 step:4 train loss:0.449595, train acc:86.325, train f1:85.490, train precision:86.765, train recall:85.664, train kappa:85.802
fold:2 epoch:50 step:5 train loss:0.455317, train acc:86.368, train f1:85.619, train precision:86.770, train recall:85.918, train kappa:85.832
fold:2 epoch:50 step:6 train loss:0.448055, train acc:86.368, train f1:85.722, train precision:87.128, train recall:85.836, train kappa:85.856
fold:2 epoch:50 step:7 train loss:0.444610, train acc:86.334, train f1:85.218, train precision:86.978, train recall:85.337, train kappa:85.799
fold:2 epoch:50 step:8 train loss:0.450433, train acc:86.185, train f1:85.200, train precision:86.635, train recall:85.362, train kappa:85.660
fold:2 epoch:50 step:9 train loss:0.449762, train acc:86.435, train f1:85.539, train precision:87.217, train recall:85.666, train kappa:85.922
fold:2 epoch:50 step:10 train loss:0.455525, train acc:86.136, train f1:85.130, train precision:86.507, train recall:85.482, train kappa:85.612
fold:2 epoch:50 step:11 train loss:0.459789, train acc:86.198, train f1:85.233, train precision:86.748, train recall:85.657, train kappa:85.670
fold:2 epoch:50        valid loss:0.666833, valid acc:83.336, valid f1:60.095, valid precision:56.575, valid recall:71.191, valid kappa:81.231
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.45840063794549, 60.256934043498546, 57.17491602205945, 70.75873910558424, 81.35845309091667]
====================================================================================================
fold:2 epoch:51 step:0 train loss:0.446456, train acc:86.533, train f1:85.524, train precision:86.495, train recall:85.928, train kappa:86.023
fold:2 epoch:51 step:1 train loss:0.452512, train acc:86.386, train f1:85.573, train precision:86.370, train recall:86.113, train kappa:85.875
fold:2 epoch:51 step:2 train loss:0.450808, train acc:86.057, train f1:85.235, train precision:86.411, train recall:85.492, train kappa:85.524
fold:2 epoch:51 step:3 train loss:0.447781, train acc:86.362, train f1:85.576, train precision:86.649, train recall:85.831, train kappa:85.836
fold:2 epoch:51 step:4 train loss:0.441291, train acc:86.649, train f1:85.724, train precision:87.259, train recall:85.576, train kappa:86.139
fold:2 epoch:51 step:5 train loss:0.445797, train acc:86.563, train f1:85.574, train precision:87.331, train recall:85.444, train kappa:86.034
fold:2 epoch:51 step:6 train loss:0.448981, train acc:86.322, train f1:85.666, train precision:87.439, train recall:85.919, train kappa:85.793
fold:2 epoch:51 step:7 train loss:0.441469, train acc:86.554, train f1:85.616, train precision:87.329, train recall:85.714, train kappa:86.026
fold:2 epoch:51 step:8 train loss:0.447632, train acc:86.542, train f1:85.674, train precision:86.948, train recall:85.856, train kappa:86.042
fold:2 epoch:51 step:9 train loss:0.445311, train acc:86.432, train f1:85.555, train precision:87.047, train recall:85.710, train kappa:85.903
fold:2 epoch:51 step:10 train loss:0.447957, train acc:86.356, train f1:85.542, train precision:86.817, train recall:85.924, train kappa:85.833
fold:2 epoch:51 step:11 train loss:0.448712, train acc:86.420, train f1:85.662, train precision:87.120, train recall:86.015, train kappa:85.905
fold:2 epoch:51        valid loss:0.667402, valid acc:83.395, valid f1:60.275, valid precision:57.035, valid recall:71.271, valid kappa:81.303
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.45840063794549, 60.256934043498546, 57.17491602205945, 70.75873910558424, 81.35845309091667]
====================================================================================================
fold:2 epoch:52 step:0 train loss:0.455186, train acc:86.136, train f1:85.372, train precision:86.733, train recall:85.628, train kappa:85.606
fold:2 epoch:52 step:1 train loss:0.444798, train acc:86.267, train f1:85.472, train precision:86.882, train recall:85.683, train kappa:85.737
fold:2 epoch:52 step:2 train loss:0.441895, train acc:86.603, train f1:85.717, train precision:87.085, train recall:85.914, train kappa:86.084
fold:2 epoch:52 step:3 train loss:0.447521, train acc:86.194, train f1:85.615, train precision:87.162, train recall:85.620, train kappa:85.660
fold:2 epoch:52 step:4 train loss:0.442584, train acc:86.642, train f1:85.567, train precision:87.050, train recall:85.535, train kappa:86.144
fold:2 epoch:52 step:5 train loss:0.445824, train acc:86.505, train f1:85.674, train precision:87.151, train recall:85.766, train kappa:85.979
fold:2 epoch:52 step:6 train loss:0.445764, train acc:86.563, train f1:85.523, train precision:86.307, train recall:85.891, train kappa:86.049
fold:2 epoch:52 step:7 train loss:0.440158, train acc:86.649, train f1:85.753, train precision:86.749, train recall:86.097, train kappa:86.133
fold:2 epoch:52 step:8 train loss:0.440692, train acc:86.517, train f1:85.576, train precision:86.728, train recall:85.704, train kappa:85.998
fold:2 epoch:52 step:9 train loss:0.445452, train acc:86.646, train f1:85.736, train precision:87.288, train recall:85.736, train kappa:86.148
fold:2 epoch:52 step:10 train loss:0.443432, train acc:86.502, train f1:85.637, train precision:87.176, train recall:85.804, train kappa:85.974
fold:2 epoch:52 step:11 train loss:0.442997, train acc:86.748, train f1:86.184, train precision:87.538, train recall:86.333, train kappa:86.253
fold:2 epoch:52        valid loss:0.666380, valid acc:83.415, valid f1:60.291, valid precision:56.999, valid recall:71.039, valid kappa:81.318
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.45840063794549, 60.256934043498546, 57.17491602205945, 70.75873910558424, 81.35845309091667]
====================================================================================================
fold:2 epoch:53 step:0 train loss:0.434126, train acc:86.801, train f1:85.866, train precision:87.190, train recall:86.093, train kappa:86.298
fold:2 epoch:53 step:1 train loss:0.440308, train acc:86.407, train f1:85.694, train precision:87.004, train recall:85.885, train kappa:85.892
fold:2 epoch:53 step:2 train loss:0.447626, train acc:86.414, train f1:85.526, train precision:87.147, train recall:85.705, train kappa:85.893
fold:2 epoch:53 step:3 train loss:0.433568, train acc:86.786, train f1:85.803, train precision:87.119, train recall:86.023, train kappa:86.278
fold:2 epoch:53 step:4 train loss:0.443441, train acc:86.435, train f1:85.515, train precision:87.112, train recall:85.754, train kappa:85.914
fold:2 epoch:53 step:5 train loss:0.440321, train acc:86.639, train f1:85.891, train precision:87.210, train recall:86.134, train kappa:86.134
fold:2 epoch:53 step:6 train loss:0.432539, train acc:86.917, train f1:86.123, train precision:87.542, train recall:86.263, train kappa:86.411
fold:2 epoch:53 step:7 train loss:0.436185, train acc:86.752, train f1:85.797, train precision:87.295, train recall:85.840, train kappa:86.245
fold:2 epoch:53 step:8 train loss:0.441684, train acc:86.655, train f1:85.635, train precision:86.949, train recall:85.769, train kappa:86.144
fold:2 epoch:53 step:9 train loss:0.434377, train acc:86.679, train f1:85.906, train precision:87.215, train recall:86.201, train kappa:86.164
fold:2 epoch:53 step:10 train loss:0.438904, train acc:86.502, train f1:85.828, train precision:87.111, train recall:85.909, train kappa:85.975
fold:2 epoch:53 step:11 train loss:0.439578, train acc:86.806, train f1:85.393, train precision:86.414, train recall:85.794, train kappa:86.314
fold:2 epoch:53        valid loss:0.665368, valid acc:83.438, valid f1:60.511, valid precision:57.348, valid recall:71.061, valid kappa:81.341
[1;31mEarlyStopping counter: 4 out of 50[0m
[83.45840063794549, 60.256934043498546, 57.17491602205945, 70.75873910558424, 81.35845309091667]
====================================================================================================
fold:2 epoch:54 step:0 train loss:0.432585, train acc:86.819, train f1:85.930, train precision:87.310, train recall:85.989, train kappa:86.309
fold:2 epoch:54 step:1 train loss:0.434643, train acc:86.642, train f1:85.627, train precision:87.321, train recall:85.702, train kappa:86.140
fold:2 epoch:54 step:2 train loss:0.433319, train acc:86.597, train f1:85.669, train precision:87.345, train recall:85.745, train kappa:86.074
fold:2 epoch:54 step:3 train loss:0.432545, train acc:86.761, train f1:85.734, train precision:87.320, train recall:85.908, train kappa:86.254
fold:2 epoch:54 step:4 train loss:0.433413, train acc:86.755, train f1:85.587, train precision:86.704, train recall:85.864, train kappa:86.246
fold:2 epoch:54 step:5 train loss:0.443684, train acc:86.728, train f1:85.954, train precision:87.163, train recall:86.313, train kappa:86.223
fold:2 epoch:54 step:6 train loss:0.435022, train acc:86.771, train f1:86.009, train precision:87.265, train recall:86.314, train kappa:86.269
fold:2 epoch:54 step:7 train loss:0.431289, train acc:86.771, train f1:85.853, train precision:87.189, train recall:86.114, train kappa:86.260
fold:2 epoch:54 step:8 train loss:0.431908, train acc:86.804, train f1:85.855, train precision:87.231, train recall:86.080, train kappa:86.295
fold:2 epoch:54 step:9 train loss:0.436195, train acc:86.627, train f1:85.865, train precision:87.179, train recall:86.076, train kappa:86.113
fold:2 epoch:54 step:10 train loss:0.437283, train acc:86.633, train f1:85.908, train precision:87.157, train recall:86.026, train kappa:86.126
fold:2 epoch:54 step:11 train loss:0.438282, train acc:86.604, train f1:86.090, train precision:87.391, train recall:86.370, train kappa:86.088
fold:2 epoch:54        valid loss:0.656561, valid acc:83.773, valid f1:60.693, valid precision:57.456, valid recall:70.963, valid kappa:81.723
[1;31mTest score increased (83.458401 --> 83.773284).[0m
[83.77328398797718, 60.69258620998287, 57.45571289649371, 70.96300319188019, 81.72270964287993]
====================================================================================================
fold:2 epoch:55 step:0 train loss:0.429553, train acc:86.841, train f1:86.236, train precision:87.542, train recall:86.277, train kappa:86.342
fold:2 epoch:55 step:1 train loss:0.430338, train acc:86.789, train f1:85.993, train precision:87.213, train recall:86.101, train kappa:86.274
fold:2 epoch:55 step:2 train loss:0.435539, train acc:86.688, train f1:85.688, train precision:86.876, train recall:85.813, train kappa:86.169
fold:2 epoch:55 step:3 train loss:0.426566, train acc:86.783, train f1:86.021, train precision:87.051, train recall:86.322, train kappa:86.275
fold:2 epoch:55 step:4 train loss:0.433707, train acc:86.731, train f1:85.731, train precision:87.016, train recall:85.977, train kappa:86.227
fold:2 epoch:55 step:5 train loss:0.439070, train acc:86.560, train f1:85.870, train precision:87.173, train recall:86.057, train kappa:86.053
fold:2 epoch:55 step:6 train loss:0.429196, train acc:86.752, train f1:85.664, train precision:86.712, train recall:86.047, train kappa:86.247
fold:2 epoch:55 step:7 train loss:0.434879, train acc:86.688, train f1:85.842, train precision:87.040, train recall:86.216, train kappa:86.188
fold:2 epoch:55 step:8 train loss:0.434511, train acc:86.716, train f1:85.836, train precision:87.129, train recall:86.104, train kappa:86.209
fold:2 epoch:55 step:9 train loss:0.431230, train acc:86.832, train f1:85.991, train precision:87.278, train recall:86.298, train kappa:86.326
fold:2 epoch:55 step:10 train loss:0.431268, train acc:86.774, train f1:85.886, train precision:87.218, train recall:85.993, train kappa:86.265
fold:2 epoch:55 step:11 train loss:0.418132, train acc:87.028, train f1:86.256, train precision:87.994, train recall:86.186, train kappa:86.525
fold:2 epoch:55        valid loss:0.667980, valid acc:83.565, valid f1:60.234, valid precision:56.958, valid recall:70.777, valid kappa:81.484
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.77328398797718, 60.69258620998287, 57.45571289649371, 70.96300319188019, 81.72270964287993]
====================================================================================================
fold:2 epoch:56 step:0 train loss:0.423293, train acc:86.963, train f1:86.113, train precision:87.404, train recall:86.119, train kappa:86.464
fold:2 epoch:56 step:1 train loss:0.429311, train acc:86.954, train f1:86.151, train precision:87.544, train recall:86.381, train kappa:86.455
fold:2 epoch:56 step:2 train loss:0.428745, train acc:86.826, train f1:85.882, train precision:86.974, train recall:86.298, train kappa:86.325
fold:2 epoch:56 step:3 train loss:0.420824, train acc:87.244, train f1:86.428, train precision:87.718, train recall:86.703, train kappa:86.758
fold:2 epoch:56 step:4 train loss:0.424870, train acc:86.880, train f1:85.972, train precision:87.123, train recall:86.147, train kappa:86.380
fold:2 epoch:56 step:5 train loss:0.429678, train acc:86.868, train f1:85.851, train precision:87.247, train recall:86.088, train kappa:86.354
fold:2 epoch:56 step:6 train loss:0.428264, train acc:86.890, train f1:86.154, train precision:87.928, train recall:86.026, train kappa:86.384
fold:2 epoch:56 step:7 train loss:0.426204, train acc:86.969, train f1:86.230, train precision:87.993, train recall:86.182, train kappa:86.467
fold:2 epoch:56 step:8 train loss:0.428803, train acc:86.826, train f1:85.850, train precision:87.117, train recall:86.003, train kappa:86.323
fold:2 epoch:56 step:9 train loss:0.428019, train acc:86.810, train f1:85.968, train precision:86.738, train recall:86.410, train kappa:86.307
fold:2 epoch:56 step:10 train loss:0.438546, train acc:86.572, train f1:85.832, train precision:86.989, train recall:86.108, train kappa:86.070
fold:2 epoch:56 step:11 train loss:0.440909, train acc:86.440, train f1:85.672, train precision:86.612, train recall:86.286, train kappa:85.906
fold:2 epoch:56        valid loss:0.668798, valid acc:83.542, valid f1:60.541, valid precision:57.185, valid recall:70.967, valid kappa:81.460
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.77328398797718, 60.69258620998287, 57.45571289649371, 70.96300319188019, 81.72270964287993]
====================================================================================================
fold:2 epoch:57 step:0 train loss:0.433416, train acc:86.777, train f1:86.011, train precision:87.051, train recall:86.400, train kappa:86.265
fold:2 epoch:57 step:1 train loss:0.422922, train acc:86.969, train f1:86.073, train precision:87.142, train recall:86.380, train kappa:86.474
fold:2 epoch:57 step:2 train loss:0.417979, train acc:87.091, train f1:86.229, train precision:87.667, train recall:86.133, train kappa:86.593
fold:2 epoch:57 step:3 train loss:0.434339, train acc:86.569, train f1:85.934, train precision:87.285, train recall:85.927, train kappa:86.045
fold:2 epoch:57 step:4 train loss:0.421996, train acc:86.951, train f1:86.105, train precision:87.560, train recall:86.061, train kappa:86.450
fold:2 epoch:57 step:5 train loss:0.425182, train acc:87.225, train f1:86.277, train precision:88.041, train recall:86.202, train kappa:86.733
fold:2 epoch:57 step:6 train loss:0.425904, train acc:86.972, train f1:86.116, train precision:87.217, train recall:86.352, train kappa:86.469
fold:2 epoch:57 step:7 train loss:0.425071, train acc:86.887, train f1:86.032, train precision:86.890, train recall:86.584, train kappa:86.392
fold:2 epoch:57 step:8 train loss:0.428573, train acc:86.765, train f1:85.922, train precision:86.831, train recall:86.397, train kappa:86.270
fold:2 epoch:57 step:9 train loss:0.428062, train acc:86.920, train f1:86.155, train precision:87.297, train recall:86.481, train kappa:86.421
fold:2 epoch:57 step:10 train loss:0.434714, train acc:86.679, train f1:85.877, train precision:87.505, train recall:85.910, train kappa:86.169
fold:2 epoch:57 step:11 train loss:0.412891, train acc:87.202, train f1:86.342, train precision:87.928, train recall:86.373, train kappa:86.725
fold:2 epoch:57        valid loss:0.660158, valid acc:83.708, valid f1:60.709, valid precision:57.636, valid recall:70.920, valid kappa:81.645
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.77328398797718, 60.69258620998287, 57.45571289649371, 70.96300319188019, 81.72270964287993]
====================================================================================================
fold:2 epoch:58 step:0 train loss:0.420695, train acc:86.963, train f1:86.295, train precision:87.775, train recall:86.410, train kappa:86.470
fold:2 epoch:58 step:1 train loss:0.414971, train acc:87.302, train f1:86.292, train precision:87.810, train recall:86.373, train kappa:86.815
fold:2 epoch:58 step:2 train loss:0.424011, train acc:86.981, train f1:86.251, train precision:87.474, train recall:86.486, train kappa:86.474
fold:2 epoch:58 step:3 train loss:0.420849, train acc:87.323, train f1:86.485, train precision:87.518, train recall:86.700, train kappa:86.840
fold:2 epoch:58 step:4 train loss:0.421812, train acc:87.177, train f1:86.461, train precision:87.581, train recall:86.680, train kappa:86.690
fold:2 epoch:58 step:5 train loss:0.426865, train acc:87.027, train f1:86.177, train precision:87.038, train recall:86.564, train kappa:86.531
fold:2 epoch:58 step:6 train loss:0.426217, train acc:87.018, train f1:86.274, train precision:87.531, train recall:86.460, train kappa:86.526
fold:2 epoch:58 step:7 train loss:0.413603, train acc:87.326, train f1:86.499, train precision:87.698, train recall:86.753, train kappa:86.840
fold:2 epoch:58 step:8 train loss:0.428176, train acc:86.783, train f1:85.975, train precision:87.506, train recall:86.120, train kappa:86.277
fold:2 epoch:58 step:9 train loss:0.433787, train acc:86.609, train f1:85.686, train precision:87.427, train recall:85.717, train kappa:86.103
fold:2 epoch:58 step:10 train loss:0.426310, train acc:86.847, train f1:85.804, train precision:86.946, train recall:86.203, train kappa:86.340
fold:2 epoch:58 step:11 train loss:0.414756, train acc:87.289, train f1:86.484, train precision:87.816, train recall:86.528, train kappa:86.794
fold:2 epoch:58        valid loss:0.661863, valid acc:83.833, valid f1:60.891, valid precision:57.704, valid recall:71.134, valid kappa:81.782
[1;31mTest score increased (83.773284 --> 83.832580).[0m
[83.83258020324288, 60.89069135236905, 57.703716462603296, 71.13382355279596, 81.7818556202145]
====================================================================================================
fold:2 epoch:59 step:0 train loss:0.417960, train acc:87.302, train f1:86.219, train precision:87.361, train recall:86.493, train kappa:86.817
fold:2 epoch:59 step:1 train loss:0.411640, train acc:87.198, train f1:86.173, train precision:87.284, train recall:86.617, train kappa:86.704
fold:2 epoch:59 step:2 train loss:0.425249, train acc:86.972, train f1:86.248, train precision:87.532, train recall:86.522, train kappa:86.466
fold:2 epoch:59 step:3 train loss:0.412547, train acc:87.283, train f1:86.401, train precision:87.576, train recall:86.671, train kappa:86.787
fold:2 epoch:59 step:4 train loss:0.418476, train acc:86.957, train f1:86.063, train precision:87.315, train recall:86.259, train kappa:86.449
fold:2 epoch:59 step:5 train loss:0.416252, train acc:87.100, train f1:86.295, train precision:87.732, train recall:86.289, train kappa:86.611
fold:2 epoch:59 step:6 train loss:0.419786, train acc:87.051, train f1:86.401, train precision:87.718, train recall:86.473, train kappa:86.565
fold:2 epoch:59 step:7 train loss:0.422441, train acc:87.158, train f1:86.465, train precision:87.667, train recall:86.685, train kappa:86.671
fold:2 epoch:59 step:8 train loss:0.422817, train acc:87.119, train f1:86.297, train precision:87.428, train recall:86.499, train kappa:86.631
fold:2 epoch:59 step:9 train loss:0.414270, train acc:87.189, train f1:86.489, train precision:87.668, train recall:86.761, train kappa:86.705
fold:2 epoch:59 step:10 train loss:0.422027, train acc:86.914, train f1:86.194, train precision:87.477, train recall:86.452, train kappa:86.417
fold:2 epoch:59 step:11 train loss:0.426155, train acc:86.671, train f1:86.228, train precision:87.536, train recall:86.385, train kappa:86.171
fold:2 epoch:59        valid loss:0.657974, valid acc:83.910, valid f1:60.803, valid precision:57.699, valid recall:70.959, valid kappa:81.863
[1;31mTest score increased (83.832580 --> 83.910279).[0m
[83.91027869221175, 60.802621953503674, 57.69896925827263, 70.95924515739613, 81.86255394976165]
====================================================================================================
fold:2 epoch:60 step:0 train loss:0.413402, train acc:87.335, train f1:86.527, train precision:87.859, train recall:86.695, train kappa:86.857
fold:2 epoch:60 step:1 train loss:0.411971, train acc:87.296, train f1:86.320, train precision:87.643, train recall:86.455, train kappa:86.811
fold:2 epoch:60 step:2 train loss:0.420402, train acc:87.210, train f1:86.415, train precision:87.456, train recall:86.653, train kappa:86.719
fold:2 epoch:60 step:3 train loss:0.415520, train acc:87.155, train f1:86.249, train precision:87.370, train recall:86.531, train kappa:86.671
fold:2 epoch:60 step:4 train loss:0.414969, train acc:87.131, train f1:86.495, train precision:87.590, train recall:86.695, train kappa:86.644
fold:2 epoch:60 step:5 train loss:0.405700, train acc:87.500, train f1:86.725, train precision:87.549, train recall:87.075, train kappa:87.031
fold:2 epoch:60 step:6 train loss:0.417403, train acc:87.219, train f1:86.386, train precision:87.420, train recall:86.606, train kappa:86.719
fold:2 epoch:60 step:7 train loss:0.410477, train acc:87.103, train f1:86.251, train precision:87.314, train recall:86.471, train kappa:86.616
fold:2 epoch:60 step:8 train loss:0.418615, train acc:87.146, train f1:86.249, train precision:87.505, train recall:86.457, train kappa:86.653
fold:2 epoch:60 step:9 train loss:0.427216, train acc:86.987, train f1:86.319, train precision:87.946, train recall:86.332, train kappa:86.479
fold:2 epoch:60 step:10 train loss:0.416346, train acc:87.204, train f1:86.166, train precision:87.686, train recall:86.182, train kappa:86.711
fold:2 epoch:60 step:11 train loss:0.410114, train acc:87.656, train f1:87.170, train precision:88.437, train recall:87.341, train kappa:87.186
fold:2 epoch:60        valid loss:0.659179, valid acc:83.706, valid f1:60.687, valid precision:57.266, valid recall:71.046, valid kappa:81.650
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.91027869221175, 60.802621953503674, 57.69896925827263, 70.95924515739613, 81.86255394976165]
====================================================================================================
fold:2 epoch:61 step:0 train loss:0.418431, train acc:86.945, train f1:86.229, train precision:87.296, train recall:86.486, train kappa:86.447
fold:2 epoch:61 step:1 train loss:0.410022, train acc:87.381, train f1:86.469, train precision:87.668, train recall:86.657, train kappa:86.898
fold:2 epoch:61 step:2 train loss:0.404640, train acc:87.485, train f1:86.580, train precision:87.584, train recall:86.920, train kappa:87.002
fold:2 epoch:61 step:3 train loss:0.416550, train acc:87.256, train f1:86.444, train precision:87.399, train recall:86.690, train kappa:86.776
fold:2 epoch:61 step:4 train loss:0.409318, train acc:87.405, train f1:86.718, train precision:87.743, train recall:86.944, train kappa:86.934
fold:2 epoch:61 step:5 train loss:0.414137, train acc:86.996, train f1:86.257, train precision:87.541, train recall:86.524, train kappa:86.504
fold:2 epoch:61 step:6 train loss:0.413915, train acc:87.009, train f1:86.144, train precision:87.337, train recall:86.315, train kappa:86.505
fold:2 epoch:61 step:7 train loss:0.418582, train acc:87.158, train f1:86.496, train precision:87.872, train recall:86.400, train kappa:86.664
fold:2 epoch:61 step:8 train loss:0.408995, train acc:87.387, train f1:86.582, train precision:87.806, train recall:86.664, train kappa:86.898
fold:2 epoch:61 step:9 train loss:0.415385, train acc:87.216, train f1:86.325, train precision:87.415, train recall:86.569, train kappa:86.734
fold:2 epoch:61 step:10 train loss:0.416555, train acc:87.454, train f1:86.529, train precision:87.397, train recall:86.792, train kappa:86.977
fold:2 epoch:61 step:11 train loss:0.413964, train acc:87.154, train f1:86.357, train precision:87.272, train recall:86.684, train kappa:86.674
fold:2 epoch:61        valid loss:0.664250, valid acc:83.890, valid f1:61.045, valid precision:57.865, valid recall:71.165, valid kappa:81.846
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.91027869221175, 60.802621953503674, 57.69896925827263, 70.95924515739613, 81.86255394976165]
====================================================================================================
fold:2 epoch:62 step:0 train loss:0.409406, train acc:87.283, train f1:86.516, train precision:87.754, train recall:86.623, train kappa:86.801
fold:2 epoch:62 step:1 train loss:0.403949, train acc:87.631, train f1:86.631, train precision:87.834, train recall:86.823, train kappa:87.155
fold:2 epoch:62 step:2 train loss:0.407685, train acc:87.326, train f1:86.513, train precision:87.810, train recall:86.741, train kappa:86.844
fold:2 epoch:62 step:3 train loss:0.406321, train acc:87.527, train f1:86.504, train precision:87.788, train recall:86.764, train kappa:87.042
fold:2 epoch:62 step:4 train loss:0.413624, train acc:87.146, train f1:86.235, train precision:87.194, train recall:86.406, train kappa:86.667
fold:2 epoch:62 step:5 train loss:0.410928, train acc:87.384, train f1:86.600, train precision:87.345, train recall:86.708, train kappa:86.902
fold:2 epoch:62 step:6 train loss:0.416259, train acc:87.158, train f1:86.343, train precision:87.145, train recall:86.680, train kappa:86.675
fold:2 epoch:62 step:7 train loss:0.417468, train acc:87.061, train f1:86.502, train precision:87.650, train recall:86.676, train kappa:86.565
fold:2 epoch:62 step:8 train loss:0.420199, train acc:87.039, train f1:86.148, train precision:87.496, train recall:86.396, train kappa:86.542
fold:2 epoch:62 step:9 train loss:0.411149, train acc:87.021, train f1:86.191, train precision:87.146, train recall:86.562, train kappa:86.525
fold:2 epoch:62 step:10 train loss:0.409699, train acc:87.314, train f1:86.518, train precision:87.604, train recall:86.787, train kappa:86.829
fold:2 epoch:62 step:11 train loss:0.406397, train acc:87.472, train f1:86.293, train precision:87.820, train recall:86.606, train kappa:86.986
fold:2 epoch:62        valid loss:0.659715, valid acc:83.878, valid f1:60.771, valid precision:57.384, valid recall:71.083, valid kappa:81.838
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.91027869221175, 60.802621953503674, 57.69896925827263, 70.95924515739613, 81.86255394976165]
====================================================================================================
fold:2 epoch:63 step:0 train loss:0.404912, train acc:87.259, train f1:86.551, train precision:87.627, train recall:86.849, train kappa:86.766
fold:2 epoch:63 step:1 train loss:0.397204, train acc:87.680, train f1:86.726, train precision:87.870, train recall:86.810, train kappa:87.218
fold:2 epoch:63 step:2 train loss:0.403091, train acc:87.488, train f1:86.563, train precision:87.559, train recall:86.660, train kappa:87.007
fold:2 epoch:63 step:3 train loss:0.406143, train acc:87.390, train f1:86.555, train precision:87.682, train recall:86.673, train kappa:86.913
fold:2 epoch:63 step:4 train loss:0.402308, train acc:87.277, train f1:86.464, train precision:87.618, train recall:86.614, train kappa:86.790
fold:2 epoch:63 step:5 train loss:0.410383, train acc:87.491, train f1:86.707, train precision:88.150, train recall:86.815, train kappa:87.007
fold:2 epoch:63 step:6 train loss:0.401224, train acc:87.570, train f1:86.882, train precision:87.949, train recall:87.244, train kappa:87.095
fold:2 epoch:63 step:7 train loss:0.398390, train acc:87.421, train f1:86.400, train precision:87.549, train recall:86.657, train kappa:86.934
fold:2 epoch:63 step:8 train loss:0.420958, train acc:86.975, train f1:86.168, train precision:87.032, train recall:86.606, train kappa:86.476
fold:2 epoch:63 step:9 train loss:0.411979, train acc:87.213, train f1:86.547, train precision:87.360, train recall:86.782, train kappa:86.734
fold:2 epoch:63 step:10 train loss:0.419537, train acc:87.225, train f1:86.600, train precision:87.366, train recall:86.906, train kappa:86.747
fold:2 epoch:63 step:11 train loss:0.409639, train acc:87.376, train f1:86.726, train precision:87.918, train recall:86.785, train kappa:86.895
fold:2 epoch:63        valid loss:0.663434, valid acc:83.859, valid f1:60.882, valid precision:57.558, valid recall:70.994, valid kappa:81.821
[1;31mEarlyStopping counter: 4 out of 50[0m
[83.91027869221175, 60.802621953503674, 57.69896925827263, 70.95924515739613, 81.86255394976165]
====================================================================================================
fold:2 epoch:64 step:0 train loss:0.392033, train acc:87.747, train f1:87.003, train precision:88.157, train recall:87.083, train kappa:87.278
fold:2 epoch:64 step:1 train loss:0.403273, train acc:87.354, train f1:86.871, train precision:87.918, train recall:87.065, train kappa:86.872
fold:2 epoch:64 step:2 train loss:0.402736, train acc:87.607, train f1:86.775, train precision:87.875, train recall:87.024, train kappa:87.132
fold:2 epoch:64 step:3 train loss:0.406099, train acc:87.491, train f1:86.674, train precision:87.678, train recall:86.877, train kappa:87.016
fold:2 epoch:64 step:4 train loss:0.420130, train acc:86.972, train f1:86.360, train precision:87.605, train recall:86.448, train kappa:86.481
fold:2 epoch:64 step:5 train loss:0.404678, train acc:87.378, train f1:86.387, train precision:88.081, train recall:86.538, train kappa:86.895
fold:2 epoch:64 step:6 train loss:0.404292, train acc:87.613, train f1:86.841, train precision:87.954, train recall:87.061, train kappa:87.140
fold:2 epoch:64 step:7 train loss:0.411997, train acc:87.143, train f1:86.422, train precision:87.490, train recall:86.781, train kappa:86.650
fold:2 epoch:64 step:8 train loss:0.405772, train acc:87.454, train f1:86.529, train precision:87.697, train recall:86.819, train kappa:86.976
fold:2 epoch:64 step:9 train loss:0.398573, train acc:87.579, train f1:86.718, train precision:87.877, train recall:86.952, train kappa:87.113
fold:2 epoch:64 step:10 train loss:0.407223, train acc:87.317, train f1:86.616, train precision:87.624, train recall:86.979, train kappa:86.829
fold:2 epoch:64 step:11 train loss:0.402297, train acc:87.366, train f1:86.206, train precision:87.776, train recall:86.183, train kappa:86.882
fold:2 epoch:64        valid loss:0.661876, valid acc:83.974, valid f1:60.887, valid precision:57.591, valid recall:70.995, valid kappa:81.944
[1;31mTest score increased (83.910279 --> 83.973664).[0m
[83.9736643016337, 60.88678326801302, 57.59137988656563, 70.9953991631552, 81.9444160441686]
====================================================================================================
fold:2 epoch:65 step:0 train loss:0.405343, train acc:87.344, train f1:86.701, train precision:87.581, train recall:87.001, train kappa:86.858
fold:2 epoch:65 step:1 train loss:0.401399, train acc:87.433, train f1:86.688, train precision:87.841, train recall:86.836, train kappa:86.958
fold:2 epoch:65 step:2 train loss:0.398012, train acc:87.634, train f1:86.854, train precision:87.730, train recall:87.120, train kappa:87.167
fold:2 epoch:65 step:3 train loss:0.397563, train acc:87.473, train f1:86.671, train precision:87.695, train recall:86.839, train kappa:86.996
fold:2 epoch:65 step:4 train loss:0.405919, train acc:87.564, train f1:86.866, train precision:88.051, train recall:87.025, train kappa:87.093
fold:2 epoch:65 step:5 train loss:0.404733, train acc:87.384, train f1:86.583, train precision:87.856, train recall:86.724, train kappa:86.905
fold:2 epoch:65 step:6 train loss:0.395378, train acc:87.698, train f1:86.998, train precision:88.584, train recall:87.054, train kappa:87.236
fold:2 epoch:65 step:7 train loss:0.403461, train acc:87.469, train f1:86.732, train precision:87.937, train recall:86.930, train kappa:86.981
fold:2 epoch:65 step:8 train loss:0.403973, train acc:87.372, train f1:86.311, train precision:87.254, train recall:86.594, train kappa:86.885
fold:2 epoch:65 step:9 train loss:0.407017, train acc:87.628, train f1:86.784, train precision:87.653, train recall:87.146, train kappa:87.157
fold:2 epoch:65 step:10 train loss:0.406401, train acc:87.421, train f1:86.749, train precision:87.621, train recall:87.009, train kappa:86.942
fold:2 epoch:65 step:11 train loss:0.393907, train acc:87.694, train f1:86.850, train precision:87.771, train recall:86.949, train kappa:87.233
fold:2 epoch:65        valid loss:0.662892, valid acc:83.959, valid f1:61.019, valid precision:57.634, valid recall:71.171, valid kappa:81.924
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.9736643016337, 60.88678326801302, 57.59137988656563, 70.9953991631552, 81.9444160441686]
====================================================================================================
fold:2 epoch:66 step:0 train loss:0.390250, train acc:87.888, train f1:87.133, train precision:88.152, train recall:87.380, train kappa:87.435
fold:2 epoch:66 step:1 train loss:0.389047, train acc:87.778, train f1:86.953, train precision:88.034, train recall:87.069, train kappa:87.315
fold:2 epoch:66 step:2 train loss:0.389408, train acc:87.909, train f1:86.935, train precision:88.159, train recall:87.010, train kappa:87.449
fold:2 epoch:66 step:3 train loss:0.400724, train acc:87.598, train f1:86.616, train precision:87.900, train recall:86.882, train kappa:87.125
fold:2 epoch:66 step:4 train loss:0.396780, train acc:87.601, train f1:86.741, train precision:87.984, train recall:86.945, train kappa:87.124
fold:2 epoch:66 step:5 train loss:0.400979, train acc:87.485, train f1:86.721, train precision:87.813, train recall:87.038, train kappa:87.008
fold:2 epoch:66 step:6 train loss:0.396309, train acc:87.830, train f1:86.781, train precision:87.924, train recall:87.207, train kappa:87.363
fold:2 epoch:66 step:7 train loss:0.396766, train acc:87.753, train f1:87.074, train precision:88.368, train recall:87.263, train kappa:87.280
fold:2 epoch:66 step:8 train loss:0.400167, train acc:87.320, train f1:86.488, train precision:87.445, train recall:86.700, train kappa:86.844
fold:2 epoch:66 step:9 train loss:0.414236, train acc:87.390, train f1:86.748, train precision:87.721, train recall:86.896, train kappa:86.912
fold:2 epoch:66 step:10 train loss:0.407708, train acc:87.454, train f1:86.964, train precision:88.118, train recall:87.058, train kappa:86.967
fold:2 epoch:66 step:11 train loss:0.409268, train acc:87.434, train f1:86.454, train precision:87.597, train recall:86.573, train kappa:86.946
fold:2 epoch:66        valid loss:0.664662, valid acc:84.055, valid f1:61.167, valid precision:57.952, valid recall:71.006, valid kappa:82.032
[1;31mTest score increased (83.973664 --> 84.055452).[0m
[84.05545218475882, 61.166562511995416, 57.95190221787635, 71.0055379309089, 82.03183193756347]
====================================================================================================
fold:2 epoch:67 step:0 train loss:0.390399, train acc:87.787, train f1:87.030, train precision:88.058, train recall:87.076, train kappa:87.328
fold:2 epoch:67 step:1 train loss:0.386762, train acc:87.918, train f1:86.982, train precision:88.111, train recall:87.129, train kappa:87.461
fold:2 epoch:67 step:2 train loss:0.403976, train acc:87.549, train f1:86.894, train precision:87.738, train recall:87.265, train kappa:87.082
fold:2 epoch:67 step:3 train loss:0.393833, train acc:87.726, train f1:86.878, train precision:87.706, train recall:87.198, train kappa:87.262
fold:2 epoch:67 step:4 train loss:0.400937, train acc:87.503, train f1:86.505, train precision:87.545, train recall:86.804, train kappa:87.029
fold:2 epoch:67 step:5 train loss:0.390387, train acc:87.796, train f1:87.078, train precision:88.418, train recall:87.309, train kappa:87.325
fold:2 epoch:67 step:6 train loss:0.403203, train acc:87.442, train f1:86.746, train precision:87.946, train recall:86.925, train kappa:86.970
fold:2 epoch:67 step:7 train loss:0.400831, train acc:87.402, train f1:86.605, train precision:87.741, train recall:86.869, train kappa:86.916
fold:2 epoch:67 step:8 train loss:0.394971, train acc:87.726, train f1:87.002, train precision:88.008, train recall:87.232, train kappa:87.258
fold:2 epoch:67 step:9 train loss:0.391232, train acc:87.738, train f1:86.908, train precision:88.051, train recall:86.941, train kappa:87.273
fold:2 epoch:67 step:10 train loss:0.404830, train acc:87.354, train f1:86.609, train precision:87.281, train recall:87.000, train kappa:86.868
fold:2 epoch:67 step:11 train loss:0.375372, train acc:88.408, train f1:87.470, train precision:88.293, train recall:87.595, train kappa:87.946
fold:2 epoch:67        valid loss:0.659386, valid acc:84.117, valid f1:61.087, valid precision:57.875, valid recall:70.898, valid kappa:82.103
[1;31mTest score increased (84.055452 --> 84.116793).[0m
[84.11679309710266, 61.08712858606761, 57.875371401466055, 70.89758395315931, 82.10325160326917]
====================================================================================================
fold:2 epoch:68 step:0 train loss:0.391676, train acc:87.738, train f1:86.944, train precision:88.143, train recall:87.113, train kappa:87.278
fold:2 epoch:68 step:1 train loss:0.394522, train acc:87.845, train f1:86.940, train precision:88.193, train recall:87.132, train kappa:87.378
fold:2 epoch:68 step:2 train loss:0.389042, train acc:87.833, train f1:86.980, train precision:88.288, train recall:87.116, train kappa:87.378
fold:2 epoch:68 step:3 train loss:0.395294, train acc:87.619, train f1:86.866, train precision:88.136, train recall:86.907, train kappa:87.141
fold:2 epoch:68 step:4 train loss:0.395819, train acc:87.726, train f1:86.864, train precision:88.126, train recall:87.099, train kappa:87.257
fold:2 epoch:68 step:5 train loss:0.392858, train acc:87.863, train f1:86.947, train precision:88.221, train recall:87.171, train kappa:87.396
fold:2 epoch:68 step:6 train loss:0.389365, train acc:87.869, train f1:87.015, train precision:88.032, train recall:87.288, train kappa:87.418
fold:2 epoch:68 step:7 train loss:0.400263, train acc:87.750, train f1:86.921, train precision:87.908, train recall:87.174, train kappa:87.288
fold:2 epoch:68 step:8 train loss:0.388160, train acc:87.885, train f1:87.029, train precision:87.706, train recall:87.404, train kappa:87.424
fold:2 epoch:68 step:9 train loss:0.394520, train acc:87.747, train f1:87.098, train precision:88.047, train recall:87.251, train kappa:87.274
fold:2 epoch:68 step:10 train loss:0.399899, train acc:87.720, train f1:87.272, train precision:88.260, train recall:87.472, train kappa:87.250
fold:2 epoch:68 step:11 train loss:0.401499, train acc:87.800, train f1:86.691, train precision:87.495, train recall:87.074, train kappa:87.330
fold:2 epoch:68        valid loss:0.660670, valid acc:84.160, valid f1:61.027, valid precision:57.830, valid recall:70.985, valid kappa:82.149
[1;31mTest score increased (84.116793 --> 84.159732).[0m
[84.15973173574335, 61.026541122910274, 57.830170858567485, 70.98543564314463, 82.14925579362288]
====================================================================================================
fold:2 epoch:69 step:0 train loss:0.397714, train acc:87.527, train f1:86.675, train precision:88.043, train recall:86.711, train kappa:87.057
fold:2 epoch:69 step:1 train loss:0.392019, train acc:87.845, train f1:86.970, train precision:88.270, train recall:87.112, train kappa:87.379
fold:2 epoch:69 step:2 train loss:0.391045, train acc:87.888, train f1:87.030, train precision:88.002, train recall:87.309, train kappa:87.431
fold:2 epoch:69 step:3 train loss:0.391005, train acc:87.918, train f1:87.208, train precision:88.291, train recall:87.472, train kappa:87.451
fold:2 epoch:69 step:4 train loss:0.392495, train acc:87.637, train f1:86.766, train precision:87.662, train recall:87.046, train kappa:87.170
fold:2 epoch:69 step:5 train loss:0.386071, train acc:87.970, train f1:87.391, train precision:88.287, train recall:87.631, train kappa:87.516
fold:2 epoch:69 step:6 train loss:0.386355, train acc:87.814, train f1:87.049, train precision:87.886, train recall:87.325, train kappa:87.349
fold:2 epoch:69 step:7 train loss:0.397878, train acc:87.866, train f1:86.955, train precision:88.083, train recall:87.030, train kappa:87.404
fold:2 epoch:69 step:8 train loss:0.395346, train acc:87.567, train f1:86.786, train precision:87.868, train recall:87.025, train kappa:87.087
fold:2 epoch:69 step:9 train loss:0.393910, train acc:87.717, train f1:86.925, train precision:88.253, train recall:86.976, train kappa:87.241
fold:2 epoch:69 step:10 train loss:0.399713, train acc:87.604, train f1:86.744, train precision:87.884, train recall:86.994, train kappa:87.143
fold:2 epoch:69 step:11 train loss:0.394340, train acc:87.820, train f1:86.994, train precision:88.158, train recall:87.220, train kappa:87.347
fold:2 epoch:69        valid loss:0.660828, valid acc:84.147, valid f1:61.243, valid precision:58.098, valid recall:70.973, valid kappa:82.134
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.15973173574335, 61.026541122910274, 57.830170858567485, 70.98543564314463, 82.14925579362288]
====================================================================================================
fold:2 epoch:70 step:0 train loss:0.388204, train acc:87.857, train f1:87.136, train precision:88.040, train recall:87.379, train kappa:87.402
fold:2 epoch:70 step:1 train loss:0.387881, train acc:87.894, train f1:87.138, train precision:88.144, train recall:87.269, train kappa:87.430
fold:2 epoch:70 step:2 train loss:0.388838, train acc:87.906, train f1:87.211, train precision:88.181, train recall:87.436, train kappa:87.450
fold:2 epoch:70 step:3 train loss:0.390449, train acc:87.735, train f1:87.080, train precision:88.199, train recall:87.162, train kappa:87.268
fold:2 epoch:70 step:4 train loss:0.390866, train acc:87.640, train f1:86.893, train precision:88.000, train recall:86.897, train kappa:87.165
fold:2 epoch:70 step:5 train loss:0.390824, train acc:87.979, train f1:87.149, train precision:88.208, train recall:87.345, train kappa:87.527
fold:2 epoch:70 step:6 train loss:0.386370, train acc:87.976, train f1:87.133, train precision:88.148, train recall:87.260, train kappa:87.521
fold:2 epoch:70 step:7 train loss:0.394628, train acc:87.827, train f1:86.913, train precision:88.046, train recall:87.177, train kappa:87.363
fold:2 epoch:70 step:8 train loss:0.389992, train acc:87.546, train f1:86.713, train precision:87.888, train recall:86.917, train kappa:87.077
fold:2 epoch:70 step:9 train loss:0.389585, train acc:87.900, train f1:86.998, train precision:88.045, train recall:87.403, train kappa:87.433
fold:2 epoch:70 step:10 train loss:0.391523, train acc:87.912, train f1:87.042, train precision:87.949, train recall:87.328, train kappa:87.446
fold:2 epoch:70 step:11 train loss:0.386943, train acc:87.771, train f1:86.608, train precision:87.507, train recall:86.873, train kappa:87.294
fold:2 epoch:70        valid loss:0.660895, valid acc:84.213, valid f1:61.174, valid precision:57.897, valid recall:71.014, valid kappa:82.212
[1;31mTest score increased (84.159732 --> 84.212894).[0m
[84.21289385977467, 61.173834462441576, 57.89694024760702, 71.01370636256156, 82.21230851067722]
====================================================================================================
fold:2 epoch:71 step:0 train loss:0.398504, train acc:87.717, train f1:87.098, train precision:88.300, train recall:87.143, train kappa:87.243
fold:2 epoch:71 step:1 train loss:0.388812, train acc:87.689, train f1:86.992, train precision:88.200, train recall:86.998, train kappa:87.208
fold:2 epoch:71 step:2 train loss:0.384452, train acc:88.089, train f1:87.171, train precision:88.536, train recall:87.139, train kappa:87.639
fold:2 epoch:71 step:3 train loss:0.384322, train acc:87.939, train f1:87.112, train precision:88.360, train recall:87.160, train kappa:87.496
fold:2 epoch:71 step:4 train loss:0.380490, train acc:88.327, train f1:87.440, train precision:88.476, train recall:87.621, train kappa:87.885
fold:2 epoch:71 step:5 train loss:0.389761, train acc:87.823, train f1:87.216, train precision:88.073, train recall:87.570, train kappa:87.356
fold:2 epoch:71 step:6 train loss:0.383730, train acc:88.031, train f1:87.218, train precision:87.820, train recall:87.700, train kappa:87.587
fold:2 epoch:71 step:7 train loss:0.393683, train acc:87.872, train f1:87.114, train precision:87.994, train recall:87.424, train kappa:87.412
fold:2 epoch:71 step:8 train loss:0.393471, train acc:87.677, train f1:86.848, train precision:87.938, train recall:87.102, train kappa:87.212
fold:2 epoch:71 step:9 train loss:0.389343, train acc:88.016, train f1:87.142, train precision:88.299, train recall:87.511, train kappa:87.555
fold:2 epoch:71 step:10 train loss:0.394832, train acc:87.537, train f1:86.884, train precision:88.318, train recall:86.962, train kappa:87.054
fold:2 epoch:71 step:11 train loss:0.404335, train acc:87.212, train f1:86.381, train precision:87.199, train recall:86.747, train kappa:86.719
fold:2 epoch:71        valid loss:0.658801, valid acc:84.215, valid f1:61.220, valid precision:57.878, valid recall:71.076, valid kappa:82.217
[1;31mTest score increased (84.212894 --> 84.214939).[0m
[84.2149385568528, 61.22004826479886, 57.87849931266429, 71.07602984030302, 82.21685389347758]
====================================================================================================
fold:2 epoch:72 step:0 train loss:0.378162, train acc:88.043, train f1:87.249, train precision:88.145, train recall:87.334, train kappa:87.592
fold:2 epoch:72 step:1 train loss:0.378765, train acc:88.040, train f1:87.332, train precision:88.284, train recall:87.328, train kappa:87.582
fold:2 epoch:72 step:2 train loss:0.376605, train acc:88.162, train f1:87.401, train precision:88.234, train recall:87.663, train kappa:87.709
fold:2 epoch:72 step:3 train loss:0.389010, train acc:87.878, train f1:87.155, train precision:88.008, train recall:87.339, train kappa:87.418
fold:2 epoch:72 step:4 train loss:0.382663, train acc:88.043, train f1:87.233, train precision:88.138, train recall:87.422, train kappa:87.599
fold:2 epoch:72 step:5 train loss:0.388045, train acc:88.031, train f1:87.277, train precision:88.251, train recall:87.648, train kappa:87.574
fold:2 epoch:72 step:6 train loss:0.378864, train acc:88.202, train f1:87.217, train precision:88.470, train recall:87.345, train kappa:87.749
fold:2 epoch:72 step:7 train loss:0.392155, train acc:87.772, train f1:86.992, train precision:88.396, train recall:87.126, train kappa:87.300
fold:2 epoch:72 step:8 train loss:0.388036, train acc:87.915, train f1:86.990, train precision:88.442, train recall:87.239, train kappa:87.452
fold:2 epoch:72 step:9 train loss:0.385344, train acc:87.988, train f1:87.306, train precision:88.429, train recall:87.502, train kappa:87.533
fold:2 epoch:72 step:10 train loss:0.386078, train acc:88.065, train f1:87.319, train precision:88.326, train recall:87.610, train kappa:87.616
fold:2 epoch:72 step:11 train loss:0.378242, train acc:87.945, train f1:87.035, train precision:87.498, train recall:87.655, train kappa:87.496
fold:2 epoch:72        valid loss:0.663206, valid acc:84.088, valid f1:61.094, valid precision:57.648, valid recall:71.003, valid kappa:82.075
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.2149385568528, 61.22004826479886, 57.87849931266429, 71.07602984030302, 82.21685389347758]
====================================================================================================
fold:2 epoch:73 step:0 train loss:0.369059, train acc:88.339, train f1:87.732, train precision:88.409, train recall:87.984, train kappa:87.896
fold:2 epoch:73 step:1 train loss:0.378640, train acc:88.184, train f1:87.337, train precision:88.213, train recall:87.435, train kappa:87.736
fold:2 epoch:73 step:2 train loss:0.380663, train acc:88.123, train f1:87.361, train precision:88.356, train recall:87.489, train kappa:87.676
fold:2 epoch:73 step:3 train loss:0.380990, train acc:88.086, train f1:87.267, train precision:88.448, train recall:87.307, train kappa:87.635
fold:2 epoch:73 step:4 train loss:0.387242, train acc:87.753, train f1:87.030, train precision:88.379, train recall:87.042, train kappa:87.285
fold:2 epoch:73 step:5 train loss:0.382743, train acc:88.013, train f1:87.501, train precision:88.700, train recall:87.643, train kappa:87.553
fold:2 epoch:73 step:6 train loss:0.388550, train acc:87.881, train f1:86.912, train precision:88.106, train recall:87.111, train kappa:87.417
fold:2 epoch:73 step:7 train loss:0.375925, train acc:88.251, train f1:87.307, train precision:88.232, train recall:87.620, train kappa:87.796
fold:2 epoch:73 step:8 train loss:0.383099, train acc:87.955, train f1:87.208, train precision:87.974, train recall:87.650, train kappa:87.494
fold:2 epoch:73 step:9 train loss:0.392071, train acc:87.845, train f1:87.068, train precision:87.948, train recall:87.187, train kappa:87.382
fold:2 epoch:73 step:10 train loss:0.384970, train acc:87.949, train f1:87.038, train precision:88.101, train recall:87.128, train kappa:87.497
fold:2 epoch:73 step:11 train loss:0.397280, train acc:87.607, train f1:86.870, train precision:87.837, train recall:87.241, train kappa:87.149
fold:2 epoch:73        valid loss:0.663244, valid acc:84.458, valid f1:61.706, valid precision:58.556, valid recall:70.922, valid kappa:82.486
[1;31mTest score increased (84.214939 --> 84.458258).[0m
[84.45825750915002, 61.70590069471537, 58.55572721672216, 70.92224370739022, 82.4862639890733]
====================================================================================================
fold:2 epoch:74 step:0 train loss:0.383509, train acc:87.869, train f1:86.909, train precision:87.549, train recall:87.086, train kappa:87.402
fold:2 epoch:74 step:1 train loss:0.384663, train acc:87.979, train f1:87.322, train precision:88.340, train recall:87.488, train kappa:87.522
fold:2 epoch:74 step:2 train loss:0.383984, train acc:87.872, train f1:86.966, train precision:87.775, train recall:87.241, train kappa:87.407
fold:2 epoch:74 step:3 train loss:0.385902, train acc:88.022, train f1:87.059, train precision:88.059, train recall:87.235, train kappa:87.569
fold:2 epoch:74 step:4 train loss:0.373972, train acc:88.290, train f1:87.463, train precision:88.437, train recall:87.681, train kappa:87.845
fold:2 epoch:74 step:5 train loss:0.377270, train acc:88.205, train f1:87.575, train precision:88.821, train recall:87.651, train kappa:87.755
fold:2 epoch:74 step:6 train loss:0.372813, train acc:88.278, train f1:87.568, train precision:88.515, train recall:87.811, train kappa:87.835
fold:2 epoch:74 step:7 train loss:0.384278, train acc:87.915, train f1:87.346, train precision:87.907, train recall:87.774, train kappa:87.460
fold:2 epoch:74 step:8 train loss:0.383883, train acc:88.071, train f1:87.268, train precision:87.946, train recall:87.548, train kappa:87.628
fold:2 epoch:74 step:9 train loss:0.377569, train acc:88.129, train f1:87.275, train precision:88.151, train recall:87.508, train kappa:87.680
fold:2 epoch:74 step:10 train loss:0.390475, train acc:87.875, train f1:87.096, train precision:88.085, train recall:87.368, train kappa:87.412
fold:2 epoch:74 step:11 train loss:0.382754, train acc:88.129, train f1:86.973, train precision:87.794, train recall:87.112, train kappa:87.680
fold:2 epoch:74        valid loss:0.662134, valid acc:84.460, valid f1:61.518, valid precision:58.401, valid recall:70.926, valid kappa:82.479
[1;31mTest score increased (84.458258 --> 84.460302).[0m
[84.46030220622815, 61.518075072823144, 58.400898525023116, 70.92594228493112, 82.47899543003632]
====================================================================================================
fold:2 epoch:75 step:0 train loss:0.369925, train acc:88.388, train f1:87.357, train precision:88.284, train recall:87.620, train kappa:87.944
fold:2 epoch:75 step:1 train loss:0.375554, train acc:88.013, train f1:87.115, train precision:88.257, train recall:87.291, train kappa:87.561
fold:2 epoch:75 step:2 train loss:0.377456, train acc:88.101, train f1:87.308, train precision:88.427, train recall:87.469, train kappa:87.651
fold:2 epoch:75 step:3 train loss:0.382888, train acc:87.946, train f1:87.245, train precision:88.315, train recall:87.393, train kappa:87.488
fold:2 epoch:75 step:4 train loss:0.377272, train acc:88.104, train f1:87.419, train precision:88.162, train recall:87.754, train kappa:87.654
fold:2 epoch:75 step:5 train loss:0.376359, train acc:88.339, train f1:87.539, train precision:88.301, train recall:87.749, train kappa:87.895
fold:2 epoch:75 step:6 train loss:0.389868, train acc:87.952, train f1:87.308, train precision:87.776, train recall:87.771, train kappa:87.508
fold:2 epoch:75 step:7 train loss:0.371044, train acc:88.364, train f1:87.741, train precision:88.466, train recall:87.919, train kappa:87.923
fold:2 epoch:75 step:8 train loss:0.383319, train acc:88.129, train f1:87.322, train precision:88.378, train recall:87.527, train kappa:87.671
fold:2 epoch:75 step:9 train loss:0.373999, train acc:88.437, train f1:87.458, train precision:88.604, train recall:87.578, train kappa:87.999
fold:2 epoch:75 step:10 train loss:0.377286, train acc:88.138, train f1:87.384, train precision:88.803, train recall:87.380, train kappa:87.676
fold:2 epoch:75 step:11 train loss:0.373896, train acc:88.302, train f1:87.761, train precision:88.981, train recall:88.013, train kappa:87.863
fold:2 epoch:75        valid loss:0.665405, valid acc:84.340, valid f1:61.410, valid precision:58.334, valid recall:70.984, valid kappa:82.355
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.46030220622815, 61.518075072823144, 58.400898525023116, 70.92594228493112, 82.47899543003632]
====================================================================================================
fold:2 epoch:76 step:0 train loss:0.377216, train acc:88.037, train f1:87.234, train precision:88.263, train recall:87.447, train kappa:87.579
fold:2 epoch:76 step:1 train loss:0.373243, train acc:88.077, train f1:87.145, train precision:87.982, train recall:87.411, train kappa:87.628
fold:2 epoch:76 step:2 train loss:0.377984, train acc:87.952, train f1:87.304, train precision:87.893, train recall:87.701, train kappa:87.498
fold:2 epoch:76 step:3 train loss:0.369049, train acc:88.370, train f1:87.728, train precision:88.527, train recall:88.090, train kappa:87.926
fold:2 epoch:76 step:4 train loss:0.376697, train acc:88.321, train f1:87.333, train precision:88.346, train recall:87.413, train kappa:87.875
fold:2 epoch:76 step:5 train loss:0.384687, train acc:87.857, train f1:87.145, train precision:87.864, train recall:87.438, train kappa:87.398
fold:2 epoch:76 step:6 train loss:0.368170, train acc:88.309, train f1:87.680, train precision:88.970, train recall:87.694, train kappa:87.865
fold:2 epoch:76 step:7 train loss:0.386759, train acc:87.759, train f1:86.907, train precision:87.989, train recall:87.000, train kappa:87.288
fold:2 epoch:76 step:8 train loss:0.380286, train acc:88.092, train f1:87.479, train precision:88.626, train recall:87.482, train kappa:87.640
fold:2 epoch:76 step:9 train loss:0.381198, train acc:87.756, train f1:86.924, train precision:87.622, train recall:87.084, train kappa:87.298
fold:2 epoch:76 step:10 train loss:0.375147, train acc:88.269, train f1:87.512, train precision:88.094, train recall:87.765, train kappa:87.824
fold:2 epoch:76 step:11 train loss:0.386866, train acc:88.119, train f1:87.107, train precision:87.989, train recall:87.342, train kappa:87.666
fold:2 epoch:76        valid loss:0.667967, valid acc:84.354, valid f1:61.885, valid precision:58.880, valid recall:71.097, valid kappa:82.368
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.46030220622815, 61.518075072823144, 58.400898525023116, 70.92594228493112, 82.47899543003632]
====================================================================================================
fold:2 epoch:77 step:0 train loss:0.369351, train acc:88.156, train f1:87.200, train precision:88.075, train recall:87.618, train kappa:87.704
fold:2 epoch:77 step:1 train loss:0.378529, train acc:87.958, train f1:87.293, train precision:88.262, train recall:87.528, train kappa:87.501
fold:2 epoch:77 step:2 train loss:0.370076, train acc:88.300, train f1:87.583, train precision:88.672, train recall:87.784, train kappa:87.863
fold:2 epoch:77 step:3 train loss:0.379496, train acc:88.245, train f1:87.235, train precision:88.512, train recall:87.432, train kappa:87.788
fold:2 epoch:77 step:4 train loss:0.369529, train acc:88.373, train f1:87.442, train precision:88.663, train recall:87.504, train kappa:87.928
fold:2 epoch:77 step:5 train loss:0.378048, train acc:88.074, train f1:87.219, train precision:87.974, train recall:87.469, train kappa:87.622
fold:2 epoch:77 step:6 train loss:0.375682, train acc:88.153, train f1:87.581, train precision:88.401, train recall:87.717, train kappa:87.704
fold:2 epoch:77 step:7 train loss:0.375604, train acc:88.138, train f1:87.456, train precision:88.080, train recall:87.780, train kappa:87.687
fold:2 epoch:77 step:8 train loss:0.369572, train acc:88.165, train f1:87.346, train precision:88.052, train recall:87.578, train kappa:87.724
fold:2 epoch:77 step:9 train loss:0.378125, train acc:88.080, train f1:87.456, train precision:88.378, train recall:87.547, train kappa:87.633
fold:2 epoch:77 step:10 train loss:0.374975, train acc:88.434, train f1:87.668, train precision:88.507, train recall:87.887, train kappa:87.995
fold:2 epoch:77 step:11 train loss:0.374547, train acc:88.293, train f1:87.376, train precision:88.435, train recall:87.474, train kappa:87.842
fold:2 epoch:77        valid loss:0.667101, valid acc:84.532, valid f1:61.801, valid precision:58.792, valid recall:71.092, valid kappa:82.563
[1;31mTest score increased (84.460302 --> 84.531867).[0m
[84.53186660396263, 61.801256022771234, 58.79225830108344, 71.09156052249, 82.56331389794099]
====================================================================================================
fold:2 epoch:78 step:0 train loss:0.372191, train acc:88.351, train f1:87.590, train precision:88.617, train recall:87.811, train kappa:87.909
fold:2 epoch:78 step:1 train loss:0.366426, train acc:88.269, train f1:87.431, train precision:88.275, train recall:87.735, train kappa:87.826
fold:2 epoch:78 step:2 train loss:0.374010, train acc:88.184, train f1:87.334, train precision:88.346, train recall:87.545, train kappa:87.734
fold:2 epoch:78 step:3 train loss:0.368656, train acc:88.550, train f1:87.781, train precision:88.860, train recall:87.916, train kappa:88.119
fold:2 epoch:78 step:4 train loss:0.371304, train acc:88.559, train f1:87.671, train precision:88.293, train recall:88.015, train kappa:88.122
fold:2 epoch:78 step:5 train loss:0.375680, train acc:88.205, train f1:87.581, train precision:88.438, train recall:87.857, train kappa:87.753
fold:2 epoch:78 step:6 train loss:0.375975, train acc:88.248, train f1:87.531, train precision:88.569, train recall:87.775, train kappa:87.799
fold:2 epoch:78 step:7 train loss:0.373450, train acc:88.245, train f1:87.381, train precision:88.494, train recall:87.597, train kappa:87.804
fold:2 epoch:78 step:8 train loss:0.374849, train acc:88.373, train f1:87.483, train precision:88.278, train recall:87.762, train kappa:87.926
fold:2 epoch:78 step:9 train loss:0.379428, train acc:88.120, train f1:87.500, train precision:88.177, train recall:87.702, train kappa:87.679
fold:2 epoch:78 step:10 train loss:0.379384, train acc:88.022, train f1:87.344, train precision:88.347, train recall:87.347, train kappa:87.571
fold:2 epoch:78 step:11 train loss:0.387516, train acc:87.675, train f1:87.055, train precision:87.877, train recall:87.431, train kappa:87.187
fold:2 epoch:78        valid loss:0.667334, valid acc:84.417, valid f1:61.802, valid precision:58.776, valid recall:70.910, valid kappa:82.445
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.53186660396263, 61.801256022771234, 58.79225830108344, 71.09156052249, 82.56331389794099]
====================================================================================================
fold:2 epoch:79 step:0 train loss:0.366289, train acc:88.330, train f1:87.518, train precision:88.562, train recall:87.697, train kappa:87.886
fold:2 epoch:79 step:1 train loss:0.367913, train acc:88.376, train f1:87.466, train precision:88.658, train recall:87.560, train kappa:87.921
fold:2 epoch:79 step:2 train loss:0.382395, train acc:87.970, train f1:87.312, train precision:88.456, train recall:87.533, train kappa:87.510
fold:2 epoch:79 step:3 train loss:0.373639, train acc:88.275, train f1:87.715, train precision:88.602, train recall:87.993, train kappa:87.839
fold:2 epoch:79 step:4 train loss:0.369860, train acc:88.165, train f1:87.545, train precision:88.676, train recall:87.640, train kappa:87.721
fold:2 epoch:79 step:5 train loss:0.368687, train acc:88.461, train f1:87.724, train precision:88.358, train recall:88.023, train kappa:88.017
fold:2 epoch:79 step:6 train loss:0.372555, train acc:88.290, train f1:87.589, train precision:88.503, train recall:87.897, train kappa:87.857
fold:2 epoch:79 step:7 train loss:0.365891, train acc:88.315, train f1:87.477, train precision:88.645, train recall:87.553, train kappa:87.884
fold:2 epoch:79 step:8 train loss:0.363610, train acc:88.754, train f1:87.706, train precision:88.684, train recall:87.972, train kappa:88.323
fold:2 epoch:79 step:9 train loss:0.372881, train acc:88.318, train f1:87.704, train precision:88.811, train recall:87.705, train kappa:87.877
fold:2 epoch:79 step:10 train loss:0.380625, train acc:87.952, train f1:87.138, train precision:88.180, train recall:87.288, train kappa:87.486
fold:2 epoch:79 step:11 train loss:0.376846, train acc:88.322, train f1:87.604, train precision:88.536, train recall:87.851, train kappa:87.877
fold:2 epoch:79        valid loss:0.669833, valid acc:84.278, valid f1:61.881, valid precision:58.683, valid recall:71.079, valid kappa:82.287
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.53186660396263, 61.801256022771234, 58.79225830108344, 71.09156052249, 82.56331389794099]
====================================================================================================
fold:2 epoch:80 step:0 train loss:0.362589, train acc:88.580, train f1:87.894, train precision:88.594, train recall:88.194, train kappa:88.151
fold:2 epoch:80 step:1 train loss:0.373401, train acc:88.290, train f1:87.570, train precision:88.188, train recall:87.933, train kappa:87.838
fold:2 epoch:80 step:2 train loss:0.365418, train acc:88.556, train f1:87.743, train precision:88.528, train recall:88.067, train kappa:88.114
fold:2 epoch:80 step:3 train loss:0.365516, train acc:88.580, train f1:87.823, train precision:88.498, train recall:88.088, train kappa:88.157
fold:2 epoch:80 step:4 train loss:0.364290, train acc:88.501, train f1:87.653, train precision:88.660, train recall:87.760, train kappa:88.059
fold:2 epoch:80 step:5 train loss:0.366959, train acc:88.455, train f1:87.709, train precision:88.961, train recall:87.751, train kappa:88.012
fold:2 epoch:80 step:6 train loss:0.375714, train acc:88.211, train f1:87.501, train precision:88.549, train recall:87.545, train kappa:87.766
fold:2 epoch:80 step:7 train loss:0.370229, train acc:88.367, train f1:87.777, train precision:88.762, train recall:87.847, train kappa:87.923
fold:2 epoch:80 step:8 train loss:0.375617, train acc:88.153, train f1:87.469, train precision:88.291, train recall:87.729, train kappa:87.710
fold:2 epoch:80 step:9 train loss:0.374945, train acc:88.083, train f1:87.277, train precision:87.938, train recall:87.567, train kappa:87.637
fold:2 epoch:80 step:10 train loss:0.363505, train acc:88.519, train f1:87.734, train precision:88.427, train recall:87.982, train kappa:88.089
fold:2 epoch:80 step:11 train loss:0.370802, train acc:88.563, train f1:87.708, train precision:88.110, train recall:88.325, train kappa:88.134
fold:2 epoch:80        valid loss:0.668477, valid acc:84.466, valid f1:62.131, valid precision:59.383, valid recall:70.885, valid kappa:82.490
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.53186660396263, 61.801256022771234, 58.79225830108344, 71.09156052249, 82.56331389794099]
====================================================================================================
fold:2 epoch:81 step:0 train loss:0.364929, train acc:88.385, train f1:87.796, train precision:88.373, train recall:88.149, train kappa:87.941
fold:2 epoch:81 step:1 train loss:0.365898, train acc:88.354, train f1:87.544, train precision:88.642, train recall:87.815, train kappa:87.917
fold:2 epoch:81 step:2 train loss:0.363066, train acc:88.605, train f1:87.647, train precision:88.750, train recall:87.772, train kappa:88.170
fold:2 epoch:81 step:3 train loss:0.363856, train acc:88.516, train f1:87.705, train precision:88.839, train recall:87.712, train kappa:88.074
fold:2 epoch:81 step:4 train loss:0.360708, train acc:88.605, train f1:87.959, train precision:89.250, train recall:87.954, train kappa:88.176
fold:2 epoch:81 step:5 train loss:0.367723, train acc:88.388, train f1:87.583, train precision:88.562, train recall:87.679, train kappa:87.945
fold:2 epoch:81 step:6 train loss:0.369192, train acc:88.187, train f1:87.440, train precision:88.148, train recall:87.595, train kappa:87.754
fold:2 epoch:81 step:7 train loss:0.369600, train acc:88.306, train f1:87.777, train precision:88.069, train recall:88.336, train kappa:87.870
fold:2 epoch:81 step:8 train loss:0.364182, train acc:88.470, train f1:87.825, train precision:88.270, train recall:88.148, train kappa:88.032
fold:2 epoch:81 step:9 train loss:0.367787, train acc:88.348, train f1:87.525, train precision:88.197, train recall:87.772, train kappa:87.906
fold:2 epoch:81 step:10 train loss:0.368516, train acc:88.290, train f1:87.452, train precision:88.384, train recall:87.580, train kappa:87.846
fold:2 epoch:81 step:11 train loss:0.370112, train acc:88.544, train f1:87.580, train precision:88.757, train recall:87.940, train kappa:88.088
fold:2 epoch:81        valid loss:0.666409, valid acc:84.614, valid f1:61.927, valid precision:58.943, valid recall:71.077, valid kappa:82.653
[1;31mTest score increased (84.531867 --> 84.613654).[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:82 step:0 train loss:0.363158, train acc:88.654, train f1:88.080, train precision:89.300, train recall:87.968, train kappa:88.231
fold:2 epoch:82 step:1 train loss:0.361211, train acc:88.498, train f1:87.715, train precision:88.840, train recall:87.820, train kappa:88.049
fold:2 epoch:82 step:2 train loss:0.368187, train acc:88.324, train f1:87.601, train precision:88.652, train recall:87.729, train kappa:87.872
fold:2 epoch:82 step:3 train loss:0.368472, train acc:88.257, train f1:87.566, train precision:88.201, train recall:87.875, train kappa:87.807
fold:2 epoch:82 step:4 train loss:0.362592, train acc:88.666, train f1:87.974, train precision:88.567, train recall:88.349, train kappa:88.242
fold:2 epoch:82 step:5 train loss:0.365124, train acc:88.370, train f1:87.558, train precision:87.974, train recall:87.866, train kappa:87.925
fold:2 epoch:82 step:6 train loss:0.358629, train acc:88.791, train f1:87.757, train precision:88.445, train recall:88.117, train kappa:88.366
fold:2 epoch:82 step:7 train loss:0.378710, train acc:88.190, train f1:87.460, train precision:88.676, train recall:87.470, train kappa:87.747
fold:2 epoch:82 step:8 train loss:0.357671, train acc:88.684, train f1:87.813, train precision:88.806, train recall:87.917, train kappa:88.260
fold:2 epoch:82 step:9 train loss:0.373462, train acc:88.412, train f1:87.717, train precision:88.776, train recall:87.931, train kappa:87.975
fold:2 epoch:82 step:10 train loss:0.377516, train acc:88.126, train f1:87.329, train precision:88.354, train recall:87.426, train kappa:87.676
fold:2 epoch:82 step:11 train loss:0.373033, train acc:88.235, train f1:87.546, train precision:88.421, train recall:87.966, train kappa:87.797
fold:2 epoch:82        valid loss:0.667528, valid acc:84.585, valid f1:61.936, valid precision:58.832, valid recall:70.944, valid kappa:82.622
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:83 step:0 train loss:0.365336, train acc:88.416, train f1:87.524, train precision:88.386, train recall:87.711, train kappa:87.963
fold:2 epoch:83 step:1 train loss:0.359625, train acc:88.589, train f1:87.897, train precision:88.624, train recall:88.223, train kappa:88.154
fold:2 epoch:83 step:2 train loss:0.371229, train acc:88.232, train f1:87.795, train precision:88.580, train recall:88.021, train kappa:87.796
fold:2 epoch:83 step:3 train loss:0.374099, train acc:88.165, train f1:87.578, train precision:88.394, train recall:87.741, train kappa:87.719
fold:2 epoch:83 step:4 train loss:0.357730, train acc:88.620, train f1:87.944, train precision:88.780, train recall:88.068, train kappa:88.182
fold:2 epoch:83 step:5 train loss:0.357595, train acc:88.675, train f1:87.915, train precision:88.979, train recall:88.018, train kappa:88.251
fold:2 epoch:83 step:6 train loss:0.360324, train acc:88.501, train f1:87.503, train precision:88.702, train recall:87.346, train kappa:88.068
fold:2 epoch:83 step:7 train loss:0.361280, train acc:88.580, train f1:87.758, train precision:88.730, train recall:87.956, train kappa:88.146
fold:2 epoch:83 step:8 train loss:0.366911, train acc:88.528, train f1:87.692, train precision:88.404, train recall:88.094, train kappa:88.093
fold:2 epoch:83 step:9 train loss:0.368231, train acc:88.315, train f1:87.511, train precision:88.031, train recall:87.967, train kappa:87.875
fold:2 epoch:83 step:10 train loss:0.362222, train acc:88.605, train f1:87.978, train precision:88.760, train recall:88.129, train kappa:88.180
fold:2 epoch:83 step:11 train loss:0.381545, train acc:87.897, train f1:87.286, train precision:88.001, train recall:87.581, train kappa:87.440
fold:2 epoch:83        valid loss:0.672689, valid acc:84.454, valid f1:61.782, valid precision:58.649, valid recall:70.823, valid kappa:82.478
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:84 step:0 train loss:0.358438, train acc:88.675, train f1:87.955, train precision:88.768, train recall:88.185, train kappa:88.245
fold:2 epoch:84 step:1 train loss:0.360637, train acc:88.284, train f1:87.547, train precision:88.632, train recall:87.548, train kappa:87.836
fold:2 epoch:84 step:2 train loss:0.363433, train acc:88.400, train f1:87.778, train precision:88.888, train recall:87.755, train kappa:87.961
fold:2 epoch:84 step:3 train loss:0.353636, train acc:88.849, train f1:88.112, train precision:89.009, train recall:88.323, train kappa:88.427
fold:2 epoch:84 step:4 train loss:0.359771, train acc:88.467, train f1:87.733, train precision:88.497, train recall:87.871, train kappa:88.033
fold:2 epoch:84 step:5 train loss:0.368178, train acc:88.220, train f1:87.520, train precision:88.321, train recall:87.740, train kappa:87.770
fold:2 epoch:84 step:6 train loss:0.370334, train acc:88.382, train f1:87.553, train precision:88.003, train recall:87.972, train kappa:87.938
fold:2 epoch:84 step:7 train loss:0.364598, train acc:88.333, train f1:87.588, train precision:88.468, train recall:87.812, train kappa:87.893
fold:2 epoch:84 step:8 train loss:0.363489, train acc:88.589, train f1:87.845, train precision:88.544, train recall:88.023, train kappa:88.166
fold:2 epoch:84 step:9 train loss:0.365628, train acc:88.376, train f1:87.672, train precision:88.590, train recall:87.960, train kappa:87.936
fold:2 epoch:84 step:10 train loss:0.364100, train acc:88.434, train f1:87.697, train precision:88.700, train recall:87.904, train kappa:87.990
fold:2 epoch:84 step:11 train loss:0.353988, train acc:88.862, train f1:87.982, train precision:88.885, train recall:88.074, train kappa:88.440
fold:2 epoch:84        valid loss:0.670495, valid acc:84.577, valid f1:62.216, valid precision:59.334, valid recall:71.000, valid kappa:82.614
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:85 step:0 train loss:0.361104, train acc:88.596, train f1:87.903, train precision:88.987, train recall:87.929, train kappa:88.169
fold:2 epoch:85 step:1 train loss:0.363703, train acc:88.492, train f1:87.862, train precision:88.938, train recall:88.100, train kappa:88.050
fold:2 epoch:85 step:2 train loss:0.366969, train acc:88.669, train f1:87.954, train precision:88.689, train recall:88.252, train kappa:88.239
fold:2 epoch:85 step:3 train loss:0.361400, train acc:88.507, train f1:87.632, train precision:88.400, train recall:87.925, train kappa:88.073
fold:2 epoch:85 step:4 train loss:0.358944, train acc:88.580, train f1:87.799, train precision:88.548, train recall:88.061, train kappa:88.156
fold:2 epoch:85 step:5 train loss:0.358900, train acc:88.617, train f1:87.942, train precision:88.457, train recall:88.334, train kappa:88.189
fold:2 epoch:85 step:6 train loss:0.360308, train acc:88.654, train f1:88.012, train precision:88.957, train recall:88.118, train kappa:88.229
fold:2 epoch:85 step:7 train loss:0.350456, train acc:88.852, train f1:88.204, train precision:88.883, train recall:88.504, train kappa:88.428
fold:2 epoch:85 step:8 train loss:0.363673, train acc:88.525, train f1:87.706, train precision:88.603, train recall:87.878, train kappa:88.086
fold:2 epoch:85 step:9 train loss:0.357569, train acc:88.727, train f1:88.036, train precision:89.091, train recall:87.985, train kappa:88.300
fold:2 epoch:85 step:10 train loss:0.358328, train acc:88.699, train f1:87.905, train precision:88.792, train recall:88.004, train kappa:88.269
fold:2 epoch:85 step:11 train loss:0.366210, train acc:88.341, train f1:87.516, train precision:88.503, train recall:87.778, train kappa:87.885
fold:2 epoch:85        valid loss:0.671360, valid acc:84.477, valid f1:62.154, valid precision:59.184, valid recall:70.912, valid kappa:82.501
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:86 step:0 train loss:0.347588, train acc:88.895, train f1:88.118, train precision:88.973, train recall:88.305, train kappa:88.471
fold:2 epoch:86 step:1 train loss:0.360411, train acc:88.541, train f1:87.900, train precision:88.675, train recall:88.202, train kappa:88.109
fold:2 epoch:86 step:2 train loss:0.355540, train acc:88.739, train f1:87.813, train precision:88.631, train recall:88.049, train kappa:88.313
fold:2 epoch:86 step:3 train loss:0.363124, train acc:88.483, train f1:87.720, train precision:88.781, train recall:87.914, train kappa:88.045
fold:2 epoch:86 step:4 train loss:0.354541, train acc:88.779, train f1:87.959, train precision:88.741, train recall:88.257, train kappa:88.349
fold:2 epoch:86 step:5 train loss:0.363119, train acc:88.416, train f1:87.781, train precision:88.723, train recall:87.879, train kappa:87.985
fold:2 epoch:86 step:6 train loss:0.364864, train acc:88.449, train f1:87.828, train precision:88.870, train recall:87.968, train kappa:88.013
fold:2 epoch:86 step:7 train loss:0.366642, train acc:88.345, train f1:87.716, train precision:88.783, train recall:87.874, train kappa:87.905
fold:2 epoch:86 step:8 train loss:0.360010, train acc:88.486, train f1:87.710, train precision:88.535, train recall:87.872, train kappa:88.048
fold:2 epoch:86 step:9 train loss:0.359715, train acc:88.495, train f1:87.855, train precision:88.585, train recall:87.936, train kappa:88.056
fold:2 epoch:86 step:10 train loss:0.354154, train acc:88.788, train f1:87.967, train precision:88.667, train recall:88.049, train kappa:88.362
fold:2 epoch:86 step:11 train loss:0.354306, train acc:88.795, train f1:87.798, train precision:88.712, train recall:87.876, train kappa:88.369
fold:2 epoch:86        valid loss:0.668122, valid acc:84.565, valid f1:62.226, valid precision:59.271, valid recall:70.965, valid kappa:82.603
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:87 step:0 train loss:0.356923, train acc:88.538, train f1:87.941, train precision:88.709, train recall:88.134, train kappa:88.104
fold:2 epoch:87 step:1 train loss:0.352836, train acc:88.715, train f1:87.894, train precision:88.836, train recall:88.105, train kappa:88.292
fold:2 epoch:87 step:2 train loss:0.355073, train acc:88.651, train f1:88.006, train precision:88.912, train recall:88.263, train kappa:88.217
fold:2 epoch:87 step:3 train loss:0.362202, train acc:88.666, train f1:88.016, train precision:88.885, train recall:88.273, train kappa:88.244
fold:2 epoch:87 step:4 train loss:0.356085, train acc:88.620, train f1:87.808, train precision:88.675, train recall:87.972, train kappa:88.190
fold:2 epoch:87 step:5 train loss:0.356255, train acc:88.870, train f1:88.041, train precision:88.792, train recall:88.226, train kappa:88.459
fold:2 epoch:87 step:6 train loss:0.363342, train acc:88.428, train f1:87.689, train precision:88.326, train recall:88.058, train kappa:87.990
fold:2 epoch:87 step:7 train loss:0.355625, train acc:88.882, train f1:88.307, train precision:89.062, train recall:88.377, train kappa:88.459
fold:2 epoch:87 step:8 train loss:0.357277, train acc:88.681, train f1:87.983, train precision:88.771, train recall:88.107, train kappa:88.253
fold:2 epoch:87 step:9 train loss:0.363944, train acc:88.522, train f1:87.838, train precision:88.643, train recall:88.220, train kappa:88.073
fold:2 epoch:87 step:10 train loss:0.364005, train acc:88.599, train f1:87.901, train precision:88.663, train recall:88.078, train kappa:88.172
fold:2 epoch:87 step:11 train loss:0.359679, train acc:88.688, train f1:87.946, train precision:88.805, train recall:88.122, train kappa:88.255
fold:2 epoch:87        valid loss:0.675203, valid acc:84.554, valid f1:61.998, valid precision:58.995, valid recall:70.934, valid kappa:82.594
[1;31mEarlyStopping counter: 6 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:88 step:0 train loss:0.358237, train acc:88.651, train f1:88.005, train precision:88.898, train recall:88.139, train kappa:88.223
fold:2 epoch:88 step:1 train loss:0.351304, train acc:88.675, train f1:87.861, train precision:88.946, train recall:88.129, train kappa:88.244
fold:2 epoch:88 step:2 train loss:0.351197, train acc:88.889, train f1:88.107, train precision:89.097, train recall:88.194, train kappa:88.461
fold:2 epoch:88 step:3 train loss:0.347553, train acc:88.809, train f1:87.880, train precision:88.792, train recall:88.182, train kappa:88.381
fold:2 epoch:88 step:4 train loss:0.362145, train acc:88.376, train f1:87.653, train precision:88.528, train recall:87.993, train kappa:87.934
fold:2 epoch:88 step:5 train loss:0.356757, train acc:88.672, train f1:87.785, train precision:88.663, train recall:87.935, train kappa:88.235
fold:2 epoch:88 step:6 train loss:0.359091, train acc:88.629, train f1:87.998, train precision:88.973, train recall:88.058, train kappa:88.196
fold:2 epoch:88 step:7 train loss:0.361694, train acc:88.684, train f1:87.955, train precision:88.672, train recall:88.208, train kappa:88.265
fold:2 epoch:88 step:8 train loss:0.362449, train acc:88.464, train f1:87.622, train precision:88.346, train recall:87.827, train kappa:88.028
fold:2 epoch:88 step:9 train loss:0.359926, train acc:88.724, train f1:88.039, train precision:88.916, train recall:88.193, train kappa:88.298
fold:2 epoch:88 step:10 train loss:0.363753, train acc:88.443, train f1:87.765, train precision:88.460, train recall:88.014, train kappa:88.018
fold:2 epoch:88 step:11 train loss:0.352976, train acc:88.669, train f1:87.678, train precision:88.427, train recall:87.985, train kappa:88.254
fold:2 epoch:88        valid loss:0.671134, valid acc:84.589, valid f1:62.221, valid precision:59.448, valid recall:70.895, valid kappa:82.629
[1;31mEarlyStopping counter: 7 out of 50[0m
[84.61365448708774, 61.926581288356516, 58.94256423198446, 71.07668758391867, 82.65328104582942]
====================================================================================================
fold:2 epoch:89 step:0 train loss:0.359269, train acc:88.562, train f1:87.823, train precision:88.600, train recall:88.105, train kappa:88.127
fold:2 epoch:89 step:1 train loss:0.356639, train acc:88.663, train f1:87.884, train precision:88.478, train recall:88.237, train kappa:88.232
fold:2 epoch:89 step:2 train loss:0.349249, train acc:88.934, train f1:87.813, train precision:88.596, train recall:88.039, train kappa:88.513
fold:2 epoch:89 step:3 train loss:0.354092, train acc:88.748, train f1:88.116, train precision:88.999, train recall:88.217, train kappa:88.332
fold:2 epoch:89 step:4 train loss:0.354926, train acc:88.800, train f1:88.019, train precision:88.672, train recall:88.261, train kappa:88.373
fold:2 epoch:89 step:5 train loss:0.356228, train acc:88.593, train f1:87.991, train precision:88.853, train recall:88.122, train kappa:88.160
fold:2 epoch:89 step:6 train loss:0.353477, train acc:88.721, train f1:87.973, train precision:88.854, train recall:88.103, train kappa:88.295
fold:2 epoch:89 step:7 train loss:0.353850, train acc:88.608, train f1:87.899, train precision:88.846, train recall:88.059, train kappa:88.179
fold:2 epoch:89 step:8 train loss:0.357502, train acc:88.745, train f1:87.928, train precision:88.563, train recall:88.204, train kappa:88.327
fold:2 epoch:89 step:9 train loss:0.359916, train acc:88.605, train f1:87.885, train precision:88.476, train recall:88.150, train kappa:88.178
fold:2 epoch:89 step:10 train loss:0.352592, train acc:88.602, train f1:87.697, train precision:88.371, train recall:87.971, train kappa:88.163
fold:2 epoch:89 step:11 train loss:0.354731, train acc:88.901, train f1:88.187, train precision:88.900, train recall:88.511, train kappa:88.476
fold:2 epoch:89        valid loss:0.671051, valid acc:84.650, valid f1:62.033, valid precision:58.927, valid recall:71.008, valid kappa:82.698
[1;31mTest score increased (84.613654 --> 84.650459).[0m
[84.65045903449405, 62.03260927389417, 58.926916044454245, 71.00777537501129, 82.6980408159495]
====================================================================================================
fold:2 epoch:90 step:0 train loss:0.350048, train acc:88.815, train f1:87.901, train precision:88.695, train recall:88.157, train kappa:88.392
fold:2 epoch:90 step:1 train loss:0.345386, train acc:89.005, train f1:88.263, train precision:89.084, train recall:88.460, train kappa:88.600
fold:2 epoch:90 step:2 train loss:0.354590, train acc:88.809, train f1:88.233, train precision:89.010, train recall:88.390, train kappa:88.396
fold:2 epoch:90 step:3 train loss:0.359093, train acc:88.657, train f1:87.859, train precision:88.569, train recall:88.201, train kappa:88.225
fold:2 epoch:90 step:4 train loss:0.345209, train acc:88.995, train f1:88.011, train precision:88.886, train recall:88.175, train kappa:88.583
fold:2 epoch:90 step:5 train loss:0.351441, train acc:88.928, train f1:88.061, train precision:88.988, train recall:88.334, train kappa:88.506
fold:2 epoch:90 step:6 train loss:0.347608, train acc:88.760, train f1:88.151, train precision:89.121, train recall:88.204, train kappa:88.336
fold:2 epoch:90 step:7 train loss:0.356037, train acc:88.654, train f1:87.748, train precision:88.467, train recall:87.987, train kappa:88.213
fold:2 epoch:90 step:8 train loss:0.360695, train acc:88.791, train f1:87.996, train precision:88.931, train recall:88.098, train kappa:88.361
fold:2 epoch:90 step:9 train loss:0.358524, train acc:88.580, train f1:87.872, train precision:88.551, train recall:88.044, train kappa:88.143
fold:2 epoch:90 step:10 train loss:0.355755, train acc:88.699, train f1:88.072, train precision:88.764, train recall:88.288, train kappa:88.268
fold:2 epoch:90 step:11 train loss:0.350605, train acc:88.766, train f1:88.041, train precision:88.884, train recall:88.232, train kappa:88.358
fold:2 epoch:90        valid loss:0.674973, valid acc:84.632, valid f1:62.346, valid precision:59.388, valid recall:70.963, valid kappa:82.676
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.65045903449405, 62.03260927389417, 58.926916044454245, 71.00777537501129, 82.6980408159495]
====================================================================================================
fold:2 epoch:91 step:0 train loss:0.351186, train acc:88.867, train f1:88.264, train precision:89.041, train recall:88.476, train kappa:88.447
fold:2 epoch:91 step:1 train loss:0.340170, train acc:89.380, train f1:88.438, train precision:89.200, train recall:88.658, train kappa:88.976
fold:2 epoch:91 step:2 train loss:0.342031, train acc:89.053, train f1:88.321, train precision:89.351, train recall:88.437, train kappa:88.646
fold:2 epoch:91 step:3 train loss:0.345690, train acc:89.017, train f1:88.231, train precision:89.083, train recall:88.567, train kappa:88.601
fold:2 epoch:91 step:4 train loss:0.359863, train acc:88.699, train f1:87.880, train precision:88.776, train recall:88.127, train kappa:88.273
fold:2 epoch:91 step:5 train loss:0.346772, train acc:89.093, train f1:88.500, train precision:89.427, train recall:88.617, train kappa:88.679
fold:2 epoch:91 step:6 train loss:0.343652, train acc:88.950, train f1:88.150, train precision:88.855, train recall:88.367, train kappa:88.534
fold:2 epoch:91 step:7 train loss:0.355241, train acc:88.589, train f1:87.975, train precision:88.729, train recall:88.182, train kappa:88.152
fold:2 epoch:91 step:8 train loss:0.353061, train acc:88.852, train f1:88.064, train precision:88.477, train recall:88.377, train kappa:88.422
fold:2 epoch:91 step:9 train loss:0.354554, train acc:88.629, train f1:87.700, train precision:88.582, train recall:87.877, train kappa:88.199
fold:2 epoch:91 step:10 train loss:0.354024, train acc:88.699, train f1:88.049, train precision:88.703, train recall:88.237, train kappa:88.283
fold:2 epoch:91 step:11 train loss:0.357563, train acc:88.640, train f1:87.750, train precision:88.386, train recall:87.991, train kappa:88.218
fold:2 epoch:91        valid loss:0.674457, valid acc:84.665, valid f1:62.374, valid precision:59.448, valid recall:70.914, valid kappa:82.711
[1;31mTest score increased (84.650459 --> 84.664772).[0m
[84.66477191404094, 62.37354477836722, 59.448050581284825, 70.91396044301112, 82.71148956887724]
====================================================================================================
fold:2 epoch:92 step:0 train loss:0.350093, train acc:88.882, train f1:88.063, train precision:89.046, train recall:88.245, train kappa:88.469
fold:2 epoch:92 step:1 train loss:0.343915, train acc:89.035, train f1:88.234, train precision:89.361, train recall:88.240, train kappa:88.615
fold:2 epoch:92 step:2 train loss:0.350427, train acc:88.611, train f1:87.792, train precision:89.001, train recall:87.787, train kappa:88.182
fold:2 epoch:92 step:3 train loss:0.340248, train acc:89.258, train f1:88.506, train precision:89.407, train recall:88.599, train kappa:88.848
fold:2 epoch:92 step:4 train loss:0.348467, train acc:88.721, train f1:88.158, train precision:88.881, train recall:88.443, train kappa:88.299
fold:2 epoch:92 step:5 train loss:0.355372, train acc:88.892, train f1:88.367, train precision:88.568, train recall:88.908, train kappa:88.481
fold:2 epoch:92 step:6 train loss:0.353309, train acc:88.721, train f1:87.829, train precision:88.514, train recall:88.190, train kappa:88.287
fold:2 epoch:92 step:7 train loss:0.345924, train acc:88.846, train f1:88.200, train precision:88.916, train recall:88.461, train kappa:88.436
fold:2 epoch:92 step:8 train loss:0.348150, train acc:88.858, train f1:88.043, train precision:88.953, train recall:88.200, train kappa:88.440
fold:2 epoch:92 step:9 train loss:0.345717, train acc:89.038, train f1:88.064, train precision:88.827, train recall:88.268, train kappa:88.619
fold:2 epoch:92 step:10 train loss:0.351715, train acc:88.971, train f1:88.146, train precision:89.012, train recall:88.278, train kappa:88.547
fold:2 epoch:92 step:11 train loss:0.359046, train acc:88.746, train f1:88.163, train precision:88.813, train recall:88.454, train kappa:88.305
fold:2 epoch:92        valid loss:0.672705, valid acc:84.657, valid f1:62.273, valid precision:59.132, valid recall:71.007, valid kappa:82.705
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.66477191404094, 62.37354477836722, 59.448050581284825, 70.91396044301112, 82.71148956887724]
====================================================================================================
fold:2 epoch:93 step:0 train loss:0.345721, train acc:88.913, train f1:88.224, train precision:89.148, train recall:88.266, train kappa:88.496
fold:2 epoch:93 step:1 train loss:0.350982, train acc:88.635, train f1:87.778, train precision:88.449, train recall:88.063, train kappa:88.207
fold:2 epoch:93 step:2 train loss:0.347459, train acc:88.931, train f1:88.262, train precision:88.921, train recall:88.534, train kappa:88.514
fold:2 epoch:93 step:3 train loss:0.346712, train acc:89.090, train f1:88.423, train precision:89.346, train recall:88.519, train kappa:88.679
fold:2 epoch:93 step:4 train loss:0.347649, train acc:88.986, train f1:88.218, train precision:88.865, train recall:88.427, train kappa:88.574
fold:2 epoch:93 step:5 train loss:0.355222, train acc:88.632, train f1:87.875, train precision:88.629, train recall:88.093, train kappa:88.196
fold:2 epoch:93 step:6 train loss:0.350829, train acc:88.806, train f1:88.173, train precision:88.970, train recall:88.338, train kappa:88.387
fold:2 epoch:93 step:7 train loss:0.349178, train acc:88.760, train f1:87.999, train precision:88.661, train recall:88.275, train kappa:88.335
fold:2 epoch:93 step:8 train loss:0.342784, train acc:89.154, train f1:88.248, train precision:89.144, train recall:88.497, train kappa:88.735
fold:2 epoch:93 step:9 train loss:0.351330, train acc:88.757, train f1:87.918, train precision:89.023, train recall:87.974, train kappa:88.324
fold:2 epoch:93 step:10 train loss:0.349396, train acc:88.815, train f1:87.957, train precision:88.930, train recall:88.142, train kappa:88.399
fold:2 epoch:93 step:11 train loss:0.359701, train acc:88.486, train f1:88.043, train precision:88.775, train recall:88.424, train kappa:88.054
fold:2 epoch:93        valid loss:0.674458, valid acc:84.706, valid f1:62.434, valid precision:59.459, valid recall:70.938, valid kappa:82.756
[1;31mTest score increased (84.664772 --> 84.705666).[0m
[84.7056658556035, 62.433857533344174, 59.45909041363744, 70.93754730605056, 82.75565907923846]
====================================================================================================
fold:2 epoch:94 step:0 train loss:0.344332, train acc:88.950, train f1:88.188, train precision:88.969, train recall:88.335, train kappa:88.521
fold:2 epoch:94 step:1 train loss:0.347885, train acc:88.849, train f1:87.993, train precision:88.773, train recall:88.134, train kappa:88.424
fold:2 epoch:94 step:2 train loss:0.336668, train acc:89.197, train f1:88.469, train precision:89.303, train recall:88.539, train kappa:88.794
fold:2 epoch:94 step:3 train loss:0.353012, train acc:88.727, train f1:87.958, train precision:88.729, train recall:88.197, train kappa:88.309
fold:2 epoch:94 step:4 train loss:0.341491, train acc:88.843, train f1:88.195, train precision:88.664, train recall:88.588, train kappa:88.427
fold:2 epoch:94 step:5 train loss:0.341461, train acc:89.105, train f1:88.226, train precision:88.808, train recall:88.610, train kappa:88.690
fold:2 epoch:94 step:6 train loss:0.354555, train acc:88.602, train f1:87.894, train precision:88.577, train recall:88.125, train kappa:88.177
fold:2 epoch:94 step:7 train loss:0.347666, train acc:89.011, train f1:88.237, train precision:89.019, train recall:88.409, train kappa:88.605
fold:2 epoch:94 step:8 train loss:0.355582, train acc:88.593, train f1:87.937, train precision:88.609, train recall:88.183, train kappa:88.159
fold:2 epoch:94 step:9 train loss:0.353202, train acc:88.907, train f1:88.280, train precision:89.059, train recall:88.523, train kappa:88.486
fold:2 epoch:94 step:10 train loss:0.349909, train acc:88.889, train f1:88.193, train precision:88.925, train recall:88.323, train kappa:88.459
fold:2 epoch:94 step:11 train loss:0.343053, train acc:89.152, train f1:88.530, train precision:89.160, train recall:88.843, train kappa:88.738
fold:2 epoch:94        valid loss:0.675400, valid acc:84.642, valid f1:62.671, valid precision:60.025, valid recall:70.678, valid kappa:82.687
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.7056658556035, 62.433857533344174, 59.45909041363744, 70.93754730605056, 82.75565907923846]
====================================================================================================
fold:2 epoch:95 step:0 train loss:0.348800, train acc:88.934, train f1:88.287, train precision:89.269, train recall:88.382, train kappa:88.517
fold:2 epoch:95 step:1 train loss:0.339641, train acc:88.885, train f1:88.365, train precision:89.066, train recall:88.465, train kappa:88.464
fold:2 epoch:95 step:2 train loss:0.353587, train acc:88.553, train f1:87.925, train precision:88.675, train recall:88.082, train kappa:88.126
fold:2 epoch:95 step:3 train loss:0.346920, train acc:88.873, train f1:88.136, train precision:88.632, train recall:88.427, train kappa:88.449
fold:2 epoch:95 step:4 train loss:0.331949, train acc:89.597, train f1:88.731, train precision:89.398, train recall:88.863, train kappa:89.211
fold:2 epoch:95 step:5 train loss:0.344925, train acc:88.962, train f1:88.276, train precision:89.195, train recall:88.415, train kappa:88.552
fold:2 epoch:95 step:6 train loss:0.350543, train acc:88.916, train f1:88.153, train precision:89.098, train recall:88.321, train kappa:88.496
fold:2 epoch:95 step:7 train loss:0.342038, train acc:89.154, train f1:88.340, train precision:88.970, train recall:88.638, train kappa:88.735
fold:2 epoch:95 step:8 train loss:0.351533, train acc:88.824, train f1:87.976, train precision:89.013, train recall:87.960, train kappa:88.399
fold:2 epoch:95 step:9 train loss:0.347205, train acc:88.879, train f1:88.311, train precision:89.081, train recall:88.508, train kappa:88.460
fold:2 epoch:95 step:10 train loss:0.355108, train acc:88.544, train f1:87.850, train precision:88.456, train recall:88.190, train kappa:88.108
fold:2 epoch:95 step:11 train loss:0.347282, train acc:88.814, train f1:87.697, train precision:88.445, train recall:87.981, train kappa:88.386
fold:2 epoch:95        valid loss:0.676167, valid acc:84.718, valid f1:62.695, valid precision:59.875, valid recall:70.960, valid kappa:82.772
[1;31mTest score increased (84.705666 --> 84.717934).[0m
[84.71793403807226, 62.69537445236587, 59.87516377270781, 70.96025600648188, 82.77218854299507]
====================================================================================================
fold:2 epoch:96 step:0 train loss:0.339417, train acc:88.977, train f1:88.455, train precision:88.946, train recall:88.831, train kappa:88.561
fold:2 epoch:96 step:1 train loss:0.346536, train acc:88.931, train f1:88.076, train precision:88.892, train recall:88.189, train kappa:88.517
fold:2 epoch:96 step:2 train loss:0.340713, train acc:89.206, train f1:88.404, train precision:89.249, train recall:88.409, train kappa:88.800
fold:2 epoch:96 step:3 train loss:0.338943, train acc:89.206, train f1:88.500, train precision:89.529, train recall:88.572, train kappa:88.796
fold:2 epoch:96 step:4 train loss:0.336708, train acc:89.240, train f1:88.359, train precision:89.197, train recall:88.404, train kappa:88.836
fold:2 epoch:96 step:5 train loss:0.345939, train acc:88.977, train f1:88.334, train precision:88.950, train recall:88.567, train kappa:88.556
fold:2 epoch:96 step:6 train loss:0.345406, train acc:88.718, train f1:88.086, train precision:88.755, train recall:88.390, train kappa:88.281
fold:2 epoch:96 step:7 train loss:0.342608, train acc:88.950, train f1:88.296, train precision:88.810, train recall:88.637, train kappa:88.542
fold:2 epoch:96 step:8 train loss:0.340026, train acc:89.252, train f1:88.452, train precision:88.880, train recall:88.941, train kappa:88.851
fold:2 epoch:96 step:9 train loss:0.346800, train acc:88.895, train f1:88.100, train precision:88.801, train recall:88.373, train kappa:88.471
fold:2 epoch:96 step:10 train loss:0.346076, train acc:88.910, train f1:88.203, train precision:89.046, train recall:88.225, train kappa:88.493
fold:2 epoch:96 step:11 train loss:0.341950, train acc:89.094, train f1:88.156, train precision:89.308, train recall:88.234, train kappa:88.671
fold:2 epoch:96        valid loss:0.681313, valid acc:84.630, valid f1:62.219, valid precision:59.409, valid recall:70.606, valid kappa:82.678
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.71793403807226, 62.69537445236587, 59.87516377270781, 70.96025600648188, 82.77218854299507]
====================================================================================================
fold:2 epoch:97 step:0 train loss:0.340244, train acc:89.053, train f1:88.245, train precision:89.136, train recall:88.355, train kappa:88.634
fold:2 epoch:97 step:1 train loss:0.337125, train acc:88.992, train f1:88.261, train precision:88.981, train recall:88.450, train kappa:88.574
fold:2 epoch:97 step:2 train loss:0.340106, train acc:89.157, train f1:88.415, train precision:89.130, train recall:88.547, train kappa:88.749
fold:2 epoch:97 step:3 train loss:0.340754, train acc:89.056, train f1:88.274, train precision:88.841, train recall:88.662, train kappa:88.640
fold:2 epoch:97 step:4 train loss:0.341125, train acc:88.913, train f1:88.332, train precision:89.126, train recall:88.504, train kappa:88.501
fold:2 epoch:97 step:5 train loss:0.345865, train acc:88.950, train f1:88.326, train precision:88.985, train recall:88.572, train kappa:88.543
fold:2 epoch:97 step:6 train loss:0.339948, train acc:89.120, train f1:88.223, train precision:88.904, train recall:88.489, train kappa:88.701
fold:2 epoch:97 step:7 train loss:0.343950, train acc:88.834, train f1:88.233, train precision:88.935, train recall:88.443, train kappa:88.413
fold:2 epoch:97 step:8 train loss:0.339671, train acc:88.956, train f1:88.047, train precision:88.914, train recall:88.271, train kappa:88.539
fold:2 epoch:97 step:9 train loss:0.342466, train acc:89.188, train f1:88.289, train precision:89.047, train recall:88.563, train kappa:88.779
fold:2 epoch:97 step:10 train loss:0.350833, train acc:88.797, train f1:88.013, train precision:88.678, train recall:88.218, train kappa:88.374
fold:2 epoch:97 step:11 train loss:0.333336, train acc:89.480, train f1:88.842, train precision:89.366, train recall:89.286, train kappa:89.098
fold:2 epoch:97        valid loss:0.681747, valid acc:84.655, valid f1:62.584, valid precision:59.770, valid recall:70.817, valid kappa:82.705
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.71793403807226, 62.69537445236587, 59.87516377270781, 70.96025600648188, 82.77218854299507]
====================================================================================================
fold:2 epoch:98 step:0 train loss:0.347157, train acc:88.730, train f1:87.903, train precision:88.657, train recall:88.083, train kappa:88.302
fold:2 epoch:98 step:1 train loss:0.335583, train acc:89.227, train f1:88.471, train precision:89.304, train recall:88.609, train kappa:88.817
fold:2 epoch:98 step:2 train loss:0.340313, train acc:88.962, train f1:88.320, train precision:88.959, train recall:88.535, train kappa:88.544
fold:2 epoch:98 step:3 train loss:0.335520, train acc:89.288, train f1:88.540, train precision:89.303, train recall:88.740, train kappa:88.878
fold:2 epoch:98 step:4 train loss:0.347654, train acc:88.843, train f1:88.229, train precision:88.955, train recall:88.422, train kappa:88.428
fold:2 epoch:98 step:5 train loss:0.335231, train acc:89.224, train f1:88.451, train precision:89.268, train recall:88.553, train kappa:88.828
fold:2 epoch:98 step:6 train loss:0.345390, train acc:88.895, train f1:88.104, train precision:88.777, train recall:88.234, train kappa:88.485
fold:2 epoch:98 step:7 train loss:0.343507, train acc:89.154, train f1:88.519, train precision:89.081, train recall:88.869, train kappa:88.743
fold:2 epoch:98 step:8 train loss:0.337700, train acc:89.255, train f1:88.604, train precision:89.043, train recall:89.007, train kappa:88.853
fold:2 epoch:98 step:9 train loss:0.337972, train acc:89.185, train f1:88.500, train precision:89.152, train recall:88.863, train kappa:88.773
fold:2 epoch:98 step:10 train loss:0.352874, train acc:88.837, train f1:87.981, train precision:88.746, train recall:88.295, train kappa:88.413
fold:2 epoch:98 step:11 train loss:0.352797, train acc:88.756, train f1:88.118, train precision:88.987, train recall:88.430, train kappa:88.318
fold:2 epoch:98        valid loss:0.679675, valid acc:84.749, valid f1:62.581, valid precision:59.782, valid recall:70.872, valid kappa:82.803
[1;31mTest score increased (84.717934 --> 84.748604).[0m
[84.74860449424418, 62.5807712527686, 59.78231319453277, 70.87162494355334, 82.80294493817384]
====================================================================================================
fold:2 epoch:99 step:0 train loss:0.335175, train acc:89.346, train f1:88.578, train precision:89.383, train recall:88.722, train kappa:88.941
fold:2 epoch:99 step:1 train loss:0.335007, train acc:89.297, train f1:88.540, train precision:89.251, train recall:88.623, train kappa:88.895
fold:2 epoch:99 step:2 train loss:0.350181, train acc:88.776, train f1:88.129, train precision:88.791, train recall:88.432, train kappa:88.348
fold:2 epoch:99 step:3 train loss:0.338375, train acc:89.233, train f1:88.549, train precision:89.187, train recall:88.722, train kappa:88.832
fold:2 epoch:99 step:4 train loss:0.336059, train acc:89.114, train f1:88.471, train precision:89.212, train recall:88.514, train kappa:88.709
fold:2 epoch:99 step:5 train loss:0.340788, train acc:89.023, train f1:88.435, train precision:89.416, train recall:88.424, train kappa:88.610
fold:2 epoch:99 step:6 train loss:0.340062, train acc:89.133, train f1:88.309, train precision:89.024, train recall:88.597, train kappa:88.716
fold:2 epoch:99 step:7 train loss:0.337521, train acc:89.264, train f1:88.422, train precision:89.140, train recall:88.697, train kappa:88.857
fold:2 epoch:99 step:8 train loss:0.343829, train acc:88.934, train f1:88.350, train precision:89.011, train recall:88.545, train kappa:88.513
fold:2 epoch:99 step:9 train loss:0.335340, train acc:89.224, train f1:88.283, train precision:89.207, train recall:88.409, train kappa:88.823
fold:2 epoch:99 step:10 train loss:0.338944, train acc:89.145, train f1:88.308, train precision:88.822, train recall:88.690, train kappa:88.735
fold:2 epoch:99 step:11 train loss:0.358392, train acc:88.698, train f1:88.021, train precision:88.493, train recall:88.601, train kappa:88.277
fold:2 epoch:99        valid loss:0.675260, valid acc:84.865, valid f1:62.778, valid precision:60.125, valid recall:70.857, valid kappa:82.934
[1;31mTest score increased (84.748604 --> 84.865152).[0m
[Fold 2] Best Score: [84.86515222769746, 62.77765749688987, 60.12462539169982, 70.85748492231902, 82.93443743145185]
fold:3 epoch:0 step:0 train loss:4.630121, train acc:1.053, train f1:0.802, train precision:1.210, train recall:1.085, train kappa:-0.064
fold:3 epoch:0 step:1 train loss:4.292177, train acc:7.288, train f1:1.330, train precision:1.887, train recall:1.885, train kappa:2.689
fold:3 epoch:0 step:2 train loss:4.086368, train acc:11.658, train f1:1.643, train precision:2.503, train recall:2.623, train kappa:5.077
fold:3 epoch:0 step:3 train loss:3.952987, train acc:12.762, train f1:2.008, train precision:3.526, train recall:3.114, train kappa:5.408
fold:3 epoch:0 step:4 train loss:3.910110, train acc:15.387, train f1:2.435, train precision:4.620, train recall:3.213, train kappa:6.981
fold:3 epoch:0 step:5 train loss:3.819757, train acc:17.923, train f1:2.536, train precision:4.839, train recall:3.243, train kappa:8.330
fold:3 epoch:0 step:6 train loss:3.774994, train acc:18.631, train f1:2.861, train precision:5.245, train recall:3.649, train kappa:9.028
fold:3 epoch:0 step:7 train loss:3.704056, train acc:19.623, train f1:3.493, train precision:6.797, train recall:4.150, train kappa:10.339
fold:3 epoch:0 step:8 train loss:3.671909, train acc:20.126, train f1:4.448, train precision:6.035, train recall:5.137, train kappa:11.377
fold:3 epoch:0 step:9 train loss:3.579768, train acc:20.700, train f1:5.141, train precision:7.455, train recall:5.842, train kappa:12.259
fold:3 epoch:0 step:10 train loss:3.512969, train acc:21.979, train f1:5.650, train precision:9.103, train recall:6.150, train kappa:13.642
fold:3 epoch:0 step:11 train loss:3.438919, train acc:22.324, train f1:5.545, train precision:9.917, train recall:6.066, train kappa:14.025
fold:3 epoch:0        valid loss:3.434045, valid acc:16.967, valid f1:1.195, valid precision:1.250, valid recall:2.328, valid kappa:4.256
None
====================================================================================================
fold:3 epoch:1 step:0 train loss:3.370068, train acc:23.315, train f1:6.311, train precision:12.690, train recall:6.629, train kappa:15.100
fold:3 epoch:1 step:1 train loss:3.318929, train acc:23.914, train f1:7.178, train precision:12.994, train recall:7.348, train kappa:15.975
fold:3 epoch:1 step:2 train loss:3.246806, train acc:25.232, train f1:9.170, train precision:14.917, train recall:9.397, train kappa:17.588
fold:3 epoch:1 step:3 train loss:3.185029, train acc:26.193, train f1:10.211, train precision:18.319, train recall:10.547, train kappa:18.923
fold:3 epoch:1 step:4 train loss:3.130705, train acc:26.840, train f1:10.499, train precision:18.292, train recall:10.939, train kappa:19.633
fold:3 epoch:1 step:5 train loss:3.031602, train acc:28.027, train f1:11.966, train precision:19.993, train recall:12.378, train kappa:21.117
fold:3 epoch:1 step:6 train loss:3.001956, train acc:28.140, train f1:12.748, train precision:20.684, train recall:13.405, train kappa:21.649
fold:3 epoch:1 step:7 train loss:2.940688, train acc:29.294, train f1:13.973, train precision:23.036, train recall:14.213, train kappa:22.919
fold:3 epoch:1 step:8 train loss:2.889877, train acc:29.489, train f1:15.487, train precision:26.590, train recall:15.641, train kappa:23.486
fold:3 epoch:1 step:9 train loss:2.828273, train acc:30.997, train f1:17.109, train precision:26.534, train recall:17.268, train kappa:25.236
fold:3 epoch:1 step:10 train loss:2.776390, train acc:32.251, train f1:19.312, train precision:31.359, train recall:18.904, train kappa:26.704
fold:3 epoch:1 step:11 train loss:2.717202, train acc:33.230, train f1:19.726, train precision:27.876, train recall:19.740, train kappa:27.973
fold:3 epoch:1        valid loss:3.830371, valid acc:28.656, valid f1:2.601, valid precision:3.689, valid recall:3.871, valid kappa:15.172
None
====================================================================================================
fold:3 epoch:2 step:0 train loss:2.663086, train acc:33.755, train f1:22.312, train precision:31.016, train recall:21.592, train kappa:28.904
fold:3 epoch:2 step:1 train loss:2.603430, train acc:35.306, train f1:23.829, train precision:33.928, train recall:23.011, train kappa:30.569
fold:3 epoch:2 step:2 train loss:2.557118, train acc:36.075, train f1:25.499, train precision:33.757, train recall:24.696, train kappa:31.512
fold:3 epoch:2 step:3 train loss:2.476714, train acc:37.875, train f1:28.021, train precision:36.895, train recall:27.368, train kappa:33.781
fold:3 epoch:2 step:4 train loss:2.431288, train acc:39.102, train f1:29.763, train precision:38.124, train recall:28.880, train kappa:35.224
fold:3 epoch:2 step:5 train loss:2.376853, train acc:39.996, train f1:31.291, train precision:39.685, train recall:31.059, train kappa:36.418
fold:3 epoch:2 step:6 train loss:2.329290, train acc:40.945, train f1:32.335, train precision:40.317, train recall:31.621, train kappa:37.395
fold:3 epoch:2 step:7 train loss:2.289860, train acc:41.412, train f1:32.564, train precision:40.689, train recall:31.696, train kappa:37.924
fold:3 epoch:2 step:8 train loss:2.252089, train acc:43.134, train f1:35.031, train precision:44.330, train recall:34.546, train kappa:39.816
fold:3 epoch:2 step:9 train loss:2.213199, train acc:43.466, train f1:35.829, train precision:42.668, train recall:35.251, train kappa:40.237
fold:3 epoch:2 step:10 train loss:2.176816, train acc:44.455, train f1:37.287, train precision:43.815, train recall:36.592, train kappa:41.364
fold:3 epoch:2 step:11 train loss:2.127867, train acc:45.247, train f1:38.883, train precision:45.051, train recall:38.147, train kappa:42.212
fold:3 epoch:2        valid loss:3.272124, valid acc:18.118, valid f1:8.715, valid precision:16.195, valid recall:16.324, valid kappa:12.472
None
====================================================================================================
fold:3 epoch:3 step:0 train loss:2.082333, train acc:46.460, train f1:39.847, train precision:47.801, train recall:38.486, train kappa:43.431
fold:3 epoch:3 step:1 train loss:2.025976, train acc:47.534, train f1:41.581, train precision:49.032, train recall:40.320, train kappa:44.640
fold:3 epoch:3 step:2 train loss:2.011184, train acc:48.468, train f1:42.871, train precision:47.898, train recall:42.275, train kappa:45.714
fold:3 epoch:3 step:3 train loss:1.960259, train acc:49.417, train f1:43.511, train precision:47.724, train recall:43.314, train kappa:46.831
fold:3 epoch:3 step:4 train loss:1.946255, train acc:49.933, train f1:44.939, train precision:50.487, train recall:43.994, train kappa:47.318
fold:3 epoch:3 step:5 train loss:1.916513, train acc:50.183, train f1:45.190, train precision:51.286, train recall:43.897, train kappa:47.617
fold:3 epoch:3 step:6 train loss:1.883646, train acc:51.199, train f1:46.027, train precision:51.987, train recall:44.411, train kappa:48.624
fold:3 epoch:3 step:7 train loss:1.848956, train acc:52.148, train f1:47.292, train precision:53.863, train recall:45.785, train kappa:49.703
fold:3 epoch:3 step:8 train loss:1.849452, train acc:51.788, train f1:47.120, train precision:51.964, train recall:45.923, train kappa:49.362
fold:3 epoch:3 step:9 train loss:1.791951, train acc:53.149, train f1:49.148, train precision:54.011, train recall:47.736, train kappa:50.871
fold:3 epoch:3 step:10 train loss:1.750869, train acc:54.465, train f1:50.178, train precision:54.327, train recall:49.290, train kappa:52.230
fold:3 epoch:3 step:11 train loss:1.774642, train acc:53.615, train f1:49.518, train precision:53.682, train recall:49.150, train kappa:51.343
fold:3 epoch:3        valid loss:2.724919, valid acc:24.567, valid f1:21.098, valid precision:29.414, valid recall:33.128, valid kappa:20.388
None
====================================================================================================
fold:3 epoch:4 step:0 train loss:1.741455, train acc:54.517, train f1:50.965, train precision:55.886, train recall:49.662, train kappa:52.266
fold:3 epoch:4 step:1 train loss:1.684242, train acc:55.850, train f1:52.016, train precision:57.336, train recall:50.948, train kappa:53.760
fold:3 epoch:4 step:2 train loss:1.673452, train acc:55.966, train f1:52.514, train precision:57.042, train recall:51.377, train kappa:53.863
fold:3 epoch:4 step:3 train loss:1.663647, train acc:57.138, train f1:53.485, train precision:58.694, train recall:52.035, train kappa:55.118
fold:3 epoch:4 step:4 train loss:1.643007, train acc:57.324, train f1:53.830, train precision:57.764, train recall:53.016, train kappa:55.357
fold:3 epoch:4 step:5 train loss:1.601685, train acc:57.629, train f1:54.713, train precision:58.782, train recall:53.562, train kappa:55.647
fold:3 epoch:4 step:6 train loss:1.604657, train acc:57.883, train f1:54.602, train precision:59.568, train recall:53.160, train kappa:55.834
fold:3 epoch:4 step:7 train loss:1.586820, train acc:58.658, train f1:55.726, train precision:60.012, train recall:54.458, train kappa:56.652
fold:3 epoch:4 step:8 train loss:1.542872, train acc:59.494, train f1:56.283, train precision:59.978, train recall:55.107, train kappa:57.580
fold:3 epoch:4 step:9 train loss:1.548719, train acc:59.219, train f1:56.202, train precision:60.087, train recall:55.213, train kappa:57.353
fold:3 epoch:4 step:10 train loss:1.519624, train acc:60.483, train f1:57.683, train precision:62.885, train recall:56.401, train kappa:58.675
fold:3 epoch:4 step:11 train loss:1.486977, train acc:61.152, train f1:58.135, train precision:61.357, train recall:57.525, train kappa:59.446
fold:3 epoch:4        valid loss:1.909613, valid acc:43.260, valid f1:29.347, valid precision:32.701, valid recall:47.158, valid kappa:38.697
None
====================================================================================================
fold:3 epoch:5 step:0 train loss:1.493355, train acc:60.825, train f1:58.052, train precision:62.184, train recall:57.429, train kappa:59.127
fold:3 epoch:5 step:1 train loss:1.462077, train acc:61.368, train f1:58.968, train precision:62.519, train recall:58.106, train kappa:59.658
fold:3 epoch:5 step:2 train loss:1.454914, train acc:62.125, train f1:59.213, train precision:62.644, train recall:58.378, train kappa:60.438
fold:3 epoch:5 step:3 train loss:1.438841, train acc:62.503, train f1:60.197, train precision:64.648, train recall:59.006, train kappa:60.833
fold:3 epoch:5 step:4 train loss:1.447469, train acc:62.204, train f1:60.111, train precision:64.547, train recall:58.831, train kappa:60.521
fold:3 epoch:5 step:5 train loss:1.421996, train acc:62.796, train f1:60.319, train precision:64.765, train recall:59.259, train kappa:61.117
fold:3 epoch:5 step:6 train loss:1.399794, train acc:63.367, train f1:61.005, train precision:64.658, train recall:60.157, train kappa:61.760
fold:3 epoch:5 step:7 train loss:1.374120, train acc:64.005, train f1:61.291, train precision:64.047, train recall:60.432, train kappa:62.422
fold:3 epoch:5 step:8 train loss:1.375805, train acc:63.873, train f1:61.436, train precision:65.050, train recall:60.608, train kappa:62.287
fold:3 epoch:5 step:9 train loss:1.361574, train acc:64.279, train f1:61.891, train precision:66.378, train recall:61.123, train kappa:62.679
fold:3 epoch:5 step:10 train loss:1.363158, train acc:64.267, train f1:61.440, train precision:64.633, train recall:60.756, train kappa:62.693
fold:3 epoch:5 step:11 train loss:1.366918, train acc:64.299, train f1:61.705, train precision:65.430, train recall:60.914, train kappa:62.782
fold:3 epoch:5        valid loss:1.521507, valid acc:56.092, valid f1:37.264, valid precision:38.085, valid recall:57.014, valid kappa:51.615
None
====================================================================================================
fold:3 epoch:6 step:0 train loss:1.342755, train acc:64.514, train f1:61.872, train precision:66.331, train recall:61.358, train kappa:62.977
fold:3 epoch:6 step:1 train loss:1.307325, train acc:65.549, train f1:63.007, train precision:65.778, train recall:62.519, train kappa:64.053
fold:3 epoch:6 step:2 train loss:1.317203, train acc:65.454, train f1:63.122, train precision:66.395, train recall:62.605, train kappa:63.958
fold:3 epoch:6 step:3 train loss:1.313289, train acc:65.875, train f1:63.342, train precision:68.420, train recall:62.389, train kappa:64.398
fold:3 epoch:6 step:4 train loss:1.287403, train acc:66.290, train f1:64.026, train precision:67.253, train recall:63.013, train kappa:64.824
fold:3 epoch:6 step:5 train loss:1.288255, train acc:65.924, train f1:63.650, train precision:67.536, train recall:62.397, train kappa:64.428
fold:3 epoch:6 step:6 train loss:1.285515, train acc:65.994, train f1:63.659, train precision:68.408, train recall:62.814, train kappa:64.511
fold:3 epoch:6 step:7 train loss:1.259038, train acc:66.739, train f1:64.507, train precision:68.874, train recall:63.807, train kappa:65.331
fold:3 epoch:6 step:8 train loss:1.255641, train acc:66.943, train f1:64.496, train precision:68.290, train recall:63.840, train kappa:65.553
fold:3 epoch:6 step:9 train loss:1.253360, train acc:66.821, train f1:64.826, train precision:68.892, train recall:64.116, train kappa:65.399
fold:3 epoch:6 step:10 train loss:1.241614, train acc:67.252, train f1:65.048, train precision:68.740, train recall:64.336, train kappa:65.838
fold:3 epoch:6 step:11 train loss:1.217322, train acc:67.957, train f1:65.612, train precision:69.395, train recall:65.087, train kappa:66.556
fold:3 epoch:6        valid loss:1.123037, valid acc:69.105, valid f1:45.058, valid precision:42.235, valid recall:64.248, valid kappa:65.577
None
====================================================================================================
fold:3 epoch:7 step:0 train loss:1.210427, train acc:67.953, train f1:65.694, train precision:68.145, train recall:65.195, train kappa:66.576
fold:3 epoch:7 step:1 train loss:1.200185, train acc:68.039, train f1:65.916, train precision:70.445, train recall:64.901, train kappa:66.679
fold:3 epoch:7 step:2 train loss:1.219733, train acc:67.749, train f1:65.615, train precision:68.766, train recall:64.535, train kappa:66.370
fold:3 epoch:7 step:3 train loss:1.190677, train acc:68.442, train f1:66.493, train precision:69.741, train recall:65.495, train kappa:67.094
fold:3 epoch:7 step:4 train loss:1.195342, train acc:68.286, train f1:66.138, train precision:70.263, train recall:65.218, train kappa:66.916
fold:3 epoch:7 step:5 train loss:1.170094, train acc:69.077, train f1:66.986, train precision:71.253, train recall:66.255, train kappa:67.775
fold:3 epoch:7 step:6 train loss:1.177823, train acc:68.927, train f1:67.043, train precision:71.344, train recall:66.100, train kappa:67.610
fold:3 epoch:7 step:7 train loss:1.176537, train acc:68.805, train f1:66.602, train precision:70.432, train recall:66.047, train kappa:67.478
fold:3 epoch:7 step:8 train loss:1.165301, train acc:68.796, train f1:66.805, train precision:72.406, train recall:65.981, train kappa:67.465
fold:3 epoch:7 step:9 train loss:1.158615, train acc:69.034, train f1:67.069, train precision:70.594, train recall:66.662, train kappa:67.706
fold:3 epoch:7 step:10 train loss:1.137505, train acc:69.574, train f1:67.268, train precision:71.029, train recall:66.846, train kappa:68.295
fold:3 epoch:7 step:11 train loss:1.127260, train acc:69.655, train f1:67.708, train precision:71.782, train recall:67.041, train kappa:68.402
fold:3 epoch:7        valid loss:1.014726, valid acc:72.180, valid f1:47.894, valid precision:45.090, valid recall:66.263, valid kappa:68.909
None
====================================================================================================
fold:3 epoch:8 step:0 train loss:1.130878, train acc:69.760, train f1:67.636, train precision:71.765, train recall:67.149, train kappa:68.485
fold:3 epoch:8 step:1 train loss:1.131603, train acc:69.696, train f1:67.462, train precision:70.826, train recall:67.057, train kappa:68.449
fold:3 epoch:8 step:2 train loss:1.125056, train acc:69.751, train f1:67.671, train precision:71.668, train recall:66.886, train kappa:68.463
fold:3 epoch:8 step:3 train loss:1.110775, train acc:70.224, train f1:68.241, train precision:72.373, train recall:67.469, train kappa:68.960
fold:3 epoch:8 step:4 train loss:1.105002, train acc:70.444, train f1:68.514, train precision:72.265, train recall:67.327, train kappa:69.193
fold:3 epoch:8 step:5 train loss:1.109451, train acc:70.361, train f1:68.340, train precision:71.903, train recall:67.589, train kappa:69.106
fold:3 epoch:8 step:6 train loss:1.094547, train acc:70.743, train f1:68.809, train precision:73.037, train recall:68.004, train kappa:69.526
fold:3 epoch:8 step:7 train loss:1.092680, train acc:70.602, train f1:68.944, train precision:72.846, train recall:68.261, train kappa:69.362
fold:3 epoch:8 step:8 train loss:1.107196, train acc:70.517, train f1:68.320, train precision:71.961, train recall:67.770, train kappa:69.276
fold:3 epoch:8 step:9 train loss:1.086609, train acc:71.127, train f1:68.929, train precision:72.238, train recall:68.749, train kappa:69.930
fold:3 epoch:8 step:10 train loss:1.077218, train acc:70.959, train f1:69.017, train precision:71.679, train recall:68.987, train kappa:69.762
fold:3 epoch:8 step:11 train loss:1.088804, train acc:70.756, train f1:68.943, train precision:73.238, train recall:68.556, train kappa:69.508
fold:3 epoch:8        valid loss:0.938063, valid acc:74.570, valid f1:49.895, valid precision:47.056, valid recall:66.627, valid kappa:71.485
None
====================================================================================================
fold:3 epoch:9 step:0 train loss:1.070722, train acc:71.188, train f1:69.117, train precision:73.485, train recall:68.630, train kappa:69.978
fold:3 epoch:9 step:1 train loss:1.054494, train acc:71.674, train f1:69.702, train precision:74.906, train recall:68.677, train kappa:70.469
fold:3 epoch:9 step:2 train loss:1.055499, train acc:71.582, train f1:69.568, train precision:74.108, train recall:68.350, train kappa:70.370
fold:3 epoch:9 step:3 train loss:1.057302, train acc:71.530, train f1:69.584, train precision:73.976, train recall:68.287, train kappa:70.314
fold:3 epoch:9 step:4 train loss:1.051667, train acc:71.674, train f1:69.614, train precision:73.494, train recall:68.593, train kappa:70.490
fold:3 epoch:9 step:5 train loss:1.038400, train acc:71.716, train f1:69.750, train precision:72.891, train recall:69.372, train kappa:70.513
fold:3 epoch:9 step:6 train loss:1.037619, train acc:72.043, train f1:69.778, train precision:73.194, train recall:70.088, train kappa:70.910
fold:3 epoch:9 step:7 train loss:1.050200, train acc:71.863, train f1:70.058, train precision:73.724, train recall:69.885, train kappa:70.716
fold:3 epoch:9 step:8 train loss:1.027964, train acc:72.455, train f1:70.257, train precision:73.581, train recall:70.324, train kappa:71.323
fold:3 epoch:9 step:9 train loss:1.038871, train acc:72.238, train f1:70.380, train precision:74.442, train recall:69.961, train kappa:71.086
fold:3 epoch:9 step:10 train loss:1.001300, train acc:72.681, train f1:70.910, train precision:74.190, train recall:70.207, train kappa:71.568
fold:3 epoch:9 step:11 train loss:1.022119, train acc:72.445, train f1:70.582, train precision:73.774, train recall:70.188, train kappa:71.290
fold:3 epoch:9        valid loss:0.899997, valid acc:75.652, valid f1:51.057, valid precision:47.701, valid recall:67.855, valid kappa:72.689
None
====================================================================================================
fold:3 epoch:10 step:0 train loss:1.022001, train acc:72.385, train f1:70.696, train precision:74.088, train recall:69.739, train kappa:71.228
fold:3 epoch:10 step:1 train loss:0.995430, train acc:72.983, train f1:71.068, train precision:75.412, train recall:70.333, train kappa:71.829
fold:3 epoch:10 step:2 train loss:0.987266, train acc:73.538, train f1:71.292, train precision:74.565, train recall:70.762, train kappa:72.435
fold:3 epoch:10 step:3 train loss:0.992184, train acc:73.349, train f1:71.410, train precision:75.278, train recall:70.565, train kappa:72.266
fold:3 epoch:10 step:4 train loss:1.004747, train acc:73.029, train f1:70.890, train precision:74.518, train recall:70.483, train kappa:71.905
fold:3 epoch:10 step:5 train loss:1.000816, train acc:72.821, train f1:70.825, train precision:73.723, train recall:70.228, train kappa:71.687
fold:3 epoch:10 step:6 train loss:0.995269, train acc:73.120, train f1:71.201, train precision:74.441, train recall:70.960, train kappa:72.026
fold:3 epoch:10 step:7 train loss:0.980802, train acc:73.550, train f1:71.598, train precision:75.226, train recall:71.201, train kappa:72.454
fold:3 epoch:10 step:8 train loss:0.959399, train acc:73.822, train f1:71.841, train precision:75.319, train recall:71.232, train kappa:72.742
fold:3 epoch:10 step:9 train loss:0.966904, train acc:73.679, train f1:72.013, train precision:75.103, train recall:71.212, train kappa:72.596
fold:3 epoch:10 step:10 train loss:0.977604, train acc:73.456, train f1:71.220, train precision:73.265, train recall:70.993, train kappa:72.339
fold:3 epoch:10 step:11 train loss:0.975845, train acc:73.728, train f1:72.298, train precision:74.570, train recall:72.012, train kappa:72.698
fold:3 epoch:10        valid loss:0.885079, valid acc:75.731, valid f1:50.948, valid precision:47.926, valid recall:68.089, valid kappa:72.844
None
====================================================================================================
fold:3 epoch:11 step:0 train loss:0.960568, train acc:73.749, train f1:71.602, train precision:74.675, train recall:71.239, train kappa:72.655
fold:3 epoch:11 step:1 train loss:0.948589, train acc:74.130, train f1:72.233, train precision:74.684, train recall:71.922, train kappa:73.087
fold:3 epoch:11 step:2 train loss:0.955964, train acc:73.975, train f1:72.131, train precision:76.391, train recall:71.818, train kappa:72.907
fold:3 epoch:11 step:3 train loss:0.941334, train acc:74.530, train f1:72.604, train precision:75.464, train recall:72.198, train kappa:73.479
fold:3 epoch:11 step:4 train loss:0.948263, train acc:74.228, train f1:72.396, train precision:76.260, train recall:71.991, train kappa:73.139
fold:3 epoch:11 step:5 train loss:0.948162, train acc:74.048, train f1:72.393, train precision:75.839, train recall:71.810, train kappa:72.992
fold:3 epoch:11 step:6 train loss:0.939602, train acc:74.435, train f1:72.756, train precision:78.055, train recall:71.993, train kappa:73.383
fold:3 epoch:11 step:7 train loss:0.950121, train acc:74.142, train f1:72.533, train precision:76.574, train recall:71.796, train kappa:73.099
fold:3 epoch:11 step:8 train loss:0.942661, train acc:74.094, train f1:72.137, train precision:75.459, train recall:71.467, train kappa:73.024
fold:3 epoch:11 step:9 train loss:0.937303, train acc:74.365, train f1:72.658, train precision:75.157, train recall:72.192, train kappa:73.299
fold:3 epoch:11 step:10 train loss:0.925350, train acc:74.780, train f1:73.363, train precision:76.505, train recall:72.998, train kappa:73.750
fold:3 epoch:11 step:11 train loss:0.929639, train acc:74.954, train f1:73.154, train precision:76.121, train recall:72.547, train kappa:73.956
fold:3 epoch:11        valid loss:0.846076, valid acc:77.014, valid f1:52.742, valid precision:49.779, valid recall:68.864, valid kappa:74.222
None
====================================================================================================
fold:3 epoch:12 step:0 train loss:0.928761, train acc:74.814, train f1:73.368, train precision:76.271, train recall:73.157, train kappa:73.791
fold:3 epoch:12 step:1 train loss:0.895772, train acc:75.351, train f1:73.441, train precision:76.540, train recall:73.080, train kappa:74.344
fold:3 epoch:12 step:2 train loss:0.926264, train acc:74.527, train f1:72.764, train precision:74.803, train recall:72.805, train kappa:73.485
fold:3 epoch:12 step:3 train loss:0.897210, train acc:75.455, train f1:73.637, train precision:77.300, train recall:73.071, train kappa:74.445
fold:3 epoch:12 step:4 train loss:0.914512, train acc:75.131, train f1:73.159, train precision:76.140, train recall:73.051, train kappa:74.118
fold:3 epoch:12 step:5 train loss:0.904583, train acc:75.287, train f1:73.798, train precision:77.140, train recall:73.196, train kappa:74.288
fold:3 epoch:12 step:6 train loss:0.901989, train acc:75.113, train f1:73.575, train precision:76.691, train recall:72.939, train kappa:74.078
fold:3 epoch:12 step:7 train loss:0.896477, train acc:75.500, train f1:73.866, train precision:77.123, train recall:73.372, train kappa:74.492
fold:3 epoch:12 step:8 train loss:0.906580, train acc:75.467, train f1:73.774, train precision:76.826, train recall:73.199, train kappa:74.467
fold:3 epoch:12 step:9 train loss:0.890170, train acc:75.348, train f1:73.713, train precision:76.544, train recall:73.192, train kappa:74.350
fold:3 epoch:12 step:10 train loss:0.883793, train acc:75.671, train f1:73.663, train precision:76.898, train recall:73.524, train kappa:74.697
fold:3 epoch:12 step:11 train loss:0.889354, train acc:76.334, train f1:74.619, train precision:77.813, train recall:74.403, train kappa:75.381
fold:3 epoch:12        valid loss:0.832765, valid acc:77.345, valid f1:52.964, valid precision:50.304, valid recall:68.882, valid kappa:74.605
None
====================================================================================================
fold:3 epoch:13 step:0 train loss:0.878857, train acc:75.879, train f1:74.125, train precision:76.583, train recall:73.860, train kappa:74.892
fold:3 epoch:13 step:1 train loss:0.878038, train acc:76.044, train f1:74.316, train precision:76.963, train recall:74.190, train kappa:75.080
fold:3 epoch:13 step:2 train loss:0.879987, train acc:75.851, train f1:74.236, train precision:77.163, train recall:73.910, train kappa:74.873
fold:3 epoch:13 step:3 train loss:0.863544, train acc:76.395, train f1:74.543, train precision:77.817, train recall:74.020, train kappa:75.426
fold:3 epoch:13 step:4 train loss:0.872061, train acc:76.254, train f1:74.546, train precision:77.928, train recall:74.374, train kappa:75.292
fold:3 epoch:13 step:5 train loss:0.879167, train acc:75.836, train f1:74.038, train precision:76.966, train recall:73.573, train kappa:74.843
fold:3 epoch:13 step:6 train loss:0.862584, train acc:76.263, train f1:74.573, train precision:77.965, train recall:74.100, train kappa:75.273
fold:3 epoch:13 step:7 train loss:0.846602, train acc:76.813, train f1:75.167, train precision:78.235, train recall:74.784, train kappa:75.874
fold:3 epoch:13 step:8 train loss:0.856877, train acc:76.108, train f1:74.424, train precision:78.234, train recall:73.883, train kappa:75.126
fold:3 epoch:13 step:9 train loss:0.846539, train acc:76.617, train f1:74.931, train precision:78.043, train recall:74.547, train kappa:75.684
fold:3 epoch:13 step:10 train loss:0.861373, train acc:76.318, train f1:74.936, train precision:77.996, train recall:74.393, train kappa:75.386
fold:3 epoch:13 step:11 train loss:0.838609, train acc:76.489, train f1:74.817, train precision:77.899, train recall:74.441, train kappa:75.544
fold:3 epoch:13        valid loss:0.829340, valid acc:77.363, valid f1:52.852, valid precision:49.836, valid recall:69.377, valid kappa:74.643
None
====================================================================================================
fold:3 epoch:14 step:0 train loss:0.831254, train acc:77.109, train f1:75.454, train precision:77.908, train recall:75.440, train kappa:76.210
fold:3 epoch:14 step:1 train loss:0.827598, train acc:76.999, train f1:75.277, train precision:77.538, train recall:75.197, train kappa:76.064
fold:3 epoch:14 step:2 train loss:0.834996, train acc:76.779, train f1:75.142, train precision:77.281, train recall:75.196, train kappa:75.841
fold:3 epoch:14 step:3 train loss:0.844213, train acc:76.721, train f1:75.093, train precision:77.828, train recall:74.973, train kappa:75.781
fold:3 epoch:14 step:4 train loss:0.841688, train acc:76.834, train f1:75.225, train precision:78.145, train recall:74.666, train kappa:75.871
fold:3 epoch:14 step:5 train loss:0.832620, train acc:77.054, train f1:75.326, train precision:78.677, train recall:74.714, train kappa:76.121
fold:3 epoch:14 step:6 train loss:0.854289, train acc:76.294, train f1:75.217, train precision:79.076, train recall:74.545, train kappa:75.336
fold:3 epoch:14 step:7 train loss:0.830325, train acc:76.956, train f1:75.466, train precision:78.731, train recall:75.015, train kappa:76.023
fold:3 epoch:14 step:8 train loss:0.819714, train acc:77.264, train f1:75.467, train precision:78.466, train recall:74.996, train kappa:76.348
fold:3 epoch:14 step:9 train loss:0.840825, train acc:76.797, train f1:75.237, train precision:78.172, train recall:75.013, train kappa:75.873
fold:3 epoch:14 step:10 train loss:0.829838, train acc:76.974, train f1:75.208, train precision:77.596, train recall:75.471, train kappa:76.063
fold:3 epoch:14 step:11 train loss:0.831288, train acc:76.749, train f1:74.549, train precision:76.531, train recall:74.829, train kappa:75.820
fold:3 epoch:14        valid loss:0.798815, valid acc:78.240, valid f1:54.502, valid precision:51.822, valid recall:69.272, valid kappa:75.562
None
====================================================================================================
fold:3 epoch:15 step:0 train loss:0.808754, train acc:77.713, train f1:76.109, train precision:79.998, train recall:75.882, train kappa:76.840
fold:3 epoch:15 step:1 train loss:0.803337, train acc:77.603, train f1:75.981, train precision:78.916, train recall:75.593, train kappa:76.687
fold:3 epoch:15 step:2 train loss:0.821032, train acc:77.292, train f1:75.958, train precision:78.999, train recall:75.307, train kappa:76.380
fold:3 epoch:15 step:3 train loss:0.823435, train acc:77.182, train f1:75.430, train precision:79.004, train recall:75.031, train kappa:76.232
fold:3 epoch:15 step:4 train loss:0.811978, train acc:77.338, train f1:75.690, train precision:79.154, train recall:74.995, train kappa:76.398
fold:3 epoch:15 step:5 train loss:0.804136, train acc:77.576, train f1:76.041, train precision:79.148, train recall:75.343, train kappa:76.665
fold:3 epoch:15 step:6 train loss:0.807944, train acc:77.704, train f1:76.315, train precision:79.065, train recall:76.086, train kappa:76.811
fold:3 epoch:15 step:7 train loss:0.806457, train acc:77.457, train f1:75.769, train precision:77.749, train recall:75.938, train kappa:76.544
fold:3 epoch:15 step:8 train loss:0.795701, train acc:77.753, train f1:76.258, train precision:78.760, train recall:76.214, train kappa:76.862
fold:3 epoch:15 step:9 train loss:0.804266, train acc:77.539, train f1:75.999, train precision:78.344, train recall:76.035, train kappa:76.655
fold:3 epoch:15 step:10 train loss:0.801053, train acc:77.527, train f1:76.297, train precision:78.278, train recall:76.407, train kappa:76.639
fold:3 epoch:15 step:11 train loss:0.784450, train acc:78.467, train f1:76.121, train precision:78.587, train recall:75.788, train kappa:77.625
fold:3 epoch:15        valid loss:0.781819, valid acc:78.796, valid f1:54.646, valid precision:51.757, valid recall:69.326, valid kappa:76.192
None
====================================================================================================
fold:3 epoch:16 step:0 train loss:0.800779, train acc:77.859, train f1:76.556, train precision:79.698, train recall:76.352, train kappa:76.970
fold:3 epoch:16 step:1 train loss:0.778205, train acc:78.064, train f1:76.752, train precision:79.384, train recall:76.435, train kappa:77.189
fold:3 epoch:16 step:2 train loss:0.783553, train acc:78.006, train f1:76.521, train precision:79.850, train recall:75.954, train kappa:77.122
fold:3 epoch:16 step:3 train loss:0.791313, train acc:78.021, train f1:76.477, train precision:80.383, train recall:76.209, train kappa:77.151
fold:3 epoch:16 step:4 train loss:0.786400, train acc:78.070, train f1:76.329, train precision:79.172, train recall:76.063, train kappa:77.190
fold:3 epoch:16 step:5 train loss:0.776903, train acc:78.339, train f1:77.013, train precision:79.582, train recall:76.712, train kappa:77.452
fold:3 epoch:16 step:6 train loss:0.769317, train acc:78.281, train f1:76.772, train precision:79.729, train recall:76.685, train kappa:77.424
fold:3 epoch:16 step:7 train loss:0.785947, train acc:78.101, train f1:76.223, train precision:78.628, train recall:76.199, train kappa:77.205
fold:3 epoch:16 step:8 train loss:0.796580, train acc:77.713, train f1:76.299, train precision:79.635, train recall:76.165, train kappa:76.829
fold:3 epoch:16 step:9 train loss:0.770901, train acc:78.470, train f1:77.026, train precision:79.529, train recall:76.758, train kappa:77.612
fold:3 epoch:16 step:10 train loss:0.775553, train acc:78.195, train f1:76.524, train precision:78.966, train recall:76.242, train kappa:77.322
fold:3 epoch:16 step:11 train loss:0.757966, train acc:78.795, train f1:76.614, train precision:78.702, train recall:76.680, train kappa:77.924
fold:3 epoch:16        valid loss:0.773250, valid acc:79.177, valid f1:54.912, valid precision:52.067, valid recall:69.421, valid kappa:76.610
None
====================================================================================================
fold:3 epoch:17 step:0 train loss:0.766779, train acc:78.326, train f1:76.757, train precision:79.353, train recall:76.387, train kappa:77.454
fold:3 epoch:17 step:1 train loss:0.757441, train acc:78.821, train f1:76.974, train precision:79.968, train recall:76.608, train kappa:77.972
fold:3 epoch:17 step:2 train loss:0.758475, train acc:78.506, train f1:76.773, train precision:78.858, train recall:76.690, train kappa:77.619
fold:3 epoch:17 step:3 train loss:0.771219, train acc:78.506, train f1:77.106, train precision:80.350, train recall:77.111, train kappa:77.654
fold:3 epoch:17 step:4 train loss:0.762053, train acc:78.659, train f1:77.145, train precision:80.260, train recall:77.170, train kappa:77.789
fold:3 epoch:17 step:5 train loss:0.754244, train acc:78.757, train f1:77.336, train precision:80.243, train recall:77.151, train kappa:77.934
fold:3 epoch:17 step:6 train loss:0.766989, train acc:78.668, train f1:77.047, train precision:79.926, train recall:76.489, train kappa:77.816
fold:3 epoch:17 step:7 train loss:0.750622, train acc:78.885, train f1:77.543, train precision:80.254, train recall:77.303, train kappa:78.056
fold:3 epoch:17 step:8 train loss:0.748533, train acc:79.105, train f1:77.876, train precision:80.135, train recall:77.875, train kappa:78.282
fold:3 epoch:17 step:9 train loss:0.762803, train acc:78.674, train f1:77.263, train precision:79.873, train recall:76.915, train kappa:77.819
fold:3 epoch:17 step:10 train loss:0.757410, train acc:78.751, train f1:77.294, train precision:80.085, train recall:77.097, train kappa:77.909
fold:3 epoch:17 step:11 train loss:0.748267, train acc:78.882, train f1:77.306, train precision:79.781, train recall:77.446, train kappa:78.018
fold:3 epoch:17        valid loss:0.764631, valid acc:79.095, valid f1:54.664, valid precision:52.183, valid recall:69.590, valid kappa:76.529
None
====================================================================================================
fold:3 epoch:18 step:0 train loss:0.737749, train acc:79.230, train f1:77.492, train precision:79.396, train recall:77.380, train kappa:78.395
fold:3 epoch:18 step:1 train loss:0.751784, train acc:78.912, train f1:77.419, train precision:79.880, train recall:77.261, train kappa:78.091
fold:3 epoch:18 step:2 train loss:0.738739, train acc:79.126, train f1:77.648, train precision:80.126, train recall:77.585, train kappa:78.281
fold:3 epoch:18 step:3 train loss:0.744838, train acc:78.830, train f1:77.290, train precision:79.766, train recall:77.276, train kappa:77.989
fold:3 epoch:18 step:4 train loss:0.738212, train acc:79.193, train f1:77.823, train precision:80.359, train recall:77.571, train kappa:78.361
fold:3 epoch:18 step:5 train loss:0.730244, train acc:79.294, train f1:78.112, train precision:81.480, train recall:77.627, train kappa:78.483
fold:3 epoch:18 step:6 train loss:0.741356, train acc:78.955, train f1:77.733, train precision:79.972, train recall:77.763, train kappa:78.112
fold:3 epoch:18 step:7 train loss:0.748403, train acc:78.961, train f1:77.838, train precision:80.124, train recall:77.611, train kappa:78.126
fold:3 epoch:18 step:8 train loss:0.736917, train acc:79.169, train f1:77.427, train precision:80.241, train recall:77.413, train kappa:78.326
fold:3 epoch:18 step:9 train loss:0.739235, train acc:79.333, train f1:78.169, train precision:80.357, train recall:78.156, train kappa:78.533
fold:3 epoch:18 step:10 train loss:0.717819, train acc:79.782, train f1:78.155, train precision:80.781, train recall:78.023, train kappa:78.968
fold:3 epoch:18 step:11 train loss:0.723541, train acc:79.375, train f1:78.097, train precision:80.248, train recall:78.156, train kappa:78.547
fold:3 epoch:18        valid loss:0.743050, valid acc:79.917, valid f1:55.612, valid precision:53.522, valid recall:69.371, valid kappa:77.402
None
====================================================================================================
fold:3 epoch:19 step:0 train loss:0.727733, train acc:79.324, train f1:78.075, train precision:80.335, train recall:77.717, train kappa:78.500
fold:3 epoch:19 step:1 train loss:0.723862, train acc:79.498, train f1:77.968, train precision:80.572, train recall:77.462, train kappa:78.669
fold:3 epoch:19 step:2 train loss:0.732197, train acc:79.211, train f1:78.048, train precision:80.898, train recall:77.454, train kappa:78.391
fold:3 epoch:19 step:3 train loss:0.728997, train acc:79.483, train f1:77.999, train precision:81.186, train recall:77.884, train kappa:78.654
fold:3 epoch:19 step:4 train loss:0.714931, train acc:79.849, train f1:78.405, train precision:81.049, train recall:78.370, train kappa:79.058
fold:3 epoch:19 step:5 train loss:0.727446, train acc:79.434, train f1:77.939, train precision:80.611, train recall:78.172, train kappa:78.628
fold:3 epoch:19 step:6 train loss:0.716886, train acc:79.901, train f1:78.505, train precision:80.434, train recall:78.730, train kappa:79.114
fold:3 epoch:19 step:7 train loss:0.716816, train acc:79.761, train f1:78.585, train precision:81.670, train recall:78.731, train kappa:78.959
fold:3 epoch:19 step:8 train loss:0.721597, train acc:79.434, train f1:78.176, train precision:80.360, train recall:77.986, train kappa:78.617
fold:3 epoch:19 step:9 train loss:0.719997, train acc:79.639, train f1:78.334, train precision:80.811, train recall:78.152, train kappa:78.827
fold:3 epoch:19 step:10 train loss:0.699054, train acc:80.194, train f1:78.716, train precision:81.068, train recall:78.408, train kappa:79.397
fold:3 epoch:19 step:11 train loss:0.695222, train acc:80.166, train f1:79.028, train precision:82.804, train recall:78.483, train kappa:79.364
fold:3 epoch:19        valid loss:0.744290, valid acc:79.698, valid f1:55.819, valid precision:53.052, valid recall:69.842, valid kappa:77.190
None
====================================================================================================
fold:3 epoch:20 step:0 train loss:0.713109, train acc:79.764, train f1:78.661, train precision:80.976, train recall:78.288, train kappa:78.969
fold:3 epoch:20 step:1 train loss:0.698243, train acc:80.273, train f1:78.870, train precision:81.285, train recall:78.656, train kappa:79.488
fold:3 epoch:20 step:2 train loss:0.713146, train acc:79.599, train f1:78.259, train precision:81.175, train recall:78.042, train kappa:78.806
fold:3 epoch:20 step:3 train loss:0.702965, train acc:80.014, train f1:78.412, train precision:80.123, train recall:78.788, train kappa:79.246
fold:3 epoch:20 step:4 train loss:0.696527, train acc:80.240, train f1:78.705, train precision:81.698, train recall:79.055, train kappa:79.458
fold:3 epoch:20 step:5 train loss:0.702234, train acc:80.075, train f1:78.770, train precision:81.036, train recall:78.824, train kappa:79.294
fold:3 epoch:20 step:6 train loss:0.698844, train acc:80.283, train f1:78.671, train precision:81.506, train recall:78.537, train kappa:79.487
fold:3 epoch:20 step:7 train loss:0.697794, train acc:80.280, train f1:79.060, train precision:81.661, train recall:78.853, train kappa:79.497
fold:3 epoch:20 step:8 train loss:0.692271, train acc:80.307, train f1:79.269, train precision:81.680, train recall:78.982, train kappa:79.521
fold:3 epoch:20 step:9 train loss:0.702676, train acc:79.965, train f1:78.847, train precision:81.584, train recall:78.405, train kappa:79.156
fold:3 epoch:20 step:10 train loss:0.687917, train acc:80.273, train f1:78.734, train precision:80.690, train recall:78.774, train kappa:79.470
fold:3 epoch:20 step:11 train loss:0.682382, train acc:80.919, train f1:79.423, train precision:81.702, train recall:79.360, train kappa:80.167
fold:3 epoch:20        valid loss:0.743667, valid acc:79.854, valid f1:55.778, valid precision:52.734, valid recall:69.965, valid kappa:77.367
None
====================================================================================================
fold:3 epoch:21 step:0 train loss:0.687053, train acc:80.518, train f1:79.333, train precision:81.499, train recall:79.199, train kappa:79.759
fold:3 epoch:21 step:1 train loss:0.691294, train acc:80.264, train f1:78.924, train precision:81.559, train recall:78.843, train kappa:79.485
fold:3 epoch:21 step:2 train loss:0.688298, train acc:80.325, train f1:78.869, train precision:81.616, train recall:78.810, train kappa:79.558
fold:3 epoch:21 step:3 train loss:0.679315, train acc:80.701, train f1:79.303, train precision:82.426, train recall:79.336, train kappa:79.943
fold:3 epoch:21 step:4 train loss:0.672653, train acc:80.777, train f1:79.125, train precision:81.294, train recall:79.284, train kappa:80.002
fold:3 epoch:21 step:5 train loss:0.699223, train acc:80.341, train f1:79.098, train precision:82.046, train recall:79.043, train kappa:79.555
fold:3 epoch:21 step:6 train loss:0.693251, train acc:80.225, train f1:79.274, train precision:81.487, train recall:79.209, train kappa:79.424
fold:3 epoch:21 step:7 train loss:0.678517, train acc:80.566, train f1:79.566, train precision:82.025, train recall:79.242, train kappa:79.796
fold:3 epoch:21 step:8 train loss:0.689567, train acc:80.344, train f1:78.882, train precision:80.859, train recall:78.670, train kappa:79.545
fold:3 epoch:21 step:9 train loss:0.683908, train acc:80.573, train f1:79.248, train precision:81.339, train recall:79.288, train kappa:79.807
fold:3 epoch:21 step:10 train loss:0.674137, train acc:80.798, train f1:79.489, train precision:81.819, train recall:79.427, train kappa:80.063
fold:3 epoch:21 step:11 train loss:0.686795, train acc:80.861, train f1:79.547, train precision:81.779, train recall:79.457, train kappa:80.100
fold:3 epoch:21        valid loss:0.736078, valid acc:80.195, valid f1:56.101, valid precision:53.768, valid recall:70.050, valid kappa:77.743
None
====================================================================================================
fold:3 epoch:22 step:0 train loss:0.677949, train acc:80.722, train f1:79.367, train precision:82.311, train recall:79.189, train kappa:79.966
fold:3 epoch:22 step:1 train loss:0.661013, train acc:81.259, train f1:79.617, train precision:82.337, train recall:79.644, train kappa:80.521
fold:3 epoch:22 step:2 train loss:0.668072, train acc:80.750, train f1:79.629, train precision:82.359, train recall:79.638, train kappa:80.003
fold:3 epoch:22 step:3 train loss:0.663080, train acc:81.223, train f1:79.945, train precision:83.295, train recall:79.724, train kappa:80.494
fold:3 epoch:22 step:4 train loss:0.661130, train acc:80.988, train f1:79.648, train precision:82.854, train recall:79.438, train kappa:80.213
fold:3 epoch:22 step:5 train loss:0.670346, train acc:80.850, train f1:79.685, train precision:82.308, train recall:79.784, train kappa:80.091
fold:3 epoch:22 step:6 train loss:0.669884, train acc:81.009, train f1:79.744, train precision:81.799, train recall:79.714, train kappa:80.265
fold:3 epoch:22 step:7 train loss:0.672203, train acc:80.777, train f1:79.411, train precision:81.193, train recall:79.560, train kappa:80.011
fold:3 epoch:22 step:8 train loss:0.673488, train acc:80.978, train f1:79.811, train precision:81.710, train recall:79.918, train kappa:80.223
fold:3 epoch:22 step:9 train loss:0.668542, train acc:80.798, train f1:79.840, train precision:82.419, train recall:79.716, train kappa:80.044
fold:3 epoch:22 step:10 train loss:0.662139, train acc:80.856, train f1:79.723, train precision:82.423, train recall:79.316, train kappa:80.099
fold:3 epoch:22 step:11 train loss:0.677252, train acc:80.600, train f1:79.279, train precision:81.286, train recall:79.421, train kappa:79.820
fold:3 epoch:22        valid loss:0.722032, valid acc:80.530, valid f1:56.803, valid precision:54.085, valid recall:70.129, valid kappa:78.127
None
====================================================================================================
fold:3 epoch:23 step:0 train loss:0.663332, train acc:81.082, train f1:79.946, train precision:82.210, train recall:80.006, train kappa:80.325
fold:3 epoch:23 step:1 train loss:0.651335, train acc:81.296, train f1:79.917, train precision:81.958, train recall:79.737, train kappa:80.557
fold:3 epoch:23 step:2 train loss:0.658931, train acc:81.104, train f1:79.926, train precision:82.592, train recall:79.766, train kappa:80.348
fold:3 epoch:23 step:3 train loss:0.658740, train acc:81.290, train f1:79.738, train precision:82.690, train recall:79.428, train kappa:80.555
fold:3 epoch:23 step:4 train loss:0.665231, train acc:80.954, train f1:79.731, train precision:81.722, train recall:79.984, train kappa:80.197
fold:3 epoch:23 step:5 train loss:0.653286, train acc:81.314, train f1:80.004, train precision:81.912, train recall:80.277, train kappa:80.594
fold:3 epoch:23 step:6 train loss:0.664561, train acc:81.058, train f1:79.971, train precision:82.529, train recall:79.805, train kappa:80.309
fold:3 epoch:23 step:7 train loss:0.646027, train acc:81.433, train f1:80.055, train precision:82.856, train recall:79.851, train kappa:80.687
fold:3 epoch:23 step:8 train loss:0.660793, train acc:81.152, train f1:80.078, train precision:82.872, train recall:80.004, train kappa:80.408
fold:3 epoch:23 step:9 train loss:0.646269, train acc:81.274, train f1:80.123, train precision:82.361, train recall:79.963, train kappa:80.536
fold:3 epoch:23 step:10 train loss:0.662993, train acc:81.180, train f1:80.167, train precision:82.446, train recall:80.172, train kappa:80.454
fold:3 epoch:23 step:11 train loss:0.642003, train acc:81.739, train f1:80.294, train precision:82.153, train recall:80.423, train kappa:81.026
fold:3 epoch:23        valid loss:0.716199, valid acc:80.647, valid f1:57.239, valid precision:54.719, valid recall:70.346, valid kappa:78.240
None
====================================================================================================
fold:3 epoch:24 step:0 train loss:0.637226, train acc:81.796, train f1:80.555, train precision:82.822, train recall:80.881, train kappa:81.073
fold:3 epoch:24 step:1 train loss:0.651776, train acc:81.061, train f1:79.998, train precision:83.239, train recall:79.751, train kappa:80.309
fold:3 epoch:24 step:2 train loss:0.648332, train acc:81.525, train f1:80.202, train precision:82.478, train recall:79.967, train kappa:80.781
fold:3 epoch:24 step:3 train loss:0.634527, train acc:81.839, train f1:80.658, train precision:82.783, train recall:80.533, train kappa:81.123
fold:3 epoch:24 step:4 train loss:0.640911, train acc:81.567, train f1:80.582, train precision:82.248, train recall:80.897, train kappa:80.857
fold:3 epoch:24 step:5 train loss:0.642847, train acc:81.586, train f1:80.577, train precision:82.647, train recall:80.565, train kappa:80.869
fold:3 epoch:24 step:6 train loss:0.645525, train acc:81.738, train f1:80.435, train precision:82.186, train recall:80.460, train kappa:81.020
fold:3 epoch:24 step:7 train loss:0.644415, train acc:81.567, train f1:80.440, train precision:82.253, train recall:80.502, train kappa:80.856
fold:3 epoch:24 step:8 train loss:0.625041, train acc:81.961, train f1:80.526, train precision:82.898, train recall:80.521, train kappa:81.269
fold:3 epoch:24 step:9 train loss:0.642177, train acc:81.491, train f1:80.140, train precision:82.505, train recall:79.962, train kappa:80.737
fold:3 epoch:24 step:10 train loss:0.632997, train acc:81.760, train f1:80.431, train precision:82.976, train recall:80.187, train kappa:81.052
fold:3 epoch:24 step:11 train loss:0.629609, train acc:81.681, train f1:80.585, train precision:83.692, train recall:80.721, train kappa:80.945
fold:3 epoch:24        valid loss:0.714273, valid acc:80.888, valid f1:56.911, valid precision:54.554, valid recall:70.125, valid kappa:78.504
None
====================================================================================================
fold:3 epoch:25 step:0 train loss:0.639461, train acc:81.607, train f1:80.421, train precision:82.521, train recall:80.512, train kappa:80.884
fold:3 epoch:25 step:1 train loss:0.628142, train acc:81.940, train f1:80.588, train precision:83.184, train recall:80.442, train kappa:81.234
fold:3 epoch:25 step:2 train loss:0.632015, train acc:81.812, train f1:80.611, train precision:82.893, train recall:80.535, train kappa:81.100
fold:3 epoch:25 step:3 train loss:0.634883, train acc:81.863, train f1:80.721, train precision:83.023, train recall:80.711, train kappa:81.148
fold:3 epoch:25 step:4 train loss:0.632044, train acc:81.827, train f1:80.725, train precision:82.757, train recall:80.847, train kappa:81.122
fold:3 epoch:25 step:5 train loss:0.626038, train acc:81.985, train f1:80.653, train precision:82.723, train recall:80.670, train kappa:81.287
fold:3 epoch:25 step:6 train loss:0.623403, train acc:81.995, train f1:80.857, train precision:83.512, train recall:80.669, train kappa:81.275
fold:3 epoch:25 step:7 train loss:0.606794, train acc:82.388, train f1:81.013, train precision:83.599, train recall:81.139, train kappa:81.694
fold:3 epoch:25 step:8 train loss:0.623170, train acc:82.108, train f1:80.740, train precision:83.046, train recall:80.823, train kappa:81.416
fold:3 epoch:25 step:9 train loss:0.627719, train acc:81.897, train f1:80.679, train precision:83.152, train recall:80.839, train kappa:81.175
fold:3 epoch:25 step:10 train loss:0.632265, train acc:81.943, train f1:80.742, train precision:83.265, train recall:80.861, train kappa:81.229
fold:3 epoch:25 step:11 train loss:0.611303, train acc:82.145, train f1:80.960, train precision:83.788, train recall:80.942, train kappa:81.440
fold:3 epoch:25        valid loss:0.711597, valid acc:80.766, valid f1:57.154, valid precision:54.535, valid recall:70.378, valid kappa:78.376
None
====================================================================================================
fold:3 epoch:26 step:0 train loss:0.621080, train acc:82.065, train f1:80.669, train precision:83.287, train recall:80.632, train kappa:81.365
fold:3 epoch:26 step:1 train loss:0.621787, train acc:82.001, train f1:80.974, train precision:83.248, train recall:80.848, train kappa:81.285
fold:3 epoch:26 step:2 train loss:0.610390, train acc:82.336, train f1:81.033, train precision:83.049, train recall:81.061, train kappa:81.638
fold:3 epoch:26 step:3 train loss:0.620786, train acc:81.995, train f1:81.084, train precision:83.315, train recall:80.984, train kappa:81.284
fold:3 epoch:26 step:4 train loss:0.609061, train acc:82.138, train f1:80.972, train precision:82.945, train recall:80.728, train kappa:81.436
fold:3 epoch:26 step:5 train loss:0.623381, train acc:82.056, train f1:80.975, train precision:82.931, train recall:80.937, train kappa:81.351
fold:3 epoch:26 step:6 train loss:0.618489, train acc:82.196, train f1:81.216, train precision:83.181, train recall:81.065, train kappa:81.495
fold:3 epoch:26 step:7 train loss:0.623770, train acc:81.735, train f1:80.495, train precision:82.980, train recall:80.495, train kappa:81.023
fold:3 epoch:26 step:8 train loss:0.604535, train acc:82.501, train f1:81.119, train precision:83.463, train recall:81.203, train kappa:81.815
fold:3 epoch:26 step:9 train loss:0.616877, train acc:82.242, train f1:81.037, train precision:83.186, train recall:81.052, train kappa:81.549
fold:3 epoch:26 step:10 train loss:0.614829, train acc:82.123, train f1:80.890, train precision:83.561, train recall:81.213, train kappa:81.430
fold:3 epoch:26 step:11 train loss:0.603927, train acc:82.434, train f1:80.931, train precision:82.560, train recall:81.073, train kappa:81.719
fold:3 epoch:26        valid loss:0.711551, valid acc:80.898, valid f1:57.372, valid precision:54.369, valid recall:70.502, valid kappa:78.531
None
====================================================================================================
fold:3 epoch:27 step:0 train loss:0.608536, train acc:82.397, train f1:81.412, train precision:83.694, train recall:81.587, train kappa:81.699
fold:3 epoch:27 step:1 train loss:0.622830, train acc:82.172, train f1:80.906, train precision:82.922, train recall:80.979, train kappa:81.464
fold:3 epoch:27 step:2 train loss:0.597366, train acc:82.715, train f1:81.379, train precision:83.579, train recall:81.328, train kappa:82.030
fold:3 epoch:27 step:3 train loss:0.605381, train acc:82.455, train f1:81.345, train precision:83.665, train recall:81.281, train kappa:81.765
fold:3 epoch:27 step:4 train loss:0.597936, train acc:82.501, train f1:81.539, train precision:83.737, train recall:81.324, train kappa:81.806
fold:3 epoch:27 step:5 train loss:0.594068, train acc:82.584, train f1:81.120, train precision:83.234, train recall:80.958, train kappa:81.896
fold:3 epoch:27 step:6 train loss:0.597388, train acc:82.550, train f1:81.379, train precision:83.680, train recall:81.296, train kappa:81.873
fold:3 epoch:27 step:7 train loss:0.603027, train acc:82.465, train f1:81.540, train precision:83.528, train recall:81.587, train kappa:81.791
fold:3 epoch:27 step:8 train loss:0.600078, train acc:82.755, train f1:81.336, train precision:82.915, train recall:81.854, train kappa:82.094
fold:3 epoch:27 step:9 train loss:0.603538, train acc:82.364, train f1:81.152, train precision:82.914, train recall:81.297, train kappa:81.670
fold:3 epoch:27 step:10 train loss:0.592534, train acc:82.648, train f1:81.388, train precision:83.253, train recall:81.504, train kappa:81.984
fold:3 epoch:27 step:11 train loss:0.606092, train acc:82.618, train f1:81.382, train precision:84.238, train recall:81.533, train kappa:81.918
fold:3 epoch:27        valid loss:0.702936, valid acc:81.201, valid f1:57.388, valid precision:54.582, valid recall:70.434, valid kappa:78.853
None
====================================================================================================
fold:3 epoch:28 step:0 train loss:0.602057, train acc:82.635, train f1:81.460, train precision:83.584, train recall:81.488, train kappa:81.968
fold:3 epoch:28 step:1 train loss:0.600608, train acc:82.639, train f1:81.610, train precision:83.769, train recall:81.626, train kappa:81.963
fold:3 epoch:28 step:2 train loss:0.595284, train acc:82.565, train f1:81.569, train precision:83.727, train recall:81.463, train kappa:81.879
fold:3 epoch:28 step:3 train loss:0.590016, train acc:82.819, train f1:81.668, train precision:83.519, train recall:81.891, train kappa:82.154
fold:3 epoch:28 step:4 train loss:0.586136, train acc:82.852, train f1:81.818, train precision:83.948, train recall:81.664, train kappa:82.186
fold:3 epoch:28 step:5 train loss:0.599517, train acc:82.455, train f1:81.375, train precision:83.366, train recall:81.439, train kappa:81.758
fold:3 epoch:28 step:6 train loss:0.597672, train acc:82.794, train f1:81.619, train precision:83.553, train recall:81.657, train kappa:82.123
fold:3 epoch:28 step:7 train loss:0.592592, train acc:82.822, train f1:81.679, train precision:83.832, train recall:81.828, train kappa:82.148
fold:3 epoch:28 step:8 train loss:0.592353, train acc:82.883, train f1:81.744, train precision:84.089, train recall:81.789, train kappa:82.189
fold:3 epoch:28 step:9 train loss:0.585097, train acc:83.017, train f1:81.685, train precision:83.536, train recall:81.825, train kappa:82.356
fold:3 epoch:28 step:10 train loss:0.583090, train acc:83.243, train f1:82.143, train precision:84.052, train recall:82.122, train kappa:82.593
fold:3 epoch:28 step:11 train loss:0.604337, train acc:82.260, train f1:81.130, train precision:82.449, train recall:81.459, train kappa:81.571
fold:3 epoch:28        valid loss:0.697907, valid acc:81.373, valid f1:57.719, valid precision:54.970, valid recall:70.673, valid kappa:79.043
None
====================================================================================================
fold:3 epoch:29 step:0 train loss:0.576145, train acc:83.176, train f1:82.089, train precision:84.198, train recall:82.102, train kappa:82.523
fold:3 epoch:29 step:1 train loss:0.591547, train acc:82.852, train f1:81.674, train precision:84.089, train recall:81.444, train kappa:82.169
fold:3 epoch:29 step:2 train loss:0.579776, train acc:82.892, train f1:81.728, train precision:83.770, train recall:81.768, train kappa:82.233
fold:3 epoch:29 step:3 train loss:0.576738, train acc:83.163, train f1:81.921, train precision:83.868, train recall:82.049, train kappa:82.508
fold:3 epoch:29 step:4 train loss:0.573161, train acc:83.252, train f1:82.020, train precision:84.144, train recall:82.001, train kappa:82.595
fold:3 epoch:29 step:5 train loss:0.598268, train acc:82.623, train f1:81.576, train precision:83.592, train recall:81.588, train kappa:81.939
fold:3 epoch:29 step:6 train loss:0.575213, train acc:83.176, train f1:81.959, train precision:83.646, train recall:82.048, train kappa:82.504
fold:3 epoch:29 step:7 train loss:0.581830, train acc:82.819, train f1:81.561, train precision:82.809, train recall:81.769, train kappa:82.135
fold:3 epoch:29 step:8 train loss:0.577940, train acc:83.136, train f1:81.935, train precision:83.943, train recall:82.094, train kappa:82.482
fold:3 epoch:29 step:9 train loss:0.582090, train acc:83.078, train f1:81.924, train precision:84.294, train recall:81.988, train kappa:82.418
fold:3 epoch:29 step:10 train loss:0.590469, train acc:82.843, train f1:81.909, train precision:83.653, train recall:82.004, train kappa:82.188
fold:3 epoch:29 step:11 train loss:0.568711, train acc:83.882, train f1:82.674, train precision:84.804, train recall:82.875, train kappa:83.267
fold:3 epoch:29        valid loss:0.692680, valid acc:81.451, valid f1:57.966, valid precision:55.127, valid recall:70.464, valid kappa:79.133
None
====================================================================================================
fold:3 epoch:30 step:0 train loss:0.578980, train acc:83.261, train f1:82.384, train precision:84.161, train recall:82.579, train kappa:82.599
fold:3 epoch:30 step:1 train loss:0.569631, train acc:83.191, train f1:82.100, train precision:83.623, train recall:82.354, train kappa:82.543
fold:3 epoch:30 step:2 train loss:0.579558, train acc:83.298, train f1:82.221, train precision:84.020, train recall:82.187, train kappa:82.641
fold:3 epoch:30 step:3 train loss:0.572832, train acc:83.276, train f1:82.081, train precision:83.914, train recall:82.194, train kappa:82.634
fold:3 epoch:30 step:4 train loss:0.573816, train acc:83.365, train f1:82.237, train precision:84.128, train recall:82.305, train kappa:82.719
fold:3 epoch:30 step:5 train loss:0.569736, train acc:83.118, train f1:82.078, train precision:84.445, train recall:82.027, train kappa:82.462
fold:3 epoch:30 step:6 train loss:0.573071, train acc:83.292, train f1:82.246, train precision:84.439, train recall:82.294, train kappa:82.635
fold:3 epoch:30 step:7 train loss:0.578216, train acc:82.983, train f1:82.066, train precision:84.660, train recall:82.224, train kappa:82.321
fold:3 epoch:30 step:8 train loss:0.576161, train acc:83.118, train f1:81.759, train precision:83.222, train recall:82.062, train kappa:82.466
fold:3 epoch:30 step:9 train loss:0.563654, train acc:83.478, train f1:82.326, train precision:83.721, train recall:82.611, train kappa:82.833
fold:3 epoch:30 step:10 train loss:0.575484, train acc:83.221, train f1:81.991, train precision:83.375, train recall:82.372, train kappa:82.581
fold:3 epoch:30 step:11 train loss:0.577633, train acc:83.042, train f1:81.585, train precision:83.814, train recall:81.727, train kappa:82.345
fold:3 epoch:30        valid loss:0.688300, valid acc:81.686, valid f1:57.926, valid precision:55.016, valid recall:70.479, valid kappa:79.404
None
====================================================================================================
fold:3 epoch:31 step:0 train loss:0.555095, train acc:83.838, train f1:82.773, train precision:84.637, train recall:82.614, train kappa:83.209
fold:3 epoch:31 step:1 train loss:0.560878, train acc:83.508, train f1:82.510, train precision:84.587, train recall:82.379, train kappa:82.866
fold:3 epoch:31 step:2 train loss:0.559278, train acc:83.588, train f1:82.474, train precision:84.654, train recall:82.335, train kappa:82.948
fold:3 epoch:31 step:3 train loss:0.560084, train acc:83.591, train f1:82.664, train precision:84.976, train recall:82.495, train kappa:82.937
fold:3 epoch:31 step:4 train loss:0.563358, train acc:83.456, train f1:82.362, train precision:84.183, train recall:82.337, train kappa:82.792
fold:3 epoch:31 step:5 train loss:0.574765, train acc:83.328, train f1:82.074, train precision:83.598, train recall:82.266, train kappa:82.685
fold:3 epoch:31 step:6 train loss:0.568671, train acc:83.063, train f1:82.081, train precision:83.867, train recall:82.449, train kappa:82.411
fold:3 epoch:31 step:7 train loss:0.562086, train acc:83.511, train f1:82.302, train precision:83.933, train recall:82.566, train kappa:82.868
fold:3 epoch:31 step:8 train loss:0.567555, train acc:83.444, train f1:82.456, train precision:84.375, train recall:82.742, train kappa:82.814
fold:3 epoch:31 step:9 train loss:0.562695, train acc:83.511, train f1:82.240, train precision:84.571, train recall:82.156, train kappa:82.866
fold:3 epoch:31 step:10 train loss:0.571398, train acc:83.270, train f1:82.409, train precision:84.095, train recall:82.573, train kappa:82.617
fold:3 epoch:31 step:11 train loss:0.560784, train acc:83.206, train f1:82.284, train precision:84.413, train recall:82.398, train kappa:82.559
fold:3 epoch:31        valid loss:0.690762, valid acc:81.724, valid f1:58.229, valid precision:55.260, valid recall:70.708, valid kappa:79.449
[81.72449751569305, 58.229463990166785, 55.260039232281486, 70.70832402989184, 79.44850322173403]
====================================================================================================
fold:3 epoch:32 step:0 train loss:0.555944, train acc:83.569, train f1:82.557, train precision:84.265, train recall:82.678, train kappa:82.925
fold:3 epoch:32 step:1 train loss:0.559438, train acc:83.447, train f1:82.541, train precision:84.099, train recall:82.660, train kappa:82.812
fold:3 epoch:32 step:2 train loss:0.550847, train acc:83.798, train f1:82.610, train precision:84.139, train recall:82.894, train kappa:83.174
fold:3 epoch:32 step:3 train loss:0.553292, train acc:83.871, train f1:82.612, train precision:84.460, train recall:82.797, train kappa:83.245
fold:3 epoch:32 step:4 train loss:0.559627, train acc:83.673, train f1:82.443, train precision:84.699, train recall:82.376, train kappa:83.035
fold:3 epoch:32 step:5 train loss:0.554731, train acc:83.557, train f1:82.506, train precision:84.687, train recall:82.512, train kappa:82.928
fold:3 epoch:32 step:6 train loss:0.563641, train acc:83.392, train f1:82.333, train precision:84.353, train recall:82.336, train kappa:82.743
fold:3 epoch:32 step:7 train loss:0.553109, train acc:83.899, train f1:82.689, train precision:84.314, train recall:82.924, train kappa:83.276
fold:3 epoch:32 step:8 train loss:0.555052, train acc:83.685, train f1:82.876, train precision:84.987, train recall:83.044, train kappa:83.043
fold:3 epoch:32 step:9 train loss:0.548350, train acc:83.878, train f1:82.831, train precision:84.823, train recall:82.843, train kappa:83.240
fold:3 epoch:32 step:10 train loss:0.559591, train acc:83.594, train f1:82.466, train precision:84.365, train recall:82.688, train kappa:82.953
fold:3 epoch:32 step:11 train loss:0.553810, train acc:83.544, train f1:82.130, train precision:84.455, train recall:82.215, train kappa:82.902
fold:3 epoch:32        valid loss:0.687476, valid acc:81.868, valid f1:58.232, valid precision:55.189, valid recall:70.472, valid kappa:79.595
[1;31mTest score increased (81.724498 --> 81.867626).[0m
[81.867626311162, 58.23163128391106, 55.18886266033368, 70.4720519891426, 79.59450212447075]
====================================================================================================
fold:3 epoch:33 step:0 train loss:0.561613, train acc:83.810, train f1:82.840, train precision:85.101, train recall:82.824, train kappa:83.167
fold:3 epoch:33 step:1 train loss:0.554899, train acc:83.612, train f1:82.650, train precision:84.325, train recall:82.844, train kappa:82.974
fold:3 epoch:33 step:2 train loss:0.545547, train acc:84.055, train f1:82.800, train precision:84.707, train recall:82.768, train kappa:83.446
fold:3 epoch:33 step:3 train loss:0.546483, train acc:83.981, train f1:82.928, train precision:84.517, train recall:83.225, train kappa:83.363
fold:3 epoch:33 step:4 train loss:0.543206, train acc:84.088, train f1:82.976, train precision:84.566, train recall:83.260, train kappa:83.462
fold:3 epoch:33 step:5 train loss:0.538536, train acc:84.241, train f1:83.055, train precision:84.850, train recall:83.175, train kappa:83.609
fold:3 epoch:33 step:6 train loss:0.541884, train acc:83.847, train f1:82.783, train precision:84.358, train recall:82.935, train kappa:83.214
fold:3 epoch:33 step:7 train loss:0.550982, train acc:83.673, train f1:82.751, train precision:85.048, train recall:82.787, train kappa:83.045
fold:3 epoch:33 step:8 train loss:0.556353, train acc:83.795, train f1:82.793, train precision:84.898, train recall:82.724, train kappa:83.165
fold:3 epoch:33 step:9 train loss:0.538115, train acc:83.786, train f1:82.747, train precision:84.394, train recall:82.864, train kappa:83.161
fold:3 epoch:33 step:10 train loss:0.550638, train acc:83.707, train f1:82.674, train precision:84.572, train recall:82.861, train kappa:83.084
fold:3 epoch:33 step:11 train loss:0.541743, train acc:84.133, train f1:83.170, train precision:84.865, train recall:83.473, train kappa:83.558
fold:3 epoch:33        valid loss:0.693003, valid acc:81.814, valid f1:58.432, valid precision:55.133, valid recall:70.841, valid kappa:79.550
[1;31mEarlyStopping counter: 1 out of 50[0m
[81.867626311162, 58.23163128391106, 55.18886266033368, 70.4720519891426, 79.59450212447075]
====================================================================================================
fold:3 epoch:34 step:0 train loss:0.541888, train acc:84.198, train f1:83.072, train precision:84.437, train recall:83.326, train kappa:83.589
fold:3 epoch:34 step:1 train loss:0.544263, train acc:84.076, train f1:83.252, train precision:84.676, train recall:83.289, train kappa:83.477
fold:3 epoch:34 step:2 train loss:0.538963, train acc:83.789, train f1:82.649, train precision:84.450, train recall:82.794, train kappa:83.151
fold:3 epoch:34 step:3 train loss:0.540723, train acc:84.232, train f1:83.201, train precision:85.048, train recall:83.168, train kappa:83.612
fold:3 epoch:34 step:4 train loss:0.543510, train acc:83.853, train f1:82.879, train precision:84.256, train recall:83.091, train kappa:83.230
fold:3 epoch:34 step:5 train loss:0.536422, train acc:84.116, train f1:83.037, train precision:84.858, train recall:83.186, train kappa:83.491
fold:3 epoch:34 step:6 train loss:0.531395, train acc:84.268, train f1:83.196, train precision:85.462, train recall:83.297, train kappa:83.655
fold:3 epoch:34 step:7 train loss:0.548660, train acc:83.838, train f1:82.582, train precision:84.928, train recall:82.846, train kappa:83.213
fold:3 epoch:34 step:8 train loss:0.544544, train acc:84.015, train f1:83.033, train precision:84.944, train recall:83.118, train kappa:83.393
fold:3 epoch:34 step:9 train loss:0.544516, train acc:83.841, train f1:82.861, train precision:84.685, train recall:83.204, train kappa:83.220
fold:3 epoch:34 step:10 train loss:0.539442, train acc:84.085, train f1:83.104, train precision:84.522, train recall:83.416, train kappa:83.463
fold:3 epoch:34 step:11 train loss:0.525939, train acc:84.432, train f1:83.312, train precision:85.418, train recall:83.285, train kappa:83.842
fold:3 epoch:34        valid loss:0.686462, valid acc:81.968, valid f1:58.529, valid precision:55.354, valid recall:70.571, valid kappa:79.717
[1;31mTest score increased (81.867626 --> 81.967816).[0m
[81.96781646799026, 58.52931991616006, 55.35409452849296, 70.57103481516698, 79.71692018605214]
====================================================================================================
fold:3 epoch:35 step:0 train loss:0.527229, train acc:84.482, train f1:83.611, train precision:85.470, train recall:83.664, train kappa:83.874
fold:3 epoch:35 step:1 train loss:0.539488, train acc:84.326, train f1:83.554, train precision:85.377, train recall:83.571, train kappa:83.728
fold:3 epoch:35 step:2 train loss:0.531015, train acc:84.259, train f1:83.301, train precision:85.113, train recall:83.371, train kappa:83.637
fold:3 epoch:35 step:3 train loss:0.527432, train acc:84.485, train f1:83.378, train precision:85.407, train recall:83.292, train kappa:83.886
fold:3 epoch:35 step:4 train loss:0.533080, train acc:84.332, train f1:83.279, train precision:85.288, train recall:83.492, train kappa:83.719
fold:3 epoch:35 step:5 train loss:0.532417, train acc:84.149, train f1:83.154, train precision:84.990, train recall:83.158, train kappa:83.524
fold:3 epoch:35 step:6 train loss:0.529393, train acc:84.387, train f1:82.967, train precision:84.342, train recall:83.250, train kappa:83.767
fold:3 epoch:35 step:7 train loss:0.530317, train acc:84.238, train f1:82.840, train precision:84.644, train recall:83.031, train kappa:83.629
fold:3 epoch:35 step:8 train loss:0.531381, train acc:84.390, train f1:83.530, train precision:85.638, train recall:83.534, train kappa:83.793
fold:3 epoch:35 step:9 train loss:0.530472, train acc:84.460, train f1:83.363, train precision:84.793, train recall:83.750, train kappa:83.872
fold:3 epoch:35 step:10 train loss:0.526999, train acc:84.320, train f1:83.159, train precision:84.410, train recall:83.423, train kappa:83.715
fold:3 epoch:35 step:11 train loss:0.549744, train acc:83.978, train f1:83.327, train precision:84.892, train recall:83.576, train kappa:83.361
fold:3 epoch:35        valid loss:0.678900, valid acc:82.232, valid f1:58.816, valid precision:55.885, valid recall:70.453, valid kappa:80.005
[1;31mTest score increased (81.967816 --> 82.231582).[0m
[82.23158239106876, 58.81565221655286, 55.88454386120253, 70.45296104813539, 80.00454392665539]
====================================================================================================
fold:3 epoch:36 step:0 train loss:0.520234, train acc:84.518, train f1:83.533, train precision:85.215, train recall:83.584, train kappa:83.921
fold:3 epoch:36 step:1 train loss:0.521567, train acc:84.561, train f1:83.317, train precision:85.418, train recall:83.190, train kappa:83.966
fold:3 epoch:36 step:2 train loss:0.530784, train acc:84.387, train f1:83.320, train precision:84.869, train recall:83.445, train kappa:83.766
fold:3 epoch:36 step:3 train loss:0.521563, train acc:84.586, train f1:83.553, train precision:85.749, train recall:83.575, train kappa:84.006
fold:3 epoch:36 step:4 train loss:0.523019, train acc:84.354, train f1:83.289, train precision:85.408, train recall:83.301, train kappa:83.743
fold:3 epoch:36 step:5 train loss:0.520581, train acc:84.427, train f1:83.347, train precision:85.232, train recall:83.475, train kappa:83.811
fold:3 epoch:36 step:6 train loss:0.528040, train acc:84.335, train f1:83.064, train precision:84.680, train recall:83.348, train kappa:83.725
fold:3 epoch:36 step:7 train loss:0.524361, train acc:84.323, train f1:83.330, train precision:85.157, train recall:83.485, train kappa:83.718
fold:3 epoch:36 step:8 train loss:0.522087, train acc:84.250, train f1:83.537, train precision:84.878, train recall:83.621, train kappa:83.638
fold:3 epoch:36 step:9 train loss:0.529961, train acc:84.406, train f1:83.467, train precision:84.853, train recall:83.541, train kappa:83.792
fold:3 epoch:36 step:10 train loss:0.527434, train acc:84.314, train f1:83.315, train precision:85.375, train recall:83.320, train kappa:83.705
fold:3 epoch:36 step:11 train loss:0.530776, train acc:83.920, train f1:83.190, train precision:85.831, train recall:83.017, train kappa:83.313
fold:3 epoch:36        valid loss:0.678542, valid acc:82.326, valid f1:59.254, valid precision:56.112, valid recall:70.592, valid kappa:80.107
[1;31mTest score increased (82.231582 --> 82.325638).[0m
[82.32563845666265, 59.25420601364767, 56.111550024014456, 70.59246338426044, 80.10719167610637]
====================================================================================================
fold:3 epoch:37 step:0 train loss:0.518720, train acc:84.744, train f1:83.869, train precision:85.886, train recall:83.704, train kappa:84.159
fold:3 epoch:37 step:1 train loss:0.514211, train acc:84.607, train f1:83.653, train precision:84.898, train recall:84.120, train kappa:84.013
fold:3 epoch:37 step:2 train loss:0.510501, train acc:85.074, train f1:84.050, train precision:85.394, train recall:84.202, train kappa:84.502
fold:3 epoch:37 step:3 train loss:0.520475, train acc:84.521, train f1:83.417, train precision:84.864, train recall:83.498, train kappa:83.921
fold:3 epoch:37 step:4 train loss:0.512590, train acc:84.863, train f1:83.625, train precision:85.184, train recall:83.901, train kappa:84.278
fold:3 epoch:37 step:5 train loss:0.516324, train acc:84.668, train f1:83.483, train precision:85.143, train recall:83.453, train kappa:84.066
fold:3 epoch:37 step:6 train loss:0.523459, train acc:84.604, train f1:83.555, train precision:85.336, train recall:83.592, train kappa:84.002
fold:3 epoch:37 step:7 train loss:0.519143, train acc:84.619, train f1:83.768, train precision:85.562, train recall:83.863, train kappa:84.022
fold:3 epoch:37 step:8 train loss:0.532387, train acc:84.100, train f1:82.892, train precision:84.897, train recall:83.000, train kappa:83.483
fold:3 epoch:37 step:9 train loss:0.512808, train acc:84.775, train f1:83.613, train precision:84.999, train recall:83.883, train kappa:84.190
fold:3 epoch:37 step:10 train loss:0.539997, train acc:84.012, train f1:83.098, train precision:84.509, train recall:83.259, train kappa:83.393
fold:3 epoch:37 step:11 train loss:0.520717, train acc:84.413, train f1:83.561, train precision:84.898, train recall:83.822, train kappa:83.804
fold:3 epoch:37        valid loss:0.678107, valid acc:82.432, valid f1:58.865, valid precision:55.666, valid recall:70.796, valid kappa:80.234
[1;31mTest score increased (82.325638 --> 82.431963).[0m
[82.4319627047253, 58.86508222919895, 55.66551828231595, 70.79637459001374, 80.23447529150589]
====================================================================================================
fold:3 epoch:38 step:0 train loss:0.502505, train acc:85.004, train f1:83.926, train precision:85.577, train recall:84.139, train kappa:84.437
fold:3 epoch:38 step:1 train loss:0.501482, train acc:85.147, train f1:84.190, train precision:85.802, train recall:84.190, train kappa:84.564
fold:3 epoch:38 step:2 train loss:0.514774, train acc:84.637, train f1:83.644, train precision:85.114, train recall:83.790, train kappa:84.038
fold:3 epoch:38 step:3 train loss:0.505945, train acc:85.010, train f1:83.852, train precision:85.707, train recall:83.872, train kappa:84.421
fold:3 epoch:38 step:4 train loss:0.514242, train acc:84.647, train f1:83.638, train precision:85.286, train recall:83.639, train kappa:84.052
fold:3 epoch:38 step:5 train loss:0.512360, train acc:84.625, train f1:83.565, train precision:85.606, train recall:83.506, train kappa:84.024
fold:3 epoch:38 step:6 train loss:0.509689, train acc:84.732, train f1:83.930, train precision:85.827, train recall:84.011, train kappa:84.145
fold:3 epoch:38 step:7 train loss:0.518909, train acc:84.906, train f1:83.896, train precision:85.777, train recall:84.167, train kappa:84.323
fold:3 epoch:38 step:8 train loss:0.521398, train acc:84.433, train f1:83.411, train precision:84.795, train recall:83.848, train kappa:83.834
fold:3 epoch:38 step:9 train loss:0.509651, train acc:84.860, train f1:83.614, train precision:85.394, train recall:83.786, train kappa:84.273
fold:3 epoch:38 step:10 train loss:0.510980, train acc:84.903, train f1:83.987, train precision:85.918, train recall:84.120, train kappa:84.321
fold:3 epoch:38 step:11 train loss:0.519775, train acc:84.992, train f1:84.054, train precision:85.942, train recall:84.070, train kappa:84.416
fold:3 epoch:38        valid loss:0.675773, valid acc:82.546, valid f1:59.517, valid precision:56.518, valid recall:70.671, valid kappa:80.356
[1;31mTest score increased (82.431963 --> 82.546466).[0m
[82.54646574110046, 59.5171732359654, 56.51804050342217, 70.67059136195265, 80.35581537662021]
====================================================================================================
fold:3 epoch:39 step:0 train loss:0.498567, train acc:85.147, train f1:84.242, train precision:86.102, train recall:84.195, train kappa:84.563
fold:3 epoch:39 step:1 train loss:0.505992, train acc:85.092, train f1:84.057, train precision:86.048, train recall:84.057, train kappa:84.513
fold:3 epoch:39 step:2 train loss:0.506651, train acc:84.885, train f1:83.941, train precision:85.825, train recall:84.101, train kappa:84.294
fold:3 epoch:39 step:3 train loss:0.503117, train acc:84.879, train f1:83.540, train precision:85.082, train recall:83.596, train kappa:84.286
fold:3 epoch:39 step:4 train loss:0.519282, train acc:84.579, train f1:83.490, train precision:84.921, train recall:83.662, train kappa:83.983
fold:3 epoch:39 step:5 train loss:0.509841, train acc:84.756, train f1:83.608, train precision:85.289, train recall:83.801, train kappa:84.172
fold:3 epoch:39 step:6 train loss:0.504581, train acc:84.872, train f1:83.839, train precision:85.578, train recall:83.964, train kappa:84.290
fold:3 epoch:39 step:7 train loss:0.517024, train acc:84.570, train f1:83.677, train precision:85.081, train recall:83.968, train kappa:83.981
fold:3 epoch:39 step:8 train loss:0.498192, train acc:85.016, train f1:84.053, train precision:85.810, train recall:84.158, train kappa:84.432
fold:3 epoch:39 step:9 train loss:0.493852, train acc:85.297, train f1:84.576, train precision:86.307, train recall:84.574, train kappa:84.738
fold:3 epoch:39 step:10 train loss:0.508579, train acc:84.698, train f1:83.694, train precision:85.094, train recall:84.015, train kappa:84.108
fold:3 epoch:39 step:11 train loss:0.508120, train acc:84.982, train f1:83.770, train precision:84.871, train recall:84.070, train kappa:84.401
fold:3 epoch:39        valid loss:0.676734, valid acc:82.414, valid f1:59.584, valid precision:56.524, valid recall:70.653, valid kappa:80.204
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.54646574110046, 59.5171732359654, 56.51804050342217, 70.67059136195265, 80.35581537662021]
====================================================================================================
fold:3 epoch:40 step:0 train loss:0.500149, train acc:84.918, train f1:83.988, train precision:85.678, train recall:84.072, train kappa:84.330
fold:3 epoch:40 step:1 train loss:0.502338, train acc:84.912, train f1:83.838, train precision:85.152, train recall:84.233, train kappa:84.324
fold:3 epoch:40 step:2 train loss:0.501537, train acc:85.184, train f1:84.185, train precision:85.853, train recall:84.198, train kappa:84.603
fold:3 epoch:40 step:3 train loss:0.496362, train acc:85.260, train f1:84.314, train precision:86.091, train recall:84.362, train kappa:84.681
fold:3 epoch:40 step:4 train loss:0.491546, train acc:85.159, train f1:84.088, train precision:85.862, train recall:84.217, train kappa:84.592
fold:3 epoch:40 step:5 train loss:0.511075, train acc:84.891, train f1:83.994, train precision:85.774, train recall:84.094, train kappa:84.319
fold:3 epoch:40 step:6 train loss:0.504506, train acc:84.991, train f1:83.753, train precision:85.368, train recall:83.962, train kappa:84.422
fold:3 epoch:40 step:7 train loss:0.507334, train acc:84.793, train f1:84.063, train precision:85.548, train recall:84.337, train kappa:84.212
fold:3 epoch:40 step:8 train loss:0.505511, train acc:84.991, train f1:84.050, train precision:85.231, train recall:84.484, train kappa:84.430
fold:3 epoch:40 step:9 train loss:0.494715, train acc:85.178, train f1:84.142, train precision:85.698, train recall:84.428, train kappa:84.591
fold:3 epoch:40 step:10 train loss:0.497296, train acc:85.141, train f1:83.999, train precision:85.361, train recall:84.283, train kappa:84.563
fold:3 epoch:40 step:11 train loss:0.515930, train acc:84.345, train f1:83.500, train precision:85.167, train recall:83.671, train kappa:83.750
fold:3 epoch:40        valid loss:0.672715, valid acc:82.618, valid f1:59.581, valid precision:56.474, valid recall:70.603, valid kappa:80.433
[1;31mTest score increased (82.546466 --> 82.618030).[0m
[82.61803013883492, 59.58082760129595, 56.473736959101075, 70.60291668000468, 80.43335111748485]
====================================================================================================
fold:3 epoch:41 step:0 train loss:0.494599, train acc:85.004, train f1:84.343, train precision:85.896, train recall:84.300, train kappa:84.425
fold:3 epoch:41 step:1 train loss:0.487053, train acc:85.318, train f1:84.385, train precision:86.303, train recall:84.187, train kappa:84.744
fold:3 epoch:41 step:2 train loss:0.494997, train acc:85.211, train f1:84.272, train precision:85.951, train recall:84.324, train kappa:84.617
fold:3 epoch:41 step:3 train loss:0.496242, train acc:85.321, train f1:84.250, train precision:85.880, train recall:84.457, train kappa:84.760
fold:3 epoch:41 step:4 train loss:0.499850, train acc:85.217, train f1:84.315, train precision:85.890, train recall:84.501, train kappa:84.647
fold:3 epoch:41 step:5 train loss:0.492865, train acc:85.376, train f1:84.552, train precision:86.124, train recall:84.794, train kappa:84.806
fold:3 epoch:41 step:6 train loss:0.499729, train acc:85.107, train f1:84.161, train precision:85.650, train recall:84.528, train kappa:84.536
fold:3 epoch:41 step:7 train loss:0.491962, train acc:85.168, train f1:84.439, train precision:85.812, train recall:84.602, train kappa:84.589
fold:3 epoch:41 step:8 train loss:0.497487, train acc:84.824, train f1:83.838, train precision:85.540, train recall:83.809, train kappa:84.241
fold:3 epoch:41 step:9 train loss:0.488581, train acc:85.275, train f1:84.308, train precision:85.960, train recall:84.233, train kappa:84.701
fold:3 epoch:41 step:10 train loss:0.497871, train acc:84.961, train f1:83.871, train precision:85.534, train recall:83.853, train kappa:84.399
fold:3 epoch:41 step:11 train loss:0.497567, train acc:84.847, train f1:83.745, train precision:85.039, train recall:84.023, train kappa:84.279
fold:3 epoch:41        valid loss:0.669574, valid acc:82.628, valid f1:59.532, valid precision:56.209, valid recall:70.716, valid kappa:80.448
[1;31mTest score increased (82.618030 --> 82.628254).[0m
[82.62825362422556, 59.5317855856194, 56.20926692090278, 70.7163345839029, 80.44764026048728]
====================================================================================================
fold:3 epoch:42 step:0 train loss:0.485506, train acc:85.504, train f1:84.483, train precision:86.059, train recall:84.664, train kappa:84.938
fold:3 epoch:42 step:1 train loss:0.491814, train acc:85.287, train f1:84.409, train precision:85.893, train recall:84.594, train kappa:84.716
fold:3 epoch:42 step:2 train loss:0.489651, train acc:85.382, train f1:84.395, train precision:86.500, train recall:84.469, train kappa:84.813
fold:3 epoch:42 step:3 train loss:0.492374, train acc:85.321, train f1:84.522, train precision:86.127, train recall:84.769, train kappa:84.768
fold:3 epoch:42 step:4 train loss:0.487330, train acc:85.324, train f1:84.504, train precision:85.912, train recall:84.695, train kappa:84.766
fold:3 epoch:42 step:5 train loss:0.489569, train acc:85.138, train f1:84.069, train precision:85.369, train recall:84.238, train kappa:84.567
fold:3 epoch:42 step:6 train loss:0.487359, train acc:85.339, train f1:84.350, train precision:85.630, train recall:84.581, train kappa:84.778
fold:3 epoch:42 step:7 train loss:0.502096, train acc:84.784, train f1:83.867, train precision:85.526, train recall:84.077, train kappa:84.179
fold:3 epoch:42 step:8 train loss:0.486965, train acc:85.306, train f1:84.378, train precision:86.091, train recall:84.433, train kappa:84.746
fold:3 epoch:42 step:9 train loss:0.483855, train acc:85.632, train f1:84.590, train precision:85.918, train recall:84.935, train kappa:85.073
fold:3 epoch:42 step:10 train loss:0.489857, train acc:85.196, train f1:84.189, train precision:85.642, train recall:84.324, train kappa:84.632
fold:3 epoch:42 step:11 train loss:0.491155, train acc:84.751, train f1:84.019, train precision:85.510, train recall:84.117, train kappa:84.160
fold:3 epoch:42        valid loss:0.674383, valid acc:82.686, valid f1:59.317, valid precision:56.097, valid recall:70.727, valid kappa:80.512
[1;31mTest score increased (82.628254 --> 82.685505).[0m
[82.68550514241315, 59.31680548785809, 56.096718627623865, 70.72659514297133, 80.51181340831171]
====================================================================================================
fold:3 epoch:43 step:0 train loss:0.483029, train acc:85.406, train f1:84.616, train precision:86.218, train recall:84.737, train kappa:84.855
fold:3 epoch:43 step:1 train loss:0.468880, train acc:85.693, train f1:84.404, train precision:86.092, train recall:84.472, train kappa:85.141
fold:3 epoch:43 step:2 train loss:0.484882, train acc:85.455, train f1:84.549, train precision:86.204, train recall:84.709, train kappa:84.896
fold:3 epoch:43 step:3 train loss:0.479601, train acc:85.635, train f1:84.616, train precision:85.876, train recall:84.794, train kappa:85.090
fold:3 epoch:43 step:4 train loss:0.485156, train acc:85.306, train f1:84.414, train precision:85.619, train recall:84.531, train kappa:84.739
fold:3 epoch:43 step:5 train loss:0.489913, train acc:85.211, train f1:84.437, train precision:85.870, train recall:84.562, train kappa:84.642
fold:3 epoch:43 step:6 train loss:0.479943, train acc:85.623, train f1:84.640, train precision:86.240, train recall:84.671, train kappa:85.066
fold:3 epoch:43 step:7 train loss:0.482141, train acc:85.434, train f1:84.560, train precision:86.279, train recall:84.550, train kappa:84.872
fold:3 epoch:43 step:8 train loss:0.486908, train acc:85.312, train f1:84.327, train precision:85.331, train recall:84.620, train kappa:84.752
fold:3 epoch:43 step:9 train loss:0.481947, train acc:85.535, train f1:84.575, train precision:85.790, train recall:85.012, train kappa:84.967
fold:3 epoch:43 step:10 train loss:0.485065, train acc:85.275, train f1:84.336, train precision:85.317, train recall:84.722, train kappa:84.714
fold:3 epoch:43 step:11 train loss:0.487087, train acc:85.281, train f1:84.381, train precision:85.401, train recall:84.911, train kappa:84.681
fold:3 epoch:43        valid loss:0.672872, valid acc:82.849, valid f1:59.688, valid precision:56.577, valid recall:70.750, valid kappa:80.687
[1;31mTest score increased (82.685505 --> 82.849081).[0m
[82.84908090866338, 59.68806997542205, 56.576761414061274, 70.74952755778384, 80.6869921048201]
====================================================================================================
fold:3 epoch:44 step:0 train loss:0.481444, train acc:85.452, train f1:84.737, train precision:86.575, train recall:84.592, train kappa:84.898
fold:3 epoch:44 step:1 train loss:0.481673, train acc:85.391, train f1:84.499, train precision:86.239, train recall:84.428, train kappa:84.805
fold:3 epoch:44 step:2 train loss:0.483725, train acc:85.385, train f1:84.459, train precision:86.170, train recall:84.509, train kappa:84.816
fold:3 epoch:44 step:3 train loss:0.480246, train acc:85.596, train f1:84.674, train precision:86.298, train recall:84.659, train kappa:85.043
fold:3 epoch:44 step:4 train loss:0.478324, train acc:85.605, train f1:84.791, train precision:86.287, train recall:84.792, train kappa:85.056
fold:3 epoch:44 step:5 train loss:0.467552, train acc:85.834, train f1:85.018, train precision:86.376, train recall:85.305, train kappa:85.280
fold:3 epoch:44 step:6 train loss:0.477689, train acc:85.385, train f1:84.733, train precision:86.194, train recall:84.942, train kappa:84.833
fold:3 epoch:44 step:7 train loss:0.475966, train acc:85.733, train f1:84.899, train precision:86.184, train recall:85.214, train kappa:85.187
fold:3 epoch:44 step:8 train loss:0.477405, train acc:85.693, train f1:84.621, train precision:85.950, train recall:84.887, train kappa:85.148
fold:3 epoch:44 step:9 train loss:0.480954, train acc:85.394, train f1:84.426, train precision:86.100, train recall:84.589, train kappa:84.826
fold:3 epoch:44 step:10 train loss:0.474810, train acc:85.730, train f1:84.744, train precision:86.479, train recall:84.857, train kappa:85.177
fold:3 epoch:44 step:11 train loss:0.476903, train acc:85.677, train f1:84.685, train precision:86.682, train recall:84.772, train kappa:85.116
fold:3 epoch:44        valid loss:0.671048, valid acc:82.986, valid f1:59.802, valid precision:56.588, valid recall:70.684, valid kappa:80.841
[1;31mTest score increased (82.849081 --> 82.986076).[0m
[82.98607561289795, 59.802222726289386, 56.58759673353059, 70.68393129185117, 80.84113466742629]
====================================================================================================
fold:3 epoch:45 step:0 train loss:0.469779, train acc:85.773, train f1:84.902, train precision:86.793, train recall:84.803, train kappa:85.216
fold:3 epoch:45 step:1 train loss:0.464661, train acc:86.008, train f1:85.203, train precision:86.647, train recall:85.190, train kappa:85.467
fold:3 epoch:45 step:2 train loss:0.467787, train acc:85.956, train f1:85.188, train precision:86.363, train recall:85.410, train kappa:85.418
fold:3 epoch:45 step:3 train loss:0.478260, train acc:85.571, train f1:84.606, train precision:85.950, train recall:84.819, train kappa:85.022
fold:3 epoch:45 step:4 train loss:0.469532, train acc:85.675, train f1:84.556, train precision:86.154, train recall:84.733, train kappa:85.128
fold:3 epoch:45 step:5 train loss:0.472998, train acc:85.895, train f1:84.916, train precision:86.287, train recall:85.155, train kappa:85.353
fold:3 epoch:45 step:6 train loss:0.475578, train acc:85.641, train f1:84.697, train precision:85.947, train recall:85.060, train kappa:85.089
fold:3 epoch:45 step:7 train loss:0.484625, train acc:85.526, train f1:84.564, train precision:85.999, train recall:84.719, train kappa:84.963
fold:3 epoch:45 step:8 train loss:0.472735, train acc:85.571, train f1:84.612, train precision:85.879, train recall:84.700, train kappa:85.017
fold:3 epoch:45 step:9 train loss:0.481388, train acc:85.388, train f1:84.474, train precision:85.540, train recall:84.876, train kappa:84.829
fold:3 epoch:45 step:10 train loss:0.464217, train acc:85.880, train f1:85.054, train precision:86.420, train recall:85.153, train kappa:85.339
fold:3 epoch:45 step:11 train loss:0.460783, train acc:86.324, train f1:85.341, train precision:86.625, train recall:85.492, train kappa:85.790
fold:3 epoch:45        valid loss:0.672231, valid acc:82.910, valid f1:60.012, valid precision:56.648, valid recall:70.852, valid kappa:80.756
[1;31mEarlyStopping counter: 1 out of 50[0m
[82.98607561289795, 59.802222726289386, 56.58759673353059, 70.68393129185117, 80.84113466742629]
====================================================================================================
fold:3 epoch:46 step:0 train loss:0.468533, train acc:85.825, train f1:84.961, train precision:86.385, train recall:85.075, train kappa:85.277
fold:3 epoch:46 step:1 train loss:0.469754, train acc:85.812, train f1:84.779, train precision:86.185, train recall:85.033, train kappa:85.269
fold:3 epoch:46 step:2 train loss:0.465774, train acc:85.956, train f1:85.109, train precision:86.507, train recall:85.178, train kappa:85.411
fold:3 epoch:46 step:3 train loss:0.466642, train acc:85.797, train f1:84.957, train precision:86.711, train recall:85.097, train kappa:85.235
fold:3 epoch:46 step:4 train loss:0.466875, train acc:85.803, train f1:84.768, train precision:86.246, train recall:84.822, train kappa:85.266
fold:3 epoch:46 step:5 train loss:0.464000, train acc:85.913, train f1:84.871, train precision:86.679, train recall:84.935, train kappa:85.371
fold:3 epoch:46 step:6 train loss:0.463328, train acc:86.124, train f1:85.155, train precision:86.655, train recall:85.248, train kappa:85.585
fold:3 epoch:46 step:7 train loss:0.466382, train acc:86.020, train f1:84.956, train precision:86.009, train recall:85.255, train kappa:85.485
fold:3 epoch:46 step:8 train loss:0.467668, train acc:85.855, train f1:85.070, train precision:86.473, train recall:85.244, train kappa:85.302
fold:3 epoch:46 step:9 train loss:0.467026, train acc:85.760, train f1:84.686, train precision:85.971, train recall:84.830, train kappa:85.215
fold:3 epoch:46 step:10 train loss:0.470100, train acc:85.876, train f1:85.209, train precision:86.224, train recall:85.409, train kappa:85.339
fold:3 epoch:46 step:11 train loss:0.480338, train acc:85.638, train f1:85.166, train precision:86.309, train recall:85.438, train kappa:85.114
fold:3 epoch:46        valid loss:0.672538, valid acc:83.023, valid f1:59.780, valid precision:56.436, valid recall:70.729, valid kappa:80.890
[1;31mTest score increased (82.986076 --> 83.022880).[0m
[83.02288016030424, 59.77992625641716, 56.43563194381066, 70.72945183685893, 80.88961883682641]
====================================================================================================
fold:3 epoch:47 step:0 train loss:0.461700, train acc:85.989, train f1:85.139, train precision:86.469, train recall:85.300, train kappa:85.453
fold:3 epoch:47 step:1 train loss:0.459070, train acc:86.127, train f1:85.194, train precision:86.302, train recall:85.502, train kappa:85.593
fold:3 epoch:47 step:2 train loss:0.459799, train acc:86.002, train f1:85.242, train precision:86.575, train recall:85.357, train kappa:85.464
fold:3 epoch:47 step:3 train loss:0.464302, train acc:85.818, train f1:84.834, train precision:86.113, train recall:84.901, train kappa:85.273
fold:3 epoch:47 step:4 train loss:0.465383, train acc:85.919, train f1:85.148, train precision:86.835, train recall:84.972, train kappa:85.384
fold:3 epoch:47 step:5 train loss:0.463904, train acc:86.023, train f1:85.200, train precision:86.859, train recall:85.173, train kappa:85.481
fold:3 epoch:47 step:6 train loss:0.464148, train acc:85.904, train f1:84.931, train precision:86.498, train recall:84.953, train kappa:85.363
fold:3 epoch:47 step:7 train loss:0.469983, train acc:85.782, train f1:85.025, train precision:86.225, train recall:85.281, train kappa:85.241
fold:3 epoch:47 step:8 train loss:0.462736, train acc:85.797, train f1:84.937, train precision:86.092, train recall:85.286, train kappa:85.252
fold:3 epoch:47 step:9 train loss:0.462091, train acc:86.053, train f1:85.220, train precision:86.533, train recall:85.492, train kappa:85.513
fold:3 epoch:47 step:10 train loss:0.459698, train acc:86.130, train f1:85.396, train precision:86.835, train recall:85.669, train kappa:85.598
fold:3 epoch:47 step:11 train loss:0.442324, train acc:86.633, train f1:85.020, train precision:86.788, train recall:85.293, train kappa:86.096
fold:3 epoch:47        valid loss:0.669434, valid acc:83.058, valid f1:59.980, valid precision:56.771, valid recall:70.663, valid kappa:80.919
[1;31mTest score increased (83.022880 --> 83.057640).[0m
[83.05764001063243, 59.98039062089035, 56.7713521331781, 70.66269200237139, 80.91928795572859]
====================================================================================================
fold:3 epoch:48 step:0 train loss:0.449268, train acc:86.432, train f1:85.530, train precision:87.079, train recall:85.668, train kappa:85.908
fold:3 epoch:48 step:1 train loss:0.461081, train acc:85.959, train f1:85.102, train precision:86.929, train recall:85.103, train kappa:85.417
fold:3 epoch:48 step:2 train loss:0.457262, train acc:85.989, train f1:85.023, train precision:86.643, train recall:85.069, train kappa:85.443
fold:3 epoch:48 step:3 train loss:0.459345, train acc:86.191, train f1:85.426, train precision:86.968, train recall:85.467, train kappa:85.662
fold:3 epoch:48 step:4 train loss:0.465842, train acc:85.922, train f1:85.136, train precision:86.520, train recall:85.189, train kappa:85.379
fold:3 epoch:48 step:5 train loss:0.465256, train acc:85.938, train f1:85.220, train precision:86.284, train recall:85.434, train kappa:85.411
fold:3 epoch:48 step:6 train loss:0.451452, train acc:86.218, train f1:85.370, train precision:86.528, train recall:85.634, train kappa:85.703
fold:3 epoch:48 step:7 train loss:0.466236, train acc:85.913, train f1:85.101, train precision:86.066, train recall:85.515, train kappa:85.374
fold:3 epoch:48 step:8 train loss:0.458646, train acc:86.105, train f1:84.944, train precision:86.211, train recall:85.196, train kappa:85.557
fold:3 epoch:48 step:9 train loss:0.466471, train acc:85.858, train f1:84.977, train precision:86.444, train recall:85.093, train kappa:85.314
fold:3 epoch:48 step:10 train loss:0.461083, train acc:85.986, train f1:85.113, train precision:86.643, train recall:85.150, train kappa:85.447
fold:3 epoch:48 step:11 train loss:0.448508, train acc:86.584, train f1:85.410, train precision:86.976, train recall:85.760, train kappa:86.048
fold:3 epoch:48        valid loss:0.666385, valid acc:83.348, valid f1:60.355, valid precision:57.434, valid recall:70.710, valid kappa:81.242
[1;31mTest score increased (83.057640 --> 83.347987).[0m
[83.34798699572659, 60.35482021341431, 57.43404272914873, 70.7103913747783, 81.24178348508883]
====================================================================================================
fold:3 epoch:49 step:0 train loss:0.453635, train acc:86.081, train f1:84.926, train precision:86.808, train recall:84.945, train kappa:85.537
fold:3 epoch:49 step:1 train loss:0.454652, train acc:86.307, train f1:85.188, train precision:86.947, train recall:85.154, train kappa:85.776
fold:3 epoch:49 step:2 train loss:0.455939, train acc:85.977, train f1:84.996, train precision:86.616, train recall:85.043, train kappa:85.423
fold:3 epoch:49 step:3 train loss:0.446114, train acc:86.334, train f1:85.491, train precision:87.027, train recall:85.475, train kappa:85.809
fold:3 epoch:49 step:4 train loss:0.461911, train acc:86.069, train f1:85.298, train precision:86.368, train recall:85.516, train kappa:85.543
fold:3 epoch:49 step:5 train loss:0.455485, train acc:86.176, train f1:85.302, train precision:86.273, train recall:85.573, train kappa:85.652
fold:3 epoch:49 step:6 train loss:0.456537, train acc:86.063, train f1:85.236, train precision:86.221, train recall:85.416, train kappa:85.523
fold:3 epoch:49 step:7 train loss:0.451919, train acc:86.166, train f1:85.404, train precision:86.467, train recall:85.634, train kappa:85.631
fold:3 epoch:49 step:8 train loss:0.465811, train acc:85.938, train f1:85.415, train precision:86.898, train recall:85.453, train kappa:85.404
fold:3 epoch:49 step:9 train loss:0.452708, train acc:86.389, train f1:85.522, train precision:87.059, train recall:85.714, train kappa:85.871
fold:3 epoch:49 step:10 train loss:0.456765, train acc:86.090, train f1:85.285, train precision:86.907, train recall:85.347, train kappa:85.559
fold:3 epoch:49 step:11 train loss:0.449707, train acc:86.440, train f1:85.375, train precision:86.709, train recall:85.617, train kappa:85.921
fold:3 epoch:49        valid loss:0.667532, valid acc:83.252, valid f1:60.433, valid precision:57.119, valid recall:70.705, valid kappa:81.138
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.34798699572659, 60.35482021341431, 57.43404272914873, 70.7103913747783, 81.24178348508883]
====================================================================================================
fold:3 epoch:50 step:0 train loss:0.447539, train acc:86.292, train f1:85.448, train precision:86.936, train recall:85.661, train kappa:85.776
fold:3 epoch:50 step:1 train loss:0.450626, train acc:86.313, train f1:85.281, train precision:86.140, train recall:85.626, train kappa:85.783
fold:3 epoch:50 step:2 train loss:0.450070, train acc:86.264, train f1:85.359, train precision:86.256, train recall:85.649, train kappa:85.744
fold:3 epoch:50 step:3 train loss:0.453207, train acc:86.255, train f1:85.402, train precision:86.452, train recall:85.673, train kappa:85.730
fold:3 epoch:50 step:4 train loss:0.446909, train acc:86.295, train f1:85.659, train precision:86.951, train recall:85.998, train kappa:85.769
fold:3 epoch:50 step:5 train loss:0.460599, train acc:86.014, train f1:85.092, train precision:86.554, train recall:85.361, train kappa:85.473
fold:3 epoch:50 step:6 train loss:0.455614, train acc:86.194, train f1:85.398, train precision:86.826, train recall:85.473, train kappa:85.663
fold:3 epoch:50 step:7 train loss:0.456448, train acc:86.090, train f1:85.079, train precision:86.800, train recall:85.095, train kappa:85.549
fold:3 epoch:50 step:8 train loss:0.447890, train acc:86.374, train f1:85.390, train precision:87.077, train recall:85.488, train kappa:85.854
fold:3 epoch:50 step:9 train loss:0.452743, train acc:86.212, train f1:85.195, train precision:86.525, train recall:85.316, train kappa:85.688
fold:3 epoch:50 step:10 train loss:0.440757, train acc:86.560, train f1:85.622, train precision:86.875, train recall:85.776, train kappa:86.034
fold:3 epoch:50 step:11 train loss:0.455479, train acc:86.150, train f1:85.599, train precision:86.831, train recall:85.869, train kappa:85.629
fold:3 epoch:50        valid loss:0.665382, valid acc:83.213, valid f1:60.230, valid precision:57.006, valid recall:70.694, valid kappa:81.096
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.34798699572659, 60.35482021341431, 57.43404272914873, 70.7103913747783, 81.24178348508883]
====================================================================================================
fold:3 epoch:51 step:0 train loss:0.437322, train acc:86.700, train f1:85.774, train precision:87.065, train recall:85.889, train kappa:86.201
fold:3 epoch:51 step:1 train loss:0.452500, train acc:86.261, train f1:85.382, train precision:86.849, train recall:85.485, train kappa:85.727
fold:3 epoch:51 step:2 train loss:0.451179, train acc:86.304, train f1:85.278, train precision:86.819, train recall:85.388, train kappa:85.772
fold:3 epoch:51 step:3 train loss:0.444272, train acc:86.600, train f1:85.686, train precision:87.276, train recall:85.637, train kappa:86.075
fold:3 epoch:51 step:4 train loss:0.449068, train acc:86.343, train f1:85.610, train precision:86.899, train recall:85.673, train kappa:85.820
fold:3 epoch:51 step:5 train loss:0.443279, train acc:86.661, train f1:85.722, train precision:86.878, train recall:85.958, train kappa:86.165
fold:3 epoch:51 step:6 train loss:0.454496, train acc:86.133, train f1:85.419, train precision:86.434, train recall:85.702, train kappa:85.602
fold:3 epoch:51 step:7 train loss:0.448764, train acc:86.340, train f1:85.769, train precision:86.569, train recall:86.113, train kappa:85.825
fold:3 epoch:51 step:8 train loss:0.443235, train acc:86.581, train f1:85.715, train precision:86.720, train recall:86.042, train kappa:86.072
fold:3 epoch:51 step:9 train loss:0.450153, train acc:86.349, train f1:85.548, train precision:86.906, train recall:85.747, train kappa:85.820
fold:3 epoch:51 step:10 train loss:0.445395, train acc:86.551, train f1:85.872, train precision:87.200, train recall:85.940, train kappa:86.026
fold:3 epoch:51 step:11 train loss:0.472982, train acc:85.774, train f1:85.043, train precision:86.557, train recall:85.370, train kappa:85.233
fold:3 epoch:51        valid loss:0.659833, valid acc:83.577, valid f1:60.859, valid precision:57.889, valid recall:70.692, valid kappa:81.494
[1;31mTest score increased (83.347987 --> 83.576993).[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:52 step:0 train loss:0.447689, train acc:86.243, train f1:85.559, train precision:87.197, train recall:85.543, train kappa:85.710
fold:3 epoch:52 step:1 train loss:0.446724, train acc:86.523, train f1:85.609, train precision:87.088, train recall:85.738, train kappa:86.003
fold:3 epoch:52 step:2 train loss:0.442292, train acc:86.426, train f1:85.585, train precision:86.556, train recall:85.774, train kappa:85.911
fold:3 epoch:52 step:3 train loss:0.442542, train acc:86.703, train f1:85.899, train precision:87.026, train recall:86.088, train kappa:86.195
fold:3 epoch:52 step:4 train loss:0.442223, train acc:86.548, train f1:85.782, train precision:87.241, train recall:85.953, train kappa:86.036
fold:3 epoch:52 step:5 train loss:0.438348, train acc:86.938, train f1:85.948, train precision:87.496, train recall:86.120, train kappa:86.440
fold:3 epoch:52 step:6 train loss:0.443947, train acc:86.438, train f1:85.506, train precision:87.133, train recall:85.659, train kappa:85.913
fold:3 epoch:52 step:7 train loss:0.440310, train acc:86.612, train f1:85.822, train precision:87.381, train recall:85.944, train kappa:86.107
fold:3 epoch:52 step:8 train loss:0.455562, train acc:86.197, train f1:85.452, train precision:86.898, train recall:85.579, train kappa:85.665
fold:3 epoch:52 step:9 train loss:0.448274, train acc:86.365, train f1:85.418, train precision:86.494, train recall:85.835, train kappa:85.844
fold:3 epoch:52 step:10 train loss:0.435633, train acc:86.661, train f1:85.591, train precision:87.030, train recall:85.788, train kappa:86.141
fold:3 epoch:52 step:11 train loss:0.451470, train acc:85.803, train f1:85.162, train precision:86.666, train recall:85.467, train kappa:85.250
fold:3 epoch:52        valid loss:0.665793, valid acc:83.446, valid f1:60.432, valid precision:57.239, valid recall:70.724, valid kappa:81.353
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:53 step:0 train loss:0.433102, train acc:86.575, train f1:85.500, train precision:86.956, train recall:85.621, train kappa:86.055
fold:3 epoch:53 step:1 train loss:0.437917, train acc:86.786, train f1:85.974, train precision:87.338, train recall:86.072, train kappa:86.273
fold:3 epoch:53 step:2 train loss:0.441362, train acc:86.554, train f1:85.660, train precision:86.989, train recall:85.779, train kappa:86.020
fold:3 epoch:53 step:3 train loss:0.432990, train acc:86.847, train f1:85.945, train precision:87.405, train recall:85.973, train kappa:86.349
fold:3 epoch:53 step:4 train loss:0.442434, train acc:86.600, train f1:85.825, train precision:87.258, train recall:85.904, train kappa:86.095
fold:3 epoch:53 step:5 train loss:0.449882, train acc:86.392, train f1:85.592, train precision:86.847, train recall:85.742, train kappa:85.875
fold:3 epoch:53 step:6 train loss:0.435986, train acc:86.630, train f1:85.945, train precision:87.048, train recall:86.240, train kappa:86.122
fold:3 epoch:53 step:7 train loss:0.444451, train acc:86.264, train f1:85.370, train precision:86.503, train recall:85.628, train kappa:85.751
fold:3 epoch:53 step:8 train loss:0.435828, train acc:86.655, train f1:85.861, train precision:86.916, train recall:86.078, train kappa:86.137
fold:3 epoch:53 step:9 train loss:0.443549, train acc:86.481, train f1:85.606, train precision:86.447, train recall:86.080, train kappa:85.969
fold:3 epoch:53 step:10 train loss:0.441650, train acc:86.481, train f1:85.671, train precision:87.032, train recall:85.901, train kappa:85.960
fold:3 epoch:53 step:11 train loss:0.446965, train acc:86.526, train f1:85.575, train precision:87.196, train recall:85.612, train kappa:86.023
fold:3 epoch:53        valid loss:0.663148, valid acc:83.514, valid f1:60.687, valid precision:57.624, valid recall:70.584, valid kappa:81.422
[1;31mEarlyStopping counter: 2 out of 50[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:54 step:0 train loss:0.431214, train acc:86.807, train f1:85.957, train precision:87.268, train recall:85.961, train kappa:86.304
fold:3 epoch:54 step:1 train loss:0.425593, train acc:86.975, train f1:85.968, train precision:87.321, train recall:85.895, train kappa:86.477
fold:3 epoch:54 step:2 train loss:0.433826, train acc:86.685, train f1:85.989, train precision:87.339, train recall:86.020, train kappa:86.175
fold:3 epoch:54 step:3 train loss:0.435913, train acc:86.523, train f1:85.797, train precision:86.944, train recall:86.135, train kappa:86.005
fold:3 epoch:54 step:4 train loss:0.443848, train acc:86.655, train f1:85.853, train precision:86.846, train recall:86.069, train kappa:86.146
fold:3 epoch:54 step:5 train loss:0.430171, train acc:86.981, train f1:86.154, train precision:87.393, train recall:86.413, train kappa:86.486
fold:3 epoch:54 step:6 train loss:0.434686, train acc:86.661, train f1:85.845, train precision:87.343, train recall:86.053, train kappa:86.141
fold:3 epoch:54 step:7 train loss:0.441195, train acc:86.371, train f1:85.437, train precision:86.924, train recall:85.613, train kappa:85.849
fold:3 epoch:54 step:8 train loss:0.448082, train acc:86.218, train f1:85.341, train precision:86.915, train recall:85.423, train kappa:85.693
fold:3 epoch:54 step:9 train loss:0.431826, train acc:86.597, train f1:85.572, train precision:87.040, train recall:85.665, train kappa:86.085
fold:3 epoch:54 step:10 train loss:0.436953, train acc:86.569, train f1:85.774, train precision:87.077, train recall:85.923, train kappa:86.050
fold:3 epoch:54 step:11 train loss:0.441209, train acc:86.584, train f1:85.639, train precision:86.492, train recall:85.945, train kappa:86.048
fold:3 epoch:54        valid loss:0.664984, valid acc:83.446, valid f1:60.934, valid precision:57.680, valid recall:70.712, valid kappa:81.354
[1;31mEarlyStopping counter: 3 out of 50[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:55 step:0 train loss:0.429002, train acc:86.774, train f1:85.972, train precision:86.909, train recall:86.137, train kappa:86.273
fold:3 epoch:55 step:1 train loss:0.434510, train acc:86.740, train f1:86.025, train precision:87.129, train recall:86.212, train kappa:86.226
fold:3 epoch:55 step:2 train loss:0.415915, train acc:87.122, train f1:86.236, train precision:87.371, train recall:86.481, train kappa:86.628
fold:3 epoch:55 step:3 train loss:0.427499, train acc:86.981, train f1:86.181, train precision:87.674, train recall:86.212, train kappa:86.484
fold:3 epoch:55 step:4 train loss:0.443869, train acc:86.594, train f1:85.878, train precision:87.487, train recall:85.875, train kappa:86.082
fold:3 epoch:55 step:5 train loss:0.436816, train acc:86.752, train f1:86.076, train precision:87.379, train recall:86.226, train kappa:86.252
fold:3 epoch:55 step:6 train loss:0.430316, train acc:86.749, train f1:85.819, train precision:86.984, train recall:86.203, train kappa:86.236
fold:3 epoch:55 step:7 train loss:0.436635, train acc:86.526, train f1:85.716, train precision:86.777, train recall:85.869, train kappa:86.010
fold:3 epoch:55 step:8 train loss:0.442544, train acc:86.432, train f1:85.789, train precision:87.013, train recall:85.942, train kappa:85.917
fold:3 epoch:55 step:9 train loss:0.438187, train acc:86.591, train f1:85.670, train precision:86.740, train recall:85.981, train kappa:86.077
fold:3 epoch:55 step:10 train loss:0.433514, train acc:86.606, train f1:85.909, train precision:87.006, train recall:86.094, train kappa:86.093
fold:3 epoch:55 step:11 train loss:0.428770, train acc:86.884, train f1:85.959, train precision:87.338, train recall:85.995, train kappa:86.376
fold:3 epoch:55        valid loss:0.664917, valid acc:83.522, valid f1:60.810, valid precision:57.526, valid recall:70.721, valid kappa:81.433
[1;31mEarlyStopping counter: 4 out of 50[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:56 step:0 train loss:0.432521, train acc:86.990, train f1:86.290, train precision:87.573, train recall:86.424, train kappa:86.497
fold:3 epoch:56 step:1 train loss:0.420429, train acc:86.902, train f1:86.083, train precision:87.408, train recall:86.229, train kappa:86.389
fold:3 epoch:56 step:2 train loss:0.427029, train acc:86.816, train f1:85.943, train precision:86.989, train recall:86.155, train kappa:86.315
fold:3 epoch:56 step:3 train loss:0.425759, train acc:86.826, train f1:86.202, train precision:87.329, train recall:86.386, train kappa:86.329
fold:3 epoch:56 step:4 train loss:0.425006, train acc:86.893, train f1:85.861, train precision:86.805, train recall:86.179, train kappa:86.379
fold:3 epoch:56 step:5 train loss:0.433452, train acc:86.566, train f1:85.673, train precision:87.034, train recall:85.793, train kappa:86.057
fold:3 epoch:56 step:6 train loss:0.436552, train acc:86.636, train f1:85.949, train precision:87.712, train recall:85.996, train kappa:86.134
fold:3 epoch:56 step:7 train loss:0.416544, train acc:87.317, train f1:86.272, train precision:87.837, train recall:86.226, train kappa:86.826
fold:3 epoch:56 step:8 train loss:0.432048, train acc:86.676, train f1:85.912, train precision:87.075, train recall:86.148, train kappa:86.165
fold:3 epoch:56 step:9 train loss:0.430388, train acc:86.710, train f1:86.059, train precision:87.400, train recall:86.166, train kappa:86.199
fold:3 epoch:56 step:10 train loss:0.436393, train acc:86.581, train f1:85.815, train precision:87.053, train recall:85.875, train kappa:86.065
fold:3 epoch:56 step:11 train loss:0.442292, train acc:86.526, train f1:85.955, train precision:86.665, train recall:86.464, train kappa:86.012
fold:3 epoch:56        valid loss:0.664176, valid acc:83.524, valid f1:61.030, valid precision:57.435, valid recall:70.866, valid kappa:81.447
[1;31mEarlyStopping counter: 5 out of 50[0m
[83.5769930684769, 60.859491078493775, 57.88866387045891, 70.69227244463255, 81.49391007517298]
====================================================================================================
fold:3 epoch:57 step:0 train loss:0.427738, train acc:86.911, train f1:86.089, train precision:87.052, train recall:86.268, train kappa:86.405
fold:3 epoch:57 step:1 train loss:0.430168, train acc:86.691, train f1:86.058, train precision:86.958, train recall:86.349, train kappa:86.190
fold:3 epoch:57 step:2 train loss:0.428541, train acc:86.880, train f1:86.243, train precision:87.558, train recall:86.258, train kappa:86.371
fold:3 epoch:57 step:3 train loss:0.429631, train acc:86.661, train f1:85.843, train precision:87.236, train recall:85.774, train kappa:86.159
fold:3 epoch:57 step:4 train loss:0.422607, train acc:87.006, train f1:86.250, train precision:87.898, train recall:86.258, train kappa:86.515
fold:3 epoch:57 step:5 train loss:0.423449, train acc:86.755, train f1:86.041, train precision:87.226, train recall:86.232, train kappa:86.251
fold:3 epoch:57 step:6 train loss:0.421178, train acc:87.180, train f1:86.182, train precision:87.302, train recall:86.407, train kappa:86.686
fold:3 epoch:57 step:7 train loss:0.428244, train acc:86.850, train f1:86.102, train precision:87.268, train recall:86.185, train kappa:86.350
fold:3 epoch:57 step:8 train loss:0.426442, train acc:86.887, train f1:85.884, train precision:86.846, train recall:86.412, train kappa:86.384
fold:3 epoch:57 step:9 train loss:0.419185, train acc:87.173, train f1:86.281, train precision:87.415, train recall:86.628, train kappa:86.677
fold:3 epoch:57 step:10 train loss:0.428831, train acc:87.018, train f1:86.192, train precision:87.437, train recall:86.394, train kappa:86.518
fold:3 epoch:57 step:11 train loss:0.449581, train acc:85.899, train f1:85.109, train precision:87.006, train recall:85.037, train kappa:85.355
fold:3 epoch:57        valid loss:0.658030, valid acc:83.743, valid f1:61.069, valid precision:57.993, valid recall:70.878, valid kappa:81.685
[1;31mTest score increased (83.576993 --> 83.742614).[0m
[83.74261353180526, 61.0690329584754, 57.99270539266412, 70.87760640369378, 81.6846974869351]
====================================================================================================
fold:3 epoch:58 step:0 train loss:0.431100, train acc:86.621, train f1:86.148, train precision:87.753, train recall:86.102, train kappa:86.119
fold:3 epoch:58 step:1 train loss:0.418856, train acc:87.146, train f1:86.294, train precision:87.557, train recall:86.325, train kappa:86.652
fold:3 epoch:58 step:2 train loss:0.421661, train acc:86.868, train f1:86.047, train precision:87.125, train recall:86.111, train kappa:86.359
fold:3 epoch:58 step:3 train loss:0.415870, train acc:87.274, train f1:86.504, train precision:87.524, train recall:86.661, train kappa:86.782
fold:3 epoch:58 step:4 train loss:0.423451, train acc:86.963, train f1:86.363, train precision:87.354, train recall:86.601, train kappa:86.471
fold:3 epoch:58 step:5 train loss:0.430274, train acc:86.801, train f1:85.875, train precision:86.678, train recall:86.321, train kappa:86.302
fold:3 epoch:58 step:6 train loss:0.424681, train acc:86.996, train f1:86.282, train precision:87.445, train recall:86.482, train kappa:86.494
fold:3 epoch:58 step:7 train loss:0.420626, train acc:86.917, train f1:85.875, train precision:87.320, train recall:85.922, train kappa:86.411
fold:3 epoch:58 step:8 train loss:0.417593, train acc:87.146, train f1:86.203, train precision:87.460, train recall:86.479, train kappa:86.652
fold:3 epoch:58 step:9 train loss:0.425986, train acc:86.963, train f1:86.216, train precision:87.450, train recall:86.406, train kappa:86.468
fold:3 epoch:58 step:10 train loss:0.424192, train acc:86.981, train f1:86.096, train precision:87.517, train recall:86.057, train kappa:86.484
fold:3 epoch:58 step:11 train loss:0.438666, train acc:86.449, train f1:85.608, train precision:86.743, train recall:85.832, train kappa:85.940
fold:3 epoch:58        valid loss:0.665089, valid acc:83.432, valid f1:60.893, valid precision:57.280, valid recall:71.123, valid kappa:81.357
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.74261353180526, 61.0690329584754, 57.99270539266412, 70.87760640369378, 81.6846974869351]
====================================================================================================
fold:3 epoch:59 step:0 train loss:0.415732, train acc:87.103, train f1:86.321, train precision:86.949, train recall:86.726, train kappa:86.631
fold:3 epoch:59 step:1 train loss:0.422198, train acc:87.009, train f1:86.484, train precision:86.960, train recall:86.880, train kappa:86.516
fold:3 epoch:59 step:2 train loss:0.421518, train acc:87.073, train f1:86.183, train precision:86.979, train recall:86.498, train kappa:86.576
fold:3 epoch:59 step:3 train loss:0.415735, train acc:87.048, train f1:86.524, train precision:87.902, train recall:86.627, train kappa:86.564
fold:3 epoch:59 step:4 train loss:0.422777, train acc:87.241, train f1:86.390, train precision:88.083, train recall:86.324, train kappa:86.762
fold:3 epoch:59 step:5 train loss:0.406056, train acc:87.497, train f1:86.677, train precision:88.085, train recall:86.712, train kappa:87.030
fold:3 epoch:59 step:6 train loss:0.423598, train acc:86.978, train f1:86.503, train precision:87.820, train recall:86.494, train kappa:86.480
fold:3 epoch:59 step:7 train loss:0.419042, train acc:87.170, train f1:86.427, train precision:87.789, train recall:86.590, train kappa:86.674
fold:3 epoch:59 step:8 train loss:0.413401, train acc:87.231, train f1:86.288, train precision:87.444, train recall:86.594, train kappa:86.737
fold:3 epoch:59 step:9 train loss:0.419349, train acc:87.238, train f1:86.321, train precision:87.226, train recall:86.646, train kappa:86.743
fold:3 epoch:59 step:10 train loss:0.425165, train acc:86.954, train f1:86.078, train precision:86.957, train recall:86.466, train kappa:86.448
fold:3 epoch:59 step:11 train loss:0.403296, train acc:87.559, train f1:86.205, train precision:87.121, train recall:86.528, train kappa:87.070
fold:3 epoch:59        valid loss:0.658589, valid acc:83.751, valid f1:60.954, valid precision:57.686, valid recall:70.835, valid kappa:81.694
[1;31mTest score increased (83.742614 --> 83.750792).[0m
[83.75079232011777, 60.95426996068895, 57.68609987053031, 70.83507899561928, 81.6936111212077]
====================================================================================================
fold:3 epoch:60 step:0 train loss:0.421404, train acc:86.981, train f1:86.059, train precision:87.204, train recall:86.217, train kappa:86.479
fold:3 epoch:60 step:1 train loss:0.422897, train acc:87.119, train f1:86.447, train precision:88.103, train recall:86.471, train kappa:86.625
fold:3 epoch:60 step:2 train loss:0.414776, train acc:87.076, train f1:86.316, train precision:87.686, train recall:86.283, train kappa:86.575
fold:3 epoch:60 step:3 train loss:0.400847, train acc:87.671, train f1:86.746, train precision:87.995, train recall:86.827, train kappa:87.196
fold:3 epoch:60 step:4 train loss:0.407674, train acc:87.311, train f1:86.578, train precision:87.797, train recall:86.720, train kappa:86.829
fold:3 epoch:60 step:5 train loss:0.415646, train acc:87.286, train f1:86.444, train precision:87.485, train recall:86.718, train kappa:86.807
fold:3 epoch:60 step:6 train loss:0.416773, train acc:87.259, train f1:86.558, train precision:87.632, train recall:86.845, train kappa:86.779
fold:3 epoch:60 step:7 train loss:0.412988, train acc:87.280, train f1:86.681, train precision:87.746, train recall:86.817, train kappa:86.797
fold:3 epoch:60 step:8 train loss:0.420952, train acc:86.966, train f1:86.111, train precision:87.151, train recall:86.333, train kappa:86.457
fold:3 epoch:60 step:9 train loss:0.418101, train acc:87.140, train f1:86.207, train precision:87.305, train recall:86.452, train kappa:86.658
fold:3 epoch:60 step:10 train loss:0.412072, train acc:87.155, train f1:86.314, train precision:87.514, train recall:86.390, train kappa:86.663
fold:3 epoch:60 step:11 train loss:0.421947, train acc:87.077, train f1:86.268, train precision:87.631, train recall:86.397, train kappa:86.567
fold:3 epoch:60        valid loss:0.667116, valid acc:83.649, valid f1:61.081, valid precision:57.400, valid recall:71.010, valid kappa:81.592
[1;31mEarlyStopping counter: 1 out of 50[0m
[83.75079232011777, 60.95426996068895, 57.68609987053031, 70.83507899561928, 81.6936111212077]
====================================================================================================
fold:3 epoch:61 step:0 train loss:0.404551, train acc:87.491, train f1:86.517, train precision:87.347, train recall:86.802, train kappa:87.020
fold:3 epoch:61 step:1 train loss:0.417993, train acc:87.128, train f1:86.606, train precision:87.563, train recall:86.848, train kappa:86.641
fold:3 epoch:61 step:2 train loss:0.416200, train acc:87.021, train f1:86.375, train precision:87.297, train recall:86.662, train kappa:86.533
fold:3 epoch:61 step:3 train loss:0.412845, train acc:87.189, train f1:86.464, train precision:87.401, train recall:86.576, train kappa:86.701
fold:3 epoch:61 step:4 train loss:0.401599, train acc:87.488, train f1:86.529, train precision:87.385, train recall:86.795, train kappa:87.004
fold:3 epoch:61 step:5 train loss:0.419043, train acc:86.960, train f1:86.445, train precision:87.584, train recall:86.574, train kappa:86.452
fold:3 epoch:61 step:6 train loss:0.415573, train acc:87.332, train f1:86.603, train precision:87.797, train recall:86.735, train kappa:86.843
fold:3 epoch:61 step:7 train loss:0.412684, train acc:87.231, train f1:86.167, train precision:87.580, train recall:86.158, train kappa:86.733
fold:3 epoch:61 step:8 train loss:0.415175, train acc:87.167, train f1:86.567, train precision:88.025, train recall:86.567, train kappa:86.686
fold:3 epoch:61 step:9 train loss:0.419743, train acc:86.826, train f1:86.164, train precision:87.447, train recall:86.325, train kappa:86.318
fold:3 epoch:61 step:10 train loss:0.413092, train acc:87.473, train f1:86.573, train precision:87.723, train recall:86.745, train kappa:87.004
fold:3 epoch:61 step:11 train loss:0.392391, train acc:88.061, train f1:87.388, train precision:88.422, train recall:87.413, train kappa:87.614
fold:3 epoch:61        valid loss:0.661789, valid acc:83.800, valid f1:61.353, valid precision:58.037, valid recall:70.928, valid kappa:81.753
[1;31mTest score increased (83.750792 --> 83.799865).[0m
[83.79986504999283, 61.35284179148701, 58.03657448161591, 70.92810691683347, 81.7533728145748]
====================================================================================================
fold:3 epoch:62 step:0 train loss:0.413087, train acc:87.314, train f1:86.369, train precision:87.274, train recall:86.722, train kappa:86.817
fold:3 epoch:62 step:1 train loss:0.414520, train acc:87.161, train f1:86.196, train precision:87.398, train recall:86.516, train kappa:86.670
fold:3 epoch:62 step:2 train loss:0.401953, train acc:87.479, train f1:86.753, train precision:88.173, train recall:86.973, train kappa:87.001
fold:3 epoch:62 step:3 train loss:0.408435, train acc:87.460, train f1:86.909, train precision:88.223, train recall:87.019, train kappa:86.989
fold:3 epoch:62 step:4 train loss:0.416451, train acc:87.134, train f1:86.234, train precision:87.564, train recall:86.472, train kappa:86.644
fold:3 epoch:62 step:5 train loss:0.401474, train acc:87.537, train f1:86.771, train precision:88.117, train recall:86.821, train kappa:87.062
fold:3 epoch:62 step:6 train loss:0.420358, train acc:86.893, train f1:86.347, train precision:87.202, train recall:86.614, train kappa:86.404
fold:3 epoch:62 step:7 train loss:0.406865, train acc:87.457, train f1:86.725, train precision:87.705, train recall:86.940, train kappa:86.981
fold:3 epoch:62 step:8 train loss:0.408212, train acc:87.256, train f1:86.337, train precision:86.970, train recall:86.663, train kappa:86.773
fold:3 epoch:62 step:9 train loss:0.417060, train acc:87.161, train f1:86.460, train precision:87.256, train recall:86.774, train kappa:86.665
fold:3 epoch:62 step:10 train loss:0.408064, train acc:87.347, train f1:86.671, train precision:88.025, train recall:86.624, train kappa:86.863
fold:3 epoch:62 step:11 train loss:0.397969, train acc:87.665, train f1:86.823, train precision:88.494, train recall:86.780, train kappa:87.198
fold:3 epoch:62        valid loss:0.655746, valid acc:84.051, valid f1:61.694, valid precision:58.597, valid recall:70.721, valid kappa:82.024
[1;31mTest score increased (83.799865 --> 84.051363).[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:63 step:0 train loss:0.399535, train acc:87.671, train f1:87.109, train precision:88.619, train recall:87.034, train kappa:87.193
fold:3 epoch:63 step:1 train loss:0.395870, train acc:87.680, train f1:86.782, train precision:87.941, train recall:86.926, train kappa:87.212
fold:3 epoch:63 step:2 train loss:0.405426, train acc:87.607, train f1:86.595, train precision:87.829, train recall:86.731, train kappa:87.129
fold:3 epoch:63 step:3 train loss:0.404610, train acc:87.341, train f1:86.583, train precision:87.615, train recall:86.742, train kappa:86.860
fold:3 epoch:63 step:4 train loss:0.415312, train acc:87.039, train f1:86.238, train precision:87.282, train recall:86.514, train kappa:86.555
fold:3 epoch:63 step:5 train loss:0.407238, train acc:87.448, train f1:86.593, train precision:87.518, train recall:86.821, train kappa:86.978
fold:3 epoch:63 step:6 train loss:0.407645, train acc:87.363, train f1:86.647, train precision:87.385, train recall:86.934, train kappa:86.878
fold:3 epoch:63 step:7 train loss:0.412514, train acc:87.231, train f1:86.814, train precision:88.093, train recall:86.985, train kappa:86.748
fold:3 epoch:63 step:8 train loss:0.412349, train acc:87.259, train f1:86.406, train precision:87.603, train recall:86.502, train kappa:86.767
fold:3 epoch:63 step:9 train loss:0.418058, train acc:86.932, train f1:86.214, train precision:87.586, train recall:86.211, train kappa:86.433
fold:3 epoch:63 step:10 train loss:0.399326, train acc:87.631, train f1:86.647, train precision:87.841, train recall:86.750, train kappa:87.150
fold:3 epoch:63 step:11 train loss:0.419774, train acc:87.105, train f1:86.667, train precision:87.718, train recall:86.954, train kappa:86.621
fold:3 epoch:63        valid loss:0.666101, valid acc:83.642, valid f1:61.365, valid precision:57.965, valid recall:70.742, valid kappa:81.587
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:64 step:0 train loss:0.402680, train acc:87.305, train f1:86.541, train precision:87.575, train recall:86.783, train kappa:86.821
fold:3 epoch:64 step:1 train loss:0.405052, train acc:87.476, train f1:86.762, train precision:87.619, train recall:86.987, train kappa:87.002
fold:3 epoch:64 step:2 train loss:0.406970, train acc:87.375, train f1:86.637, train precision:87.539, train recall:86.786, train kappa:86.903
fold:3 epoch:64 step:3 train loss:0.410234, train acc:87.173, train f1:86.273, train precision:87.363, train recall:86.428, train kappa:86.680
fold:3 epoch:64 step:4 train loss:0.410016, train acc:87.427, train f1:86.791, train precision:88.269, train recall:86.836, train kappa:86.937
fold:3 epoch:64 step:5 train loss:0.397579, train acc:87.445, train f1:86.468, train precision:87.930, train recall:86.424, train kappa:86.970
fold:3 epoch:64 step:6 train loss:0.409877, train acc:87.381, train f1:86.844, train precision:87.847, train recall:87.050, train kappa:86.910
fold:3 epoch:64 step:7 train loss:0.392084, train acc:87.762, train f1:86.901, train precision:87.976, train recall:87.088, train kappa:87.294
fold:3 epoch:64 step:8 train loss:0.401552, train acc:87.631, train f1:86.874, train precision:87.943, train recall:87.145, train kappa:87.157
fold:3 epoch:64 step:9 train loss:0.404722, train acc:87.433, train f1:86.665, train precision:87.526, train recall:86.841, train kappa:86.942
fold:3 epoch:64 step:10 train loss:0.399471, train acc:87.677, train f1:87.023, train precision:87.949, train recall:87.139, train kappa:87.212
fold:3 epoch:64 step:11 train loss:0.420451, train acc:87.028, train f1:86.584, train precision:87.682, train recall:86.909, train kappa:86.535
fold:3 epoch:64        valid loss:0.661113, valid acc:83.814, valid f1:61.590, valid precision:58.383, valid recall:70.894, valid kappa:81.767
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:65 step:0 train loss:0.404782, train acc:87.421, train f1:86.843, train precision:88.250, train recall:87.056, train kappa:86.944
fold:3 epoch:65 step:1 train loss:0.402016, train acc:87.634, train f1:86.868, train precision:87.926, train recall:86.972, train kappa:87.158
fold:3 epoch:65 step:2 train loss:0.399807, train acc:87.494, train f1:86.604, train precision:87.999, train recall:86.567, train kappa:87.017
fold:3 epoch:65 step:3 train loss:0.396732, train acc:87.589, train f1:86.604, train precision:88.044, train recall:86.669, train kappa:87.107
fold:3 epoch:65 step:4 train loss:0.400380, train acc:87.564, train f1:86.806, train precision:88.030, train recall:86.842, train kappa:87.092
fold:3 epoch:65 step:5 train loss:0.405080, train acc:87.466, train f1:86.594, train precision:87.427, train recall:86.999, train kappa:87.005
fold:3 epoch:65 step:6 train loss:0.406410, train acc:87.311, train f1:86.641, train precision:87.360, train recall:86.947, train kappa:86.832
fold:3 epoch:65 step:7 train loss:0.400335, train acc:87.643, train f1:87.066, train precision:87.923, train recall:87.404, train kappa:87.177
fold:3 epoch:65 step:8 train loss:0.401188, train acc:87.698, train f1:86.805, train precision:87.682, train recall:87.022, train kappa:87.233
fold:3 epoch:65 step:9 train loss:0.406598, train acc:87.494, train f1:86.900, train precision:88.062, train recall:86.985, train kappa:87.021
fold:3 epoch:65 step:10 train loss:0.399091, train acc:87.515, train f1:86.676, train precision:87.587, train recall:86.787, train kappa:87.021
fold:3 epoch:65 step:11 train loss:0.410227, train acc:87.192, train f1:86.225, train precision:87.834, train recall:86.304, train kappa:86.690
fold:3 epoch:65        valid loss:0.661596, valid acc:84.008, valid f1:61.264, valid precision:58.062, valid recall:70.566, valid kappa:81.986
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:66 step:0 train loss:0.386849, train acc:87.885, train f1:86.961, train precision:88.115, train recall:87.121, train kappa:87.422
fold:3 epoch:66 step:1 train loss:0.405768, train acc:87.280, train f1:86.611, train precision:87.767, train recall:86.742, train kappa:86.799
fold:3 epoch:66 step:2 train loss:0.406996, train acc:87.436, train f1:86.931, train precision:87.884, train recall:87.087, train kappa:86.957
fold:3 epoch:66 step:3 train loss:0.388296, train acc:88.022, train f1:87.082, train precision:88.057, train recall:87.324, train kappa:87.558
fold:3 epoch:66 step:4 train loss:0.394200, train acc:87.558, train f1:86.855, train precision:87.828, train recall:87.032, train kappa:87.091
fold:3 epoch:66 step:5 train loss:0.397676, train acc:87.732, train f1:87.019, train precision:87.901, train recall:87.258, train kappa:87.263
fold:3 epoch:66 step:6 train loss:0.395156, train acc:87.674, train f1:86.857, train precision:87.787, train recall:87.088, train kappa:87.205
fold:3 epoch:66 step:7 train loss:0.399573, train acc:87.454, train f1:86.764, train precision:87.826, train recall:86.864, train kappa:86.976
fold:3 epoch:66 step:8 train loss:0.402259, train acc:87.552, train f1:86.672, train precision:87.804, train recall:86.837, train kappa:87.091
fold:3 epoch:66 step:9 train loss:0.404505, train acc:87.250, train f1:86.432, train precision:87.430, train recall:86.679, train kappa:86.756
fold:3 epoch:66 step:10 train loss:0.409576, train acc:87.494, train f1:86.881, train precision:87.669, train recall:87.287, train kappa:87.026
fold:3 epoch:66 step:11 train loss:0.392403, train acc:87.993, train f1:87.190, train precision:88.318, train recall:87.498, train kappa:87.524
fold:3 epoch:66        valid loss:0.664379, valid acc:83.861, valid f1:61.356, valid precision:57.953, valid recall:70.811, valid kappa:81.826
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:67 step:0 train loss:0.395742, train acc:87.634, train f1:87.078, train precision:88.165, train recall:87.257, train kappa:87.158
fold:3 epoch:67 step:1 train loss:0.383312, train acc:88.089, train f1:87.165, train precision:88.230, train recall:87.386, train kappa:87.635
fold:3 epoch:67 step:2 train loss:0.391444, train acc:87.790, train f1:87.022, train precision:88.031, train recall:87.221, train kappa:87.324
fold:3 epoch:67 step:3 train loss:0.392557, train acc:87.656, train f1:86.983, train precision:88.107, train recall:87.092, train kappa:87.189
fold:3 epoch:67 step:4 train loss:0.400844, train acc:87.595, train f1:86.833, train precision:88.032, train recall:86.795, train kappa:87.125
fold:3 epoch:67 step:5 train loss:0.388442, train acc:87.881, train f1:87.156, train precision:88.294, train recall:87.139, train kappa:87.419
fold:3 epoch:67 step:6 train loss:0.398868, train acc:87.350, train f1:86.628, train precision:87.531, train recall:86.691, train kappa:86.875
fold:3 epoch:67 step:7 train loss:0.395204, train acc:87.823, train f1:86.969, train precision:88.018, train recall:87.068, train kappa:87.357
fold:3 epoch:67 step:8 train loss:0.399663, train acc:87.680, train f1:86.944, train precision:87.810, train recall:87.197, train kappa:87.208
fold:3 epoch:67 step:9 train loss:0.396574, train acc:87.579, train f1:86.666, train precision:87.604, train recall:86.915, train kappa:87.109
fold:3 epoch:67 step:10 train loss:0.399837, train acc:87.671, train f1:87.047, train precision:88.101, train recall:87.302, train kappa:87.204
fold:3 epoch:67 step:11 train loss:0.391698, train acc:87.742, train f1:86.861, train precision:88.002, train recall:87.117, train kappa:87.259
fold:3 epoch:67        valid loss:0.665640, valid acc:83.839, valid f1:61.173, valid precision:57.935, valid recall:70.562, valid kappa:81.792
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.05136279060257, 61.69439021633654, 58.596791962989144, 70.72103254307838, 82.02423534078696]
====================================================================================================
fold:3 epoch:68 step:0 train loss:0.391439, train acc:87.723, train f1:87.143, train precision:88.258, train recall:87.306, train kappa:87.272
fold:3 epoch:68 step:1 train loss:0.390713, train acc:87.936, train f1:87.108, train precision:88.283, train recall:87.320, train kappa:87.472
fold:3 epoch:68 step:2 train loss:0.395058, train acc:87.671, train f1:87.062, train precision:88.363, train recall:87.169, train kappa:87.205
fold:3 epoch:68 step:3 train loss:0.392800, train acc:87.683, train f1:86.852, train precision:87.877, train recall:86.895, train kappa:87.223
fold:3 epoch:68 step:4 train loss:0.390747, train acc:88.010, train f1:87.182, train precision:88.483, train recall:87.218, train kappa:87.543
fold:3 epoch:68 step:5 train loss:0.390175, train acc:87.906, train f1:87.330, train precision:88.251, train recall:87.503, train kappa:87.444
fold:3 epoch:68 step:6 train loss:0.398128, train acc:87.466, train f1:86.804, train precision:87.708, train recall:87.035, train kappa:86.985
fold:3 epoch:68 step:7 train loss:0.387885, train acc:87.881, train f1:87.219, train precision:88.217, train recall:87.340, train kappa:87.422
fold:3 epoch:68 step:8 train loss:0.390051, train acc:87.527, train f1:86.828, train precision:87.659, train recall:87.005, train kappa:87.052
fold:3 epoch:68 step:9 train loss:0.401254, train acc:87.534, train f1:86.849, train precision:87.962, train recall:87.056, train kappa:87.062
fold:3 epoch:68 step:10 train loss:0.399688, train acc:87.537, train f1:86.593, train precision:87.531, train recall:86.925, train kappa:87.058
fold:3 epoch:68 step:11 train loss:0.391124, train acc:88.129, train f1:87.109, train precision:88.245, train recall:87.445, train kappa:87.661
fold:3 epoch:68        valid loss:0.661966, valid acc:84.129, valid f1:61.522, valid precision:58.458, valid recall:70.503, valid kappa:82.114
[1;31mTest score increased (84.051363 --> 84.129061).[0m
[84.12906127957143, 61.521701093089106, 58.457665199025286, 70.50304968091487, 82.11364129162077]
====================================================================================================
fold:3 epoch:69 step:0 train loss:0.391327, train acc:87.689, train f1:86.971, train precision:88.131, train recall:87.099, train kappa:87.215
fold:3 epoch:69 step:1 train loss:0.385316, train acc:88.010, train f1:87.125, train precision:88.497, train recall:87.227, train kappa:87.546
fold:3 epoch:69 step:2 train loss:0.395223, train acc:87.601, train f1:86.890, train precision:87.961, train recall:86.981, train kappa:87.125
fold:3 epoch:69 step:3 train loss:0.393669, train acc:87.610, train f1:86.814, train precision:88.053, train recall:86.742, train kappa:87.135
fold:3 epoch:69 step:4 train loss:0.382299, train acc:88.089, train f1:87.416, train precision:88.309, train recall:87.600, train kappa:87.639
fold:3 epoch:69 step:5 train loss:0.387181, train acc:88.068, train f1:87.165, train precision:88.105, train recall:87.298, train kappa:87.605
fold:3 epoch:69 step:6 train loss:0.391410, train acc:87.741, train f1:87.037, train precision:88.109, train recall:87.123, train kappa:87.274
fold:3 epoch:69 step:7 train loss:0.382949, train acc:88.101, train f1:87.351, train precision:88.217, train recall:87.497, train kappa:87.657
fold:3 epoch:69 step:8 train loss:0.401962, train acc:87.469, train f1:86.751, train precision:87.764, train recall:86.905, train kappa:87.000
fold:3 epoch:69 step:9 train loss:0.397762, train acc:87.476, train f1:86.661, train precision:87.740, train recall:86.824, train kappa:86.998
fold:3 epoch:69 step:10 train loss:0.396817, train acc:87.762, train f1:86.957, train precision:87.743, train recall:87.224, train kappa:87.298
fold:3 epoch:69 step:11 train loss:0.385216, train acc:88.071, train f1:87.432, train precision:88.774, train recall:87.667, train kappa:87.627
fold:3 epoch:69        valid loss:0.665379, valid acc:84.053, valid f1:61.340, valid precision:57.855, valid recall:70.738, valid kappa:82.035
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.12906127957143, 61.521701093089106, 58.457665199025286, 70.50304968091487, 82.11364129162077]
====================================================================================================
fold:3 epoch:70 step:0 train loss:0.393309, train acc:87.616, train f1:86.916, train precision:88.174, train recall:87.072, train kappa:87.137
fold:3 epoch:70 step:1 train loss:0.389130, train acc:87.933, train f1:87.289, train precision:88.029, train recall:87.730, train kappa:87.474
fold:3 epoch:70 step:2 train loss:0.384326, train acc:88.074, train f1:87.246, train precision:88.158, train recall:87.413, train kappa:87.611
fold:3 epoch:70 step:3 train loss:0.385175, train acc:87.714, train f1:87.089, train precision:88.201, train recall:87.077, train kappa:87.251
fold:3 epoch:70 step:4 train loss:0.393666, train acc:87.646, train f1:86.930, train precision:88.043, train recall:86.975, train kappa:87.176
fold:3 epoch:70 step:5 train loss:0.388993, train acc:87.689, train f1:86.966, train precision:87.876, train recall:87.026, train kappa:87.221
fold:3 epoch:70 step:6 train loss:0.382741, train acc:88.083, train f1:87.326, train precision:87.968, train recall:87.541, train kappa:87.639
fold:3 epoch:70 step:7 train loss:0.387230, train acc:87.875, train f1:87.255, train precision:88.168, train recall:87.329, train kappa:87.421
fold:3 epoch:70 step:8 train loss:0.394795, train acc:87.665, train f1:86.812, train precision:87.689, train recall:87.011, train kappa:87.203
fold:3 epoch:70 step:9 train loss:0.382779, train acc:88.113, train f1:87.366, train precision:88.366, train recall:87.567, train kappa:87.654
fold:3 epoch:70 step:10 train loss:0.383811, train acc:87.891, train f1:87.009, train precision:88.233, train recall:87.157, train kappa:87.429
fold:3 epoch:70 step:11 train loss:0.401537, train acc:87.530, train f1:86.872, train precision:88.156, train recall:87.023, train kappa:87.042
fold:3 epoch:70        valid loss:0.669344, valid acc:83.970, valid f1:61.499, valid precision:58.286, valid recall:70.746, valid kappa:81.942
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.12906127957143, 61.521701093089106, 58.457665199025286, 70.50304968091487, 82.11364129162077]
====================================================================================================
fold:3 epoch:71 step:0 train loss:0.381431, train acc:88.016, train f1:87.375, train precision:88.666, train recall:87.447, train kappa:87.561
fold:3 epoch:71 step:1 train loss:0.377148, train acc:88.251, train f1:87.513, train precision:88.531, train recall:87.723, train kappa:87.810
fold:3 epoch:71 step:2 train loss:0.380102, train acc:87.894, train f1:87.233, train precision:88.250, train recall:87.275, train kappa:87.431
fold:3 epoch:71 step:3 train loss:0.400162, train acc:87.228, train f1:86.532, train precision:87.435, train recall:86.836, train kappa:86.742
fold:3 epoch:71 step:4 train loss:0.384170, train acc:87.863, train f1:86.953, train precision:87.907, train recall:87.071, train kappa:87.404
fold:3 epoch:71 step:5 train loss:0.377540, train acc:88.138, train f1:87.455, train precision:88.453, train recall:87.516, train kappa:87.685
fold:3 epoch:71 step:6 train loss:0.391036, train acc:87.799, train f1:87.171, train precision:87.974, train recall:87.428, train kappa:87.342
fold:3 epoch:71 step:7 train loss:0.391493, train acc:87.811, train f1:87.094, train precision:87.981, train recall:87.216, train kappa:87.354
fold:3 epoch:71 step:8 train loss:0.385848, train acc:88.110, train f1:87.629, train precision:88.625, train recall:87.652, train kappa:87.654
fold:3 epoch:71 step:9 train loss:0.386883, train acc:87.845, train f1:87.008, train precision:88.035, train recall:87.217, train kappa:87.383
fold:3 epoch:71 step:10 train loss:0.381966, train acc:87.970, train f1:87.295, train precision:88.263, train recall:87.260, train kappa:87.499
fold:3 epoch:71 step:11 train loss:0.395009, train acc:87.762, train f1:87.085, train precision:87.882, train recall:87.432, train kappa:87.285
fold:3 epoch:71        valid loss:0.661418, valid acc:84.125, valid f1:61.572, valid precision:58.371, valid recall:70.646, valid kappa:82.118
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.12906127957143, 61.521701093089106, 58.457665199025286, 70.50304968091487, 82.11364129162077]
====================================================================================================
fold:3 epoch:72 step:0 train loss:0.394634, train acc:87.775, train f1:86.965, train precision:87.627, train recall:87.324, train kappa:87.316
fold:3 epoch:72 step:1 train loss:0.384142, train acc:87.732, train f1:86.878, train precision:87.944, train recall:87.258, train kappa:87.270
fold:3 epoch:72 step:2 train loss:0.382878, train acc:87.799, train f1:86.866, train precision:87.732, train recall:87.101, train kappa:87.338
fold:3 epoch:72 step:3 train loss:0.377438, train acc:87.866, train f1:87.124, train precision:88.355, train recall:87.142, train kappa:87.399
fold:3 epoch:72 step:4 train loss:0.384769, train acc:87.918, train f1:87.320, train precision:88.332, train recall:87.360, train kappa:87.458
fold:3 epoch:72 step:5 train loss:0.386532, train acc:87.869, train f1:87.105, train precision:88.080, train recall:87.140, train kappa:87.406
fold:3 epoch:72 step:6 train loss:0.381732, train acc:87.955, train f1:87.171, train precision:87.910, train recall:87.443, train kappa:87.498
fold:3 epoch:72 step:7 train loss:0.389938, train acc:87.714, train f1:87.144, train precision:87.952, train recall:87.333, train kappa:87.242
fold:3 epoch:72 step:8 train loss:0.390257, train acc:87.827, train f1:87.206, train precision:87.696, train recall:87.584, train kappa:87.371
fold:3 epoch:72 step:9 train loss:0.364800, train acc:88.602, train f1:87.804, train precision:88.704, train recall:87.949, train kappa:88.159
fold:3 epoch:72 step:10 train loss:0.390852, train acc:87.808, train f1:87.178, train precision:88.343, train recall:87.341, train kappa:87.351
fold:3 epoch:72 step:11 train loss:0.395584, train acc:87.607, train f1:87.026, train precision:88.548, train recall:87.071, train kappa:87.146
fold:3 epoch:72        valid loss:0.665273, valid acc:84.227, valid f1:61.583, valid precision:58.519, valid recall:70.417, valid kappa:82.228
[1;31mTest score increased (84.129061 --> 84.227207).[0m
[84.22720673932157, 61.583357155745475, 58.51871472135113, 70.41701826699818, 82.22800931679359]
====================================================================================================
fold:3 epoch:73 step:0 train loss:0.387245, train acc:87.885, train f1:87.018, train precision:88.317, train recall:87.147, train kappa:87.425
fold:3 epoch:73 step:1 train loss:0.385099, train acc:87.860, train f1:87.078, train precision:88.185, train recall:87.341, train kappa:87.397
fold:3 epoch:73 step:2 train loss:0.375616, train acc:87.973, train f1:87.248, train precision:88.039, train recall:87.396, train kappa:87.522
fold:3 epoch:73 step:3 train loss:0.381629, train acc:88.165, train f1:87.582, train precision:88.408, train recall:87.885, train kappa:87.723
fold:3 epoch:73 step:4 train loss:0.382814, train acc:87.918, train f1:87.057, train precision:87.849, train recall:87.234, train kappa:87.463
fold:3 epoch:73 step:5 train loss:0.390391, train acc:87.698, train f1:87.010, train precision:87.694, train recall:87.326, train kappa:87.228
fold:3 epoch:73 step:6 train loss:0.390421, train acc:87.665, train f1:87.013, train precision:88.091, train recall:86.995, train kappa:87.200
fold:3 epoch:73 step:7 train loss:0.375198, train acc:88.083, train f1:87.599, train precision:88.764, train recall:87.588, train kappa:87.631
fold:3 epoch:73 step:8 train loss:0.387760, train acc:87.750, train f1:87.133, train precision:88.291, train recall:87.220, train kappa:87.282
fold:3 epoch:73 step:9 train loss:0.380507, train acc:88.098, train f1:87.301, train precision:88.168, train recall:87.458, train kappa:87.643
fold:3 epoch:73 step:10 train loss:0.395096, train acc:87.769, train f1:87.179, train precision:88.175, train recall:87.273, train kappa:87.303
fold:3 epoch:73 step:11 train loss:0.392075, train acc:87.916, train f1:87.266, train precision:88.169, train recall:87.636, train kappa:87.428
fold:3 epoch:73        valid loss:0.659516, valid acc:84.201, valid f1:61.679, valid precision:58.472, valid recall:70.533, valid kappa:82.199
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.22720673932157, 61.583357155745475, 58.51871472135113, 70.41701826699818, 82.22800931679359]
====================================================================================================
fold:3 epoch:74 step:0 train loss:0.383032, train acc:87.863, train f1:87.109, train precision:87.900, train recall:87.296, train kappa:87.412
fold:3 epoch:74 step:1 train loss:0.376258, train acc:88.004, train f1:87.276, train precision:88.495, train recall:87.282, train kappa:87.544
fold:3 epoch:74 step:2 train loss:0.381406, train acc:88.092, train f1:87.196, train precision:88.190, train recall:87.457, train kappa:87.640
fold:3 epoch:74 step:3 train loss:0.374332, train acc:88.034, train f1:87.151, train precision:88.061, train recall:87.323, train kappa:87.575
fold:3 epoch:74 step:4 train loss:0.378208, train acc:88.297, train f1:87.604, train precision:88.492, train recall:87.750, train kappa:87.846
fold:3 epoch:74 step:5 train loss:0.380724, train acc:88.052, train f1:87.333, train precision:88.250, train recall:87.585, train kappa:87.596
fold:3 epoch:74 step:6 train loss:0.384518, train acc:87.885, train f1:87.199, train precision:88.519, train recall:87.088, train kappa:87.423
fold:3 epoch:74 step:7 train loss:0.392875, train acc:87.741, train f1:87.078, train precision:88.211, train recall:87.196, train kappa:87.275
fold:3 epoch:74 step:8 train loss:0.384256, train acc:87.708, train f1:86.986, train precision:88.090, train recall:87.028, train kappa:87.238
fold:3 epoch:74 step:9 train loss:0.388153, train acc:87.878, train f1:87.168, train precision:88.057, train recall:87.286, train kappa:87.418
fold:3 epoch:74 step:10 train loss:0.386372, train acc:87.799, train f1:87.145, train precision:87.809, train recall:87.408, train kappa:87.346
fold:3 epoch:74 step:11 train loss:0.380213, train acc:88.312, train f1:87.554, train precision:88.503, train recall:87.944, train kappa:87.856
fold:3 epoch:74        valid loss:0.658904, valid acc:84.113, valid f1:61.767, valid precision:58.384, valid recall:70.719, valid kappa:82.106
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.22720673932157, 61.583357155745475, 58.51871472135113, 70.41701826699818, 82.22800931679359]
====================================================================================================
fold:3 epoch:75 step:0 train loss:0.376413, train acc:88.092, train f1:87.244, train precision:88.207, train recall:87.371, train kappa:87.640
fold:3 epoch:75 step:1 train loss:0.369362, train acc:88.467, train f1:87.659, train precision:88.662, train recall:87.849, train kappa:88.033
fold:3 epoch:75 step:2 train loss:0.372271, train acc:88.220, train f1:87.366, train precision:88.583, train recall:87.445, train kappa:87.770
fold:3 epoch:75 step:3 train loss:0.379278, train acc:88.098, train f1:87.375, train precision:88.416, train recall:87.426, train kappa:87.653
fold:3 epoch:75 step:4 train loss:0.378504, train acc:88.077, train f1:87.269, train precision:88.000, train recall:87.523, train kappa:87.619
fold:3 epoch:75 step:5 train loss:0.384394, train acc:87.936, train f1:87.201, train precision:87.947, train recall:87.399, train kappa:87.483
fold:3 epoch:75 step:6 train loss:0.378856, train acc:88.077, train f1:87.419, train precision:88.237, train recall:87.552, train kappa:87.612
fold:3 epoch:75 step:7 train loss:0.377800, train acc:88.104, train f1:87.439, train precision:88.102, train recall:87.781, train kappa:87.649
fold:3 epoch:75 step:8 train loss:0.378084, train acc:88.196, train f1:87.599, train precision:88.886, train recall:87.699, train kappa:87.752
fold:3 epoch:75 step:9 train loss:0.381547, train acc:88.010, train f1:87.189, train precision:88.117, train recall:87.464, train kappa:87.554
fold:3 epoch:75 step:10 train loss:0.389403, train acc:87.885, train f1:87.020, train precision:87.856, train recall:87.219, train kappa:87.421
fold:3 epoch:75 step:11 train loss:0.387124, train acc:87.820, train f1:87.117, train precision:88.111, train recall:87.272, train kappa:87.382
fold:3 epoch:75        valid loss:0.670168, valid acc:84.107, valid f1:61.688, valid precision:58.384, valid recall:70.662, valid kappa:82.093
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.22720673932157, 61.583357155745475, 58.51871472135113, 70.41701826699818, 82.22800931679359]
====================================================================================================
fold:3 epoch:76 step:0 train loss:0.377393, train acc:88.104, train f1:87.454, train precision:88.647, train recall:87.461, train kappa:87.662
fold:3 epoch:76 step:1 train loss:0.370310, train acc:88.242, train f1:87.717, train precision:88.654, train recall:87.901, train kappa:87.786
fold:3 epoch:76 step:2 train loss:0.374375, train acc:88.171, train f1:87.090, train precision:87.713, train recall:87.410, train kappa:87.727
fold:3 epoch:76 step:3 train loss:0.380885, train acc:88.016, train f1:87.292, train precision:87.929, train recall:87.561, train kappa:87.556
fold:3 epoch:76 step:4 train loss:0.388573, train acc:87.967, train f1:87.410, train precision:88.143, train recall:87.614, train kappa:87.514
fold:3 epoch:76 step:5 train loss:0.385342, train acc:87.759, train f1:87.025, train precision:87.903, train recall:87.273, train kappa:87.295
fold:3 epoch:76 step:6 train loss:0.381096, train acc:88.046, train f1:87.414, train precision:88.521, train recall:87.616, train kappa:87.592
fold:3 epoch:76 step:7 train loss:0.375668, train acc:88.245, train f1:87.534, train precision:88.712, train recall:87.540, train kappa:87.788
fold:3 epoch:76 step:8 train loss:0.371184, train acc:88.287, train f1:87.556, train precision:88.664, train recall:87.555, train kappa:87.838
fold:3 epoch:76 step:9 train loss:0.384619, train acc:88.046, train f1:87.255, train precision:88.239, train recall:87.392, train kappa:87.593
fold:3 epoch:76 step:10 train loss:0.366445, train acc:88.507, train f1:87.817, train precision:88.531, train recall:87.969, train kappa:88.084
fold:3 epoch:76 step:11 train loss:0.385903, train acc:88.032, train f1:87.181, train precision:87.896, train recall:87.611, train kappa:87.565
fold:3 epoch:76        valid loss:0.671465, valid acc:83.990, valid f1:61.415, valid precision:58.081, valid recall:70.488, valid kappa:81.969
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.22720673932157, 61.583357155745475, 58.51871472135113, 70.41701826699818, 82.22800931679359]
====================================================================================================
fold:3 epoch:77 step:0 train loss:0.362715, train acc:88.580, train f1:87.840, train precision:88.713, train recall:87.990, train kappa:88.163
fold:3 epoch:77 step:1 train loss:0.379098, train acc:88.086, train f1:87.360, train precision:88.388, train recall:87.571, train kappa:87.624
fold:3 epoch:77 step:2 train loss:0.372105, train acc:88.260, train f1:87.503, train precision:88.577, train recall:87.685, train kappa:87.811
fold:3 epoch:77 step:3 train loss:0.377259, train acc:87.982, train f1:87.240, train precision:88.392, train recall:87.346, train kappa:87.529
fold:3 epoch:77 step:4 train loss:0.383369, train acc:87.799, train f1:87.159, train precision:88.168, train recall:87.380, train kappa:87.335
fold:3 epoch:77 step:5 train loss:0.377839, train acc:88.031, train f1:87.323, train precision:88.208, train recall:87.523, train kappa:87.581
fold:3 epoch:77 step:6 train loss:0.365106, train acc:88.513, train f1:87.700, train precision:88.306, train recall:87.884, train kappa:88.074
fold:3 epoch:77 step:7 train loss:0.380289, train acc:87.979, train f1:87.422, train precision:88.179, train recall:87.541, train kappa:87.519
fold:3 epoch:77 step:8 train loss:0.369603, train acc:88.443, train f1:87.644, train precision:88.495, train recall:87.722, train kappa:88.011
fold:3 epoch:77 step:9 train loss:0.372455, train acc:88.358, train f1:87.505, train precision:88.164, train recall:87.775, train kappa:87.916
fold:3 epoch:77 step:10 train loss:0.376273, train acc:88.037, train f1:87.444, train precision:88.392, train recall:87.489, train kappa:87.585
fold:3 epoch:77 step:11 train loss:0.378938, train acc:87.675, train f1:86.535, train precision:87.675, train recall:86.801, train kappa:87.182
fold:3 epoch:77        valid loss:0.666641, valid acc:84.352, valid f1:61.821, valid precision:58.882, valid recall:70.378, valid kappa:82.361
[1;31mTest score increased (84.227207 --> 84.351933).[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:78 step:0 train loss:0.370648, train acc:88.290, train f1:87.397, train precision:88.732, train recall:87.521, train kappa:87.837
fold:3 epoch:78 step:1 train loss:0.365964, train acc:88.379, train f1:87.550, train precision:88.625, train recall:87.650, train kappa:87.929
fold:3 epoch:78 step:2 train loss:0.371504, train acc:88.290, train f1:87.581, train precision:88.552, train recall:87.846, train kappa:87.849
fold:3 epoch:78 step:3 train loss:0.369961, train acc:88.367, train f1:87.721, train precision:88.691, train recall:87.935, train kappa:87.932
fold:3 epoch:78 step:4 train loss:0.376688, train acc:88.116, train f1:87.533, train precision:88.267, train recall:87.802, train kappa:87.668
fold:3 epoch:78 step:5 train loss:0.370229, train acc:88.257, train f1:87.463, train precision:88.194, train recall:87.616, train kappa:87.813
fold:3 epoch:78 step:6 train loss:0.362040, train acc:88.446, train f1:87.754, train precision:88.449, train recall:87.881, train kappa:88.006
fold:3 epoch:78 step:7 train loss:0.381436, train acc:87.839, train f1:87.206, train precision:88.225, train recall:87.222, train kappa:87.382
fold:3 epoch:78 step:8 train loss:0.375338, train acc:88.211, train f1:87.313, train precision:88.429, train recall:87.279, train kappa:87.765
fold:3 epoch:78 step:9 train loss:0.370624, train acc:88.388, train f1:87.574, train precision:88.567, train recall:87.772, train kappa:87.941
fold:3 epoch:78 step:10 train loss:0.386866, train acc:87.915, train f1:87.234, train precision:88.248, train recall:87.336, train kappa:87.453
fold:3 epoch:78 step:11 train loss:0.375724, train acc:88.109, train f1:87.204, train precision:88.148, train recall:87.396, train kappa:87.673
fold:3 epoch:78        valid loss:0.676944, valid acc:84.068, valid f1:61.535, valid precision:58.007, valid recall:70.655, valid kappa:82.063
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:79 step:0 train loss:0.359574, train acc:88.513, train f1:87.819, train precision:88.365, train recall:88.284, train kappa:88.073
fold:3 epoch:79 step:1 train loss:0.374555, train acc:88.019, train f1:87.126, train precision:87.931, train recall:87.384, train kappa:87.565
fold:3 epoch:79 step:2 train loss:0.371142, train acc:88.428, train f1:87.568, train precision:88.445, train recall:87.759, train kappa:87.987
fold:3 epoch:79 step:3 train loss:0.375096, train acc:88.104, train f1:87.564, train precision:88.341, train recall:87.857, train kappa:87.655
fold:3 epoch:79 step:4 train loss:0.369741, train acc:88.272, train f1:87.660, train precision:88.885, train recall:87.749, train kappa:87.824
fold:3 epoch:79 step:5 train loss:0.376507, train acc:88.083, train f1:87.415, train precision:88.364, train recall:87.576, train kappa:87.635
fold:3 epoch:79 step:6 train loss:0.365455, train acc:88.452, train f1:87.850, train precision:88.603, train recall:88.045, train kappa:88.019
fold:3 epoch:79 step:7 train loss:0.369335, train acc:88.495, train f1:87.704, train precision:88.411, train recall:87.936, train kappa:88.055
fold:3 epoch:79 step:8 train loss:0.379568, train acc:88.196, train f1:87.431, train precision:88.161, train recall:87.696, train kappa:87.747
fold:3 epoch:79 step:9 train loss:0.377171, train acc:88.174, train f1:87.352, train precision:88.145, train recall:87.666, train kappa:87.732
fold:3 epoch:79 step:10 train loss:0.366806, train acc:88.397, train f1:87.659, train precision:88.428, train recall:87.891, train kappa:87.964
fold:3 epoch:79 step:11 train loss:0.370855, train acc:88.244, train f1:87.409, train precision:89.176, train recall:87.443, train kappa:87.803
fold:3 epoch:79        valid loss:0.667221, valid acc:84.188, valid f1:61.549, valid precision:58.418, valid recall:70.308, valid kappa:82.181
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:80 step:0 train loss:0.377142, train acc:88.058, train f1:87.272, train precision:88.108, train recall:87.484, train kappa:87.609
fold:3 epoch:80 step:1 train loss:0.356811, train acc:88.565, train f1:87.714, train precision:88.642, train recall:87.777, train kappa:88.135
fold:3 epoch:80 step:2 train loss:0.370103, train acc:88.327, train f1:87.721, train precision:88.679, train recall:87.694, train kappa:87.888
fold:3 epoch:80 step:3 train loss:0.364413, train acc:88.364, train f1:87.782, train precision:88.653, train recall:87.913, train kappa:87.922
fold:3 epoch:80 step:4 train loss:0.363449, train acc:88.370, train f1:87.560, train precision:88.353, train recall:87.874, train kappa:87.924
fold:3 epoch:80 step:5 train loss:0.376937, train acc:88.007, train f1:87.430, train precision:88.428, train recall:87.622, train kappa:87.556
fold:3 epoch:80 step:6 train loss:0.366198, train acc:88.611, train f1:87.916, train precision:88.980, train recall:88.080, train kappa:88.184
fold:3 epoch:80 step:7 train loss:0.376458, train acc:88.235, train f1:87.389, train precision:88.151, train recall:87.565, train kappa:87.787
fold:3 epoch:80 step:8 train loss:0.374492, train acc:87.939, train f1:87.334, train precision:88.125, train recall:87.595, train kappa:87.489
fold:3 epoch:80 step:9 train loss:0.364286, train acc:88.516, train f1:87.766, train precision:88.519, train recall:87.981, train kappa:88.067
fold:3 epoch:80 step:10 train loss:0.366358, train acc:88.315, train f1:87.547, train precision:88.669, train recall:87.495, train kappa:87.866
fold:3 epoch:80 step:11 train loss:0.366982, train acc:88.264, train f1:87.529, train precision:88.662, train recall:87.492, train kappa:87.813
fold:3 epoch:80        valid loss:0.667808, valid acc:84.219, valid f1:61.703, valid precision:58.453, valid recall:70.461, valid kappa:82.218
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:81 step:0 train loss:0.365607, train acc:88.403, train f1:87.687, train precision:88.475, train recall:87.817, train kappa:87.958
fold:3 epoch:81 step:1 train loss:0.360223, train acc:88.608, train f1:87.760, train precision:88.778, train recall:87.759, train kappa:88.184
fold:3 epoch:81 step:2 train loss:0.369732, train acc:88.309, train f1:87.366, train precision:87.965, train recall:87.757, train kappa:87.867
fold:3 epoch:81 step:3 train loss:0.362349, train acc:88.382, train f1:87.671, train precision:88.501, train recall:87.808, train kappa:87.949
fold:3 epoch:81 step:4 train loss:0.367819, train acc:88.495, train f1:87.795, train precision:88.724, train recall:88.005, train kappa:88.061
fold:3 epoch:81 step:5 train loss:0.365856, train acc:88.217, train f1:87.426, train precision:88.348, train recall:87.528, train kappa:87.772
fold:3 epoch:81 step:6 train loss:0.372363, train acc:88.113, train f1:87.582, train precision:88.280, train recall:87.854, train kappa:87.668
fold:3 epoch:81 step:7 train loss:0.371423, train acc:88.190, train f1:87.413, train precision:88.179, train recall:87.661, train kappa:87.728
fold:3 epoch:81 step:8 train loss:0.364713, train acc:88.458, train f1:87.800, train precision:88.721, train recall:88.008, train kappa:88.024
fold:3 epoch:81 step:9 train loss:0.366902, train acc:88.556, train f1:87.846, train precision:88.517, train recall:88.028, train kappa:88.117
fold:3 epoch:81 step:10 train loss:0.368969, train acc:88.550, train f1:88.109, train precision:88.634, train recall:88.277, train kappa:88.115
fold:3 epoch:81 step:11 train loss:0.369946, train acc:88.167, train f1:87.510, train precision:88.129, train recall:87.897, train kappa:87.723
fold:3 epoch:81        valid loss:0.668969, valid acc:84.309, valid f1:61.804, valid precision:58.556, valid recall:70.359, valid kappa:82.318
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:82 step:0 train loss:0.365278, train acc:88.260, train f1:87.694, train precision:88.624, train recall:87.680, train kappa:87.806
fold:3 epoch:82 step:1 train loss:0.360714, train acc:88.620, train f1:87.836, train precision:88.857, train recall:87.884, train kappa:88.180
fold:3 epoch:82 step:2 train loss:0.361201, train acc:88.605, train f1:87.920, train precision:89.157, train recall:87.849, train kappa:88.169
fold:3 epoch:82 step:3 train loss:0.363160, train acc:88.519, train f1:87.734, train precision:88.950, train recall:87.825, train kappa:88.087
fold:3 epoch:82 step:4 train loss:0.370427, train acc:88.513, train f1:87.785, train precision:88.786, train recall:88.020, train kappa:88.078
fold:3 epoch:82 step:5 train loss:0.364389, train acc:88.455, train f1:87.662, train precision:88.587, train recall:87.734, train kappa:88.025
fold:3 epoch:82 step:6 train loss:0.368355, train acc:88.385, train f1:87.617, train precision:88.215, train recall:88.014, train kappa:87.958
fold:3 epoch:82 step:7 train loss:0.371030, train acc:88.376, train f1:87.546, train precision:88.348, train recall:87.938, train kappa:87.933
fold:3 epoch:82 step:8 train loss:0.367213, train acc:88.455, train f1:87.925, train precision:88.622, train recall:88.175, train kappa:88.022
fold:3 epoch:82 step:9 train loss:0.371529, train acc:88.232, train f1:87.575, train precision:88.236, train recall:87.799, train kappa:87.786
fold:3 epoch:82 step:10 train loss:0.365550, train acc:88.593, train f1:87.804, train precision:88.721, train recall:87.911, train kappa:88.159
fold:3 epoch:82 step:11 train loss:0.371133, train acc:88.380, train f1:87.607, train precision:88.353, train recall:87.932, train kappa:87.928
fold:3 epoch:82        valid loss:0.666412, valid acc:84.325, valid f1:62.024, valid precision:58.790, valid recall:70.518, valid kappa:82.337
[1;31mEarlyStopping counter: 5 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:83 step:0 train loss:0.372077, train acc:88.187, train f1:87.600, train precision:88.436, train recall:87.724, train kappa:87.740
fold:3 epoch:83 step:1 train loss:0.354391, train acc:88.629, train f1:87.922, train precision:88.771, train recall:88.027, train kappa:88.194
fold:3 epoch:83 step:2 train loss:0.359998, train acc:88.507, train f1:87.793, train precision:88.507, train recall:88.120, train kappa:88.063
fold:3 epoch:83 step:3 train loss:0.358613, train acc:88.812, train f1:87.952, train precision:88.852, train recall:88.117, train kappa:88.391
fold:3 epoch:83 step:4 train loss:0.366356, train acc:88.327, train f1:87.614, train precision:88.715, train recall:87.690, train kappa:87.885
fold:3 epoch:83 step:5 train loss:0.363451, train acc:88.498, train f1:87.883, train precision:89.083, train recall:87.962, train kappa:88.054
fold:3 epoch:83 step:6 train loss:0.369168, train acc:88.327, train f1:87.566, train precision:88.739, train recall:87.638, train kappa:87.881
fold:3 epoch:83 step:7 train loss:0.375189, train acc:88.165, train f1:87.568, train precision:88.443, train recall:87.707, train kappa:87.717
fold:3 epoch:83 step:8 train loss:0.359741, train acc:88.458, train f1:87.782, train precision:88.479, train recall:88.022, train kappa:88.030
fold:3 epoch:83 step:9 train loss:0.364150, train acc:88.602, train f1:87.835, train precision:88.567, train recall:88.083, train kappa:88.173
fold:3 epoch:83 step:10 train loss:0.365268, train acc:88.248, train f1:87.595, train precision:88.086, train recall:87.899, train kappa:87.811
fold:3 epoch:83 step:11 train loss:0.356914, train acc:88.814, train f1:88.159, train precision:88.839, train recall:88.321, train kappa:88.390
fold:3 epoch:83        valid loss:0.668217, valid acc:84.327, valid f1:61.851, valid precision:58.672, valid recall:70.403, valid kappa:82.339
[1;31mEarlyStopping counter: 6 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:84 step:0 train loss:0.358495, train acc:88.992, train f1:88.127, train precision:89.213, train recall:88.175, train kappa:88.572
fold:3 epoch:84 step:1 train loss:0.356385, train acc:88.635, train f1:87.737, train precision:89.026, train recall:87.634, train kappa:88.208
fold:3 epoch:84 step:2 train loss:0.363549, train acc:88.504, train f1:87.586, train precision:88.637, train recall:87.649, train kappa:88.058
fold:3 epoch:84 step:3 train loss:0.359053, train acc:88.538, train f1:87.796, train precision:88.708, train recall:88.017, train kappa:88.099
fold:3 epoch:84 step:4 train loss:0.362236, train acc:88.409, train f1:87.724, train precision:88.603, train recall:87.903, train kappa:87.969
fold:3 epoch:84 step:5 train loss:0.366009, train acc:88.492, train f1:87.699, train precision:88.377, train recall:87.906, train kappa:88.049
fold:3 epoch:84 step:6 train loss:0.360664, train acc:88.525, train f1:87.714, train precision:88.304, train recall:88.058, train kappa:88.093
fold:3 epoch:84 step:7 train loss:0.353767, train acc:88.907, train f1:88.072, train precision:88.701, train recall:88.406, train kappa:88.496
fold:3 epoch:84 step:8 train loss:0.366257, train acc:88.373, train f1:87.878, train precision:88.329, train recall:88.119, train kappa:87.934
fold:3 epoch:84 step:9 train loss:0.364550, train acc:88.422, train f1:87.673, train precision:88.635, train recall:87.838, train kappa:87.991
fold:3 epoch:84 step:10 train loss:0.370207, train acc:88.031, train f1:87.251, train precision:88.112, train recall:87.467, train kappa:87.581
fold:3 epoch:84 step:11 train loss:0.371831, train acc:87.897, train f1:87.231, train precision:88.130, train recall:87.433, train kappa:87.438
fold:3 epoch:84        valid loss:0.672961, valid acc:84.280, valid f1:61.973, valid precision:58.821, valid recall:70.513, valid kappa:82.285
[1;31mEarlyStopping counter: 7 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:85 step:0 train loss:0.351803, train acc:88.931, train f1:88.194, train precision:89.306, train recall:88.253, train kappa:88.513
fold:3 epoch:85 step:1 train loss:0.356727, train acc:88.647, train f1:87.864, train precision:88.567, train recall:88.130, train kappa:88.211
fold:3 epoch:85 step:2 train loss:0.355840, train acc:88.773, train f1:88.089, train precision:88.909, train recall:88.328, train kappa:88.347
fold:3 epoch:85 step:3 train loss:0.363706, train acc:88.583, train f1:87.883, train precision:88.623, train recall:88.054, train kappa:88.152
fold:3 epoch:85 step:4 train loss:0.358875, train acc:88.681, train f1:87.796, train precision:88.637, train recall:87.953, train kappa:88.243
fold:3 epoch:85 step:5 train loss:0.358738, train acc:88.449, train f1:87.746, train precision:88.581, train recall:87.923, train kappa:88.005
fold:3 epoch:85 step:6 train loss:0.357524, train acc:88.644, train f1:88.044, train precision:88.726, train recall:88.334, train kappa:88.221
fold:3 epoch:85 step:7 train loss:0.361902, train acc:88.580, train f1:87.972, train precision:88.795, train recall:88.146, train kappa:88.146
fold:3 epoch:85 step:8 train loss:0.359996, train acc:88.635, train f1:87.900, train precision:88.893, train recall:87.943, train kappa:88.211
fold:3 epoch:85 step:9 train loss:0.356882, train acc:88.510, train f1:87.738, train precision:88.614, train recall:87.764, train kappa:88.077
fold:3 epoch:85 step:10 train loss:0.357733, train acc:88.589, train f1:87.725, train precision:88.396, train recall:88.045, train kappa:88.167
fold:3 epoch:85 step:11 train loss:0.363995, train acc:88.592, train f1:87.771, train precision:88.727, train recall:87.775, train kappa:88.151
fold:3 epoch:85        valid loss:0.666496, valid acc:84.344, valid f1:61.778, valid precision:58.497, valid recall:70.311, valid kappa:82.359
[1;31mEarlyStopping counter: 8 out of 50[0m
[84.35193326108738, 61.821132485778776, 58.88231358229188, 70.37779638479395, 82.36100492430045]
====================================================================================================
fold:3 epoch:86 step:0 train loss:0.363393, train acc:88.348, train f1:87.705, train precision:88.268, train recall:87.938, train kappa:87.911
fold:3 epoch:86 step:1 train loss:0.358040, train acc:88.519, train f1:87.857, train precision:88.534, train recall:87.986, train kappa:88.091
fold:3 epoch:86 step:2 train loss:0.359588, train acc:88.495, train f1:87.817, train precision:88.737, train recall:87.944, train kappa:88.056
fold:3 epoch:86 step:3 train loss:0.352588, train acc:88.690, train f1:87.943, train precision:88.770, train recall:88.051, train kappa:88.260
fold:3 epoch:86 step:4 train loss:0.354847, train acc:88.733, train f1:88.373, train precision:89.327, train recall:88.639, train kappa:88.301
fold:3 epoch:86 step:5 train loss:0.355451, train acc:88.635, train f1:88.060, train precision:89.004, train recall:88.057, train kappa:88.204
fold:3 epoch:86 step:6 train loss:0.360698, train acc:88.510, train f1:87.908, train precision:88.913, train recall:87.999, train kappa:88.079
fold:3 epoch:86 step:7 train loss:0.358397, train acc:88.690, train f1:87.750, train precision:88.443, train recall:87.966, train kappa:88.255
fold:3 epoch:86 step:8 train loss:0.362198, train acc:88.412, train f1:87.617, train precision:88.241, train recall:87.847, train kappa:87.966
fold:3 epoch:86 step:9 train loss:0.363991, train acc:88.525, train f1:87.683, train precision:88.674, train recall:87.786, train kappa:88.095
fold:3 epoch:86 step:10 train loss:0.363424, train acc:88.391, train f1:87.512, train precision:88.357, train recall:87.761, train kappa:87.956
fold:3 epoch:86 step:11 train loss:0.349391, train acc:88.988, train f1:88.293, train precision:89.597, train recall:88.173, train kappa:88.578
fold:3 epoch:86        valid loss:0.667854, valid acc:84.534, valid f1:62.370, valid precision:59.123, valid recall:70.595, valid kappa:82.570
[1;31mTest score increased (84.351933 --> 84.533911).[0m
[84.53391130104076, 62.36985582441943, 59.12286991016336, 70.59530887297866, 82.5699371038112]
====================================================================================================
fold:3 epoch:87 step:0 train loss:0.362272, train acc:88.303, train f1:87.805, train precision:88.672, train recall:87.942, train kappa:87.860
fold:3 epoch:87 step:1 train loss:0.359748, train acc:88.461, train f1:87.770, train precision:88.437, train recall:88.054, train kappa:88.027
fold:3 epoch:87 step:2 train loss:0.346218, train acc:88.840, train f1:88.126, train precision:88.692, train recall:88.241, train kappa:88.424
fold:3 epoch:87 step:3 train loss:0.348854, train acc:88.791, train f1:88.049, train precision:88.504, train recall:88.312, train kappa:88.366
fold:3 epoch:87 step:4 train loss:0.358376, train acc:88.544, train f1:87.831, train precision:88.431, train recall:88.105, train kappa:88.106
fold:3 epoch:87 step:5 train loss:0.354892, train acc:88.745, train f1:88.072, train precision:88.748, train recall:88.338, train kappa:88.316
fold:3 epoch:87 step:6 train loss:0.366008, train acc:88.489, train f1:87.720, train precision:88.726, train recall:87.946, train kappa:88.054
fold:3 epoch:87 step:7 train loss:0.363408, train acc:88.580, train f1:87.737, train precision:88.574, train recall:87.890, train kappa:88.143
fold:3 epoch:87 step:8 train loss:0.355075, train acc:88.684, train f1:87.988, train precision:88.844, train recall:88.133, train kappa:88.255
fold:3 epoch:87 step:9 train loss:0.353943, train acc:88.641, train f1:87.953, train precision:88.765, train recall:88.120, train kappa:88.215
fold:3 epoch:87 step:10 train loss:0.362136, train acc:88.470, train f1:87.779, train precision:88.493, train recall:87.980, train kappa:88.043
fold:3 epoch:87 step:11 train loss:0.355435, train acc:88.698, train f1:88.019, train precision:88.267, train recall:88.455, train kappa:88.269
fold:3 epoch:87        valid loss:0.671621, valid acc:84.475, valid f1:62.086, valid precision:58.815, valid recall:70.460, valid kappa:82.504
[1;31mEarlyStopping counter: 1 out of 50[0m
[84.53391130104076, 62.36985582441943, 59.12286991016336, 70.59530887297866, 82.5699371038112]
====================================================================================================
fold:3 epoch:88 step:0 train loss:0.354536, train acc:88.541, train f1:88.011, train precision:88.892, train recall:88.059, train kappa:88.107
fold:3 epoch:88 step:1 train loss:0.351553, train acc:88.733, train f1:87.998, train precision:89.042, train recall:87.999, train kappa:88.308
fold:3 epoch:88 step:2 train loss:0.354442, train acc:88.678, train f1:87.865, train precision:89.194, train recall:87.800, train kappa:88.239
fold:3 epoch:88 step:3 train loss:0.344209, train acc:89.020, train f1:88.057, train precision:88.983, train recall:88.094, train kappa:88.600
fold:3 epoch:88 step:4 train loss:0.365465, train acc:88.113, train f1:87.435, train precision:88.040, train recall:87.683, train kappa:87.672
fold:3 epoch:88 step:5 train loss:0.357619, train acc:88.626, train f1:87.904, train precision:88.373, train recall:88.268, train kappa:88.197
fold:3 epoch:88 step:6 train loss:0.354454, train acc:88.556, train f1:87.974, train precision:88.516, train recall:88.312, train kappa:88.118
fold:3 epoch:88 step:7 train loss:0.365937, train acc:88.327, train f1:87.722, train precision:88.284, train recall:87.866, train kappa:87.889
fold:3 epoch:88 step:8 train loss:0.357306, train acc:88.620, train f1:88.124, train precision:88.803, train recall:88.404, train kappa:88.190
fold:3 epoch:88 step:9 train loss:0.357284, train acc:88.504, train f1:87.760, train precision:88.723, train recall:87.852, train kappa:88.081
fold:3 epoch:88 step:10 train loss:0.350609, train acc:89.093, train f1:88.112, train precision:89.124, train recall:88.161, train kappa:88.673
fold:3 epoch:88 step:11 train loss:0.360140, train acc:88.698, train f1:87.776, train precision:88.792, train recall:87.879, train kappa:88.259
fold:3 epoch:88        valid loss:0.671634, valid acc:84.448, valid f1:62.081, valid precision:58.985, valid recall:70.423, valid kappa:82.474
[1;31mEarlyStopping counter: 2 out of 50[0m
[84.53391130104076, 62.36985582441943, 59.12286991016336, 70.59530887297866, 82.5699371038112]
====================================================================================================
fold:3 epoch:89 step:0 train loss:0.361404, train acc:88.412, train f1:87.705, train precision:88.489, train recall:87.963, train kappa:87.982
fold:3 epoch:89 step:1 train loss:0.355109, train acc:88.632, train f1:87.767, train precision:88.364, train recall:88.045, train kappa:88.207
fold:3 epoch:89 step:2 train loss:0.361722, train acc:88.544, train f1:87.668, train precision:88.268, train recall:87.926, train kappa:88.114
fold:3 epoch:89 step:3 train loss:0.363433, train acc:88.376, train f1:87.731, train precision:88.318, train recall:88.037, train kappa:87.945
fold:3 epoch:89 step:4 train loss:0.344771, train acc:88.858, train f1:88.140, train precision:88.893, train recall:88.229, train kappa:88.436
fold:3 epoch:89 step:5 train loss:0.346920, train acc:88.943, train f1:88.333, train precision:88.974, train recall:88.521, train kappa:88.525
fold:3 epoch:89 step:6 train loss:0.361339, train acc:88.535, train f1:87.785, train precision:88.786, train recall:87.794, train kappa:88.085
fold:3 epoch:89 step:7 train loss:0.357766, train acc:88.593, train f1:87.865, train precision:88.731, train recall:87.997, train kappa:88.150
fold:3 epoch:89 step:8 train loss:0.356285, train acc:88.559, train f1:88.093, train precision:88.858, train recall:88.239, train kappa:88.134
fold:3 epoch:89 step:9 train loss:0.348383, train acc:88.922, train f1:88.169, train precision:88.875, train recall:88.228, train kappa:88.499
fold:3 epoch:89 step:10 train loss:0.344308, train acc:89.090, train f1:88.269, train precision:88.904, train recall:88.466, train kappa:88.677
fold:3 epoch:89 step:11 train loss:0.354824, train acc:88.630, train f1:87.793, train precision:88.614, train recall:87.962, train kappa:88.203
fold:3 epoch:89        valid loss:0.669775, valid acc:84.395, valid f1:61.877, valid precision:58.692, valid recall:70.379, valid kappa:82.413
[1;31mEarlyStopping counter: 3 out of 50[0m
[84.53391130104076, 62.36985582441943, 59.12286991016336, 70.59530887297866, 82.5699371038112]
====================================================================================================
fold:3 epoch:90 step:0 train loss:0.341474, train acc:89.059, train f1:88.232, train precision:88.961, train recall:88.366, train kappa:88.646
fold:3 epoch:90 step:1 train loss:0.345459, train acc:88.882, train f1:87.876, train precision:88.656, train recall:88.025, train kappa:88.462
fold:3 epoch:90 step:2 train loss:0.349935, train acc:89.020, train f1:88.335, train precision:89.180, train recall:88.527, train kappa:88.608
fold:3 epoch:90 step:3 train loss:0.359020, train acc:88.547, train f1:87.785, train precision:88.802, train recall:87.890, train kappa:88.112
fold:3 epoch:90 step:4 train loss:0.353665, train acc:88.864, train f1:87.920, train precision:88.741, train recall:88.257, train kappa:88.442
fold:3 epoch:90 step:5 train loss:0.345009, train acc:89.011, train f1:88.122, train precision:88.992, train recall:88.384, train kappa:88.591
fold:3 epoch:90 step:6 train loss:0.358768, train acc:88.632, train f1:88.126, train precision:88.837, train recall:88.387, train kappa:88.200
fold:3 epoch:90 step:7 train loss:0.345631, train acc:89.023, train f1:88.196, train precision:88.816, train recall:88.453, train kappa:88.606
fold:3 epoch:90 step:8 train loss:0.355669, train acc:88.660, train f1:88.009, train precision:88.709, train recall:88.120, train kappa:88.228
fold:3 epoch:90 step:9 train loss:0.352061, train acc:88.821, train f1:88.209, train precision:88.932, train recall:88.285, train kappa:88.402
fold:3 epoch:90 step:10 train loss:0.366193, train acc:88.330, train f1:87.622, train precision:88.434, train recall:87.838, train kappa:87.896
fold:3 epoch:90 step:11 train loss:0.356156, train acc:88.360, train f1:87.755, train precision:88.551, train recall:88.115, train kappa:87.927
fold:3 epoch:90        valid loss:0.675784, valid acc:84.491, valid f1:62.262, valid precision:59.031, valid recall:70.403, valid kappa:82.526
[1;31mEarlyStopping counter: 4 out of 50[0m
[84.53391130104076, 62.36985582441943, 59.12286991016336, 70.59530887297866, 82.5699371038112]
====================================================================================================
fold:3 epoch:91 step:0 train loss:0.347301, train acc:88.843, train f1:88.407, train precision:89.149, train recall:88.588, train kappa:88.419
fold:3 epoch:91 step:1 train loss:0.353733, train acc:88.803, train f1:88.131, train precision:88.953, train recall:88.227, train kappa:88.377
fold:3 epoch:91 step:2 train loss:0.345051, train acc:88.815, train f1:88.261, train precision:89.065, train recall:88.324, train kappa:88.397
fold:3 epoch:91 step:3 train loss:0.349666, train acc:88.748, train f1:88.027, train precision:88.622, train recall:88.203, train kappa:88.323
fold:3 epoch:91 step:4 train loss:0.342617, train acc:89.160, train f1:88.539, train precision:89.386, train recall:88.587, train kappa:88.754
fold:3 epoch:91 step:5 train loss:0.353273, train acc:88.718, train f1:88.018, train precision:88.677, train recall:88.250, train kappa:88.284
fold:3 epoch:91 step:6 train loss:0.349206, train acc:88.892, train f1:87.955, train precision:88.676, train recall:88.238, train kappa:88.472
fold:3 epoch:91 step:7 train loss:0.346930, train acc:88.925, train f1:88.170, train precision:88.807, train recall:88.423, train kappa:88.514
fold:3 epoch:91 step:8 train loss:0.352408, train acc:88.794, train f1:87.972, train precision:88.676, train recall:88.235, train kappa:88.364
fold:3 epoch:91 step:9 train loss:0.355024, train acc:88.657, train f1:88.158, train precision:89.086, train recall:88.212, train kappa:88.232
fold:3 epoch:91 step:10 train loss:0.351672, train acc:88.678, train f1:87.938, train precision:88.746, train recall:88.048, train kappa:88.249
fold:3 epoch:91 step:11 train loss:0.337507, train acc:89.219, train f1:88.466, train precision:89.090, train recall:88.715, train kappa:88.808
fold:3 epoch:91        valid loss:0.675254, valid acc:84.614, valid f1:62.417, valid precision:59.221, valid recall:70.503, valid kappa:82.654
[1;31mTest score increased (84.533911 --> 84.613654).[0m
[84.61365448708774, 62.417317767556845, 59.221439826798985, 70.50348533331183, 82.6538541941448]
====================================================================================================
fold:3 epoch:92 step:0 train loss:0.343872, train acc:89.032, train f1:88.470, train precision:89.179, train recall:88.578, train kappa:88.612
fold:3 epoch:92 step:1 train loss:0.340342, train acc:88.959, train f1:88.245, train precision:89.220, train recall:88.242, train kappa:88.542
fold:3 epoch:92 step:2 train loss:0.359522, train acc:88.455, train f1:87.947, train precision:88.983, train recall:87.972, train kappa:88.020
fold:3 epoch:92 step:3 train loss:0.349195, train acc:88.776, train f1:88.245, train precision:88.888, train recall:88.391, train kappa:88.347
fold:3 epoch:92 step:4 train loss:0.342500, train acc:89.093, train f1:88.285, train precision:88.951, train recall:88.488, train kappa:88.677
fold:3 epoch:92 step:5 train loss:0.355873, train acc:88.654, train f1:87.823, train precision:88.355, train recall:88.163, train kappa:88.217
fold:3 epoch:92 step:6 train loss:0.363518, train acc:88.525, train f1:88.045, train precision:88.920, train recall:88.071, train kappa:88.091
fold:3 epoch:92 step:7 train loss:0.350691, train acc:88.699, train f1:87.927, train precision:88.834, train recall:88.076, train kappa:88.274
fold:3 epoch:92 step:8 train loss:0.351126, train acc:88.770, train f1:88.008, train precision:88.693, train recall:88.214, train kappa:88.351
fold:3 epoch:92 step:9 train loss:0.348676, train acc:88.992, train f1:88.017, train precision:88.985, train recall:88.010, train kappa:88.582
fold:3 epoch:92 step:10 train loss:0.343410, train acc:88.980, train f1:88.164, train precision:88.906, train recall:88.412, train kappa:88.568
fold:3 epoch:92 step:11 train loss:0.349496, train acc:88.698, train f1:88.023, train precision:88.877, train recall:88.202, train kappa:88.267
