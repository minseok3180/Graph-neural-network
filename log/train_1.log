nohup: ignoring input
running on cuda:0
HetDDI(
  (kg): HGNN(
    (dropout): Dropout(p=0.2, inplace=False)
    (node_embedding): Embedding(98744, 300)
    (gat_layers): ModuleList(
      (0): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (1): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
      (2): HetConv(
        (edge_embedding): Embedding(109, 300)
        (bn): Sequential(
          (0): Linear(in_features=300, out_features=300, bias=True)
          (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        )
        (leaky_relu): LeakyReLU(negative_slope=0.02)
      )
    )
  )
  (kg_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (mol): Mol(
    (readout): AvgPooling()
    (gnn): HGNN(
      (dropout): Dropout(p=0.2, inplace=False)
      (node_embedding): Embedding(47601, 300)
      (gat_layers): ModuleList(
        (0): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (1): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
        (2): HetConv(
          (edge_embedding): Embedding(5, 300)
          (bn): Sequential(
            (0): Linear(in_features=300, out_features=300, bias=True)
            (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          )
          (leaky_relu): LeakyReLU(negative_slope=0.02)
        )
      )
    )
  )
  (mol_fc): Sequential(
    (0): Linear(in_features=300, out_features=300, bias=True)
    (1): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (2): Dropout(p=0.1, inplace=False)
    (3): ReLU()
    (4): Linear(in_features=300, out_features=300, bias=True)
    (5): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (6): Dropout(p=0.1, inplace=False)
    (7): ReLU()
    (8): Linear(in_features=300, out_features=300, bias=True)
    (9): BatchNorm1d(300, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (10): Dropout(p=0.1, inplace=False)
    (11): ReLU()
  )
  (decoder): Mlp(
    (fc_layer): Sequential(
      (0): Linear(in_features=1200, out_features=1200, bias=True)
      (1): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (2): ReLU()
      (3): Dropout(p=0.5, inplace=False)
      (4): Linear(in_features=1200, out_features=1200, bias=True)
      (5): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (6): ReLU()
      (7): Dropout(p=0.5, inplace=False)
      (8): Linear(in_features=1200, out_features=1200, bias=True)
      (9): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (10): ReLU()
      (11): Dropout(p=0.5, inplace=False)
    )
    (output_layer): Sequential(
      (0): Linear(in_features=1200, out_features=86, bias=False)
    )
  )
)
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:0 train loss:4.564497, train acc:1.590, train f1:0.850, train precision:1.013, train recall:1.115, train kappa:-0.002
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:1 train loss:4.372978, train acc:7.870, train f1:1.289, train precision:1.759, train recall:1.994, train kappa:1.740
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:2 train loss:4.202259, train acc:9.958, train f1:1.657, train precision:3.348, train recall:2.443, train kappa:3.150
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:3 train loss:4.093819, train acc:11.752, train f1:2.328, train precision:2.853, train recall:3.356, train kappa:4.666
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:4 train loss:4.034952, train acc:13.361, train f1:3.664, train precision:6.031, train recall:4.645, train kappa:6.030
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:5 train loss:3.956721, train acc:13.623, train f1:3.884, train precision:4.726, train recall:4.866, train kappa:6.317
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:6 train loss:3.903330, train acc:13.770, train f1:4.302, train precision:5.441, train recall:5.260, train kappa:6.688
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:7 train loss:3.832667, train acc:14.618, train f1:4.926, train precision:7.481, train recall:5.606, train kappa:7.249
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:8 train loss:3.812908, train acc:15.436, train f1:5.903, train precision:10.888, train recall:6.347, train kappa:8.421
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0 step:9 train loss:3.718948, train acc:16.668, train f1:6.602, train precision:12.663, train recall:6.675, train kappa:9.787
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:0        valid loss:3.721200, valid acc:23.435, valid f1:1.577, valid precision:2.176, valid recall:2.014, valid kappa:6.661
None
====================================================================================================
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:0 train loss:3.640820, train acc:18.030, train f1:8.577, train precision:13.576, train recall:8.834, train kappa:11.623
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:1 train loss:3.556862, train acc:19.370, train f1:10.001, train precision:14.713, train recall:10.603, train kappa:13.377
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:2 train loss:3.493745, train acc:19.778, train f1:10.712, train precision:17.214, train recall:11.585, train kappa:14.372
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:3 train loss:3.397690, train acc:20.938, train f1:11.455, train precision:17.620, train recall:12.574, train kappa:15.783
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:4 train loss:3.323123, train acc:22.220, train f1:13.631, train precision:21.749, train recall:14.967, train kappa:17.586
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:5 train loss:3.278552, train acc:23.264, train f1:15.055, train precision:22.369, train recall:16.449, train kappa:18.988
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:6 train loss:3.179130, train acc:24.762, train f1:16.283, train precision:24.261, train recall:17.351, train kappa:20.597
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:7 train loss:3.098141, train acc:26.129, train f1:17.972, train precision:26.741, train recall:18.353, train kappa:21.994
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:8 train loss:3.035515, train acc:26.898, train f1:19.107, train precision:27.906, train recall:19.253, train kappa:22.787
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1 step:9 train loss:2.942949, train acc:28.185, train f1:20.671, train precision:28.205, train recall:20.574, train kappa:24.357
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:1        valid loss:4.295786, valid acc:11.191, valid f1:2.003, valid precision:2.757, valid recall:3.463, valid kappa:2.770
None
====================================================================================================
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:0 train loss:2.880242, train acc:29.449, train f1:22.083, train precision:32.086, train recall:21.952, train kappa:25.791
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:1 train loss:2.821658, train acc:30.774, train f1:24.087, train precision:31.046, train recall:24.154, train kappa:27.415
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:2 train loss:2.779475, train acc:31.274, train f1:25.107, train precision:32.891, train recall:24.879, train kappa:27.959
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:3 train loss:2.709152, train acc:32.950, train f1:26.965, train precision:35.181, train recall:27.297, train kappa:30.022
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:4 train loss:2.648727, train acc:34.067, train f1:28.567, train precision:33.537, train recall:29.087, train kappa:31.301
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:5 train loss:2.590033, train acc:35.342, train f1:30.400, train precision:37.101, train recall:30.285, train kappa:32.572
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:6 train loss:2.526505, train acc:37.024, train f1:32.018, train precision:39.067, train recall:31.722, train kappa:34.345
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:7 train loss:2.478296, train acc:37.555, train f1:32.575, train precision:39.476, train recall:32.629, train kappa:35.009
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:8 train loss:2.416729, train acc:39.102, train f1:34.899, train precision:41.460, train recall:34.889, train kappa:36.718
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2 step:9 train loss:2.348166, train acc:40.965, train f1:36.187, train precision:41.169, train recall:36.759, train kappa:38.736
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:0 epoch:2        valid loss:4.442113, valid acc:11.876, valid f1:3.017, valid precision:5.432, valid recall:4.823, valid kappa:0.667
[Fold 0] Best Score: [11.876445730446369, 3.016946939549173, 5.431642762737368, 4.822627950032726, 0.6671122269784058]
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:0 train loss:4.579557, train acc:1.672, train f1:0.889, train precision:1.101, train recall:1.159, train kappa:0.069
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:1 train loss:4.340489, train acc:7.687, train f1:1.217, train precision:1.811, train recall:2.025, train kappa:2.124
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:2 train loss:4.187631, train acc:10.822, train f1:1.401, train precision:1.980, train recall:2.644, train kappa:3.990
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:3 train loss:4.066753, train acc:11.926, train f1:2.128, train precision:4.203, train recall:3.299, train kappa:4.840
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:4 train loss:4.002012, train acc:12.778, train f1:3.175, train precision:4.937, train recall:4.278, train kappa:5.778
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:5 train loss:3.931703, train acc:13.629, train f1:3.443, train precision:6.613, train recall:4.311, train kappa:6.800
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:6 train loss:3.838094, train acc:15.057, train f1:4.760, train precision:7.787, train recall:5.656, train kappa:8.569
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:7 train loss:3.757753, train acc:15.381, train f1:5.776, train precision:12.449, train recall:6.532, train kappa:8.983
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:8 train loss:3.698867, train acc:16.641, train f1:6.358, train precision:9.956, train recall:7.373, train kappa:10.307
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0 step:9 train loss:3.588135, train acc:17.648, train f1:7.624, train precision:12.704, train recall:8.211, train kappa:11.510
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:0        valid loss:3.733651, valid acc:11.611, valid f1:1.221, valid precision:2.143, valid recall:1.918, valid kappa:1.985
None
====================================================================================================
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:0 train loss:3.542009, train acc:18.152, train f1:8.395, train precision:14.928, train recall:9.191, train kappa:12.212
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:1 train loss:3.464018, train acc:19.092, train f1:9.495, train precision:15.545, train recall:10.185, train kappa:13.483
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:2 train loss:3.400865, train acc:20.459, train f1:10.820, train precision:18.657, train recall:11.693, train kappa:15.015
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:3 train loss:3.293997, train acc:21.582, train f1:12.444, train precision:18.803, train recall:12.794, train kappa:16.616
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:4 train loss:3.222789, train acc:23.141, train f1:14.115, train precision:21.733, train recall:14.821, train kappa:18.454
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:5 train loss:3.139212, train acc:24.432, train f1:15.251, train precision:22.099, train recall:16.139, train kappa:20.079
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:6 train loss:3.061549, train acc:26.117, train f1:17.095, train precision:25.435, train recall:18.159, train kappa:22.098
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:7 train loss:3.006758, train acc:26.434, train f1:18.767, train precision:26.767, train recall:19.534, train kappa:22.759
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:8 train loss:2.919662, train acc:28.113, train f1:20.864, train precision:27.627, train recall:21.144, train kappa:24.586
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1 step:9 train loss:2.852085, train acc:29.729, train f1:23.351, train precision:31.362, train recall:23.199, train kappa:26.431
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:1        valid loss:4.080207, valid acc:5.709, valid f1:1.924, valid precision:3.047, valid recall:4.105, valid kappa:4.358
None
====================================================================================================
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:0 train loss:2.804569, train acc:30.368, train f1:24.280, train precision:31.506, train recall:24.131, train kappa:27.136
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:1 train loss:2.718213, train acc:31.604, train f1:25.956, train precision:32.542, train recall:25.759, train kappa:28.578
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:2 train loss:2.646204, train acc:34.302, train f1:28.773, train precision:34.983, train recall:28.631, train kappa:31.503
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:3 train loss:2.607368, train acc:34.906, train f1:29.540, train precision:37.444, train recall:29.473, train kappa:32.170
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:4 train loss:2.506804, train acc:37.250, train f1:31.817, train precision:37.764, train recall:32.198, train kappa:34.725
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:5 train loss:2.484527, train acc:37.973, train f1:33.192, train precision:39.117, train recall:33.383, train kappa:35.505
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:6 train loss:2.423896, train acc:39.099, train f1:34.925, train precision:40.851, train recall:34.957, train kappa:36.721
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:7 train loss:2.349894, train acc:40.701, train f1:36.431, train precision:42.340, train recall:36.138, train kappa:38.402
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:8 train loss:2.296791, train acc:41.458, train f1:37.686, train precision:43.857, train recall:37.962, train kappa:39.325
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2 step:9 train loss:2.281083, train acc:41.827, train f1:38.368, train precision:43.472, train recall:38.777, train kappa:39.728
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])
fold:1 epoch:2        valid loss:4.461369, valid acc:4.379, valid f1:3.318, valid precision:8.977, valid recall:8.733, valid kappa:3.225
[Fold 1] Best Score: [4.379490448983595, 3.3182887821848825, 8.977429264743627, 8.733175951004357, 3.225092089650128]
[1;31mFinal DDI result:[0m
acc: 8.128, f1: 3.168, precision: 7.205, recall: 6.778, kappa: 1.946
kg_emb.shape: torch.Size([98743, 300])
kg_emb.shape after fc: torch.Size([98743, 300])
mol_emb.shape before fc: torch.Size([1706, 300])
mol_emb.shape: torch.Size([1706, 300])

[1;34mInference result saved to: results/DrugBank_multi_class_concat_s1_20250630_194934.csv[0m
